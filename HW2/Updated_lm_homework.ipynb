{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Updated_lm_homework.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GDZSVhLr8BtP",
        "X1xV4hU28BuO",
        "_ODfcbzQ8BvG",
        "Ps3DtmuR8Bvo",
        "1RZK_pPW8Bvw",
        "ZtUgQcLw8Bv1",
        "EcC--G6w8Bv3",
        "SDAT-P2L8BwC",
        "O9OXVOFX8BwI",
        "Z8a_-xZz8BxG",
        "fHqB7SQ20O8y",
        "vx9TM9ui8BxQ",
        "7tUpJJzp8BxT",
        "Iat6XrhD8BxW",
        "ElfxRup68Bxc",
        "Vg6pBDZw0O9X",
        "Fd3bYBH78Bxl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2HCzN-nn8BsK"
      },
      "source": [
        "# DS-GA 1011 Homework 2\n",
        "## N-Gram and Neural Language Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tNWcR__B8d-i",
        "outputId": "44a1210a-6f1b-430e-9636-1d27e4e9504d",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install jsonlines\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcAb5_wQVc7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import hashlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0P3D72q38BsL",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import jsonlines\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import operator\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bZXhR1La8BsS"
      },
      "source": [
        "## I. N-Gram Language Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RyYA19ji8BsU"
      },
      "source": [
        "#### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4ZfFvEXa8BsW",
        "colab": {}
      },
      "source": [
        "def load_wikitext(filename='wikitext2-sentencized.json'):\n",
        "    if not os.path.exists(filename):\n",
        "        !wget \"https://nyu.box.com/shared/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\" -O $filename\n",
        "    \n",
        "    datasets = json.load(open(filename, 'r'))\n",
        "    for name in datasets:\n",
        "        datasets[name] = [x.split() for x in datasets[name]]\n",
        "    vocab = list(set([t for ts in datasets['train'] for t in ts]))      \n",
        "    print(\"Vocab size: %d\" % (len(vocab)))\n",
        "    return datasets, vocab\n",
        "\n",
        "def perplexity(model, sequences):\n",
        "    n_total = 0\n",
        "    logp_total = 0\n",
        "    for sequence in sequences:\n",
        "        logp_total += model.sequence_logp(sequence)\n",
        "        n_total += len(sequence) + 1  \n",
        "    ppl = 2 ** (- (1.0 / n_total) * logp_total)  \n",
        "    return ppl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V50F-WEd8Bsc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "5f8d3d65-5c53-4c75-d935-af4e1aeb4a3c"
      },
      "source": [
        "datasets, vocab = load_wikitext()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-09 11:45:14--  https://nyu.box.com/shared/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\n",
            "Resolving nyu.box.com (nyu.box.com)... 185.235.236.197\n",
            "Connecting to nyu.box.com (nyu.box.com)|185.235.236.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json [following]\n",
            "--2019-10-09 11:45:15--  https://nyu.box.com/public/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\n",
            "Reusing existing connection to nyu.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://nyu.app.box.com/public/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json [following]\n",
            "--2019-10-09 11:45:15--  https://nyu.app.box.com/public/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\n",
            "Resolving nyu.app.box.com (nyu.app.box.com)... 185.235.236.199\n",
            "Connecting to nyu.app.box.com (nyu.app.box.com)|185.235.236.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!7d9Ue2mgtWwIsUgrSE2k0UCSxhe7hLsJ4syTl-b7lifQ3sG6tJ4GaflLCMvf9TxOXoTs4TAI1_1zV8tF4NHBh_IzIQ0q8NSuQ0YkfBwxBLpd0B9lw95DI4LaepP--uLqqIiRtIq8msUy7ufm90DXwNy5ZRVp8QBjrm0E0wGpVH8iiuzVSZuJ9PHGUrTGRO_TZpELpta1mdM9Rhg7E60CdjHLmuu2kIguleE7lWhfwuiN_J3_Fu4tX4hADFUA1YNhVAJ8BKUbLB3NzJFpr5NiqwAxoe6Bhjd8Jnv7JxPQu4o3KExd1TV501_5QQ4HAVSapi54oR-21E8pSDoCpaaeH6ED3nEHQ8KvX2u2ut5HCzemcn3IcjhCfurEpHXiSRYD9DNE2gVnCjsCNTwRRxZKk6BkRF-am_BQJeJair83Qb37_I0tP4mbWqTj0rPOaPyzUjPsPzLS2s04a6KdMx1iOPRcMTy1L2SVRP8YyzeR2dRHvKDzex9tzVhBhez3V3R_5dk8kJMxCgwHZAuWOeDdVJPWhBEEbQyI9Ylk3Q9BPK7CrgN0r6XWqR7oyfPkQDnT5wR_7j8fM06Xb10IhvZtxPcXZgwkvaFv_5JKUFnMtD3mOYjveQnfLMsKnEM62eop9CWJlNvx8dsrjqL9WyPK6wV4xQJ4ripf9SeEmLUMmqPwhuTCixH6oR16OqsiROFIqvnJLTRGTOsqTvi4T_uv1XXfSkA4acNnoovPN1tP9GUFxBZNlPQsAcpRvGUoDSfqKFxRE2FNmOnP0xyjGpoaiw4L8rcKWaKEhTIHtCu0s-mdKPhvdF577cOPA7FaN64qC0UutZZzS7UXHxUgsKxilkPg-Dz67mLnJoGQ3xz66qNnKnqt1dvtwAfpfjZRjF_NRy-2-ZzOjnoXSfcqwTu7W_Tg_5qJ03ajRbOA6nf1akde9p2w6dQLukBtqttARiLieuBNtOZ5AJeQdLPa3q5IRSTNiNVkvdM65oYO_rzxCKe0R0PuqlOGrzdkqAYbpfci6mnzCm-u8BoHuMdMdL8J8LCowRW1YRDyIb7KOV5DIYVz7hi4QGHBr-EOTFHFmUWOzKLIU67MB9JlWIF8teSJMLzL_Z5VoIt_NTjclXLEuqNRsBjapA6sf_uOG8mDpjqPLmQ23wWAtQCkoCcgWF_QGasMl9nfBAggcaIWTsxu0smvxj_9XHYiOwhlm26EwEVuSeeh1aUE0BEZ6d6cywOdzlwMU3fVYisz-kk8zjwmlJIxJ291KHhqLgehYfjgfUE-NYJrvHrjKOBA5k1LQNZJW_ujKVl3su5KPkR8nWsu6AVim7S-IuU2sbPCIVjjlAt2qRxzLqr6i8a8rDVRQ_-9xRJVvyQLavVKlBGDxPj8ggA33QHWpHjWlqIBNwRg72pa9ZzYd9A-dkDdXg../download [following]\n",
            "--2019-10-09 11:45:15--  https://public.boxcloud.com/d/1/b1!7d9Ue2mgtWwIsUgrSE2k0UCSxhe7hLsJ4syTl-b7lifQ3sG6tJ4GaflLCMvf9TxOXoTs4TAI1_1zV8tF4NHBh_IzIQ0q8NSuQ0YkfBwxBLpd0B9lw95DI4LaepP--uLqqIiRtIq8msUy7ufm90DXwNy5ZRVp8QBjrm0E0wGpVH8iiuzVSZuJ9PHGUrTGRO_TZpELpta1mdM9Rhg7E60CdjHLmuu2kIguleE7lWhfwuiN_J3_Fu4tX4hADFUA1YNhVAJ8BKUbLB3NzJFpr5NiqwAxoe6Bhjd8Jnv7JxPQu4o3KExd1TV501_5QQ4HAVSapi54oR-21E8pSDoCpaaeH6ED3nEHQ8KvX2u2ut5HCzemcn3IcjhCfurEpHXiSRYD9DNE2gVnCjsCNTwRRxZKk6BkRF-am_BQJeJair83Qb37_I0tP4mbWqTj0rPOaPyzUjPsPzLS2s04a6KdMx1iOPRcMTy1L2SVRP8YyzeR2dRHvKDzex9tzVhBhez3V3R_5dk8kJMxCgwHZAuWOeDdVJPWhBEEbQyI9Ylk3Q9BPK7CrgN0r6XWqR7oyfPkQDnT5wR_7j8fM06Xb10IhvZtxPcXZgwkvaFv_5JKUFnMtD3mOYjveQnfLMsKnEM62eop9CWJlNvx8dsrjqL9WyPK6wV4xQJ4ripf9SeEmLUMmqPwhuTCixH6oR16OqsiROFIqvnJLTRGTOsqTvi4T_uv1XXfSkA4acNnoovPN1tP9GUFxBZNlPQsAcpRvGUoDSfqKFxRE2FNmOnP0xyjGpoaiw4L8rcKWaKEhTIHtCu0s-mdKPhvdF577cOPA7FaN64qC0UutZZzS7UXHxUgsKxilkPg-Dz67mLnJoGQ3xz66qNnKnqt1dvtwAfpfjZRjF_NRy-2-ZzOjnoXSfcqwTu7W_Tg_5qJ03ajRbOA6nf1akde9p2w6dQLukBtqttARiLieuBNtOZ5AJeQdLPa3q5IRSTNiNVkvdM65oYO_rzxCKe0R0PuqlOGrzdkqAYbpfci6mnzCm-u8BoHuMdMdL8J8LCowRW1YRDyIb7KOV5DIYVz7hi4QGHBr-EOTFHFmUWOzKLIU67MB9JlWIF8teSJMLzL_Z5VoIt_NTjclXLEuqNRsBjapA6sf_uOG8mDpjqPLmQ23wWAtQCkoCcgWF_QGasMl9nfBAggcaIWTsxu0smvxj_9XHYiOwhlm26EwEVuSeeh1aUE0BEZ6d6cywOdzlwMU3fVYisz-kk8zjwmlJIxJ291KHhqLgehYfjgfUE-NYJrvHrjKOBA5k1LQNZJW_ujKVl3su5KPkR8nWsu6AVim7S-IuU2sbPCIVjjlAt2qRxzLqr6i8a8rDVRQ_-9xRJVvyQLavVKlBGDxPj8ggA33QHWpHjWlqIBNwRg72pa9ZzYd9A-dkDdXg../download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 185.235.236.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|185.235.236.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12714601 (12M) [application/octet-stream]\n",
            "Saving to: ‘wikitext2-sentencized.json’\n",
            "\n",
            "wikitext2-sentenciz 100%[===================>]  12.12M  8.03MB/s    in 1.5s    \n",
            "\n",
            "2019-10-09 11:45:18 (8.03 MB/s) - ‘wikitext2-sentencized.json’ saved [12714601/12714601]\n",
            "\n",
            "Vocab size: 33175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zeJp7NFs8Bsk"
      },
      "source": [
        "### Additive Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "820qKy6U8Bsm",
        "colab": {}
      },
      "source": [
        "class NGramAdditive(object):\n",
        "    def __init__(self, n, delta, vsize):\n",
        "        self.n = n\n",
        "        self.delta = delta\n",
        "        self.count = defaultdict(lambda: defaultdict(float))\n",
        "        self.total = defaultdict(float)\n",
        "        self.vsize = vsize\n",
        "    \n",
        "    def estimate(self, sequences):\n",
        "        for sequence in sequences:\n",
        "            padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
        "            for i in range(len(padded_sequence) - self.n+1):\n",
        "                ngram = tuple(padded_sequence[i:i+self.n])\n",
        "                prefix, word = ngram[:-1], ngram[-1]\n",
        "                self.count[prefix][word] += 1\n",
        "                self.total[prefix] += 1\n",
        "                \n",
        "    def sequence_logp(self, sequence):\n",
        "        padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
        "        total_logp = 0\n",
        "        for i in range(len(padded_sequence) - self.n+1):\n",
        "            ngram = tuple(padded_sequence[i:i+self.n])\n",
        "            total_logp += np.log2(self.ngram_prob(ngram))\n",
        "        return total_logp\n",
        "\n",
        "    def ngram_prob(self, ngram):\n",
        "        prefix = ngram[:-1]\n",
        "        word = ngram[-1]\n",
        "        prob = ((self.delta + self.count[prefix][word]) / \n",
        "                (self.total[prefix] + self.delta*self.vsize))\n",
        "        return prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dlaXszzj8Bsq",
        "colab": {}
      },
      "source": [
        "# delta = 0.0005\n",
        "# for n in [2, 3, 4]:\n",
        "#     lm = NGramAdditive(n=n, delta=delta, vsize=len(vocab)+1)  # +1 is for <eos>\n",
        "#     lm.estimate(datasets['train'])\n",
        "\n",
        "#     print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Train Perplexity: %.3f\" % (n, delta, perplexity(lm, datasets['train'])))\n",
        "#     print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Valid Perplexity: %.3f\" % (n, delta, perplexity(lm, datasets['valid'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_7cWyvDm8BtA"
      },
      "source": [
        "### I.1 Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5imstdWS8BtB",
        "colab": {}
      },
      "source": [
        "class NGramInterpolation(object):\n",
        "    def __init__(self, n, lamb_list, vsize):\n",
        "        # lamb_list should be a list containing all lambda values for interpolation\n",
        "        self.n = n\n",
        "        self.count = defaultdict(lambda: defaultdict(float))\n",
        "        self.total = defaultdict(float)\n",
        "        self.vsize = vsize\n",
        "        self.word_count = defaultdict(float) # Count of every word\n",
        "        self.length = 0 # The total length of the dataset\n",
        "        \n",
        "        # Check if lambda fulfill our conditions\n",
        "        if len(lamb_list) != n + 1:\n",
        "            raise ValueError(\"Lambda list must have length n + 1\")\n",
        "        elif np.abs(np.sum(lamb_list) - 1) > 0.00001:\n",
        "            raise ValueError(\"Sum of lambdas must be 1\")\n",
        "        self.lamb_list = lamb_list\n",
        "\n",
        "    def estimate(self, sequences):\n",
        "        for sequence in sequences:\n",
        "            for w in sequence:\n",
        "                self.word_count[w] += 1\n",
        "                self.length += 1\n",
        "            for current_n in range(2, self.n + 1):\n",
        "                padded_sequence = ['<bos>']*(current_n-1) + sequence + ['<eos>']\n",
        "                for i in range(len(padded_sequence) - current_n+1):\n",
        "                    ngram = tuple(padded_sequence[i:i+current_n])\n",
        "                    prefix, word = ngram[:-1], ngram[-1]\n",
        "                    self.count[prefix][word] += 1\n",
        "                    self.total[prefix] += 1\n",
        "\n",
        "    def sequence_logp(self, sequence):\n",
        "        padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
        "        total_logp = 0\n",
        "        for i in range(len(padded_sequence) - self.n+1):\n",
        "            ngram = tuple(padded_sequence[i:i+self.n])\n",
        "            total_logp += np.log2(self.ngram_prob(lamb_list[-1], ngram, self.n))\n",
        "        return total_logp\n",
        "    \n",
        "    def ngram_prob(self, lamb, ngram, order):\n",
        "        \"\"\"\n",
        "        lamb: a single value from the lambda list\n",
        "        order: means which index of lambda we are talking about, max and initial\n",
        "            order should be n\n",
        "        \"\"\"\n",
        "        \n",
        "        if order > n:\n",
        "            raise ValueError(\"Order can't exceed n\")\n",
        "        elif order == 0:\n",
        "            return lamb * (1 / self.vsize) # Since p_0 = 1 / |vocab|\n",
        "        elif order >= 1:\n",
        "            prefix = ngram[:-1]\n",
        "            word = ngram[-1]\n",
        "            if prefix: # Check if prefix is empty\n",
        "                if self.total[prefix] == 0:\n",
        "                    prob = 0\n",
        "                else:\n",
        "                    prob = self.count[prefix][word] / self.total[prefix]\n",
        "            else: # If prefix is empty, we are in lambda_1\n",
        "                prob = self.word_count[word] / self.length\n",
        "            \n",
        "            return lamb * prob + self.ngram_prob(self.lamb_list[order], \n",
        "                                                 ngram[1:], order - 1)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NwE6KP0P8BtF"
      },
      "source": [
        "#### Results (showing $\\lambda_0,\\ldots,\\lambda_n$ values):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tj8Z2ly_8BtG",
        "outputId": "a8d7fe50-41d5-40ff-b778-3678dacb8f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for n in [2, 3, 4]:\n",
        "    if n == 2:\n",
        "        lamb_list = [0.3, 0.3, 0.4]\n",
        "    elif n == 3:\n",
        "        lamb_list = [0.2, 0.2, 0.3, 0.3]\n",
        "    else:\n",
        "        lamb_list = [0.05, 0.15, 0.2, 0.3, 0.3]\n",
        "    interp = NGramInterpolation(n=n, lamb_list = lamb_list, vsize=len(vocab)+1)  # +1 is for <eos>\n",
        "    interp.estimate(datasets['train'])\n",
        "\n",
        "    print(f\"Interpolation model, n = {n}, lambda = {lamb_list}, Train Perplexity = {perplexity(interp, datasets['train'])}\")\n",
        "    print(f\"Interpolation model, n = {n}, lambda = {lamb_list}, Validation Perplexity = {perplexity(interp, datasets['valid'])}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Interpolation model, n = 2, lambda = [0.3, 0.3, 0.4], Train Perplexity = 150.5889382820586\n",
            "Interpolation model, n = 2, lambda = [0.3, 0.3, 0.4], Validation Perplexity = 340.41001196504266\n",
            "Interpolation model, n = 3, lambda = [0.2, 0.2, 0.3, 0.3], Train Perplexity = 19.476557684727467\n",
            "Interpolation model, n = 3, lambda = [0.2, 0.2, 0.3, 0.3], Validation Perplexity = 283.3942638303449\n",
            "Interpolation model, n = 4, lambda = [0.05, 0.15, 0.2, 0.3, 0.3], Train Perplexity = 4.706373565940121\n",
            "Interpolation model, n = 4, lambda = [0.05, 0.15, 0.2, 0.3, 0.3], Validation Perplexity = 281.6049590165684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gXP7CFYG0tC9"
      },
      "source": [
        "The $\\lambda$ values we chose for bi-gram are [0.3, 0.3, 0.4], tri-gram are [0.2, 0.2, 0.3, 0.3], 4-gram are [0.05, 0.15, 0.2, 0.3, 0.3], we could see that both train and validation perplexity are decreasing with the increase of the $n$. And the results are significantly better than the base case model (although notice that the base case model has a better training perplexity for 2-gram)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2w1966f00y-H"
      },
      "source": [
        "### I.3. Kneser-Ney Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xpWmh1Pi01vl",
        "colab": {}
      },
      "source": [
        "class new_KN_Smoothing(object):\n",
        "    def __init__(self, n, vsize):\n",
        "        self.n = n\n",
        "        self.vsize = vsize\n",
        "        self.count = defaultdict(lambda: defaultdict(float))\n",
        "        self.total = defaultdict(float)\n",
        "        self.word_count = defaultdict(float) # Count of every word\n",
        "        self.length = 0 # The total length of the dataset\n",
        "        self.discounting_dict = defaultdict(lambda: defaultdict(float))\n",
        "        # N_l dict has N1,N2,N3+ values for every possible prefix\n",
        "        self.N_l = defaultdict(list)\n",
        "\n",
        "    def estimate(self, sequences):\n",
        "        for which_gram in range(2, self.n + 1):\n",
        "            n_dict = defaultdict(int) # Changed n_dict\n",
        "            count = 0\n",
        "            for sequence in sequences:\n",
        "                for w in sequence:\n",
        "                    self.word_count[w] += 1\n",
        "                    self.length += 1\n",
        "                padded_sequence = ['<bos>']*(which_gram-1) + sequence + ['<eos>']\n",
        "                for i in range(len(padded_sequence) - which_gram+1):\n",
        "                    ngram = tuple(padded_sequence[i:i+which_gram])\n",
        "                    prefix, word = ngram[:-1], ngram[-1]\n",
        "                    self.count[prefix][word] += 1\n",
        "                    self.total[prefix] += 1\n",
        "                    # Find n_k which is the number of ngram that happens exactly\n",
        "                    # k times, we only consder k = 1, 2, and 3+\n",
        "                    found = False\n",
        "                    if n_dict[ngram] <= 4: \n",
        "                        n_dict[ngram] += 1\n",
        "                count += 1\n",
        "                if count % 30000 == 0:\n",
        "                    print(f\"{count} sequence process finished for {which_gram}-gram\")\n",
        "            n_values = defaultdict(int)\n",
        "            for key, value in sorted(n_dict.items()):\n",
        "                n_values[value] += 1\n",
        "            \n",
        "            # Calculating Y\n",
        "            Y = n_values[1] / (n_values[1] + 2 * n_values[2])\n",
        "            # Calculating discouting factors for this level of gram\n",
        "            D_list = [0]\n",
        "            for i in range(1, 4):\n",
        "                D_i = i - (i+1) * Y * n_values[i + 1] / n_values[i]\n",
        "                if D_i < 0:\n",
        "                    print(D_i)\n",
        "                D_list.append(D_i)\n",
        "            self.discounting_dict[which_gram] = D_list\n",
        "\n",
        "            print(f\"discouting factors for {which_gram}-gram calculated\")\n",
        "                    \n",
        "        # Now we use self.count to derive self.N_l\n",
        "        for prefix in self.total:\n",
        "            N_1, N_2, N_3 = 0, 0, 0\n",
        "            for word in self.count[prefix]:\n",
        "                if self.count[prefix][word] == 1:\n",
        "                    N_1 += 1\n",
        "                elif self.count[prefix][word] == 2:\n",
        "                    N_2 += 1\n",
        "                else:\n",
        "                    N_3 += 1\n",
        "            self.N_l[prefix] = [N_1, N_2, N_3]\n",
        "        print(\"Training finished\")\n",
        "\n",
        "    def sequence_logp(self, sequence):\n",
        "        padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
        "        total_logp = 0\n",
        "        for i in range(len(padded_sequence) - self.n+1):\n",
        "            ngram = tuple(padded_sequence[i:i+self.n])\n",
        "            result = self.ngram_prob(ngram, self.n)\n",
        "            total_logp += np.log2(self.ngram_prob(ngram, self.n))\n",
        "        return total_logp\n",
        "    \n",
        "    def alpha(self, prefix, word, order):\n",
        "        if prefix not in self.N_l:\n",
        "            return 1 / self.vsize\n",
        "        else:\n",
        "            if len(prefix) == 0:\n",
        "                count = self.word_count[word]\n",
        "                if count >= 3:\n",
        "                    D_index = 3\n",
        "                else:\n",
        "                    D_index = int(count)\n",
        "                return np.max(count - self.discounting_dict[order][D_index], 0) / self.length\n",
        "            else:\n",
        "                count = self.count[prefix][word]\n",
        "                if count >= 3:\n",
        "                    D_index = 3\n",
        "                else:\n",
        "                    D_index = int(count)\n",
        "                return np.max(count - self.discounting_dict[order][D_index], 0) / self.total[prefix]\n",
        "    \n",
        "    def gamma(self, prefix, word, order):\n",
        "        if prefix not in self.N_l:\n",
        "            return 1 #/ self.vsize\n",
        "        else:\n",
        "            numerator = 0\n",
        "            for i in range(1, 4):\n",
        "                numerator += self.discounting_dict[order][i] * self.N_l[prefix][i - 1]\n",
        "            return numerator / self.total[prefix]\n",
        "            \n",
        "    \n",
        "    def ngram_prob(self, ngram, order):\n",
        "        \"\"\"\n",
        "        ngram: the n gram we are considering\n",
        "        order: means which gram we are doing, e.g., bi-gram, tri-gram...\n",
        "        \"\"\"\n",
        "\n",
        "        if order == 1:\n",
        "            prefix = ngram[:-1]\n",
        "            word = ngram[-1]\n",
        "            return self.alpha(prefix, word, order) + 1 / self.vsize\n",
        "        else:\n",
        "            prefix = ngram[:-1]\n",
        "            word = ngram[-1]\n",
        "            return self.alpha(prefix, word, order) + self.gamma(prefix, word, order) * self.ngram_prob(ngram[1:], order - 1)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YhE1umwK1CUs",
        "outputId": "de5c8ed1-fbec-4f78-cf5e-071f3f40a914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Result\n",
        "for n in [2, 3, 4]:\n",
        "\n",
        "    kn_smooth = new_KN_Smoothing(n = n, vsize=len(vocab)+1)\n",
        "    kn_smooth.estimate(datasets['train'])\n",
        "\n",
        "    print(f\"Kneser-Ney smoothing model, n = {n}, Train Perplexity = {perplexity(kn_smooth, datasets['train'])}\")\n",
        "    print(f\"Kneser-Ney smoothing model, n = {n}, Validation Perplexity = {perplexity(kn_smooth, datasets['valid'])}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000 sequence process finished for 2-gram\n",
            "60000 sequence process finished for 2-gram\n",
            "discouting factors for 2-gram calculated\n",
            "Training finished\n",
            "Kneser-Ney smoothing model, n = 2, Train Perplexity = 111.3616559603293\n",
            "Kneser-Ney smoothing model, n = 2, Validation Perplexity = 332.9237850930038\n",
            "30000 sequence process finished for 2-gram\n",
            "60000 sequence process finished for 2-gram\n",
            "discouting factors for 2-gram calculated\n",
            "30000 sequence process finished for 3-gram\n",
            "60000 sequence process finished for 3-gram\n",
            "discouting factors for 3-gram calculated\n",
            "Training finished\n",
            "Kneser-Ney smoothing model, n = 3, Train Perplexity = 19.967979699460248\n",
            "Kneser-Ney smoothing model, n = 3, Validation Perplexity = 274.9963223589329\n",
            "30000 sequence process finished for 2-gram\n",
            "60000 sequence process finished for 2-gram\n",
            "discouting factors for 2-gram calculated\n",
            "30000 sequence process finished for 3-gram\n",
            "60000 sequence process finished for 3-gram\n",
            "discouting factors for 3-gram calculated\n",
            "30000 sequence process finished for 4-gram\n",
            "60000 sequence process finished for 4-gram\n",
            "discouting factors for 4-gram calculated\n",
            "Training finished\n",
            "Kneser-Ney smoothing model, n = 4, Train Perplexity = 8.457330995199234\n",
            "Kneser-Ney smoothing model, n = 4, Validation Perplexity = 239.54563118305083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TaUVqQel1Jfr"
      },
      "source": [
        "####By using Kneser-Ney Smoothing, we reached even better validation perplexity results compared with the interpolation model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tXlT_7WV8BtK"
      },
      "source": [
        "## II. Neural Language Modeling with a Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f59E088X8BtM",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, RandomSampler, SequentialSampler,DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GDZSVhLr8BtP"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXP5LO2P8BtQ",
        "colab": {}
      },
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self, datasets, include_valid=False):\n",
        "        self.tokens = []\n",
        "        self.ids = {}\n",
        "        self.counts = {}\n",
        "        \n",
        "        # add special tokens\n",
        "        self.add_token('<bos>')\n",
        "        self.add_token('<eos>')\n",
        "        self.add_token('<pad>')\n",
        "        self.add_token('<unk>') # validation token is not seen in the training dataset\n",
        "                                # <unk> is in the original training dataset. \n",
        "        \n",
        "        for line in tqdm(datasets['train']):\n",
        "            for w in line:\n",
        "                self.add_token(w)\n",
        "                    \n",
        "        if include_valid is True:\n",
        "            for line in tqdm(datasets['valid']):\n",
        "                for w in line:\n",
        "                    self.add_token(w)\n",
        "                            \n",
        "    def add_token(self, w):\n",
        "        if w not in self.tokens:\n",
        "            self.tokens.append(w)\n",
        "            _w_id = len(self.tokens) - 1\n",
        "            self.ids[w] = _w_id\n",
        "            self.counts[w] = 1\n",
        "        else:\n",
        "            self.counts[w] += 1\n",
        "\n",
        "    def get_id(self, w):\n",
        "        return self.ids[w]\n",
        "    \n",
        "    def get_token(self, idx):\n",
        "        return self.tokens[idx]\n",
        "    \n",
        "    def decode_idx_seq(self, l):\n",
        "        return [self.tokens[i] for i in l]\n",
        "    \n",
        "    def encode_token_seq(self, l):\n",
        "        return [self.ids[i] if i in self.ids else self.ids['<unk>'] for i in l]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PkqJe4HI8BtU",
        "outputId": "adb1e084-1917-471c-9149-f9103cfcc285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "train_dict=Dictionary(datasets) # excluding validation dataset #109\n",
        "#all_dict=Dictionary(datasets, include_valid = True)\n",
        "\n",
        "# example\n",
        "rand_int = np.random.randint(1, len(datasets['valid']))\n",
        "print(' '.join(datasets['valid'][rand_int]))\n",
        "encoded = train_dict.encode_token_seq(datasets['valid'][rand_int])\n",
        "print(f'\\n encoded - {encoded}')\n",
        "decoded = train_dict.decode_idx_seq(encoded)\n",
        "print(f'\\n decoded - {decoded}')\n",
        "\n",
        "# checking\n",
        "print('length of train_dict is ', len(train_dict)) # that's because <unk> is already in the dataset \n",
        "print('unique words in training dataset is ', len(vocab))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78274/78274 [02:18<00:00, 563.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The highway was routed through Ferry , <unk> and <unk> , replacing M @-@ 41 .\n",
            "\n",
            " encoded - [75, 3563, 118, 18430, 173, 16178, 10, 3, 30, 3, 10, 8105, 1217, 23, 3763, 39]\n",
            "\n",
            " decoded - ['The', 'highway', 'was', 'routed', 'through', 'Ferry', ',', '<unk>', 'and', '<unk>', ',', 'replacing', 'M', '@-@', '41', '.']\n",
            "length of train_dict is  33178\n",
            "unique words in training dataset is  33175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhkIjBnj8BtZ",
        "colab": {}
      },
      "source": [
        "# given the dictionary from above, now write a function that tokenize the all datasets into id's\n",
        "def tokenize_dataset(datasets, dictionary, ngram_order=2):\n",
        "    tokenized_datasets = {}\n",
        "    for split, dataset in datasets.items():\n",
        "        _current_dictified = []\n",
        "        for l in tqdm(dataset):\n",
        "            l = ['<bos>']*(ngram_order-1) + l + ['<eos>']\n",
        "            encoded_l = dictionary.encode_token_seq(l)\n",
        "            _current_dictified.append(encoded_l)\n",
        "        tokenized_datasets[split] = _current_dictified\n",
        "        \n",
        "    return tokenized_datasets\n",
        "\n",
        "# Given a tokenzied dataset with ngram defined, slice the input sequences into n-grams \n",
        "# [0,1,2,3,4,5], 2 -> [0,1], [1,2], [2,3], [3,4], [4,5]\n",
        "def slice_sequences_given_order(tokenized_dataset_with_spec, ngram_order=2):\n",
        "    sliced_datasets = {}\n",
        "    for split, dataset in tokenized_dataset_with_spec.items():\n",
        "        _list_of_sliced_ngrams = []\n",
        "        for seq in tqdm(dataset):\n",
        "            ngrams = [seq[i:i+ngram_order] for i in range(len(seq)-ngram_order+1)]\n",
        "            _list_of_sliced_ngrams.extend(ngrams)\n",
        "        sliced_datasets[split] = _list_of_sliced_ngrams\n",
        "\n",
        "    return sliced_datasets\n",
        "\n",
        "# # Now we create a dataset\n",
        "class NgramDataset(Dataset):\n",
        "    def __init__(self, sliced_dataset_split):\n",
        "        super().__init__()\n",
        "\n",
        "        # for each sample: [:-1] is input, [-1] is target\n",
        "        self.sequences = [torch.tensor(i, dtype=torch.long) for i in sliced_dataset_split]\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        sample = self.sequences[i]\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "def batchify(list_minibatch):\n",
        "    inp_list = [i[:-1] for i in list_minibatch]\n",
        "    tar_list = [i[-1] for i in list_minibatch]\n",
        "\n",
        "    inp_tensor = torch.stack(inp_list, dim=0) # list of tensors and create a new tensor a u-dimension specified by dim\n",
        "    tar_tensor = torch.stack(tar_list, dim=0)\n",
        "    # cat: take a list of tensors and use existing dimension to concatent. Cannot create a new u-dimension speicfied. \n",
        "\n",
        "    return inp_tensor, tar_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WY8VffsL8Btg",
        "outputId": "4694fb1a-59f3-4989-d632-5bccbc253588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#  returns dictionary of three items with 'train', 'valid' and 'test' with lists of token ids \n",
        "tokenized_ngram = tokenize_dataset(datasets, train_dict, ngram_order=2)\n",
        "\n",
        "# returns dictionary of three items, each item is a list of sliced n-grams\n",
        "sliced_ngram = slice_sequences_given_order(tokenized_ngram, ngram_order=2)\n",
        "\n",
        "# check that the sentence is encoded with (n-1)<bos> and can be decoded back to tokens \n",
        "decoded_with_spec = train_dict.decode_idx_seq(tokenized_ngram['train'][3010])\n",
        "print(f'\\n decoded with spec - {decoded_with_spec}')\n",
        "\n",
        "ngram_datasets = {}\n",
        "ngram_loaders = {}\n",
        "for split, dataset_sliced in sliced_ngram.items():\n",
        "    if split == 'train':\n",
        "        shuffle_ = True\n",
        "    else:\n",
        "        shuffle_ = False\n",
        "    dataset_ = NgramDataset(dataset_sliced)\n",
        "    ngram_datasets[split] = dataset_\n",
        "    ngram_loaders[split] = DataLoader(dataset_, batch_size=2048, shuffle=shuffle_, collate_fn=batchify)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78274/78274 [00:00<00:00, 82386.40it/s]\n",
            "100%|██████████| 8464/8464 [00:00<00:00, 104356.10it/s]\n",
            "100%|██████████| 9708/9708 [00:00<00:00, 110281.95it/s]\n",
            "100%|██████████| 78274/78274 [00:02<00:00, 27421.82it/s]\n",
            "100%|██████████| 8464/8464 [00:00<00:00, 15732.38it/s]\n",
            "100%|██████████| 9708/9708 [00:00<00:00, 137425.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " decoded with spec - ['<bos>', 'The', 'Nataraja', 'and', 'Ardhanarishvara', 'sculptures', 'are', 'also', 'attributed', 'to', 'the', 'Rashtrakutas', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bu1jlFox8Btk",
        "outputId": "fb5e7898-e4d2-4397-e554-7c06f4a928ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('The length of original training dataset is: ', len(datasets['train']))\n",
        "print('The length of tokenzied training dataset is: ', len(tokenized_ngram['train']))\n",
        "print('Slided_ngram for training dataset now has length of ', len(sliced_ngram['train']))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of original training dataset is:  78274\n",
            "The length of tokenzied training dataset is:  78274\n",
            "Slided_ngram for training dataset now has length of  2003028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LzJBw4I88Bto",
        "outputId": "550e3742-63ec-4e03-ea7f-b243e06cba37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(tokenized_ngram['valid'][10])\n",
        "print(train_dict.decode_idx_seq(tokenized_ngram['valid'][10]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 504, 1506, 7106, 741, 459, 20, 140, 98, 432, 19366, 10, 150, 15605, 13, 260, 3748, 955, 1826, 1384, 1145, 98, 1722, 4303, 39, 1]\n",
            "['<bos>', 'This', 'may', 'occur', 'several', 'times', 'a', 'year', 'for', 'young', 'lobsters', ',', 'but', 'decreases', 'to', 'once', 'every', '1', '–', '2', 'years', 'for', 'larger', 'animals', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSWY6ayI8Bt_",
        "colab": {}
      },
      "source": [
        "class TensoredDataset(Dataset):\n",
        "    def __init__(self, list_of_lists_of_tokens):\n",
        "        self.input_tensors = []\n",
        "        self.target_tensors = []\n",
        "        \n",
        "        for sample in list_of_lists_of_tokens:\n",
        "            self.input_tensors.append(torch.tensor([sample[:-1]], dtype=torch.long))\n",
        "            self.target_tensors.append(torch.tensor([sample[1:]], dtype=torch.long))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # return a (input, target) tuple\n",
        "        return (self.input_tensors[idx], self.target_tensors[idx])\n",
        "    \n",
        "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
        "    max_length = max([t.size(-1) for t in list_of_tensors]) # t.size(-1) changes the type from torch.Size to int.\n",
        "    padded_list = []\n",
        "    \n",
        "    for t in list_of_tensors:  # dim = 0: cat on row, dim = 1: add on column \n",
        "        padded_tensor = torch.cat([t, torch.tensor([[pad_token]*(max_length - t.size(-1))], dtype=torch.long)], dim = -1)\n",
        "        padded_list.append(padded_tensor)\n",
        "        \n",
        "    padded_tensor = torch.cat(padded_list, dim=0)\n",
        "    \n",
        "    return padded_tensor\n",
        "\n",
        "def pad_collate_fn(batch):\n",
        "    # batch is a list of sample tuples\n",
        "    input_list = [s[0] for s in batch]\n",
        "    target_list = [s[1] for s in batch]\n",
        "    \n",
        "    #pad_token = persona_dict.get_id('<pad>')\n",
        "    pad_token = 2\n",
        "    \n",
        "    input_tensor = pad_list_of_tensors(input_list, pad_token)\n",
        "    target_tensor = pad_list_of_tensors(target_list, pad_token)\n",
        "    \n",
        "    return input_tensor, target_tensor\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NM1MWdTo8BuD",
        "outputId": "ba83714f-a405-4554-c69e-8e756e671387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tensor_dataset = {}\n",
        "\n",
        "# split: train, valid, test\n",
        "for split, listoflists in tokenized_ngram.items():\n",
        "    tensor_dataset[split] = TensoredDataset(listoflists)\n",
        "    \n",
        "# check the first example\n",
        "tensor_dataset['train'][24]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  0, 282,  13, 283, 181, 194, 195, 284,  13,  20, 285, 286,  39]]),\n",
              " tensor([[282,  13, 283, 181, 194, 195, 284,  13,  20, 285, 286,  39,   1]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jRvBF-uB8BuI",
        "colab": {}
      },
      "source": [
        "\n",
        "loaders = {}\n",
        "batch_size = 32\n",
        "for split, dataset in tensor_dataset.items():\n",
        "    loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle = True, collate_fn=pad_collate_fn)\n",
        "    \n",
        "# Shuffle = TRUE this loader because we don't use loader for validating and testing. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X1xV4hU28BuO"
      },
      "source": [
        "### Baseline Model: RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wlERvjpg8BuQ",
        "colab": {}
      },
      "source": [
        "from torch.nn import RNNBase, RNN\n",
        "from torch.nn import Embedding\n",
        "from torch.nn import Linear, functional\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VZvqpivh8Buu",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNNLanguageModel(nn.Module):\n",
        "    \"\"\"\n",
        "    This model combines embedding, rnn and projection layer into a single model\n",
        "    \"\"\"\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        # create each LM part here \n",
        "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
        "        # before nn.RNN is hidden\n",
        "        # Now: you do lookup table, and returns the tensors of sequence. No need of concat, becuase RNN naturally takes care of this\n",
        "        # RNN natrually takes multi sentence inputs and outputs hidden_size \n",
        "        self.rnn = nn.RNN(options['input_size'], options['hidden_size'], options['num_layers'], dropout=options['rnn_dropout'], batch_first=True)\n",
        "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
        "        \n",
        "    def forward(self, encoded_input_sequence):\n",
        "        \"\"\"\n",
        "        Forward method process the input from token ids to logits\n",
        "        \"\"\"\n",
        "        embeddings = self.lookup(encoded_input_sequence)\n",
        "        rnn_outputs = self.rnn(embeddings)\n",
        "        # project of outputs \n",
        "        # rnn_outputs: tuple with second element being last hidden state. \n",
        "        logits = self.projection(rnn_outputs[0])\n",
        "        \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YKYJzsLto6K2",
        "colab": {}
      },
      "source": [
        "# check\n",
        "# define lookup, rnn, and projection\n",
        "# lookup table: stores embeddings of a fixed dictionary and size.\n",
        "lookup = nn.Embedding(num_embeddings=options['num_embeddings'], \n",
        "                      embedding_dim=options['embedding_dim'], \n",
        "                      padding_idx=options['padding_idx'])\n",
        "\n",
        "# before nn.RNN is hidden\n",
        "# Now: you do lookup table, and returns the tensors of sequence. No need of concat, becuase RNN naturally takes care of this\n",
        "# RNN natrually takes multi sentence inputs and outputs hidden_size \n",
        "rnn = nn.RNN(options['input_size'], options['hidden_size'], \n",
        "             options['num_layers'], dropout=options['rnn_dropout'], \n",
        "             batch_first=True)\n",
        "# input_size == embedding_dimension\n",
        "projection = nn.Linear(options['hidden_size'], options['num_embeddings'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QsYq0aW18Bux",
        "colab": {}
      },
      "source": [
        "load_pretrained = False\n",
        "\n",
        "num_gpus = torch.cuda.device_count()\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "if load_pretrained:\n",
        "    if not os.path.exists('personachat_rnn_lm.pt'):\n",
        "        raise EOFError('Download pretrained model!')\n",
        "    model_dict = torch.load('personachat_rnn_lm.pt') # change the model name\n",
        "    \n",
        "    options = model_dict['options']\n",
        "    model = RNNLanguageModel(options).to(current_device)\n",
        "    model.load_state_dict(model_dict['model_dict'])\n",
        "    \n",
        "else:\n",
        "    embedding_size = 64\n",
        "    hidden_size = 128 # output of dimension \n",
        "    num_layers = 2\n",
        "    rnn_dropout = 0.1\n",
        "    input_size = lookup.weight.size(1) # embedding_dim\n",
        "    vocab_size = lookup.weight.size(0) # num_embeddings\n",
        "    \n",
        "    options = {\n",
        "        'num_embeddings': len(train_dict),\n",
        "        'embedding_dim': embedding_size,\n",
        "        'padding_idx': train_dict.get_id('<pad>'),\n",
        "        'input_size': embedding_size,\n",
        "        'hidden_size': hidden_size,\n",
        "        'num_layers': num_layers,\n",
        "        'rnn_dropout': rnn_dropout,\n",
        "        'bias': True,\n",
        "        'bid': False \n",
        "    }\n",
        "    \n",
        "    model = RNNLanguageModel(options).to(current_device)\n",
        "\n",
        "# same as previous nn based \n",
        "criterion = nn.CrossEntropyLoss(ignore_index=train_dict.get_id('<pad>'))\n",
        "\n",
        "# change the type from generator to list \n",
        "model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.Adam(model_parameters, lr=0.001)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "giDfRLtCAmOS",
        "outputId": "6e08be23-3296-4e5a-cd75-2bcfef3a08e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lookup # embedding_size, embedding_dim"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(33178, 64, padding_idx=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u6sdjrdxAqcB",
        "outputId": "1d14106d-c48f-47cb-ee53-ff32108edd76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rnn # embedding_dim, hidden_size"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(64, 128, num_layers=2, batch_first=True, dropout=0.1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVpIUfUeAdug",
        "outputId": "9c58ad0c-5df6-412c-a824-83ea9f10d68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "projection \n",
        "# in_features – size of each input sample = hidden_size\n",
        "# out_features – size of each output sample = number of possible next token\n",
        "# bias – If set to False, the layer will not learn an additive bias. Default: True"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=128, out_features=33178, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YGnsOgMI8Bu0",
        "outputId": "cc8c1bbe-8804-4039-943a-01ef213b1bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# check model\n",
        "model"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (lookup): Embedding(33178, 64, padding_idx=2)\n",
              "  (rnn): RNN(64, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=128, out_features=33178, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TOgwouSJ8Bu9",
        "outputId": "2dc086ea-937d-4d11-c1b6-902b0d37a19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "\n",
        "plot_cache = []\n",
        "\n",
        "for epoch_number in range(100):\n",
        "    avg_loss=0\n",
        "    if not load_pretrained:\n",
        "        model.train()\n",
        "        train_log_cache = []\n",
        "        for i, (inp, target) in enumerate(loaders['train']):\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "            \n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_log_cache.append(loss.item())\n",
        "            \n",
        "            if i % 100 == 0:\n",
        "                avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
        "                print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
        "                train_log_cache = []\n",
        "            \n",
        "    #do valid\n",
        "    valid_losses = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(loaders['valid']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            valid_losses.append(loss.item())\n",
        "        avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
        "        print('Validation loss after {} epoch = {:.{prec}f}'.format(epoch_number, avg_val_loss, prec=4))\n",
        "        \n",
        "    plot_cache.append((avg_loss, avg_val_loss))\n",
        "\n",
        "    if load_pretrained:\n",
        "        break\n",
        "\n",
        "print('Saving best model...')\n",
        "torch.save({\n",
        "'options': options,\n",
        "'loss_cache': plot_cache,\n",
        "'model_dict': best_model.state_dict()\n",
        "        }, './baseline_RNN.pt')\n",
        "\n",
        "# MD5 (baseline_RNN.pt) = e5d2c5a64255a786a8901d12bcae6220"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 avg train loss = 10.4347\n",
            "Step 100 avg train loss = 7.7255\n",
            "Step 200 avg train loss = 6.9448\n",
            "Step 300 avg train loss = 6.7479\n",
            "Step 400 avg train loss = 6.6020\n",
            "Step 500 avg train loss = 6.5238\n",
            "Step 600 avg train loss = 6.4444\n",
            "Step 700 avg train loss = 6.3687\n",
            "Step 800 avg train loss = 6.3088\n",
            "Step 900 avg train loss = 6.2642\n",
            "Step 1000 avg train loss = 6.2030\n",
            "Step 1100 avg train loss = 6.1762\n",
            "Step 1200 avg train loss = 6.1313\n",
            "Step 1300 avg train loss = 6.1102\n",
            "Step 1400 avg train loss = 6.0654\n",
            "Step 1500 avg train loss = 6.0286\n",
            "Step 1600 avg train loss = 6.0137\n",
            "Step 1700 avg train loss = 5.9976\n",
            "Step 1800 avg train loss = 5.9683\n",
            "Step 1900 avg train loss = 5.9564\n",
            "Step 2000 avg train loss = 5.9412\n",
            "Step 2100 avg train loss = 5.9246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-a6274d42989d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sfw_BFDp8BvB",
        "outputId": "95abf217-cf3c-485e-c073-d684766f7b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "epochs = np.array(list(range(len(plot_cache))))\n",
        "plt.plot(epochs, [2**(i[0]/np.log(2)) for i in plot_cache], label='Train ppl')\n",
        "plt.plot(epochs, [2**(i[1]/np.log(2)) for i in plot_cache], label='Valid ppl')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('PPL curves of RNN baseline model')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ODfcbzQ8BvG"
      },
      "source": [
        "### II.1 LSTM and Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IS8rQKQ98BvH",
        "colab": {}
      },
      "source": [
        "from torch.nn import LSTM\n",
        "# input_size, hidden_size, num_layers. \n",
        "# Optional: bias = False, dropout = 0 (probability of dropout)\n",
        "# bidirectional = False. \n",
        "rnn = nn.LSTM(10, 20, 2)\n",
        "\n",
        "# input: tensor containing feature of the input sequence \n",
        "# shape: seq_len, batch, input_size\n",
        "input = torch.randn(5,3,10)\n",
        "\n",
        "# h0: tensor contain hidden state for t = seq_len\n",
        "# shape: num_layers * num*directions, batch, hidden_size\n",
        "h0 = torch.randn(2,3,20)\n",
        "\n",
        "# c0: tensor contain cell state for t = seq_length\n",
        "# shape: num_layers * num_directions, batch, hidden_size \n",
        "c0 = torch.randn(2,3,20)\n",
        "\n",
        "# output: shape (seq_len, batch, num_direction * hidden size)\n",
        "output, (hn,cn) = rnn(input, (h0,c0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SoKNOBmB8BvO",
        "colab": {}
      },
      "source": [
        "# From the baseline, we will stop the epoch around 20 \n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    This model combines embedding, rnn and projection layer into a single model\n",
        "    \"\"\"\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        # create each LM part here \n",
        "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
        "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], \n",
        "                            dropout=options['lstm_dropout'], batch_first=True, bias = options['bias'],\n",
        "                           bidirectional = options['bid'])\n",
        "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
        "        \n",
        "    def forward(self, encoded_input_sequence):\n",
        "        \"\"\"\n",
        "        Forward method process the input from token ids to logits\n",
        "        \"\"\"\n",
        "        \n",
        "        embeddings = self.lookup(encoded_input_sequence)\n",
        "        lstm_outputs = self.lstm(embeddings) # each batch initialize hidden layers to 0 \n",
        "        # project of outputs \n",
        "        # rnn_outputs: tupple with second element being last hidden state. \n",
        "        logits = self.projection(lstm_outputs[0])\n",
        "        \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7cnF0Xq98HPP",
        "colab": {}
      },
      "source": [
        "\n",
        "load_pretrained = False\n",
        "\n",
        "num_gpus = torch.cuda.device_count()\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "if load_pretrained:\n",
        "    if not os.path.exists('personachat_rnn_lm.pt'):\n",
        "        raise EOFError('Download pretrained model!')\n",
        "    model_dict = torch.load('personachat_rnn_lm.pt')\n",
        "    \n",
        "    options = model_dict['options']\n",
        "    model = LSTMModel(options).to(current_device)\n",
        "    model.load_state_dict(model_dict['model_dict'])\n",
        "    \n",
        "else:\n",
        "    embedding_size = 64\n",
        "    hidden_size = 128 # output of dimension \n",
        "    num_layers = 2\n",
        "    lstm_dropout = 0.1\n",
        "#     input_size = lookup.weight.size(1)\n",
        "    vocab_size = len(train_dict)\n",
        "    \n",
        "    options = {\n",
        "        'num_embeddings': len(train_dict),\n",
        "        'embedding_dim': embedding_size,\n",
        "        'padding_idx': train_dict.get_id('<pad>'),\n",
        "        'input_size': embedding_size,\n",
        "        'hidden_size': hidden_size,\n",
        "        'num_layers': num_layers,\n",
        "        'lstm_dropout': lstm_dropout,\n",
        "        'bias': True,\n",
        "        'bid': False \n",
        "    }\n",
        "\n",
        "    \n",
        "    model = LSTMModel(options).to(current_device)\n",
        "\n",
        "# same as previous nn based \n",
        "criterion = nn.CrossEntropyLoss(ignore_index=train_dict.get_id('<pad>'))\n",
        "\n",
        "model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.Adam(model_parameters, lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p4LKhWXs9MeR",
        "outputId": "4a1a0f3f-e8b8-4865-f8cf-18de77dc438c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (lookup): Embedding(33178, 64, padding_idx=2)\n",
              "  (lstm): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=128, out_features=33178, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wi5oI78I6b1Q",
        "colab": {}
      },
      "source": [
        "# The following cell geives the performance of the baseline LSTM\n",
        "# TAKE A LONG TIME TO RUN. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wp6kNjF_9OD_",
        "outputId": "e4017a58-b2ed-46f9-cd05-5309c8b39ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model = LSTMModel(options).to(current_device)\n",
        "plot_cache = []\n",
        "min_val_loss = 20 \n",
        "for epoch_number in range(20):\n",
        "    avg_loss=0\n",
        "    if not load_pretrained:\n",
        "        model.train()\n",
        "        train_log_cache = []\n",
        "        for i, (inp, target) in enumerate(loaders['train']):\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "            \n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_log_cache.append(loss.item())\n",
        "            \n",
        "            if i % 100 == 0:\n",
        "                avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
        "                print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
        "                train_log_cache = []\n",
        "            \n",
        "    #do valid\n",
        "    valid_losses = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(loaders['valid']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            valid_losses.append(loss.item())\n",
        "        avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
        "        print('Validation loss after {} epoch = {:.{prec}f}'.format(epoch_number, avg_val_loss, prec=4))\n",
        "        best = avg_val_loss < min_val_loss\n",
        "        if best:\n",
        "            min_val_loss = avg_val_loss\n",
        "            best_model = model\n",
        "                        \n",
        "    plot_cache.append((avg_loss, avg_val_loss))\n",
        "\n",
        "    if load_pretrained:\n",
        "        break\n",
        "        \n",
        "print('Saving best model...')\n",
        "torch.save({\n",
        "'options': options,\n",
        "'loss_cache': plot_cache,\n",
        "'model_dict': best_model.state_dict()\n",
        "        }, './baseline_LSTM.pt')\n",
        "\n",
        "# MD5 (baseline_LSTM.pt) = 4e5cf81b23d48827cf5b920c4a121407"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 avg train loss = 7.0863\n",
            "Step 100 avg train loss = 7.0200\n",
            "Step 200 avg train loss = 6.9266\n",
            "Step 300 avg train loss = 6.8133\n",
            "Step 400 avg train loss = 6.7200\n",
            "Step 500 avg train loss = 6.6318\n",
            "Step 600 avg train loss = 6.5733\n",
            "Step 700 avg train loss = 6.5168\n",
            "Step 800 avg train loss = 6.4810\n",
            "Step 900 avg train loss = 6.4369\n",
            "Step 1000 avg train loss = 6.3943\n",
            "Step 1100 avg train loss = 6.3615\n",
            "Step 1200 avg train loss = 6.3266\n",
            "Step 1300 avg train loss = 6.2870\n",
            "Step 1400 avg train loss = 6.2620\n",
            "Step 1500 avg train loss = 6.2168\n",
            "Step 1600 avg train loss = 6.2051\n",
            "Step 1700 avg train loss = 6.1710\n",
            "Step 1800 avg train loss = 6.1293\n",
            "Step 1900 avg train loss = 6.1156\n",
            "Step 2000 avg train loss = 6.0862\n",
            "Step 2100 avg train loss = 6.0944\n",
            "Step 2200 avg train loss = 6.0612\n",
            "Step 2300 avg train loss = 6.0266\n",
            "Step 2400 avg train loss = 6.0032\n",
            "Validation loss after 0 epoch = 5.8233\n",
            "Step 0 avg train loss = 5.8466\n",
            "Step 100 avg train loss = 5.9111\n",
            "Step 200 avg train loss = 5.8860\n",
            "Step 300 avg train loss = 5.8898\n",
            "Step 400 avg train loss = 5.8895\n",
            "Step 500 avg train loss = 5.8599\n",
            "Step 600 avg train loss = 5.8661\n",
            "Step 700 avg train loss = 5.8486\n",
            "Step 800 avg train loss = 5.8073\n",
            "Step 900 avg train loss = 5.8136\n",
            "Step 1000 avg train loss = 5.8237\n",
            "Step 1100 avg train loss = 5.7940\n",
            "Step 1200 avg train loss = 5.7931\n",
            "Step 1300 avg train loss = 5.7645\n",
            "Step 1400 avg train loss = 5.7615\n",
            "Step 1500 avg train loss = 5.7428\n",
            "Step 1600 avg train loss = 5.7537\n",
            "Step 1700 avg train loss = 5.7298\n",
            "Step 1800 avg train loss = 5.6969\n",
            "Step 1900 avg train loss = 5.7121\n",
            "Step 2000 avg train loss = 5.6991\n",
            "Step 2100 avg train loss = 5.6891\n",
            "Step 2200 avg train loss = 5.6726\n",
            "Step 2300 avg train loss = 5.6940\n",
            "Step 2400 avg train loss = 5.6580\n",
            "Validation loss after 1 epoch = 5.5607\n",
            "Step 0 avg train loss = 5.5434\n",
            "Step 100 avg train loss = 5.5452\n",
            "Step 200 avg train loss = 5.5621\n",
            "Step 300 avg train loss = 5.5332\n",
            "Step 400 avg train loss = 5.5507\n",
            "Step 500 avg train loss = 5.5510\n",
            "Step 600 avg train loss = 5.5591\n",
            "Step 700 avg train loss = 5.5285\n",
            "Step 800 avg train loss = 5.5261\n",
            "Step 900 avg train loss = 5.5465\n",
            "Step 1000 avg train loss = 5.5328\n",
            "Step 1100 avg train loss = 5.5330\n",
            "Step 1200 avg train loss = 5.5034\n",
            "Step 1300 avg train loss = 5.5002\n",
            "Step 1400 avg train loss = 5.5018\n",
            "Step 1500 avg train loss = 5.4922\n",
            "Step 1600 avg train loss = 5.4849\n",
            "Step 1700 avg train loss = 5.4831\n",
            "Step 1800 avg train loss = 5.4891\n",
            "Step 1900 avg train loss = 5.4797\n",
            "Step 2000 avg train loss = 5.4614\n",
            "Step 2100 avg train loss = 5.4622\n",
            "Step 2200 avg train loss = 5.4617\n",
            "Step 2300 avg train loss = 5.4520\n",
            "Step 2400 avg train loss = 5.4403\n",
            "Validation loss after 2 epoch = 5.4297\n",
            "Step 0 avg train loss = 5.1113\n",
            "Step 100 avg train loss = 5.3614\n",
            "Step 200 avg train loss = 5.3298\n",
            "Step 300 avg train loss = 5.3446\n",
            "Step 400 avg train loss = 5.3246\n",
            "Step 500 avg train loss = 5.3085\n",
            "Step 600 avg train loss = 5.3320\n",
            "Step 700 avg train loss = 5.3338\n",
            "Step 800 avg train loss = 5.3105\n",
            "Step 900 avg train loss = 5.3265\n",
            "Step 1000 avg train loss = 5.3130\n",
            "Step 1100 avg train loss = 5.3274\n",
            "Step 1200 avg train loss = 5.3137\n",
            "Step 1300 avg train loss = 5.3129\n",
            "Step 1400 avg train loss = 5.3313\n",
            "Step 1500 avg train loss = 5.3077\n",
            "Step 1600 avg train loss = 5.2862\n",
            "Step 1700 avg train loss = 5.3240\n",
            "Step 1800 avg train loss = 5.2860\n",
            "Step 1900 avg train loss = 5.2976\n",
            "Step 2000 avg train loss = 5.2729\n",
            "Step 2100 avg train loss = 5.2752\n",
            "Step 2200 avg train loss = 5.2920\n",
            "Step 2300 avg train loss = 5.2710\n",
            "Step 2400 avg train loss = 5.2845\n",
            "Validation loss after 3 epoch = 5.3562\n",
            "Step 0 avg train loss = 5.1434\n",
            "Step 100 avg train loss = 5.1718\n",
            "Step 200 avg train loss = 5.1707\n",
            "Step 300 avg train loss = 5.1684\n",
            "Step 400 avg train loss = 5.1573\n",
            "Step 500 avg train loss = 5.1514\n",
            "Step 600 avg train loss = 5.1843\n",
            "Step 700 avg train loss = 5.1482\n",
            "Step 800 avg train loss = 5.1617\n",
            "Step 900 avg train loss = 5.1539\n",
            "Step 1000 avg train loss = 5.1785\n",
            "Step 1100 avg train loss = 5.1625\n",
            "Step 1200 avg train loss = 5.1502\n",
            "Step 1300 avg train loss = 5.1451\n",
            "Step 1400 avg train loss = 5.1660\n",
            "Step 1500 avg train loss = 5.1323\n",
            "Step 1600 avg train loss = 5.1497\n",
            "Step 1700 avg train loss = 5.1697\n",
            "Step 1800 avg train loss = 5.1509\n",
            "Step 1900 avg train loss = 5.1492\n",
            "Step 2000 avg train loss = 5.1416\n",
            "Step 2100 avg train loss = 5.1433\n",
            "Step 2200 avg train loss = 5.1633\n",
            "Step 2300 avg train loss = 5.1416\n",
            "Step 2400 avg train loss = 5.1608\n",
            "Validation loss after 4 epoch = 5.3118\n",
            "Step 0 avg train loss = 4.9447\n",
            "Step 100 avg train loss = 5.0148\n",
            "Step 200 avg train loss = 5.0230\n",
            "Step 300 avg train loss = 5.0276\n",
            "Step 400 avg train loss = 5.0230\n",
            "Step 500 avg train loss = 5.0330\n",
            "Step 600 avg train loss = 5.0120\n",
            "Step 700 avg train loss = 5.0337\n",
            "Step 800 avg train loss = 5.0339\n",
            "Step 900 avg train loss = 5.0303\n",
            "Step 1000 avg train loss = 5.0622\n",
            "Step 1100 avg train loss = 5.0296\n",
            "Step 1200 avg train loss = 5.0335\n",
            "Step 1300 avg train loss = 5.0202\n",
            "Step 1400 avg train loss = 5.0432\n",
            "Step 1500 avg train loss = 5.0423\n",
            "Step 1600 avg train loss = 5.0470\n",
            "Step 1700 avg train loss = 5.0465\n",
            "Step 1800 avg train loss = 5.0368\n",
            "Step 1900 avg train loss = 5.0461\n",
            "Step 2000 avg train loss = 5.0525\n",
            "Step 2100 avg train loss = 5.0449\n",
            "Step 2200 avg train loss = 5.0178\n",
            "Step 2300 avg train loss = 5.0546\n",
            "Step 2400 avg train loss = 5.0173\n",
            "Validation loss after 5 epoch = 5.2922\n",
            "Step 0 avg train loss = 4.7017\n",
            "Step 100 avg train loss = 4.9204\n",
            "Step 200 avg train loss = 4.9169\n",
            "Step 300 avg train loss = 4.9215\n",
            "Step 400 avg train loss = 4.9211\n",
            "Step 500 avg train loss = 4.8891\n",
            "Step 600 avg train loss = 4.9412\n",
            "Step 700 avg train loss = 4.9295\n",
            "Step 800 avg train loss = 4.9425\n",
            "Step 900 avg train loss = 4.9328\n",
            "Step 1000 avg train loss = 4.9519\n",
            "Step 1100 avg train loss = 4.9247\n",
            "Step 1200 avg train loss = 4.9585\n",
            "Step 1300 avg train loss = 4.9448\n",
            "Step 1400 avg train loss = 4.9278\n",
            "Step 1500 avg train loss = 4.9288\n",
            "Step 1600 avg train loss = 4.9582\n",
            "Step 1700 avg train loss = 4.9372\n",
            "Step 1800 avg train loss = 4.9196\n",
            "Step 1900 avg train loss = 4.9321\n",
            "Step 2000 avg train loss = 4.9250\n",
            "Step 2100 avg train loss = 4.9101\n",
            "Step 2200 avg train loss = 4.9163\n",
            "Step 2300 avg train loss = 4.9302\n",
            "Step 2400 avg train loss = 4.9549\n",
            "Validation loss after 6 epoch = 5.2841\n",
            "Step 0 avg train loss = 4.8695\n",
            "Step 100 avg train loss = 4.8045\n",
            "Step 200 avg train loss = 4.8294\n",
            "Step 300 avg train loss = 4.8278\n",
            "Step 400 avg train loss = 4.8329\n",
            "Step 500 avg train loss = 4.8239\n",
            "Step 600 avg train loss = 4.8349\n",
            "Step 700 avg train loss = 4.8690\n",
            "Step 800 avg train loss = 4.8324\n",
            "Step 900 avg train loss = 4.8435\n",
            "Step 1000 avg train loss = 4.8450\n",
            "Step 1100 avg train loss = 4.8368\n",
            "Step 1200 avg train loss = 4.8505\n",
            "Step 1300 avg train loss = 4.8468\n",
            "Step 1400 avg train loss = 4.8510\n",
            "Step 1500 avg train loss = 4.8339\n",
            "Step 1600 avg train loss = 4.8627\n",
            "Step 1700 avg train loss = 4.8453\n",
            "Step 1800 avg train loss = 4.8560\n",
            "Step 1900 avg train loss = 4.8612\n",
            "Step 2000 avg train loss = 4.8578\n",
            "Step 2100 avg train loss = 4.8430\n",
            "Step 2200 avg train loss = 4.8702\n",
            "Step 2300 avg train loss = 4.8353\n",
            "Step 2400 avg train loss = 4.8638\n",
            "Validation loss after 7 epoch = 5.2809\n",
            "Step 0 avg train loss = 4.7470\n",
            "Step 100 avg train loss = 4.7459\n",
            "Step 200 avg train loss = 4.7354\n",
            "Step 300 avg train loss = 4.7444\n",
            "Step 400 avg train loss = 4.7343\n",
            "Step 500 avg train loss = 4.7408\n",
            "Step 600 avg train loss = 4.7603\n",
            "Step 700 avg train loss = 4.7504\n",
            "Step 800 avg train loss = 4.7704\n",
            "Step 900 avg train loss = 4.7664\n",
            "Step 1000 avg train loss = 4.7505\n",
            "Step 1100 avg train loss = 4.7623\n",
            "Step 1200 avg train loss = 4.7743\n",
            "Step 1300 avg train loss = 4.7701\n",
            "Step 1400 avg train loss = 4.7791\n",
            "Step 1500 avg train loss = 4.7600\n",
            "Step 1600 avg train loss = 4.7797\n",
            "Step 1700 avg train loss = 4.7896\n",
            "Step 1800 avg train loss = 4.7708\n",
            "Step 1900 avg train loss = 4.7825\n",
            "Step 2000 avg train loss = 4.7981\n",
            "Step 2100 avg train loss = 4.7845\n",
            "Step 2200 avg train loss = 4.8000\n",
            "Step 2300 avg train loss = 4.7924\n",
            "Step 2400 avg train loss = 4.7921\n",
            "Validation loss after 8 epoch = 5.2987\n",
            "Step 0 avg train loss = 4.6857\n",
            "Step 100 avg train loss = 4.6830\n",
            "Step 200 avg train loss = 4.6996\n",
            "Step 300 avg train loss = 4.6605\n",
            "Step 400 avg train loss = 4.6979\n",
            "Step 500 avg train loss = 4.6663\n",
            "Step 600 avg train loss = 4.6855\n",
            "Step 700 avg train loss = 4.6916\n",
            "Step 800 avg train loss = 4.6988\n",
            "Step 900 avg train loss = 4.7003\n",
            "Step 1000 avg train loss = 4.6932\n",
            "Step 1100 avg train loss = 4.6996\n",
            "Step 1200 avg train loss = 4.7004\n",
            "Step 1300 avg train loss = 4.7015\n",
            "Step 1400 avg train loss = 4.7098\n",
            "Step 1500 avg train loss = 4.7027\n",
            "Step 1600 avg train loss = 4.7106\n",
            "Step 1700 avg train loss = 4.7222\n",
            "Step 1800 avg train loss = 4.7225\n",
            "Step 1900 avg train loss = 4.7178\n",
            "Step 2000 avg train loss = 4.7214\n",
            "Step 2100 avg train loss = 4.7269\n",
            "Step 2200 avg train loss = 4.7266\n",
            "Step 2300 avg train loss = 4.7068\n",
            "Step 2400 avg train loss = 4.7275\n",
            "Validation loss after 9 epoch = 5.3080\n",
            "Step 0 avg train loss = 4.5204\n",
            "Step 100 avg train loss = 4.5975\n",
            "Step 200 avg train loss = 4.5952\n",
            "Step 300 avg train loss = 4.6278\n",
            "Step 400 avg train loss = 4.6466\n",
            "Step 500 avg train loss = 4.6292\n",
            "Step 600 avg train loss = 4.6288\n",
            "Step 700 avg train loss = 4.6286\n",
            "Step 800 avg train loss = 4.6309\n",
            "Step 900 avg train loss = 4.6270\n",
            "Step 1000 avg train loss = 4.6611\n",
            "Step 1100 avg train loss = 4.6526\n",
            "Step 1200 avg train loss = 4.6538\n",
            "Step 1300 avg train loss = 4.6346\n",
            "Step 1400 avg train loss = 4.6592\n",
            "Step 1500 avg train loss = 4.6529\n",
            "Step 1600 avg train loss = 4.6495\n",
            "Step 1700 avg train loss = 4.6491\n",
            "Step 1800 avg train loss = 4.6481\n",
            "Step 1900 avg train loss = 4.6594\n",
            "Step 2000 avg train loss = 4.6472\n",
            "Step 2100 avg train loss = 4.6552\n",
            "Step 2200 avg train loss = 4.6634\n",
            "Step 2300 avg train loss = 4.6580\n",
            "Step 2400 avg train loss = 4.6653\n",
            "Validation loss after 10 epoch = 5.3153\n",
            "Step 0 avg train loss = 4.6411\n",
            "Step 100 avg train loss = 4.5584\n",
            "Step 200 avg train loss = 4.5436\n",
            "Step 300 avg train loss = 4.5719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-8114e8b6de41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VfunetAO9QlT",
        "outputId": "f9899005-ace4-4685-dc05-71233a219567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "epochs = np.array(list(range(len(plot_cache))))\n",
        "plt.plot(epochs, [2**(i[0]/np.log(2)) for i in plot_cache], label='Train ppl')\n",
        "plt.plot(epochs, [2**(i[1]/np.log(2)) for i in plot_cache], label='Valid ppl')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('PPL curves of LSTM model')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0CullJf7f9MERIOsxlWJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H658b0MW9UJ4",
        "outputId": "7ce53cfc-cded-49fa-a571-9e2972ed3b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "perp = [2**(i[1]/np.log(2)) for i in plot_cache] \n",
        "print('The minimum perplexity occurred at {} and it is {}'.format(perp.index(min(perp)),min(perp)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum validation loss occurred at 7 and it is 196.54008318910067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rAM0w4gp8BvR",
        "colab": {}
      },
      "source": [
        "# train the model with hyperparamters chosen: embed_dim: 300, hidden_zise = 300\n",
        "\n",
        "load_pretrained = False\n",
        "\n",
        "num_gpus = torch.cuda.device_count()\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "if load_pretrained:\n",
        "    if not os.path.exists('personachat_rnn_lm.pt'):\n",
        "        raise EOFError('Download pretrained model!')\n",
        "    model_dict = torch.load('personachat_rnn_lm.pt')\n",
        "    \n",
        "    options = model_dict['options']\n",
        "    model = LSTMModel(options).to(current_device)\n",
        "    model.load_state_dict(model_dict['model_dict'])\n",
        "    \n",
        "else:\n",
        "    embedding_size = 300\n",
        "    hidden_size = 300 # output of dimension \n",
        "    num_layers = 2\n",
        "    lstm_dropout = 0.1\n",
        "#     input_size = lookup.weight.size(1)\n",
        "    vocab_size = len(train_dict)\n",
        "    \n",
        "    options = {\n",
        "        'num_embeddings': len(train_dict),\n",
        "        'embedding_dim': embedding_size,\n",
        "        'padding_idx': train_dict.get_id('<pad>'),\n",
        "        'input_size': embedding_size,\n",
        "        'hidden_size': hidden_size,\n",
        "        'num_layers': num_layers,\n",
        "        'lstm_dropout': lstm_dropout,\n",
        "        'bias': True,\n",
        "        'bid': False \n",
        "    }\n",
        "\n",
        "    \n",
        "    model = LSTMModel(options).to(current_device)\n",
        "\n",
        "# same as previous nn based \n",
        "criterion = nn.CrossEntropyLoss(ignore_index=train_dict.get_id('<pad>'))\n",
        "\n",
        "model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.Adam(model_parameters, lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mztEAFSg8BvU",
        "outputId": "e155f7e6-9541-4700-8c2e-814d7c1f264c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# verify the model \n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
              "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bmVR8WOW8BvY",
        "outputId": "4cb4889e-c6ed-408f-b581-1466bf9dca08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model = LSTMModel(options).to(current_device)\n",
        "# train the model with hyperparamters chosen: embed_dim: 300, hidden_zise = 300\n",
        "\n",
        "plot_cache = []\n",
        "min_val_loss = 20 \n",
        "epoch_num = 20\n",
        "for epoch_number in range(epoch_num):\n",
        "    avg_loss=0\n",
        "    if not load_pretrained:\n",
        "        model.train()\n",
        "        train_log_cache = []\n",
        "        for i, (inp, target) in enumerate(loaders['train']):\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "            \n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_log_cache.append(loss.item())\n",
        "            \n",
        "            if i % 100 == 0:\n",
        "                avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
        "                print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
        "                train_log_cache = []\n",
        "            \n",
        "    #do valid\n",
        "    valid_losses = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(loaders['valid']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            valid_losses.append(loss.item())\n",
        "        avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
        "        print('Validation loss after {} epoch = {:.{prec}f}'.format(epoch_number, avg_val_loss, prec=4))\n",
        "        best = avg_val_loss < min_val_loss\n",
        "        if best:\n",
        "            min_val_loss = avg_val_loss\n",
        "            best_model = model\n",
        "            print(\"update the best to:\")\n",
        "            print(best_model)\n",
        "            print(\"current validation loss is:\")\n",
        "            print(min_val_loss)\n",
        "                        \n",
        "    plot_cache.append((avg_loss, avg_val_loss))\n",
        "\n",
        "    if load_pretrained:\n",
        "        break\n",
        "        \n",
        "print('Saving best model...')\n",
        "torch.save({\n",
        "'options': options,\n",
        "'loss_cache': plot_cache,\n",
        "'model_dict': best_model.state_dict()\n",
        "        }, './best_300_300_LSTM.pt')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 avg train loss = 7.0963\n",
            "Step 100 avg train loss = 7.1643\n",
            "Step 200 avg train loss = 6.9912\n",
            "Step 300 avg train loss = 6.8097\n",
            "Step 400 avg train loss = 6.6316\n",
            "Step 500 avg train loss = 6.5043\n",
            "Step 600 avg train loss = 6.4055\n",
            "Step 700 avg train loss = 6.3217\n",
            "Step 800 avg train loss = 6.2781\n",
            "Step 900 avg train loss = 6.1911\n",
            "Step 1000 avg train loss = 6.1272\n",
            "Step 1100 avg train loss = 6.0845\n",
            "Step 1200 avg train loss = 6.0255\n",
            "Step 1300 avg train loss = 6.0025\n",
            "Step 1400 avg train loss = 5.9498\n",
            "Step 1500 avg train loss = 5.9080\n",
            "Step 1600 avg train loss = 5.8947\n",
            "Step 1700 avg train loss = 5.8399\n",
            "Step 1800 avg train loss = 5.7976\n",
            "Step 1900 avg train loss = 5.8105\n",
            "Step 2000 avg train loss = 5.7670\n",
            "Step 2100 avg train loss = 5.7527\n",
            "Step 2200 avg train loss = 5.7363\n",
            "Step 2300 avg train loss = 5.6854\n",
            "Step 2400 avg train loss = 5.6774\n",
            "Validation loss after 0 epoch = 5.5204\n",
            "update the best to:\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "current validation loss is:\n",
            "5.520387977024295\n",
            "Step 0 avg train loss = 5.6179\n",
            "Step 100 avg train loss = 5.5519\n",
            "Step 200 avg train loss = 5.4950\n",
            "Step 300 avg train loss = 5.5017\n",
            "Step 400 avg train loss = 5.4774\n",
            "Step 500 avg train loss = 5.4747\n",
            "Step 600 avg train loss = 5.4848\n",
            "Step 700 avg train loss = 5.4545\n",
            "Step 800 avg train loss = 5.4363\n",
            "Step 900 avg train loss = 5.4233\n",
            "Step 1000 avg train loss = 5.4134\n",
            "Step 1100 avg train loss = 5.3924\n",
            "Step 1200 avg train loss = 5.3886\n",
            "Step 1300 avg train loss = 5.3621\n",
            "Step 1400 avg train loss = 5.3610\n",
            "Step 1500 avg train loss = 5.3277\n",
            "Step 1600 avg train loss = 5.3297\n",
            "Step 1700 avg train loss = 5.3323\n",
            "Step 1800 avg train loss = 5.3010\n",
            "Step 1900 avg train loss = 5.2779\n",
            "Step 2000 avg train loss = 5.3112\n",
            "Step 2100 avg train loss = 5.2738\n",
            "Step 2200 avg train loss = 5.2660\n",
            "Step 2300 avg train loss = 5.2601\n",
            "Step 2400 avg train loss = 5.2794\n",
            "Validation loss after 1 epoch = 5.2590\n",
            "update the best to:\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "current validation loss is:\n",
            "5.258957803474282\n",
            "Step 0 avg train loss = 5.0729\n",
            "Step 100 avg train loss = 5.0421\n",
            "Step 200 avg train loss = 5.0402\n",
            "Step 300 avg train loss = 5.0608\n",
            "Step 400 avg train loss = 5.0638\n",
            "Step 500 avg train loss = 5.0504\n",
            "Step 600 avg train loss = 5.0652\n",
            "Step 700 avg train loss = 5.0654\n",
            "Step 800 avg train loss = 5.0178\n",
            "Step 900 avg train loss = 5.0349\n",
            "Step 1000 avg train loss = 5.0329\n",
            "Step 1100 avg train loss = 5.0048\n",
            "Step 1200 avg train loss = 5.0134\n",
            "Step 1300 avg train loss = 4.9993\n",
            "Step 1400 avg train loss = 4.9877\n",
            "Step 1500 avg train loss = 4.9917\n",
            "Step 1600 avg train loss = 4.9959\n",
            "Step 1700 avg train loss = 4.9841\n",
            "Step 1800 avg train loss = 4.9921\n",
            "Step 1900 avg train loss = 4.9914\n",
            "Step 2000 avg train loss = 4.9707\n",
            "Step 2100 avg train loss = 4.9773\n",
            "Step 2200 avg train loss = 4.9577\n",
            "Step 2300 avg train loss = 4.9680\n",
            "Step 2400 avg train loss = 4.9633\n",
            "Validation loss after 2 epoch = 5.1532\n",
            "update the best to:\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "current validation loss is:\n",
            "5.153161520328162\n",
            "Step 0 avg train loss = 4.8499\n",
            "Step 100 avg train loss = 4.7384\n",
            "Step 200 avg train loss = 4.7116\n",
            "Step 300 avg train loss = 4.7450\n",
            "Step 400 avg train loss = 4.7599\n",
            "Step 500 avg train loss = 4.7415\n",
            "Step 600 avg train loss = 4.7406\n",
            "Step 700 avg train loss = 4.7455\n",
            "Step 800 avg train loss = 4.7482\n",
            "Step 900 avg train loss = 4.7498\n",
            "Step 1000 avg train loss = 4.7576\n",
            "Step 1100 avg train loss = 4.7450\n",
            "Step 1200 avg train loss = 4.7322\n",
            "Step 1300 avg train loss = 4.7445\n",
            "Step 1400 avg train loss = 4.7419\n",
            "Step 1500 avg train loss = 4.7139\n",
            "Step 1600 avg train loss = 4.7399\n",
            "Step 1700 avg train loss = 4.7451\n",
            "Step 1800 avg train loss = 4.7524\n",
            "Step 1900 avg train loss = 4.7283\n",
            "Step 2000 avg train loss = 4.7272\n",
            "Step 2100 avg train loss = 4.7242\n",
            "Step 2200 avg train loss = 4.7086\n",
            "Step 2300 avg train loss = 4.7202\n",
            "Step 2400 avg train loss = 4.7051\n",
            "Validation loss after 3 epoch = 5.1240\n",
            "update the best to:\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "current validation loss is:\n",
            "5.1240091377834105\n",
            "Step 0 avg train loss = 4.2403\n",
            "Step 100 avg train loss = 4.4755\n",
            "Step 200 avg train loss = 4.5189\n",
            "Step 300 avg train loss = 4.4997\n",
            "Step 400 avg train loss = 4.5024\n",
            "Step 500 avg train loss = 4.5085\n",
            "Step 600 avg train loss = 4.4997\n",
            "Step 700 avg train loss = 4.5424\n",
            "Step 800 avg train loss = 4.5209\n",
            "Step 900 avg train loss = 4.5155\n",
            "Step 1000 avg train loss = 4.5030\n",
            "Step 1100 avg train loss = 4.5263\n",
            "Step 1200 avg train loss = 4.5174\n",
            "Step 1300 avg train loss = 4.5216\n",
            "Step 1400 avg train loss = 4.5076\n",
            "Step 1500 avg train loss = 4.5216\n",
            "Step 1600 avg train loss = 4.5220\n",
            "Step 1700 avg train loss = 4.5271\n",
            "Step 1800 avg train loss = 4.5288\n",
            "Step 1900 avg train loss = 4.5162\n",
            "Step 2000 avg train loss = 4.5171\n",
            "Step 2100 avg train loss = 4.5284\n",
            "Step 2200 avg train loss = 4.5220\n",
            "Step 2300 avg train loss = 4.5491\n",
            "Step 2400 avg train loss = 4.5348\n",
            "Validation loss after 4 epoch = 5.1514\n",
            "Step 0 avg train loss = 4.2330\n",
            "Step 100 avg train loss = 4.2637\n",
            "Step 200 avg train loss = 4.2819\n",
            "Step 300 avg train loss = 4.3145\n",
            "Step 400 avg train loss = 4.2894\n",
            "Step 500 avg train loss = 4.3025\n",
            "Step 600 avg train loss = 4.3162\n",
            "Step 700 avg train loss = 4.3113\n",
            "Step 800 avg train loss = 4.3035\n",
            "Step 900 avg train loss = 4.3288\n",
            "Step 1000 avg train loss = 4.3191\n",
            "Step 1100 avg train loss = 4.3400\n",
            "Step 1200 avg train loss = 4.3778\n",
            "Step 1300 avg train loss = 4.3485\n",
            "Step 1400 avg train loss = 4.3576\n",
            "Step 1500 avg train loss = 4.3466\n",
            "Step 1600 avg train loss = 4.3487\n",
            "Step 1700 avg train loss = 4.3467\n",
            "Step 1800 avg train loss = 4.3449\n",
            "Step 1900 avg train loss = 4.3766\n",
            "Step 2000 avg train loss = 4.3859\n",
            "Step 2100 avg train loss = 4.3532\n",
            "Step 2200 avg train loss = 4.3767\n",
            "Step 2300 avg train loss = 4.3666\n",
            "Step 2400 avg train loss = 4.3729\n",
            "Validation loss after 5 epoch = 5.1989\n",
            "Step 0 avg train loss = 4.0421\n",
            "Step 100 avg train loss = 4.1299\n",
            "Step 200 avg train loss = 4.1321\n",
            "Step 300 avg train loss = 4.1553\n",
            "Step 400 avg train loss = 4.1473\n",
            "Step 500 avg train loss = 4.1434\n",
            "Step 600 avg train loss = 4.1833\n",
            "Step 700 avg train loss = 4.1568\n",
            "Step 800 avg train loss = 4.1612\n",
            "Step 900 avg train loss = 4.1660\n",
            "Step 1000 avg train loss = 4.1943\n",
            "Step 1100 avg train loss = 4.1805\n",
            "Step 1200 avg train loss = 4.1957\n",
            "Step 1300 avg train loss = 4.2071\n",
            "Step 1400 avg train loss = 4.1799\n",
            "Step 1500 avg train loss = 4.2031\n",
            "Step 1600 avg train loss = 4.1892\n",
            "Step 1700 avg train loss = 4.2055\n",
            "Step 1800 avg train loss = 4.1970\n",
            "Step 1900 avg train loss = 4.1906\n",
            "Step 2000 avg train loss = 4.2205\n",
            "Step 2100 avg train loss = 4.2090\n",
            "Step 2200 avg train loss = 4.2018\n",
            "Step 2300 avg train loss = 4.2241\n",
            "Step 2400 avg train loss = 4.2278\n",
            "Validation loss after 6 epoch = 5.2634\n",
            "Step 0 avg train loss = 3.9514\n",
            "Step 100 avg train loss = 3.9639\n",
            "Step 200 avg train loss = 3.9919\n",
            "Step 300 avg train loss = 3.9997\n",
            "Step 400 avg train loss = 3.9899\n",
            "Step 500 avg train loss = 4.0071\n",
            "Step 600 avg train loss = 4.0111\n",
            "Step 700 avg train loss = 4.0287\n",
            "Step 800 avg train loss = 4.0385\n",
            "Step 900 avg train loss = 4.0413\n",
            "Step 1000 avg train loss = 4.0285\n",
            "Step 1100 avg train loss = 4.0451\n",
            "Step 1200 avg train loss = 4.0490\n",
            "Step 1300 avg train loss = 4.0460\n",
            "Step 1400 avg train loss = 4.0713\n",
            "Step 1500 avg train loss = 4.0879\n",
            "Step 1600 avg train loss = 4.0937\n",
            "Step 1700 avg train loss = 4.0824\n",
            "Step 1800 avg train loss = 4.0584\n",
            "Step 1900 avg train loss = 4.0970\n",
            "Step 2000 avg train loss = 4.0975\n",
            "Step 2100 avg train loss = 4.1142\n",
            "Step 2200 avg train loss = 4.1017\n",
            "Step 2300 avg train loss = 4.1026\n",
            "Step 2400 avg train loss = 4.0853\n",
            "Validation loss after 7 epoch = 5.3301\n",
            "Step 0 avg train loss = 3.9261\n",
            "Step 100 avg train loss = 3.8440\n",
            "Step 200 avg train loss = 3.8684\n",
            "Step 300 avg train loss = 3.8729\n",
            "Step 400 avg train loss = 3.8734\n",
            "Step 500 avg train loss = 3.9069\n",
            "Step 600 avg train loss = 3.9219\n",
            "Step 700 avg train loss = 3.8951\n",
            "Step 800 avg train loss = 3.8965\n",
            "Step 900 avg train loss = 3.9264\n",
            "Step 1000 avg train loss = 3.9477\n",
            "Step 1100 avg train loss = 3.9400\n",
            "Step 1200 avg train loss = 3.9614\n",
            "Step 1300 avg train loss = 3.9445\n",
            "Step 1400 avg train loss = 3.9456\n",
            "Step 1500 avg train loss = 3.9390\n",
            "Step 1600 avg train loss = 3.9407\n",
            "Step 1700 avg train loss = 3.9592\n",
            "Step 1800 avg train loss = 3.9591\n",
            "Step 1900 avg train loss = 3.9809\n",
            "Step 2000 avg train loss = 3.9808\n",
            "Step 2100 avg train loss = 3.9648\n",
            "Step 2200 avg train loss = 3.9733\n",
            "Step 2300 avg train loss = 3.9929\n",
            "Step 2400 avg train loss = 4.0095\n",
            "Validation loss after 8 epoch = 5.3986\n",
            "Step 0 avg train loss = 3.8569\n",
            "Step 100 avg train loss = 3.7448\n",
            "Step 200 avg train loss = 3.7514\n",
            "Step 300 avg train loss = 3.7689\n",
            "Step 400 avg train loss = 3.7628\n",
            "Step 500 avg train loss = 3.7833\n",
            "Step 600 avg train loss = 3.7902\n",
            "Step 700 avg train loss = 3.7783\n",
            "Step 800 avg train loss = 3.8215\n",
            "Step 900 avg train loss = 3.8231\n",
            "Step 1000 avg train loss = 3.8275\n",
            "Step 1100 avg train loss = 3.8398\n",
            "Step 1200 avg train loss = 3.8314\n",
            "Step 1300 avg train loss = 3.8419\n",
            "Step 1400 avg train loss = 3.8455\n",
            "Step 1500 avg train loss = 3.8639\n",
            "Step 1600 avg train loss = 3.8601\n",
            "Step 1700 avg train loss = 3.8649\n",
            "Step 1800 avg train loss = 3.8622\n",
            "Step 1900 avg train loss = 3.8639\n",
            "Step 2000 avg train loss = 3.8649\n",
            "Step 2100 avg train loss = 3.8894\n",
            "Step 2200 avg train loss = 3.9049\n",
            "Step 2300 avg train loss = 3.8968\n",
            "Step 2400 avg train loss = 3.8814\n",
            "Validation loss after 9 epoch = 5.4724\n",
            "Step 0 avg train loss = 3.6322\n",
            "Step 100 avg train loss = 3.6339\n",
            "Step 200 avg train loss = 3.6528\n",
            "Step 300 avg train loss = 3.6707\n",
            "Step 400 avg train loss = 3.6762\n",
            "Step 500 avg train loss = 3.6733\n",
            "Step 600 avg train loss = 3.6885\n",
            "Step 700 avg train loss = 3.7217\n",
            "Step 800 avg train loss = 3.7021\n",
            "Step 900 avg train loss = 3.7318\n",
            "Step 1000 avg train loss = 3.7315\n",
            "Step 1100 avg train loss = 3.7547\n",
            "Step 1200 avg train loss = 3.7369\n",
            "Step 1300 avg train loss = 3.7508\n",
            "Step 1400 avg train loss = 3.7451\n",
            "Step 1500 avg train loss = 3.7455\n",
            "Step 1600 avg train loss = 3.7796\n",
            "Step 1700 avg train loss = 3.7875\n",
            "Step 1800 avg train loss = 3.7810\n",
            "Step 1900 avg train loss = 3.7766\n",
            "Step 2000 avg train loss = 3.7877\n",
            "Step 2100 avg train loss = 3.7848\n",
            "Step 2200 avg train loss = 3.7925\n",
            "Step 2300 avg train loss = 3.8148\n",
            "Step 2400 avg train loss = 3.8224\n",
            "Validation loss after 10 epoch = 5.5384\n",
            "Step 0 avg train loss = 3.6623\n",
            "Step 100 avg train loss = 3.5528\n",
            "Step 200 avg train loss = 3.5669\n",
            "Step 300 avg train loss = 3.5739\n",
            "Step 400 avg train loss = 3.5682\n",
            "Step 500 avg train loss = 3.5993\n",
            "Step 600 avg train loss = 3.6179\n",
            "Step 700 avg train loss = 3.6319\n",
            "Step 800 avg train loss = 3.6124\n",
            "Step 900 avg train loss = 3.6349\n",
            "Step 1000 avg train loss = 3.6409\n",
            "Step 1100 avg train loss = 3.6784\n",
            "Step 1200 avg train loss = 3.6471\n",
            "Step 1300 avg train loss = 3.6662\n",
            "Step 1400 avg train loss = 3.6523\n",
            "Step 1500 avg train loss = 3.6712\n",
            "Step 1600 avg train loss = 3.7040\n",
            "Step 1700 avg train loss = 3.7016\n",
            "Step 1800 avg train loss = 3.6965\n",
            "Step 1900 avg train loss = 3.7071\n",
            "Step 2000 avg train loss = 3.7121\n",
            "Step 2100 avg train loss = 3.6970\n",
            "Step 2200 avg train loss = 3.7061\n",
            "Step 2300 avg train loss = 3.7240\n",
            "Step 2400 avg train loss = 3.7387\n",
            "Validation loss after 11 epoch = 5.6109\n",
            "Step 0 avg train loss = 3.5031\n",
            "Step 100 avg train loss = 3.4773\n",
            "Step 200 avg train loss = 3.4853\n",
            "Step 300 avg train loss = 3.5031\n",
            "Step 400 avg train loss = 3.5186\n",
            "Step 500 avg train loss = 3.5199\n",
            "Step 600 avg train loss = 3.5490\n",
            "Step 700 avg train loss = 3.5425\n",
            "Step 800 avg train loss = 3.5337\n",
            "Step 900 avg train loss = 3.5510\n",
            "Step 1000 avg train loss = 3.5587\n",
            "Step 1100 avg train loss = 3.5905\n",
            "Step 1200 avg train loss = 3.5673\n",
            "Step 1300 avg train loss = 3.5937\n",
            "Step 1400 avg train loss = 3.5926\n",
            "Step 1500 avg train loss = 3.6081\n",
            "Step 1600 avg train loss = 3.5871\n",
            "Step 1700 avg train loss = 3.6191\n",
            "Step 1800 avg train loss = 3.6468\n",
            "Step 1900 avg train loss = 3.6066\n",
            "Step 2000 avg train loss = 3.6250\n",
            "Step 2100 avg train loss = 3.6412\n",
            "Step 2200 avg train loss = 3.6447\n",
            "Step 2300 avg train loss = 3.6349\n",
            "Step 2400 avg train loss = 3.6611\n",
            "Validation loss after 12 epoch = 5.6649\n",
            "Step 0 avg train loss = 3.2465\n",
            "Step 100 avg train loss = 3.3980\n",
            "Step 200 avg train loss = 3.3929\n",
            "Step 300 avg train loss = 3.4516\n",
            "Step 400 avg train loss = 3.4609\n",
            "Step 500 avg train loss = 3.4520\n",
            "Step 600 avg train loss = 3.4679\n",
            "Step 700 avg train loss = 3.4703\n",
            "Step 800 avg train loss = 3.4921\n",
            "Step 900 avg train loss = 3.5049\n",
            "Step 1000 avg train loss = 3.5061\n",
            "Step 1100 avg train loss = 3.5030\n",
            "Step 1200 avg train loss = 3.5061\n",
            "Step 1300 avg train loss = 3.5051\n",
            "Step 1400 avg train loss = 3.5276\n",
            "Step 1500 avg train loss = 3.5379\n",
            "Step 1600 avg train loss = 3.5539\n",
            "Step 1700 avg train loss = 3.5217\n",
            "Step 1800 avg train loss = 3.5708\n",
            "Step 1900 avg train loss = 3.5493\n",
            "Step 2000 avg train loss = 3.5485\n",
            "Step 2100 avg train loss = 3.5556\n",
            "Step 2200 avg train loss = 3.5588\n",
            "Step 2300 avg train loss = 3.5681\n",
            "Step 2400 avg train loss = 3.5727\n",
            "Validation loss after 13 epoch = 5.7428\n",
            "Step 0 avg train loss = 3.4843\n",
            "Step 100 avg train loss = 3.3408\n",
            "Step 200 avg train loss = 3.3699\n",
            "Step 300 avg train loss = 3.3662\n",
            "Step 400 avg train loss = 3.3690\n",
            "Step 500 avg train loss = 3.3666\n",
            "Step 600 avg train loss = 3.3983\n",
            "Step 700 avg train loss = 3.4059\n",
            "Step 800 avg train loss = 3.4280\n",
            "Step 900 avg train loss = 3.4331\n",
            "Step 1000 avg train loss = 3.4389\n",
            "Step 1100 avg train loss = 3.4261\n",
            "Step 1200 avg train loss = 3.4480\n",
            "Step 1300 avg train loss = 3.4433\n",
            "Step 1400 avg train loss = 3.4438\n",
            "Step 1500 avg train loss = 3.4724\n",
            "Step 1600 avg train loss = 3.4493\n",
            "Step 1700 avg train loss = 3.4870\n",
            "Step 1800 avg train loss = 3.4867\n",
            "Step 1900 avg train loss = 3.4986\n",
            "Step 2000 avg train loss = 3.4951\n",
            "Step 2100 avg train loss = 3.5089\n",
            "Step 2200 avg train loss = 3.5053\n",
            "Step 2300 avg train loss = 3.4890\n",
            "Step 2400 avg train loss = 3.5005\n",
            "Validation loss after 14 epoch = 5.8012\n",
            "Step 0 avg train loss = 3.2950\n",
            "Step 100 avg train loss = 3.2704\n",
            "Step 200 avg train loss = 3.3078\n",
            "Step 300 avg train loss = 3.2987\n",
            "Step 400 avg train loss = 3.3082\n",
            "Step 500 avg train loss = 3.3257\n",
            "Step 600 avg train loss = 3.3474\n",
            "Step 700 avg train loss = 3.3411\n",
            "Step 800 avg train loss = 3.3460\n",
            "Step 900 avg train loss = 3.3694\n",
            "Step 1000 avg train loss = 3.3675\n",
            "Step 1100 avg train loss = 3.3700\n",
            "Step 1200 avg train loss = 3.3982\n",
            "Step 1300 avg train loss = 3.3869\n",
            "Step 1400 avg train loss = 3.4140\n",
            "Step 1500 avg train loss = 3.3982\n",
            "Step 1600 avg train loss = 3.3937\n",
            "Step 1700 avg train loss = 3.3875\n",
            "Step 1800 avg train loss = 3.4254\n",
            "Step 1900 avg train loss = 3.4274\n",
            "Step 2000 avg train loss = 3.4398\n",
            "Step 2100 avg train loss = 3.4476\n",
            "Step 2200 avg train loss = 3.4547\n",
            "Step 2300 avg train loss = 3.4491\n",
            "Step 2400 avg train loss = 3.4558\n",
            "Validation loss after 15 epoch = 5.8667\n",
            "Step 0 avg train loss = 3.0764\n",
            "Step 100 avg train loss = 3.2389\n",
            "Step 200 avg train loss = 3.2277\n",
            "Step 300 avg train loss = 3.2444\n",
            "Step 400 avg train loss = 3.2594\n",
            "Step 500 avg train loss = 3.2803\n",
            "Step 600 avg train loss = 3.2746\n",
            "Step 700 avg train loss = 3.2957\n",
            "Step 800 avg train loss = 3.2991\n",
            "Step 900 avg train loss = 3.3178\n",
            "Step 1000 avg train loss = 3.3319\n",
            "Step 1100 avg train loss = 3.3365\n",
            "Step 1200 avg train loss = 3.3164\n",
            "Step 1300 avg train loss = 3.3491\n",
            "Step 1400 avg train loss = 3.3146\n",
            "Step 1500 avg train loss = 3.3328\n",
            "Step 1600 avg train loss = 3.3364\n",
            "Step 1700 avg train loss = 3.3402\n",
            "Step 1800 avg train loss = 3.3682\n",
            "Step 1900 avg train loss = 3.3743\n",
            "Step 2000 avg train loss = 3.3754\n",
            "Step 2100 avg train loss = 3.3694\n",
            "Step 2200 avg train loss = 3.3999\n",
            "Step 2300 avg train loss = 3.3946\n",
            "Step 2400 avg train loss = 3.4192\n",
            "Validation loss after 16 epoch = 5.9372\n",
            "Step 0 avg train loss = 3.3933\n",
            "Step 100 avg train loss = 3.1784\n",
            "Step 200 avg train loss = 3.1701\n",
            "Step 300 avg train loss = 3.1890\n",
            "Step 400 avg train loss = 3.1968\n",
            "Step 500 avg train loss = 3.2134\n",
            "Step 600 avg train loss = 3.2178\n",
            "Step 700 avg train loss = 3.2144\n",
            "Step 800 avg train loss = 3.2375\n",
            "Step 900 avg train loss = 3.2455\n",
            "Step 1000 avg train loss = 3.2681\n",
            "Step 1100 avg train loss = 3.2639\n",
            "Step 1200 avg train loss = 3.2868\n",
            "Step 1300 avg train loss = 3.2853\n",
            "Step 1400 avg train loss = 3.2861\n",
            "Step 1500 avg train loss = 3.2977\n",
            "Step 1600 avg train loss = 3.3114\n",
            "Step 1700 avg train loss = 3.3193\n",
            "Step 1800 avg train loss = 3.3016\n",
            "Step 1900 avg train loss = 3.3397\n",
            "Step 2000 avg train loss = 3.3420\n",
            "Step 2100 avg train loss = 3.3277\n",
            "Step 2200 avg train loss = 3.3378\n",
            "Step 2300 avg train loss = 3.3350\n",
            "Step 2400 avg train loss = 3.3512\n",
            "Validation loss after 17 epoch = 5.9951\n",
            "Step 0 avg train loss = 3.0336\n",
            "Step 100 avg train loss = 3.1353\n",
            "Step 200 avg train loss = 3.1264\n",
            "Step 300 avg train loss = 3.1186\n",
            "Step 400 avg train loss = 3.1541\n",
            "Step 500 avg train loss = 3.1671\n",
            "Step 600 avg train loss = 3.1556\n",
            "Step 700 avg train loss = 3.2066\n",
            "Step 800 avg train loss = 3.1836\n",
            "Step 900 avg train loss = 3.2164\n",
            "Step 1000 avg train loss = 3.2107\n",
            "Step 1100 avg train loss = 3.2105\n",
            "Step 1200 avg train loss = 3.2309\n",
            "Step 1300 avg train loss = 3.2257\n",
            "Step 1400 avg train loss = 3.2504\n",
            "Step 1500 avg train loss = 3.2449\n",
            "Step 1600 avg train loss = 3.2530\n",
            "Step 1700 avg train loss = 3.2546\n",
            "Step 1800 avg train loss = 3.2687\n",
            "Step 1900 avg train loss = 3.2740\n",
            "Step 2000 avg train loss = 3.2803\n",
            "Step 2100 avg train loss = 3.2730\n",
            "Step 2200 avg train loss = 3.3055\n",
            "Step 2300 avg train loss = 3.3069\n",
            "Step 2400 avg train loss = 3.2893\n",
            "Validation loss after 18 epoch = 6.0573\n",
            "Step 0 avg train loss = 2.9826\n",
            "Step 100 avg train loss = 3.1011\n",
            "Step 200 avg train loss = 3.0790\n",
            "Step 300 avg train loss = 3.1038\n",
            "Step 400 avg train loss = 3.0980\n",
            "Step 500 avg train loss = 3.1306\n",
            "Step 600 avg train loss = 3.1302\n",
            "Step 700 avg train loss = 3.1368\n",
            "Step 800 avg train loss = 3.1633\n",
            "Step 900 avg train loss = 3.1501\n",
            "Step 1000 avg train loss = 3.1537\n",
            "Step 1100 avg train loss = 3.1750\n",
            "Step 1200 avg train loss = 3.1863\n",
            "Step 1300 avg train loss = 3.1878\n",
            "Step 1400 avg train loss = 3.1940\n",
            "Step 1500 avg train loss = 3.2031\n",
            "Step 1600 avg train loss = 3.2004\n",
            "Step 1700 avg train loss = 3.1932\n",
            "Step 1800 avg train loss = 3.2144\n",
            "Step 1900 avg train loss = 3.1903\n",
            "Step 2000 avg train loss = 3.2335\n",
            "Step 2100 avg train loss = 3.2522\n",
            "Step 2200 avg train loss = 3.2534\n",
            "Step 2300 avg train loss = 3.2527\n",
            "Step 2400 avg train loss = 3.2656\n",
            "Validation loss after 19 epoch = 6.1049\n",
            "Saving best model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OPyqYWy08Bve",
        "outputId": "002ffbb5-89b5-4713-b58b-c27229979efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "epochs = np.array(list(range(len(plot_cache))))\n",
        "plt.plot(epochs, [2**(i[0]/np.log(2)) for i in plot_cache], label='Train ppl')\n",
        "plt.plot(epochs, [2**(i[1]/np.log(2)) for i in plot_cache], label='Valid ppl')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('PPL curves of tuned LSTM model')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VK8jRW5c8Bvj",
        "outputId": "1a803577-0fa6-4184-b8d3-3110bc75b830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "perp = [2**(i[1]/np.log(2)) for i in plot_cache] \n",
        "print('The minimum validation loss occurred at {} and it is {}'.format(perp.index(min(perp)),min(perp)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum validation loss occurred at 3 and it is 168.0075867791675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ps3DtmuR8Bvo"
      },
      "source": [
        "#### Results (LSTM vs. Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hbgtu3AL3wSr",
        "outputId": "58f751c5-5ab7-4a4e-b548-5c4b4ce030cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# first hyperparameter tuning: embedding dimension: 100 - 500\n",
        "\n",
        "\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "# single grid search for the hyperparameter tuning\n",
        "param_grid_emb = {\"embedding_size\": [100,200,300,400,500]}      \n",
        "\n",
        "# list of parameters=========== \n",
        "epoch_num = 20\n",
        "hidden_size = 128 # the second hyperparameter to be tuned. \n",
        "learning_rate=0.001\n",
        "# Loop over embedding size:\n",
        "for embedding_size in param_grid_emb[\"embedding_size\"]:\n",
        "  \n",
        "    embedding_size = embedding_size\n",
        "    hidden_size = hidden_size # output of dimension \n",
        "    num_layers = 2\n",
        "    lstm_dropout = 0.1\n",
        "    # input_size = lookup.weight.size(1)\n",
        "    vocab_size = len(train_dict)\n",
        "\n",
        "    options = {\n",
        "        'num_embeddings': len(train_dict),\n",
        "        'embedding_dim': embedding_size,\n",
        "        'padding_idx': train_dict.get_id('<pad>'),\n",
        "        'input_size': embedding_size,\n",
        "        'hidden_size': hidden_size,\n",
        "        'num_layers': num_layers,\n",
        "        'lstm_dropout': lstm_dropout,\n",
        "        'bias': True,\n",
        "        'bid': False \n",
        "    }\n",
        "\n",
        "    model = LSTMModel(options).to(current_device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=train_dict.get_id('<pad>'))\n",
        "    model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(model_parameters, lr=learning_rate)\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    plot_cache = []\n",
        "    min_val_loss = 20   # why is it 20??\n",
        "\n",
        "    for epoch_number in range(epoch_num):\n",
        "\n",
        "    # do train \n",
        "    avg_loss=0\n",
        "    if not load_pretrained:\n",
        "        model.train()\n",
        "        train_log_cache = []\n",
        "        for i, (inp, target) in enumerate(loaders['train']):\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_log_cache.append(loss.item())\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
        "                print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
        "                train_log_cache = []\n",
        "\n",
        "    #do valid\n",
        "    valid_losses = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(loaders['valid']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            valid_losses.append(loss.item())\n",
        "        avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
        "        print('Validation loss after {} epoch = {:.{prec}f}'.format(epoch_number, avg_val_loss, prec=4))\n",
        "        best = avg_val_loss < min_val_loss\n",
        "        if best:\n",
        "            min_val_loss = avg_val_loss\n",
        "            best_model = model\n",
        "\n",
        "    plot_cache.append((avg_loss, avg_val_loss))\n",
        "\n",
        "    if load_pretrained:\n",
        "        break\n",
        "\n",
        "# save the best model in this single grid search:         \n",
        "print('Saving best model with best embedding dimension...')\n",
        "torch.save({\n",
        "'options': options,\n",
        "'loss_cache': plot_cache,\n",
        "'model_dict': best_model.state_dict()\n",
        "        }, './emb_tune_best_LSTM.pt')\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 100, padding_idx=2)\n",
            "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=128, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4213\n",
            "Step 100 avg train loss = 7.8746\n",
            "Step 200 avg train loss = 7.1487\n",
            "Step 300 avg train loss = 6.9989\n",
            "Step 400 avg train loss = 6.8819\n",
            "Step 500 avg train loss = 6.7695\n",
            "Step 600 avg train loss = 6.6904\n",
            "Step 700 avg train loss = 6.6061\n",
            "Step 800 avg train loss = 6.5169\n",
            "Step 900 avg train loss = 6.4813\n",
            "Step 1000 avg train loss = 6.4483\n",
            "Step 1100 avg train loss = 6.3791\n",
            "Step 1200 avg train loss = 6.3451\n",
            "Step 1300 avg train loss = 6.3354\n",
            "Step 1400 avg train loss = 6.2372\n",
            "Step 1500 avg train loss = 6.2236\n",
            "Step 1600 avg train loss = 6.1985\n",
            "Step 1700 avg train loss = 6.1570\n",
            "Step 1800 avg train loss = 6.1361\n",
            "Step 1900 avg train loss = 6.1115\n",
            "Step 2000 avg train loss = 6.0735\n",
            "Step 2100 avg train loss = 6.0716\n",
            "Step 2200 avg train loss = 6.0352\n",
            "Step 2300 avg train loss = 6.0043\n",
            "Step 2400 avg train loss = 5.9858\n",
            "Validation loss after 0 epoch = 5.8060\n",
            "Step 0 avg train loss = 5.9210\n",
            "Step 100 avg train loss = 5.8924\n",
            "Step 200 avg train loss = 5.8761\n",
            "Step 300 avg train loss = 5.8770\n",
            "Step 400 avg train loss = 5.8671\n",
            "Step 500 avg train loss = 5.8507\n",
            "Step 600 avg train loss = 5.8032\n",
            "Step 700 avg train loss = 5.8165\n",
            "Step 800 avg train loss = 5.7875\n",
            "Step 900 avg train loss = 5.7804\n",
            "Step 1000 avg train loss = 5.7752\n",
            "Step 1100 avg train loss = 5.7494\n",
            "Step 1200 avg train loss = 5.7438\n",
            "Step 1300 avg train loss = 5.7528\n",
            "Step 1400 avg train loss = 5.7070\n",
            "Step 1500 avg train loss = 5.7132\n",
            "Step 1600 avg train loss = 5.6873\n",
            "Step 1700 avg train loss = 5.6781\n",
            "Step 1800 avg train loss = 5.6919\n",
            "Step 1900 avg train loss = 5.6888\n",
            "Step 2000 avg train loss = 5.6731\n",
            "Step 2100 avg train loss = 5.6440\n",
            "Step 2200 avg train loss = 5.6168\n",
            "Step 2300 avg train loss = 5.6168\n",
            "Step 2400 avg train loss = 5.6350\n",
            "Validation loss after 1 epoch = 5.5183\n",
            "Step 0 avg train loss = 5.2898\n",
            "Step 100 avg train loss = 5.5252\n",
            "Step 200 avg train loss = 5.5130\n",
            "Step 300 avg train loss = 5.4821\n",
            "Step 400 avg train loss = 5.5221\n",
            "Step 500 avg train loss = 5.5088\n",
            "Step 600 avg train loss = 5.4730\n",
            "Step 700 avg train loss = 5.4989\n",
            "Step 800 avg train loss = 5.4681\n",
            "Step 900 avg train loss = 5.4549\n",
            "Step 1000 avg train loss = 5.4655\n",
            "Step 1100 avg train loss = 5.4779\n",
            "Step 1200 avg train loss = 5.4838\n",
            "Step 1300 avg train loss = 5.4428\n",
            "Step 1400 avg train loss = 5.4224\n",
            "Step 1500 avg train loss = 5.4363\n",
            "Step 1600 avg train loss = 5.4266\n",
            "Step 1700 avg train loss = 5.4350\n",
            "Step 1800 avg train loss = 5.4167\n",
            "Step 1900 avg train loss = 5.4456\n",
            "Step 2000 avg train loss = 5.4338\n",
            "Step 2100 avg train loss = 5.3956\n",
            "Step 2200 avg train loss = 5.4055\n",
            "Step 2300 avg train loss = 5.3788\n",
            "Step 2400 avg train loss = 5.4058\n",
            "Validation loss after 2 epoch = 5.3863\n",
            "Step 0 avg train loss = 5.3325\n",
            "Step 100 avg train loss = 5.2772\n",
            "Step 200 avg train loss = 5.2860\n",
            "Step 300 avg train loss = 5.2600\n",
            "Step 400 avg train loss = 5.2802\n",
            "Step 500 avg train loss = 5.2665\n",
            "Step 600 avg train loss = 5.2443\n",
            "Step 700 avg train loss = 5.2463\n",
            "Step 800 avg train loss = 5.2773\n",
            "Step 900 avg train loss = 5.2569\n",
            "Step 1000 avg train loss = 5.2485\n",
            "Step 1100 avg train loss = 5.2619\n",
            "Step 1200 avg train loss = 5.2589\n",
            "Step 1300 avg train loss = 5.2629\n",
            "Step 1400 avg train loss = 5.2452\n",
            "Step 1500 avg train loss = 5.2442\n",
            "Step 1600 avg train loss = 5.2689\n",
            "Step 1700 avg train loss = 5.2641\n",
            "Step 1800 avg train loss = 5.2548\n",
            "Step 1900 avg train loss = 5.2363\n",
            "Step 2000 avg train loss = 5.2428\n",
            "Step 2100 avg train loss = 5.2338\n",
            "Step 2200 avg train loss = 5.2127\n",
            "Step 2300 avg train loss = 5.2210\n",
            "Step 2400 avg train loss = 5.2042\n",
            "Validation loss after 3 epoch = 5.3096\n",
            "Step 0 avg train loss = 4.8802\n",
            "Step 100 avg train loss = 5.1177\n",
            "Step 200 avg train loss = 5.1024\n",
            "Step 300 avg train loss = 5.1025\n",
            "Step 400 avg train loss = 5.1164\n",
            "Step 500 avg train loss = 5.1124\n",
            "Step 600 avg train loss = 5.1118\n",
            "Step 700 avg train loss = 5.1105\n",
            "Step 800 avg train loss = 5.1044\n",
            "Step 900 avg train loss = 5.0983\n",
            "Step 1000 avg train loss = 5.1144\n",
            "Step 1100 avg train loss = 5.1187\n",
            "Step 1200 avg train loss = 5.1188\n",
            "Step 1300 avg train loss = 5.0738\n",
            "Step 1400 avg train loss = 5.0609\n",
            "Step 1500 avg train loss = 5.0963\n",
            "Step 1600 avg train loss = 5.0890\n",
            "Step 1700 avg train loss = 5.1065\n",
            "Step 1800 avg train loss = 5.0918\n",
            "Step 1900 avg train loss = 5.0748\n",
            "Step 2000 avg train loss = 5.0908\n",
            "Step 2100 avg train loss = 5.0621\n",
            "Step 2200 avg train loss = 5.1015\n",
            "Step 2300 avg train loss = 5.0835\n",
            "Step 2400 avg train loss = 5.1103\n",
            "Validation loss after 4 epoch = 5.2752\n",
            "Step 0 avg train loss = 4.7336\n",
            "Step 100 avg train loss = 4.9430\n",
            "Step 200 avg train loss = 4.9663\n",
            "Step 300 avg train loss = 4.9658\n",
            "Step 400 avg train loss = 4.9664\n",
            "Step 500 avg train loss = 4.9587\n",
            "Step 600 avg train loss = 4.9794\n",
            "Step 700 avg train loss = 4.9756\n",
            "Step 800 avg train loss = 4.9788\n",
            "Step 900 avg train loss = 4.9832\n",
            "Step 1000 avg train loss = 4.9915\n",
            "Step 1100 avg train loss = 4.9797\n",
            "Step 1200 avg train loss = 4.9717\n",
            "Step 1300 avg train loss = 4.9927\n",
            "Step 1400 avg train loss = 4.9951\n",
            "Step 1500 avg train loss = 4.9762\n",
            "Step 1600 avg train loss = 4.9692\n",
            "Step 1700 avg train loss = 4.9871\n",
            "Step 1800 avg train loss = 4.9658\n",
            "Step 1900 avg train loss = 4.9636\n",
            "Step 2000 avg train loss = 4.9914\n",
            "Step 2100 avg train loss = 4.9707\n",
            "Step 2200 avg train loss = 4.9736\n",
            "Step 2300 avg train loss = 4.9931\n",
            "Step 2400 avg train loss = 4.9727\n",
            "Validation loss after 5 epoch = 5.2612\n",
            "Step 0 avg train loss = 4.9070\n",
            "Step 100 avg train loss = 4.8496\n",
            "Step 200 avg train loss = 4.8462\n",
            "Step 300 avg train loss = 4.8680\n",
            "Step 400 avg train loss = 4.8684\n",
            "Step 500 avg train loss = 4.8638\n",
            "Step 600 avg train loss = 4.8692\n",
            "Step 700 avg train loss = 4.8554\n",
            "Step 800 avg train loss = 4.8742\n",
            "Step 900 avg train loss = 4.8756\n",
            "Step 1000 avg train loss = 4.8830\n",
            "Step 1100 avg train loss = 4.8991\n",
            "Step 1200 avg train loss = 4.8882\n",
            "Step 1300 avg train loss = 4.8722\n",
            "Step 1400 avg train loss = 4.8845\n",
            "Step 1500 avg train loss = 4.8755\n",
            "Step 1600 avg train loss = 4.8785\n",
            "Step 1700 avg train loss = 4.8972\n",
            "Step 1800 avg train loss = 4.8711\n",
            "Step 1900 avg train loss = 4.8826\n",
            "Step 2000 avg train loss = 4.8773\n",
            "Step 2100 avg train loss = 4.8837\n",
            "Step 2200 avg train loss = 4.8666\n",
            "Step 2300 avg train loss = 4.8724\n",
            "Step 2400 avg train loss = 4.8667\n",
            "Validation loss after 6 epoch = 5.2549\n",
            "Step 0 avg train loss = 4.9683\n",
            "Step 100 avg train loss = 4.7569\n",
            "Step 200 avg train loss = 4.7748\n",
            "Step 300 avg train loss = 4.7621\n",
            "Step 400 avg train loss = 4.7830\n",
            "Step 500 avg train loss = 4.7746\n",
            "Step 600 avg train loss = 4.7811\n",
            "Step 700 avg train loss = 4.7867\n",
            "Step 800 avg train loss = 4.7782\n",
            "Step 900 avg train loss = 4.7891\n",
            "Step 1000 avg train loss = 4.7958\n",
            "Step 1100 avg train loss = 4.7838\n",
            "Step 1200 avg train loss = 4.7977\n",
            "Step 1300 avg train loss = 4.7782\n",
            "Step 1400 avg train loss = 4.8013\n",
            "Step 1500 avg train loss = 4.8037\n",
            "Step 1600 avg train loss = 4.8004\n",
            "Step 1700 avg train loss = 4.7862\n",
            "Step 1800 avg train loss = 4.7852\n",
            "Step 1900 avg train loss = 4.7985\n",
            "Step 2000 avg train loss = 4.7969\n",
            "Step 2100 avg train loss = 4.7974\n",
            "Step 2200 avg train loss = 4.7890\n",
            "Step 2300 avg train loss = 4.7932\n",
            "Step 2400 avg train loss = 4.8149\n",
            "Validation loss after 7 epoch = 5.2613\n",
            "Step 0 avg train loss = 4.7626\n",
            "Step 100 avg train loss = 4.6603\n",
            "Step 200 avg train loss = 4.6610\n",
            "Step 300 avg train loss = 4.6759\n",
            "Step 400 avg train loss = 4.6923\n",
            "Step 500 avg train loss = 4.7105\n",
            "Step 600 avg train loss = 4.7110\n",
            "Step 700 avg train loss = 4.6866\n",
            "Step 800 avg train loss = 4.7092\n",
            "Step 900 avg train loss = 4.6980\n",
            "Step 1000 avg train loss = 4.6930\n",
            "Step 1100 avg train loss = 4.7068\n",
            "Step 1200 avg train loss = 4.7120\n",
            "Step 1300 avg train loss = 4.7182\n",
            "Step 1400 avg train loss = 4.7141\n",
            "Step 1500 avg train loss = 4.7250\n",
            "Step 1600 avg train loss = 4.7170\n",
            "Step 1700 avg train loss = 4.7178\n",
            "Step 1800 avg train loss = 4.7172\n",
            "Step 1900 avg train loss = 4.7579\n",
            "Step 2000 avg train loss = 4.7407\n",
            "Step 2100 avg train loss = 4.7469\n",
            "Step 2200 avg train loss = 4.7218\n",
            "Step 2300 avg train loss = 4.7487\n",
            "Step 2400 avg train loss = 4.7335\n",
            "Validation loss after 8 epoch = 5.2732\n",
            "Step 0 avg train loss = 4.2264\n",
            "Step 100 avg train loss = 4.5932\n",
            "Step 200 avg train loss = 4.6094\n",
            "Step 300 avg train loss = 4.6086\n",
            "Step 400 avg train loss = 4.6216\n",
            "Step 500 avg train loss = 4.6283\n",
            "Step 600 avg train loss = 4.6185\n",
            "Step 700 avg train loss = 4.6355\n",
            "Step 800 avg train loss = 4.6510\n",
            "Step 900 avg train loss = 4.6355\n",
            "Step 1000 avg train loss = 4.6416\n",
            "Step 1100 avg train loss = 4.6430\n",
            "Step 1200 avg train loss = 4.6357\n",
            "Step 1300 avg train loss = 4.6544\n",
            "Step 1400 avg train loss = 4.6548\n",
            "Step 1500 avg train loss = 4.6553\n",
            "Step 1600 avg train loss = 4.6641\n",
            "Step 1700 avg train loss = 4.6564\n",
            "Step 1800 avg train loss = 4.6535\n",
            "Step 1900 avg train loss = 4.6741\n",
            "Step 2000 avg train loss = 4.6606\n",
            "Step 2100 avg train loss = 4.6679\n",
            "Step 2200 avg train loss = 4.6566\n",
            "Step 2300 avg train loss = 4.6698\n",
            "Step 2400 avg train loss = 4.6707\n",
            "Validation loss after 9 epoch = 5.2908\n",
            "Step 0 avg train loss = 4.3609\n",
            "Step 100 avg train loss = 4.5336\n",
            "Step 200 avg train loss = 4.5316\n",
            "Step 300 avg train loss = 4.5584\n",
            "Step 400 avg train loss = 4.5622\n",
            "Step 500 avg train loss = 4.5577\n",
            "Step 600 avg train loss = 4.5820\n",
            "Step 700 avg train loss = 4.5767\n",
            "Step 800 avg train loss = 4.5726\n",
            "Step 900 avg train loss = 4.5919\n",
            "Step 1000 avg train loss = 4.5902\n",
            "Step 1100 avg train loss = 4.5911\n",
            "Step 1200 avg train loss = 4.5693\n",
            "Step 1300 avg train loss = 4.6063\n",
            "Step 1400 avg train loss = 4.5837\n",
            "Step 1500 avg train loss = 4.5770\n",
            "Step 1600 avg train loss = 4.6167\n",
            "Step 1700 avg train loss = 4.6097\n",
            "Step 1800 avg train loss = 4.5910\n",
            "Step 1900 avg train loss = 4.5874\n",
            "Step 2000 avg train loss = 4.5941\n",
            "Step 2100 avg train loss = 4.6049\n",
            "Step 2200 avg train loss = 4.6131\n",
            "Step 2300 avg train loss = 4.6140\n",
            "Step 2400 avg train loss = 4.6092\n",
            "Validation loss after 10 epoch = 5.3071\n",
            "Step 0 avg train loss = 4.5234\n",
            "Step 100 avg train loss = 4.4774\n",
            "Step 200 avg train loss = 4.4867\n",
            "Step 300 avg train loss = 4.5109\n",
            "Step 400 avg train loss = 4.5060\n",
            "Step 500 avg train loss = 4.4964\n",
            "Step 600 avg train loss = 4.4925\n",
            "Step 700 avg train loss = 4.5249\n",
            "Step 800 avg train loss = 4.5542\n",
            "Step 900 avg train loss = 4.5296\n",
            "Step 1000 avg train loss = 4.5133\n",
            "Step 1100 avg train loss = 4.5333\n",
            "Step 1200 avg train loss = 4.5208\n",
            "Step 1300 avg train loss = 4.5406\n",
            "Step 1400 avg train loss = 4.5366\n",
            "Step 1500 avg train loss = 4.5508\n",
            "Step 1600 avg train loss = 4.5247\n",
            "Step 1700 avg train loss = 4.5251\n",
            "Step 1800 avg train loss = 4.5395\n",
            "Step 1900 avg train loss = 4.5391\n",
            "Step 2000 avg train loss = 4.5513\n",
            "Step 2100 avg train loss = 4.5668\n",
            "Step 2200 avg train loss = 4.5612\n",
            "Step 2300 avg train loss = 4.5668\n",
            "Step 2400 avg train loss = 4.5683\n",
            "Validation loss after 11 epoch = 5.3244\n",
            "Step 0 avg train loss = 4.6189\n",
            "Step 100 avg train loss = 4.4407\n",
            "Step 200 avg train loss = 4.4447\n",
            "Step 300 avg train loss = 4.4481\n",
            "Step 400 avg train loss = 4.4525\n",
            "Step 500 avg train loss = 4.4532\n",
            "Step 600 avg train loss = 4.4556\n",
            "Step 700 avg train loss = 4.4450\n",
            "Step 800 avg train loss = 4.4729\n",
            "Step 900 avg train loss = 4.4709\n",
            "Step 1000 avg train loss = 4.4684\n",
            "Step 1100 avg train loss = 4.4602\n",
            "Step 1200 avg train loss = 4.4782\n",
            "Step 1300 avg train loss = 4.4995\n",
            "Step 1400 avg train loss = 4.4816\n",
            "Step 1500 avg train loss = 4.4980\n",
            "Step 1600 avg train loss = 4.4720\n",
            "Step 1700 avg train loss = 4.4893\n",
            "Step 1800 avg train loss = 4.4811\n",
            "Step 1900 avg train loss = 4.5094\n",
            "Step 2000 avg train loss = 4.5121\n",
            "Step 2100 avg train loss = 4.5122\n",
            "Step 2200 avg train loss = 4.5054\n",
            "Step 2300 avg train loss = 4.5327\n",
            "Step 2400 avg train loss = 4.5322\n",
            "Validation loss after 12 epoch = 5.3482\n",
            "Step 0 avg train loss = 4.5102\n",
            "Step 100 avg train loss = 4.3774\n",
            "Step 200 avg train loss = 4.4062\n",
            "Step 300 avg train loss = 4.3978\n",
            "Step 400 avg train loss = 4.4094\n",
            "Step 500 avg train loss = 4.3967\n",
            "Step 600 avg train loss = 4.4133\n",
            "Step 700 avg train loss = 4.4134\n",
            "Step 800 avg train loss = 4.3941\n",
            "Step 900 avg train loss = 4.4223\n",
            "Step 1000 avg train loss = 4.4277\n",
            "Step 1100 avg train loss = 4.4349\n",
            "Step 1200 avg train loss = 4.4507\n",
            "Step 1300 avg train loss = 4.4455\n",
            "Step 1400 avg train loss = 4.4516\n",
            "Step 1500 avg train loss = 4.4522\n",
            "Step 1600 avg train loss = 4.4395\n",
            "Step 1700 avg train loss = 4.4390\n",
            "Step 1800 avg train loss = 4.4805\n",
            "Step 1900 avg train loss = 4.4753\n",
            "Step 2000 avg train loss = 4.4691\n",
            "Step 2100 avg train loss = 4.4474\n",
            "Step 2200 avg train loss = 4.4603\n",
            "Step 2300 avg train loss = 4.4719\n",
            "Step 2400 avg train loss = 4.4617\n",
            "Validation loss after 13 epoch = 5.3702\n",
            "Step 0 avg train loss = 4.5009\n",
            "Step 100 avg train loss = 4.3261\n",
            "Step 200 avg train loss = 4.3439\n",
            "Step 300 avg train loss = 4.3785\n",
            "Step 400 avg train loss = 4.3482\n",
            "Step 500 avg train loss = 4.3721\n",
            "Step 600 avg train loss = 4.3677\n",
            "Step 700 avg train loss = 4.3822\n",
            "Step 800 avg train loss = 4.3751\n",
            "Step 900 avg train loss = 4.3660\n",
            "Step 1000 avg train loss = 4.3929\n",
            "Step 1100 avg train loss = 4.3891\n",
            "Step 1200 avg train loss = 4.4001\n",
            "Step 1300 avg train loss = 4.4061\n",
            "Step 1400 avg train loss = 4.3954\n",
            "Step 1500 avg train loss = 4.3983\n",
            "Step 1600 avg train loss = 4.4164\n",
            "Step 1700 avg train loss = 4.4249\n",
            "Step 1800 avg train loss = 4.4160\n",
            "Step 1900 avg train loss = 4.4266\n",
            "Step 2000 avg train loss = 4.4438\n",
            "Step 2100 avg train loss = 4.4120\n",
            "Step 2200 avg train loss = 4.3997\n",
            "Step 2300 avg train loss = 4.4218\n",
            "Step 2400 avg train loss = 4.4174\n",
            "Validation loss after 14 epoch = 5.3874\n",
            "Step 0 avg train loss = 4.2326\n",
            "Step 100 avg train loss = 4.3039\n",
            "Step 200 avg train loss = 4.2992\n",
            "Step 300 avg train loss = 4.3161\n",
            "Step 400 avg train loss = 4.3237\n",
            "Step 500 avg train loss = 4.3170\n",
            "Step 600 avg train loss = 4.3386\n",
            "Step 700 avg train loss = 4.3483\n",
            "Step 800 avg train loss = 4.3323\n",
            "Step 900 avg train loss = 4.3385\n",
            "Step 1000 avg train loss = 4.3675\n",
            "Step 1100 avg train loss = 4.3489\n",
            "Step 1200 avg train loss = 4.3481\n",
            "Step 1300 avg train loss = 4.3677\n",
            "Step 1400 avg train loss = 4.3548\n",
            "Step 1500 avg train loss = 4.3598\n",
            "Step 1600 avg train loss = 4.3679\n",
            "Step 1700 avg train loss = 4.3411\n",
            "Step 1800 avg train loss = 4.3936\n",
            "Step 1900 avg train loss = 4.3764\n",
            "Step 2000 avg train loss = 4.3731\n",
            "Step 2100 avg train loss = 4.3836\n",
            "Step 2200 avg train loss = 4.3778\n",
            "Step 2300 avg train loss = 4.4034\n",
            "Step 2400 avg train loss = 4.3864\n",
            "Validation loss after 15 epoch = 5.4136\n",
            "Step 0 avg train loss = 4.2984\n",
            "Step 100 avg train loss = 4.2669\n",
            "Step 200 avg train loss = 4.2530\n",
            "Step 300 avg train loss = 4.2793\n",
            "Step 400 avg train loss = 4.2854\n",
            "Step 500 avg train loss = 4.3026\n",
            "Step 600 avg train loss = 4.2912\n",
            "Step 700 avg train loss = 4.2836\n",
            "Step 800 avg train loss = 4.2947\n",
            "Step 900 avg train loss = 4.3052\n",
            "Step 1000 avg train loss = 4.2963\n",
            "Step 1100 avg train loss = 4.3239\n",
            "Step 1200 avg train loss = 4.3211\n",
            "Step 1300 avg train loss = 4.2995\n",
            "Step 1400 avg train loss = 4.3260\n",
            "Step 1500 avg train loss = 4.3411\n",
            "Step 1600 avg train loss = 4.3345\n",
            "Step 1700 avg train loss = 4.3502\n",
            "Step 1800 avg train loss = 4.3376\n",
            "Step 1900 avg train loss = 4.3567\n",
            "Step 2000 avg train loss = 4.3515\n",
            "Step 2100 avg train loss = 4.3368\n",
            "Step 2200 avg train loss = 4.3526\n",
            "Step 2300 avg train loss = 4.3681\n",
            "Step 2400 avg train loss = 4.3282\n",
            "Validation loss after 16 epoch = 5.4343\n",
            "Step 0 avg train loss = 4.1605\n",
            "Step 100 avg train loss = 4.2267\n",
            "Step 200 avg train loss = 4.2250\n",
            "Step 300 avg train loss = 4.2411\n",
            "Step 400 avg train loss = 4.2660\n",
            "Step 500 avg train loss = 4.2262\n",
            "Step 600 avg train loss = 4.2590\n",
            "Step 700 avg train loss = 4.2621\n",
            "Step 800 avg train loss = 4.2726\n",
            "Step 900 avg train loss = 4.2636\n",
            "Step 1000 avg train loss = 4.2787\n",
            "Step 1100 avg train loss = 4.2690\n",
            "Step 1200 avg train loss = 4.2664\n",
            "Step 1300 avg train loss = 4.2884\n",
            "Step 1400 avg train loss = 4.3142\n",
            "Step 1500 avg train loss = 4.2918\n",
            "Step 1600 avg train loss = 4.2721\n",
            "Step 1700 avg train loss = 4.2999\n",
            "Step 1800 avg train loss = 4.2989\n",
            "Step 1900 avg train loss = 4.3143\n",
            "Step 2000 avg train loss = 4.2947\n",
            "Step 2100 avg train loss = 4.3045\n",
            "Step 2200 avg train loss = 4.3129\n",
            "Step 2300 avg train loss = 4.3625\n",
            "Step 2400 avg train loss = 4.3251\n",
            "Validation loss after 17 epoch = 5.4610\n",
            "Step 0 avg train loss = 4.2360\n",
            "Step 100 avg train loss = 4.1870\n",
            "Step 200 avg train loss = 4.1929\n",
            "Step 300 avg train loss = 4.2190\n",
            "Step 400 avg train loss = 4.1917\n",
            "Step 500 avg train loss = 4.2137\n",
            "Step 600 avg train loss = 4.2025\n",
            "Step 700 avg train loss = 4.2336\n",
            "Step 800 avg train loss = 4.2289\n",
            "Step 900 avg train loss = 4.2205\n",
            "Step 1000 avg train loss = 4.2273\n",
            "Step 1100 avg train loss = 4.2746\n",
            "Step 1200 avg train loss = 4.2316\n",
            "Step 1300 avg train loss = 4.2392\n",
            "Step 1400 avg train loss = 4.2620\n",
            "Step 1500 avg train loss = 4.2703\n",
            "Step 1600 avg train loss = 4.2682\n",
            "Step 1700 avg train loss = 4.2784\n",
            "Step 1800 avg train loss = 4.2766\n",
            "Step 1900 avg train loss = 4.2842\n",
            "Step 2000 avg train loss = 4.2974\n",
            "Step 2100 avg train loss = 4.2884\n",
            "Step 2200 avg train loss = 4.2990\n",
            "Step 2300 avg train loss = 4.2737\n",
            "Step 2400 avg train loss = 4.3108\n",
            "Validation loss after 18 epoch = 5.4789\n",
            "Step 0 avg train loss = 4.2661\n",
            "Step 100 avg train loss = 4.1634\n",
            "Step 200 avg train loss = 4.1750\n",
            "Step 300 avg train loss = 4.1774\n",
            "Step 400 avg train loss = 4.1695\n",
            "Step 500 avg train loss = 4.1819\n",
            "Step 600 avg train loss = 4.1751\n",
            "Step 700 avg train loss = 4.1987\n",
            "Step 800 avg train loss = 4.2052\n",
            "Step 900 avg train loss = 4.2081\n",
            "Step 1000 avg train loss = 4.1995\n",
            "Step 1100 avg train loss = 4.2407\n",
            "Step 1200 avg train loss = 4.2215\n",
            "Step 1300 avg train loss = 4.2203\n",
            "Step 1400 avg train loss = 4.2317\n",
            "Step 1500 avg train loss = 4.2465\n",
            "Step 1600 avg train loss = 4.2369\n",
            "Step 1700 avg train loss = 4.2419\n",
            "Step 1800 avg train loss = 4.2411\n",
            "Step 1900 avg train loss = 4.2564\n",
            "Step 2000 avg train loss = 4.2516\n",
            "Step 2100 avg train loss = 4.2519\n",
            "Step 2200 avg train loss = 4.2472\n",
            "Step 2300 avg train loss = 4.2614\n",
            "Step 2400 avg train loss = 4.2573\n",
            "Validation loss after 19 epoch = 5.5068\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 200, padding_idx=2)\n",
            "  (lstm): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=128, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4072\n",
            "Step 100 avg train loss = 7.8734\n",
            "Step 200 avg train loss = 7.1471\n",
            "Step 300 avg train loss = 6.9900\n",
            "Step 400 avg train loss = 6.8690\n",
            "Step 500 avg train loss = 6.7549\n",
            "Step 600 avg train loss = 6.6119\n",
            "Step 700 avg train loss = 6.5381\n",
            "Step 800 avg train loss = 6.4657\n",
            "Step 900 avg train loss = 6.4130\n",
            "Step 1000 avg train loss = 6.3581\n",
            "Step 1100 avg train loss = 6.3145\n",
            "Step 1200 avg train loss = 6.2397\n",
            "Step 1300 avg train loss = 6.2099\n",
            "Step 1400 avg train loss = 6.1619\n",
            "Step 1500 avg train loss = 6.1458\n",
            "Step 1600 avg train loss = 6.1025\n",
            "Step 1700 avg train loss = 6.0803\n",
            "Step 1800 avg train loss = 6.0359\n",
            "Step 1900 avg train loss = 6.0127\n",
            "Step 2000 avg train loss = 5.9815\n",
            "Step 2100 avg train loss = 5.9464\n",
            "Step 2200 avg train loss = 5.9454\n",
            "Step 2300 avg train loss = 5.9100\n",
            "Step 2400 avg train loss = 5.9083\n",
            "Validation loss after 0 epoch = 5.7213\n",
            "Step 0 avg train loss = 5.7127\n",
            "Step 100 avg train loss = 5.7983\n",
            "Step 200 avg train loss = 5.7793\n",
            "Step 300 avg train loss = 5.7620\n",
            "Step 400 avg train loss = 5.7586\n",
            "Step 500 avg train loss = 5.7486\n",
            "Step 600 avg train loss = 5.7258\n",
            "Step 700 avg train loss = 5.7270\n",
            "Step 800 avg train loss = 5.7068\n",
            "Step 900 avg train loss = 5.6857\n",
            "Step 1000 avg train loss = 5.6785\n",
            "Step 1100 avg train loss = 5.6672\n",
            "Step 1200 avg train loss = 5.6578\n",
            "Step 1300 avg train loss = 5.6541\n",
            "Step 1400 avg train loss = 5.6405\n",
            "Step 1500 avg train loss = 5.6194\n",
            "Step 1600 avg train loss = 5.6212\n",
            "Step 1700 avg train loss = 5.5919\n",
            "Step 1800 avg train loss = 5.5986\n",
            "Step 1900 avg train loss = 5.5820\n",
            "Step 2000 avg train loss = 5.5825\n",
            "Step 2100 avg train loss = 5.5540\n",
            "Step 2200 avg train loss = 5.5547\n",
            "Step 2300 avg train loss = 5.5617\n",
            "Step 2400 avg train loss = 5.5197\n",
            "Validation loss after 1 epoch = 5.4519\n",
            "Step 0 avg train loss = 5.3700\n",
            "Step 100 avg train loss = 5.4337\n",
            "Step 200 avg train loss = 5.3993\n",
            "Step 300 avg train loss = 5.4125\n",
            "Step 400 avg train loss = 5.4128\n",
            "Step 500 avg train loss = 5.4004\n",
            "Step 600 avg train loss = 5.4129\n",
            "Step 700 avg train loss = 5.3832\n",
            "Step 800 avg train loss = 5.3888\n",
            "Step 900 avg train loss = 5.3802\n",
            "Step 1000 avg train loss = 5.4008\n",
            "Step 1100 avg train loss = 5.3652\n",
            "Step 1200 avg train loss = 5.3819\n",
            "Step 1300 avg train loss = 5.3645\n",
            "Step 1400 avg train loss = 5.3651\n",
            "Step 1500 avg train loss = 5.3479\n",
            "Step 1600 avg train loss = 5.3501\n",
            "Step 1700 avg train loss = 5.3341\n",
            "Step 1800 avg train loss = 5.3439\n",
            "Step 1900 avg train loss = 5.3335\n",
            "Step 2000 avg train loss = 5.3543\n",
            "Step 2100 avg train loss = 5.3197\n",
            "Step 2200 avg train loss = 5.3092\n",
            "Step 2300 avg train loss = 5.3198\n",
            "Step 2400 avg train loss = 5.3211\n",
            "Validation loss after 2 epoch = 5.3333\n",
            "Step 0 avg train loss = 5.1641\n",
            "Step 100 avg train loss = 5.1876\n",
            "Step 200 avg train loss = 5.1706\n",
            "Step 300 avg train loss = 5.1738\n",
            "Step 400 avg train loss = 5.1707\n",
            "Step 500 avg train loss = 5.1782\n",
            "Step 600 avg train loss = 5.1721\n",
            "Step 700 avg train loss = 5.1858\n",
            "Step 800 avg train loss = 5.1804\n",
            "Step 900 avg train loss = 5.1827\n",
            "Step 1000 avg train loss = 5.1771\n",
            "Step 1100 avg train loss = 5.1885\n",
            "Step 1200 avg train loss = 5.1812\n",
            "Step 1300 avg train loss = 5.1638\n",
            "Step 1400 avg train loss = 5.1602\n",
            "Step 1500 avg train loss = 5.1755\n",
            "Step 1600 avg train loss = 5.1627\n",
            "Step 1700 avg train loss = 5.1379\n",
            "Step 1800 avg train loss = 5.1525\n",
            "Step 1900 avg train loss = 5.1664\n",
            "Step 2000 avg train loss = 5.1349\n",
            "Step 2100 avg train loss = 5.1540\n",
            "Step 2200 avg train loss = 5.1496\n",
            "Step 2300 avg train loss = 5.1238\n",
            "Step 2400 avg train loss = 5.1435\n",
            "Validation loss after 3 epoch = 5.2613\n",
            "Step 0 avg train loss = 5.0862\n",
            "Step 100 avg train loss = 5.0027\n",
            "Step 200 avg train loss = 5.0167\n",
            "Step 300 avg train loss = 5.0061\n",
            "Step 400 avg train loss = 5.0147\n",
            "Step 500 avg train loss = 5.0007\n",
            "Step 600 avg train loss = 4.9987\n",
            "Step 700 avg train loss = 5.0205\n",
            "Step 800 avg train loss = 4.9979\n",
            "Step 900 avg train loss = 5.0138\n",
            "Step 1000 avg train loss = 5.0195\n",
            "Step 1100 avg train loss = 5.0022\n",
            "Step 1200 avg train loss = 5.0169\n",
            "Step 1300 avg train loss = 5.0220\n",
            "Step 1400 avg train loss = 5.0102\n",
            "Step 1500 avg train loss = 5.0159\n",
            "Step 1600 avg train loss = 5.0053\n",
            "Step 1700 avg train loss = 5.0121\n",
            "Step 1800 avg train loss = 5.0187\n",
            "Step 1900 avg train loss = 5.0028\n",
            "Step 2000 avg train loss = 5.0128\n",
            "Step 2100 avg train loss = 4.9970\n",
            "Step 2200 avg train loss = 5.0086\n",
            "Step 2300 avg train loss = 5.0139\n",
            "Step 2400 avg train loss = 4.9951\n",
            "Validation loss after 4 epoch = 5.2234\n",
            "Step 0 avg train loss = 4.7910\n",
            "Step 100 avg train loss = 4.8562\n",
            "Step 200 avg train loss = 4.8613\n",
            "Step 300 avg train loss = 4.8863\n",
            "Step 400 avg train loss = 4.8549\n",
            "Step 500 avg train loss = 4.8889\n",
            "Step 600 avg train loss = 4.8718\n",
            "Step 700 avg train loss = 4.8905\n",
            "Step 800 avg train loss = 4.8810\n",
            "Step 900 avg train loss = 4.8913\n",
            "Step 1000 avg train loss = 4.8911\n",
            "Step 1100 avg train loss = 4.8873\n",
            "Step 1200 avg train loss = 4.8806\n",
            "Step 1300 avg train loss = 4.8800\n",
            "Step 1400 avg train loss = 4.8919\n",
            "Step 1500 avg train loss = 4.8815\n",
            "Step 1600 avg train loss = 4.8875\n",
            "Step 1700 avg train loss = 4.8996\n",
            "Step 1800 avg train loss = 4.8842\n",
            "Step 1900 avg train loss = 4.8843\n",
            "Step 2000 avg train loss = 4.8781\n",
            "Step 2100 avg train loss = 4.8721\n",
            "Step 2200 avg train loss = 4.9032\n",
            "Step 2300 avg train loss = 4.8716\n",
            "Step 2400 avg train loss = 4.9014\n",
            "Validation loss after 5 epoch = 5.2085\n",
            "Step 0 avg train loss = 4.5154\n",
            "Step 100 avg train loss = 4.7395\n",
            "Step 200 avg train loss = 4.7420\n",
            "Step 300 avg train loss = 4.7591\n",
            "Step 400 avg train loss = 4.7462\n",
            "Step 500 avg train loss = 4.7480\n",
            "Step 600 avg train loss = 4.7729\n",
            "Step 700 avg train loss = 4.7864\n",
            "Step 800 avg train loss = 4.7813\n",
            "Step 900 avg train loss = 4.7982\n",
            "Step 1000 avg train loss = 4.7523\n",
            "Step 1100 avg train loss = 4.7426\n",
            "Step 1200 avg train loss = 4.7852\n",
            "Step 1300 avg train loss = 4.7630\n",
            "Step 1400 avg train loss = 4.7863\n",
            "Step 1500 avg train loss = 4.7631\n",
            "Step 1600 avg train loss = 4.7773\n",
            "Step 1700 avg train loss = 4.8014\n",
            "Step 1800 avg train loss = 4.7995\n",
            "Step 1900 avg train loss = 4.7921\n",
            "Step 2000 avg train loss = 4.7768\n",
            "Step 2100 avg train loss = 4.7744\n",
            "Step 2200 avg train loss = 4.8140\n",
            "Step 2300 avg train loss = 4.8047\n",
            "Step 2400 avg train loss = 4.8054\n",
            "Validation loss after 6 epoch = 5.2093\n",
            "Step 0 avg train loss = 4.5736\n",
            "Step 100 avg train loss = 4.6334\n",
            "Step 200 avg train loss = 4.6583\n",
            "Step 300 avg train loss = 4.6586\n",
            "Step 400 avg train loss = 4.6652\n",
            "Step 500 avg train loss = 4.6765\n",
            "Step 600 avg train loss = 4.6583\n",
            "Step 700 avg train loss = 4.6679\n",
            "Step 800 avg train loss = 4.6738\n",
            "Step 900 avg train loss = 4.6697\n",
            "Step 1000 avg train loss = 4.6871\n",
            "Step 1100 avg train loss = 4.6736\n",
            "Step 1200 avg train loss = 4.6892\n",
            "Step 1300 avg train loss = 4.6855\n",
            "Step 1400 avg train loss = 4.6756\n",
            "Step 1500 avg train loss = 4.7132\n",
            "Step 1600 avg train loss = 4.6891\n",
            "Step 1700 avg train loss = 4.7001\n",
            "Step 1800 avg train loss = 4.6795\n",
            "Step 1900 avg train loss = 4.7140\n",
            "Step 2000 avg train loss = 4.6911\n",
            "Step 2100 avg train loss = 4.6988\n",
            "Step 2200 avg train loss = 4.7135\n",
            "Step 2300 avg train loss = 4.7172\n",
            "Step 2400 avg train loss = 4.7030\n",
            "Validation loss after 7 epoch = 5.2206\n",
            "Step 0 avg train loss = 4.7209\n",
            "Step 100 avg train loss = 4.5570\n",
            "Step 200 avg train loss = 4.5865\n",
            "Step 300 avg train loss = 4.5709\n",
            "Step 400 avg train loss = 4.5668\n",
            "Step 500 avg train loss = 4.5801\n",
            "Step 600 avg train loss = 4.5937\n",
            "Step 700 avg train loss = 4.5678\n",
            "Step 800 avg train loss = 4.5914\n",
            "Step 900 avg train loss = 4.6029\n",
            "Step 1000 avg train loss = 4.5958\n",
            "Step 1100 avg train loss = 4.6013\n",
            "Step 1200 avg train loss = 4.6071\n",
            "Step 1300 avg train loss = 4.6439\n",
            "Step 1400 avg train loss = 4.6006\n",
            "Step 1500 avg train loss = 4.5940\n",
            "Step 1600 avg train loss = 4.6271\n",
            "Step 1700 avg train loss = 4.6006\n",
            "Step 1800 avg train loss = 4.6212\n",
            "Step 1900 avg train loss = 4.6221\n",
            "Step 2000 avg train loss = 4.6258\n",
            "Step 2100 avg train loss = 4.6108\n",
            "Step 2200 avg train loss = 4.6259\n",
            "Step 2300 avg train loss = 4.6351\n",
            "Step 2400 avg train loss = 4.6376\n",
            "Validation loss after 8 epoch = 5.2339\n",
            "Step 0 avg train loss = 4.5395\n",
            "Step 100 avg train loss = 4.4844\n",
            "Step 200 avg train loss = 4.4784\n",
            "Step 300 avg train loss = 4.5089\n",
            "Step 400 avg train loss = 4.4969\n",
            "Step 500 avg train loss = 4.5090\n",
            "Step 600 avg train loss = 4.5387\n",
            "Step 700 avg train loss = 4.5052\n",
            "Step 800 avg train loss = 4.5192\n",
            "Step 900 avg train loss = 4.5294\n",
            "Step 1000 avg train loss = 4.5147\n",
            "Step 1100 avg train loss = 4.5183\n",
            "Step 1200 avg train loss = 4.5238\n",
            "Step 1300 avg train loss = 4.5396\n",
            "Step 1400 avg train loss = 4.5302\n",
            "Step 1500 avg train loss = 4.5614\n",
            "Step 1600 avg train loss = 4.5436\n",
            "Step 1700 avg train loss = 4.5283\n",
            "Step 1800 avg train loss = 4.5534\n",
            "Step 1900 avg train loss = 4.5506\n",
            "Step 2000 avg train loss = 4.5634\n",
            "Step 2100 avg train loss = 4.5676\n",
            "Step 2200 avg train loss = 4.5539\n",
            "Step 2300 avg train loss = 4.5558\n",
            "Step 2400 avg train loss = 4.5609\n",
            "Validation loss after 9 epoch = 5.2535\n",
            "Step 0 avg train loss = 4.4260\n",
            "Step 100 avg train loss = 4.4039\n",
            "Step 200 avg train loss = 4.4179\n",
            "Step 300 avg train loss = 4.4186\n",
            "Step 400 avg train loss = 4.4270\n",
            "Step 500 avg train loss = 4.4493\n",
            "Step 600 avg train loss = 4.4389\n",
            "Step 700 avg train loss = 4.4444\n",
            "Step 800 avg train loss = 4.4455\n",
            "Step 900 avg train loss = 4.4573\n",
            "Step 1000 avg train loss = 4.4721\n",
            "Step 1100 avg train loss = 4.4426\n",
            "Step 1200 avg train loss = 4.4768\n",
            "Step 1300 avg train loss = 4.4696\n",
            "Step 1400 avg train loss = 4.4682\n",
            "Step 1500 avg train loss = 4.4698\n",
            "Step 1600 avg train loss = 4.5027\n",
            "Step 1700 avg train loss = 4.4927\n",
            "Step 1800 avg train loss = 4.4908\n",
            "Step 1900 avg train loss = 4.4720\n",
            "Step 2000 avg train loss = 4.4912\n",
            "Step 2100 avg train loss = 4.4981\n",
            "Step 2200 avg train loss = 4.4861\n",
            "Step 2300 avg train loss = 4.5120\n",
            "Step 2400 avg train loss = 4.5051\n",
            "Validation loss after 10 epoch = 5.2752\n",
            "Step 0 avg train loss = 4.1379\n",
            "Step 100 avg train loss = 4.3538\n",
            "Step 200 avg train loss = 4.3465\n",
            "Step 300 avg train loss = 4.3662\n",
            "Step 400 avg train loss = 4.3811\n",
            "Step 500 avg train loss = 4.3694\n",
            "Step 600 avg train loss = 4.3720\n",
            "Step 700 avg train loss = 4.3686\n",
            "Step 800 avg train loss = 4.3761\n",
            "Step 900 avg train loss = 4.3973\n",
            "Step 1000 avg train loss = 4.4346\n",
            "Step 1100 avg train loss = 4.4071\n",
            "Step 1200 avg train loss = 4.4056\n",
            "Step 1300 avg train loss = 4.4084\n",
            "Step 1400 avg train loss = 4.4134\n",
            "Step 1500 avg train loss = 4.4248\n",
            "Step 1600 avg train loss = 4.4239\n",
            "Step 1700 avg train loss = 4.4405\n",
            "Step 1800 avg train loss = 4.4399\n",
            "Step 1900 avg train loss = 4.4291\n",
            "Step 2000 avg train loss = 4.4387\n",
            "Step 2100 avg train loss = 4.4464\n",
            "Step 2200 avg train loss = 4.4417\n",
            "Step 2300 avg train loss = 4.4337\n",
            "Step 2400 avg train loss = 4.4449\n",
            "Validation loss after 11 epoch = 5.2981\n",
            "Step 0 avg train loss = 4.4015\n",
            "Step 100 avg train loss = 4.3116\n",
            "Step 200 avg train loss = 4.2860\n",
            "Step 300 avg train loss = 4.3145\n",
            "Step 400 avg train loss = 4.3321\n",
            "Step 500 avg train loss = 4.3110\n",
            "Step 600 avg train loss = 4.3394\n",
            "Step 700 avg train loss = 4.3310\n",
            "Step 800 avg train loss = 4.3234\n",
            "Step 900 avg train loss = 4.3438\n",
            "Step 1000 avg train loss = 4.3542\n",
            "Step 1100 avg train loss = 4.3503\n",
            "Step 1200 avg train loss = 4.3205\n",
            "Step 1300 avg train loss = 4.3513\n",
            "Step 1400 avg train loss = 4.3764\n",
            "Step 1500 avg train loss = 4.3456\n",
            "Step 1600 avg train loss = 4.3771\n",
            "Step 1700 avg train loss = 4.3615\n",
            "Step 1800 avg train loss = 4.3607\n",
            "Step 1900 avg train loss = 4.3651\n",
            "Step 2000 avg train loss = 4.4010\n",
            "Step 2100 avg train loss = 4.3963\n",
            "Step 2200 avg train loss = 4.4192\n",
            "Step 2300 avg train loss = 4.3878\n",
            "Step 2400 avg train loss = 4.3866\n",
            "Validation loss after 12 epoch = 5.3268\n",
            "Step 0 avg train loss = 4.1954\n",
            "Step 100 avg train loss = 4.2482\n",
            "Step 200 avg train loss = 4.2359\n",
            "Step 300 avg train loss = 4.2367\n",
            "Step 400 avg train loss = 4.2612\n",
            "Step 500 avg train loss = 4.2920\n",
            "Step 600 avg train loss = 4.2888\n",
            "Step 700 avg train loss = 4.2701\n",
            "Step 800 avg train loss = 4.2946\n",
            "Step 900 avg train loss = 4.3153\n",
            "Step 1000 avg train loss = 4.2971\n",
            "Step 1100 avg train loss = 4.2984\n",
            "Step 1200 avg train loss = 4.2932\n",
            "Step 1300 avg train loss = 4.3182\n",
            "Step 1400 avg train loss = 4.3139\n",
            "Step 1500 avg train loss = 4.3306\n",
            "Step 1600 avg train loss = 4.3260\n",
            "Step 1700 avg train loss = 4.3133\n",
            "Step 1800 avg train loss = 4.3404\n",
            "Step 1900 avg train loss = 4.3176\n",
            "Step 2000 avg train loss = 4.3522\n",
            "Step 2100 avg train loss = 4.3210\n",
            "Step 2200 avg train loss = 4.3386\n",
            "Step 2300 avg train loss = 4.3423\n",
            "Step 2400 avg train loss = 4.3232\n",
            "Validation loss after 13 epoch = 5.3515\n",
            "Step 0 avg train loss = 4.1868\n",
            "Step 100 avg train loss = 4.2284\n",
            "Step 200 avg train loss = 4.1772\n",
            "Step 300 avg train loss = 4.2114\n",
            "Step 400 avg train loss = 4.2367\n",
            "Step 500 avg train loss = 4.2289\n",
            "Step 600 avg train loss = 4.2441\n",
            "Step 700 avg train loss = 4.2209\n",
            "Step 800 avg train loss = 4.2631\n",
            "Step 900 avg train loss = 4.2440\n",
            "Step 1000 avg train loss = 4.2469\n",
            "Step 1100 avg train loss = 4.2578\n",
            "Step 1200 avg train loss = 4.2676\n",
            "Step 1300 avg train loss = 4.2573\n",
            "Step 1400 avg train loss = 4.2699\n",
            "Step 1500 avg train loss = 4.2751\n",
            "Step 1600 avg train loss = 4.2915\n",
            "Step 1700 avg train loss = 4.2617\n",
            "Step 1800 avg train loss = 4.2539\n",
            "Step 1900 avg train loss = 4.2760\n",
            "Step 2000 avg train loss = 4.2728\n",
            "Step 2100 avg train loss = 4.2873\n",
            "Step 2200 avg train loss = 4.2856\n",
            "Step 2300 avg train loss = 4.2880\n",
            "Step 2400 avg train loss = 4.2990\n",
            "Validation loss after 14 epoch = 5.3798\n",
            "Step 0 avg train loss = 3.9694\n",
            "Step 100 avg train loss = 4.1541\n",
            "Step 200 avg train loss = 4.1601\n",
            "Step 300 avg train loss = 4.1889\n",
            "Step 400 avg train loss = 4.1788\n",
            "Step 500 avg train loss = 4.1664\n",
            "Step 600 avg train loss = 4.1742\n",
            "Step 700 avg train loss = 4.2005\n",
            "Step 800 avg train loss = 4.2060\n",
            "Step 900 avg train loss = 4.2018\n",
            "Step 1000 avg train loss = 4.2024\n",
            "Step 1100 avg train loss = 4.2122\n",
            "Step 1200 avg train loss = 4.2456\n",
            "Step 1300 avg train loss = 4.2165\n",
            "Step 1400 avg train loss = 4.2209\n",
            "Step 1500 avg train loss = 4.2472\n",
            "Step 1600 avg train loss = 4.2171\n",
            "Step 1700 avg train loss = 4.2426\n",
            "Step 1800 avg train loss = 4.2255\n",
            "Step 1900 avg train loss = 4.2298\n",
            "Step 2000 avg train loss = 4.2223\n",
            "Step 2100 avg train loss = 4.2484\n",
            "Step 2200 avg train loss = 4.2681\n",
            "Step 2300 avg train loss = 4.2514\n",
            "Step 2400 avg train loss = 4.2473\n",
            "Validation loss after 15 epoch = 5.4066\n",
            "Step 0 avg train loss = 4.2376\n",
            "Step 100 avg train loss = 4.1166\n",
            "Step 200 avg train loss = 4.1233\n",
            "Step 300 avg train loss = 4.1392\n",
            "Step 400 avg train loss = 4.1489\n",
            "Step 500 avg train loss = 4.1407\n",
            "Step 600 avg train loss = 4.1554\n",
            "Step 700 avg train loss = 4.1312\n",
            "Step 800 avg train loss = 4.1651\n",
            "Step 900 avg train loss = 4.1784\n",
            "Step 1000 avg train loss = 4.1738\n",
            "Step 1100 avg train loss = 4.1455\n",
            "Step 1200 avg train loss = 4.1770\n",
            "Step 1300 avg train loss = 4.1742\n",
            "Step 1400 avg train loss = 4.1887\n",
            "Step 1500 avg train loss = 4.1778\n",
            "Step 1600 avg train loss = 4.1858\n",
            "Step 1700 avg train loss = 4.1826\n",
            "Step 1800 avg train loss = 4.1982\n",
            "Step 1900 avg train loss = 4.2017\n",
            "Step 2000 avg train loss = 4.2095\n",
            "Step 2100 avg train loss = 4.2138\n",
            "Step 2200 avg train loss = 4.2040\n",
            "Step 2300 avg train loss = 4.2178\n",
            "Step 2400 avg train loss = 4.2090\n",
            "Validation loss after 16 epoch = 5.4379\n",
            "Step 0 avg train loss = 4.0614\n",
            "Step 100 avg train loss = 4.0570\n",
            "Step 200 avg train loss = 4.0855\n",
            "Step 300 avg train loss = 4.0890\n",
            "Step 400 avg train loss = 4.1000\n",
            "Step 500 avg train loss = 4.1185\n",
            "Step 600 avg train loss = 4.0977\n",
            "Step 700 avg train loss = 4.1101\n",
            "Step 800 avg train loss = 4.1214\n",
            "Step 900 avg train loss = 4.1088\n",
            "Step 1000 avg train loss = 4.1242\n",
            "Step 1100 avg train loss = 4.1499\n",
            "Step 1200 avg train loss = 4.1463\n",
            "Step 1300 avg train loss = 4.1285\n",
            "Step 1400 avg train loss = 4.1380\n",
            "Step 1500 avg train loss = 4.1419\n",
            "Step 1600 avg train loss = 4.1527\n",
            "Step 1700 avg train loss = 4.1422\n",
            "Step 1800 avg train loss = 4.1489\n",
            "Step 1900 avg train loss = 4.1748\n",
            "Step 2000 avg train loss = 4.1730\n",
            "Step 2100 avg train loss = 4.1749\n",
            "Step 2200 avg train loss = 4.1967\n",
            "Step 2300 avg train loss = 4.1798\n",
            "Step 2400 avg train loss = 4.1927\n",
            "Validation loss after 17 epoch = 5.4691\n",
            "Step 0 avg train loss = 4.2660\n",
            "Step 100 avg train loss = 4.0254\n",
            "Step 200 avg train loss = 4.0464\n",
            "Step 300 avg train loss = 4.0588\n",
            "Step 400 avg train loss = 4.0721\n",
            "Step 500 avg train loss = 4.0575\n",
            "Step 600 avg train loss = 4.0670\n",
            "Step 700 avg train loss = 4.0978\n",
            "Step 800 avg train loss = 4.0892\n",
            "Step 900 avg train loss = 4.0724\n",
            "Step 1000 avg train loss = 4.1005\n",
            "Step 1100 avg train loss = 4.0947\n",
            "Step 1200 avg train loss = 4.1061\n",
            "Step 1300 avg train loss = 4.0877\n",
            "Step 1400 avg train loss = 4.1069\n",
            "Step 1500 avg train loss = 4.1205\n",
            "Step 1600 avg train loss = 4.1290\n",
            "Step 1700 avg train loss = 4.1129\n",
            "Step 1800 avg train loss = 4.1316\n",
            "Step 1900 avg train loss = 4.1349\n",
            "Step 2000 avg train loss = 4.1324\n",
            "Step 2100 avg train loss = 4.1205\n",
            "Step 2200 avg train loss = 4.1396\n",
            "Step 2300 avg train loss = 4.1578\n",
            "Step 2400 avg train loss = 4.1480\n",
            "Validation loss after 18 epoch = 5.4949\n",
            "Step 0 avg train loss = 4.0512\n",
            "Step 100 avg train loss = 3.9958\n",
            "Step 200 avg train loss = 4.0035\n",
            "Step 300 avg train loss = 4.0203\n",
            "Step 400 avg train loss = 4.0256\n",
            "Step 500 avg train loss = 4.0288\n",
            "Step 600 avg train loss = 4.0257\n",
            "Step 700 avg train loss = 4.0490\n",
            "Step 800 avg train loss = 4.0708\n",
            "Step 900 avg train loss = 4.0587\n",
            "Step 1000 avg train loss = 4.0584\n",
            "Step 1100 avg train loss = 4.0559\n",
            "Step 1200 avg train loss = 4.0658\n",
            "Step 1300 avg train loss = 4.0672\n",
            "Step 1400 avg train loss = 4.0846\n",
            "Step 1500 avg train loss = 4.0657\n",
            "Step 1600 avg train loss = 4.0857\n",
            "Step 1700 avg train loss = 4.1016\n",
            "Step 1800 avg train loss = 4.0952\n",
            "Step 1900 avg train loss = 4.1037\n",
            "Step 2000 avg train loss = 4.1114\n",
            "Step 2100 avg train loss = 4.0961\n",
            "Step 2200 avg train loss = 4.0982\n",
            "Step 2300 avg train loss = 4.0962\n",
            "Step 2400 avg train loss = 4.1322\n",
            "Validation loss after 19 epoch = 5.5245\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=128, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4132\n",
            "Step 100 avg train loss = 7.8714\n",
            "Step 200 avg train loss = 7.0718\n",
            "Step 300 avg train loss = 6.9174\n",
            "Step 400 avg train loss = 6.7383\n",
            "Step 500 avg train loss = 6.6138\n",
            "Step 600 avg train loss = 6.5480\n",
            "Step 700 avg train loss = 6.4684\n",
            "Step 800 avg train loss = 6.3962\n",
            "Step 900 avg train loss = 6.3300\n",
            "Step 1000 avg train loss = 6.2845\n",
            "Step 1100 avg train loss = 6.2470\n",
            "Step 1200 avg train loss = 6.1912\n",
            "Step 1300 avg train loss = 6.1466\n",
            "Step 1400 avg train loss = 6.0905\n",
            "Step 1500 avg train loss = 6.0833\n",
            "Step 1600 avg train loss = 6.0545\n",
            "Step 1700 avg train loss = 6.0238\n",
            "Step 1800 avg train loss = 6.0048\n",
            "Step 1900 avg train loss = 5.9594\n",
            "Step 2000 avg train loss = 5.9311\n",
            "Step 2100 avg train loss = 5.9381\n",
            "Step 2200 avg train loss = 5.8777\n",
            "Step 2300 avg train loss = 5.8600\n",
            "Step 2400 avg train loss = 5.8589\n",
            "Validation loss after 0 epoch = 5.6767\n",
            "Step 0 avg train loss = 5.7587\n",
            "Step 100 avg train loss = 5.7528\n",
            "Step 200 avg train loss = 5.7185\n",
            "Step 300 avg train loss = 5.7048\n",
            "Step 400 avg train loss = 5.7110\n",
            "Step 500 avg train loss = 5.7001\n",
            "Step 600 avg train loss = 5.7094\n",
            "Step 700 avg train loss = 5.6934\n",
            "Step 800 avg train loss = 5.6502\n",
            "Step 900 avg train loss = 5.6611\n",
            "Step 1000 avg train loss = 5.6310\n",
            "Step 1100 avg train loss = 5.6267\n",
            "Step 1200 avg train loss = 5.6277\n",
            "Step 1300 avg train loss = 5.5999\n",
            "Step 1400 avg train loss = 5.6039\n",
            "Step 1500 avg train loss = 5.5820\n",
            "Step 1600 avg train loss = 5.5850\n",
            "Step 1700 avg train loss = 5.5689\n",
            "Step 1800 avg train loss = 5.5302\n",
            "Step 1900 avg train loss = 5.5379\n",
            "Step 2000 avg train loss = 5.5269\n",
            "Step 2100 avg train loss = 5.5479\n",
            "Step 2200 avg train loss = 5.5299\n",
            "Step 2300 avg train loss = 5.5011\n",
            "Step 2400 avg train loss = 5.5004\n",
            "Validation loss after 1 epoch = 5.4238\n",
            "Step 0 avg train loss = 5.5506\n",
            "Step 100 avg train loss = 5.3963\n",
            "Step 200 avg train loss = 5.3657\n",
            "Step 300 avg train loss = 5.3674\n",
            "Step 400 avg train loss = 5.3633\n",
            "Step 500 avg train loss = 5.3702\n",
            "Step 600 avg train loss = 5.3783\n",
            "Step 700 avg train loss = 5.3514\n",
            "Step 800 avg train loss = 5.3522\n",
            "Step 900 avg train loss = 5.3666\n",
            "Step 1000 avg train loss = 5.3614\n",
            "Step 1100 avg train loss = 5.3267\n",
            "Step 1200 avg train loss = 5.3230\n",
            "Step 1300 avg train loss = 5.3262\n",
            "Step 1400 avg train loss = 5.3109\n",
            "Step 1500 avg train loss = 5.3222\n",
            "Step 1600 avg train loss = 5.2921\n",
            "Step 1700 avg train loss = 5.2936\n",
            "Step 1800 avg train loss = 5.2926\n",
            "Step 1900 avg train loss = 5.2965\n",
            "Step 2000 avg train loss = 5.2875\n",
            "Step 2100 avg train loss = 5.2914\n",
            "Step 2200 avg train loss = 5.2825\n",
            "Step 2300 avg train loss = 5.2815\n",
            "Step 2400 avg train loss = 5.2795\n",
            "Validation loss after 2 epoch = 5.2959\n",
            "Step 0 avg train loss = 5.0195\n",
            "Step 100 avg train loss = 5.1366\n",
            "Step 200 avg train loss = 5.1382\n",
            "Step 300 avg train loss = 5.1205\n",
            "Step 400 avg train loss = 5.1541\n",
            "Step 500 avg train loss = 5.1322\n",
            "Step 600 avg train loss = 5.1403\n",
            "Step 700 avg train loss = 5.1263\n",
            "Step 800 avg train loss = 5.1309\n",
            "Step 900 avg train loss = 5.1300\n",
            "Step 1000 avg train loss = 5.1390\n",
            "Step 1100 avg train loss = 5.1246\n",
            "Step 1200 avg train loss = 5.1436\n",
            "Step 1300 avg train loss = 5.1297\n",
            "Step 1400 avg train loss = 5.1331\n",
            "Step 1500 avg train loss = 5.1092\n",
            "Step 1600 avg train loss = 5.1036\n",
            "Step 1700 avg train loss = 5.1178\n",
            "Step 1800 avg train loss = 5.1242\n",
            "Step 1900 avg train loss = 5.1057\n",
            "Step 2000 avg train loss = 5.1104\n",
            "Step 2100 avg train loss = 5.0977\n",
            "Step 2200 avg train loss = 5.1044\n",
            "Step 2300 avg train loss = 5.1035\n",
            "Step 2400 avg train loss = 5.0999\n",
            "Validation loss after 3 epoch = 5.2366\n",
            "Step 0 avg train loss = 4.8921\n",
            "Step 100 avg train loss = 4.9432\n",
            "Step 200 avg train loss = 4.9525\n",
            "Step 300 avg train loss = 4.9740\n",
            "Step 400 avg train loss = 4.9508\n",
            "Step 500 avg train loss = 4.9661\n",
            "Step 600 avg train loss = 4.9629\n",
            "Step 700 avg train loss = 4.9784\n",
            "Step 800 avg train loss = 4.9607\n",
            "Step 900 avg train loss = 4.9889\n",
            "Step 1000 avg train loss = 4.9693\n",
            "Step 1100 avg train loss = 4.9704\n",
            "Step 1200 avg train loss = 4.9815\n",
            "Step 1300 avg train loss = 4.9598\n",
            "Step 1400 avg train loss = 4.9858\n",
            "Step 1500 avg train loss = 4.9625\n",
            "Step 1600 avg train loss = 4.9674\n",
            "Step 1700 avg train loss = 4.9663\n",
            "Step 1800 avg train loss = 4.9582\n",
            "Step 1900 avg train loss = 4.9630\n",
            "Step 2000 avg train loss = 4.9627\n",
            "Step 2100 avg train loss = 4.9805\n",
            "Step 2200 avg train loss = 4.9635\n",
            "Step 2300 avg train loss = 4.9540\n",
            "Step 2400 avg train loss = 4.9612\n",
            "Validation loss after 4 epoch = 5.2103\n",
            "Step 0 avg train loss = 4.6798\n",
            "Step 100 avg train loss = 4.8180\n",
            "Step 200 avg train loss = 4.8346\n",
            "Step 300 avg train loss = 4.8313\n",
            "Step 400 avg train loss = 4.8162\n",
            "Step 500 avg train loss = 4.8379\n",
            "Step 600 avg train loss = 4.8344\n",
            "Step 700 avg train loss = 4.8493\n",
            "Step 800 avg train loss = 4.8353\n",
            "Step 900 avg train loss = 4.8277\n",
            "Step 1000 avg train loss = 4.8371\n",
            "Step 1100 avg train loss = 4.8447\n",
            "Step 1200 avg train loss = 4.8419\n",
            "Step 1300 avg train loss = 4.8302\n",
            "Step 1400 avg train loss = 4.8531\n",
            "Step 1500 avg train loss = 4.8365\n",
            "Step 1600 avg train loss = 4.8542\n",
            "Step 1700 avg train loss = 4.8545\n",
            "Step 1800 avg train loss = 4.8356\n",
            "Step 1900 avg train loss = 4.8338\n",
            "Step 2000 avg train loss = 4.8203\n",
            "Step 2100 avg train loss = 4.8353\n",
            "Step 2200 avg train loss = 4.8453\n",
            "Step 2300 avg train loss = 4.8232\n",
            "Step 2400 avg train loss = 4.8604\n",
            "Validation loss after 5 epoch = 5.2010\n",
            "Step 0 avg train loss = 4.6998\n",
            "Step 100 avg train loss = 4.7235\n",
            "Step 200 avg train loss = 4.6999\n",
            "Step 300 avg train loss = 4.6949\n",
            "Step 400 avg train loss = 4.7107\n",
            "Step 500 avg train loss = 4.7160\n",
            "Step 600 avg train loss = 4.7304\n",
            "Step 700 avg train loss = 4.7101\n",
            "Step 800 avg train loss = 4.7077\n",
            "Step 900 avg train loss = 4.7209\n",
            "Step 1000 avg train loss = 4.7556\n",
            "Step 1100 avg train loss = 4.7351\n",
            "Step 1200 avg train loss = 4.7228\n",
            "Step 1300 avg train loss = 4.7430\n",
            "Step 1400 avg train loss = 4.7261\n",
            "Step 1500 avg train loss = 4.7591\n",
            "Step 1600 avg train loss = 4.7589\n",
            "Step 1700 avg train loss = 4.7402\n",
            "Step 1800 avg train loss = 4.7493\n",
            "Step 1900 avg train loss = 4.7287\n",
            "Step 2000 avg train loss = 4.7516\n",
            "Step 2100 avg train loss = 4.7284\n",
            "Step 2200 avg train loss = 4.7357\n",
            "Step 2300 avg train loss = 4.7516\n",
            "Step 2400 avg train loss = 4.7478\n",
            "Validation loss after 6 epoch = 5.2127\n",
            "Step 0 avg train loss = 4.4473\n",
            "Step 100 avg train loss = 4.6054\n",
            "Step 200 avg train loss = 4.6297\n",
            "Step 300 avg train loss = 4.6115\n",
            "Step 400 avg train loss = 4.6327\n",
            "Step 500 avg train loss = 4.6328\n",
            "Step 600 avg train loss = 4.6112\n",
            "Step 700 avg train loss = 4.6301\n",
            "Step 800 avg train loss = 4.6088\n",
            "Step 900 avg train loss = 4.6406\n",
            "Step 1000 avg train loss = 4.6494\n",
            "Step 1100 avg train loss = 4.6394\n",
            "Step 1200 avg train loss = 4.6366\n",
            "Step 1300 avg train loss = 4.6285\n",
            "Step 1400 avg train loss = 4.6434\n",
            "Step 1500 avg train loss = 4.6441\n",
            "Step 1600 avg train loss = 4.6587\n",
            "Step 1700 avg train loss = 4.6592\n",
            "Step 1800 avg train loss = 4.6515\n",
            "Step 1900 avg train loss = 4.6606\n",
            "Step 2000 avg train loss = 4.6479\n",
            "Step 2100 avg train loss = 4.6624\n",
            "Step 2200 avg train loss = 4.6377\n",
            "Step 2300 avg train loss = 4.6708\n",
            "Step 2400 avg train loss = 4.6581\n",
            "Validation loss after 7 epoch = 5.2190\n",
            "Step 0 avg train loss = 4.2927\n",
            "Step 100 avg train loss = 4.4935\n",
            "Step 200 avg train loss = 4.5162\n",
            "Step 300 avg train loss = 4.5264\n",
            "Step 400 avg train loss = 4.5315\n",
            "Step 500 avg train loss = 4.5391\n",
            "Step 600 avg train loss = 4.5384\n",
            "Step 700 avg train loss = 4.5460\n",
            "Step 800 avg train loss = 4.5488\n",
            "Step 900 avg train loss = 4.5770\n",
            "Step 1000 avg train loss = 4.5476\n",
            "Step 1100 avg train loss = 4.5600\n",
            "Step 1200 avg train loss = 4.5727\n",
            "Step 1300 avg train loss = 4.5778\n",
            "Step 1400 avg train loss = 4.5445\n",
            "Step 1500 avg train loss = 4.5699\n",
            "Step 1600 avg train loss = 4.5815\n",
            "Step 1700 avg train loss = 4.5835\n",
            "Step 1800 avg train loss = 4.5899\n",
            "Step 1900 avg train loss = 4.5956\n",
            "Step 2000 avg train loss = 4.5685\n",
            "Step 2100 avg train loss = 4.5766\n",
            "Step 2200 avg train loss = 4.6023\n",
            "Step 2300 avg train loss = 4.5796\n",
            "Step 2400 avg train loss = 4.5731\n",
            "Validation loss after 8 epoch = 5.2386\n",
            "Step 0 avg train loss = 4.4380\n",
            "Step 100 avg train loss = 4.4550\n",
            "Step 200 avg train loss = 4.4457\n",
            "Step 300 avg train loss = 4.4483\n",
            "Step 400 avg train loss = 4.4734\n",
            "Step 500 avg train loss = 4.4549\n",
            "Step 600 avg train loss = 4.4839\n",
            "Step 700 avg train loss = 4.4780\n",
            "Step 800 avg train loss = 4.4784\n",
            "Step 900 avg train loss = 4.5049\n",
            "Step 1000 avg train loss = 4.4631\n",
            "Step 1100 avg train loss = 4.4889\n",
            "Step 1200 avg train loss = 4.4929\n",
            "Step 1300 avg train loss = 4.4843\n",
            "Step 1400 avg train loss = 4.4992\n",
            "Step 1500 avg train loss = 4.4775\n",
            "Step 1600 avg train loss = 4.5039\n",
            "Step 1700 avg train loss = 4.5227\n",
            "Step 1800 avg train loss = 4.4995\n",
            "Step 1900 avg train loss = 4.5082\n",
            "Step 2000 avg train loss = 4.4815\n",
            "Step 2100 avg train loss = 4.5146\n",
            "Step 2200 avg train loss = 4.4961\n",
            "Step 2300 avg train loss = 4.5280\n",
            "Step 2400 avg train loss = 4.5080\n",
            "Validation loss after 9 epoch = 5.2582\n",
            "Step 0 avg train loss = 4.4055\n",
            "Step 100 avg train loss = 4.3765\n",
            "Step 200 avg train loss = 4.3724\n",
            "Step 300 avg train loss = 4.3788\n",
            "Step 400 avg train loss = 4.4054\n",
            "Step 500 avg train loss = 4.3940\n",
            "Step 600 avg train loss = 4.4031\n",
            "Step 700 avg train loss = 4.3958\n",
            "Step 800 avg train loss = 4.4139\n",
            "Step 900 avg train loss = 4.4374\n",
            "Step 1000 avg train loss = 4.4126\n",
            "Step 1100 avg train loss = 4.4152\n",
            "Step 1200 avg train loss = 4.4322\n",
            "Step 1300 avg train loss = 4.4198\n",
            "Step 1400 avg train loss = 4.4141\n",
            "Step 1500 avg train loss = 4.4266\n",
            "Step 1600 avg train loss = 4.4492\n",
            "Step 1700 avg train loss = 4.4342\n",
            "Step 1800 avg train loss = 4.4374\n",
            "Step 1900 avg train loss = 4.4539\n",
            "Step 2000 avg train loss = 4.4652\n",
            "Step 2100 avg train loss = 4.4614\n",
            "Step 2200 avg train loss = 4.4463\n",
            "Step 2300 avg train loss = 4.4552\n",
            "Step 2400 avg train loss = 4.4479\n",
            "Validation loss after 10 epoch = 5.2892\n",
            "Step 0 avg train loss = 4.3618\n",
            "Step 100 avg train loss = 4.3037\n",
            "Step 200 avg train loss = 4.3026\n",
            "Step 300 avg train loss = 4.3128\n",
            "Step 400 avg train loss = 4.3145\n",
            "Step 500 avg train loss = 4.3393\n",
            "Step 600 avg train loss = 4.3507\n",
            "Step 700 avg train loss = 4.3289\n",
            "Step 800 avg train loss = 4.3566\n",
            "Step 900 avg train loss = 4.3549\n",
            "Step 1000 avg train loss = 4.3586\n",
            "Step 1100 avg train loss = 4.3561\n",
            "Step 1200 avg train loss = 4.3660\n",
            "Step 1300 avg train loss = 4.3641\n",
            "Step 1400 avg train loss = 4.3784\n",
            "Step 1500 avg train loss = 4.3786\n",
            "Step 1600 avg train loss = 4.3619\n",
            "Step 1700 avg train loss = 4.3822\n",
            "Step 1800 avg train loss = 4.4005\n",
            "Step 1900 avg train loss = 4.4051\n",
            "Step 2000 avg train loss = 4.3930\n",
            "Step 2100 avg train loss = 4.3909\n",
            "Step 2200 avg train loss = 4.4177\n",
            "Step 2300 avg train loss = 4.4144\n",
            "Step 2400 avg train loss = 4.4052\n",
            "Validation loss after 11 epoch = 5.3104\n",
            "Step 0 avg train loss = 4.2222\n",
            "Step 100 avg train loss = 4.2431\n",
            "Step 200 avg train loss = 4.2607\n",
            "Step 300 avg train loss = 4.2780\n",
            "Step 400 avg train loss = 4.2829\n",
            "Step 500 avg train loss = 4.2874\n",
            "Step 600 avg train loss = 4.2693\n",
            "Step 700 avg train loss = 4.2963\n",
            "Step 800 avg train loss = 4.2916\n",
            "Step 900 avg train loss = 4.3065\n",
            "Step 1000 avg train loss = 4.3078\n",
            "Step 1100 avg train loss = 4.3065\n",
            "Step 1200 avg train loss = 4.3225\n",
            "Step 1300 avg train loss = 4.3066\n",
            "Step 1400 avg train loss = 4.3129\n",
            "Step 1500 avg train loss = 4.3258\n",
            "Step 1600 avg train loss = 4.3162\n",
            "Step 1700 avg train loss = 4.3184\n",
            "Step 1800 avg train loss = 4.3419\n",
            "Step 1900 avg train loss = 4.3227\n",
            "Step 2000 avg train loss = 4.3440\n",
            "Step 2100 avg train loss = 4.3308\n",
            "Step 2200 avg train loss = 4.3603\n",
            "Step 2300 avg train loss = 4.3454\n",
            "Step 2400 avg train loss = 4.3487\n",
            "Validation loss after 12 epoch = 5.3362\n",
            "Step 0 avg train loss = 4.2120\n",
            "Step 100 avg train loss = 4.1886\n",
            "Step 200 avg train loss = 4.1989\n",
            "Step 300 avg train loss = 4.2311\n",
            "Step 400 avg train loss = 4.2388\n",
            "Step 500 avg train loss = 4.2294\n",
            "Step 600 avg train loss = 4.2298\n",
            "Step 700 avg train loss = 4.2463\n",
            "Step 800 avg train loss = 4.2391\n",
            "Step 900 avg train loss = 4.2502\n",
            "Step 1000 avg train loss = 4.2688\n",
            "Step 1100 avg train loss = 4.2590\n",
            "Step 1200 avg train loss = 4.2649\n",
            "Step 1300 avg train loss = 4.2649\n",
            "Step 1400 avg train loss = 4.2731\n",
            "Step 1500 avg train loss = 4.2836\n",
            "Step 1600 avg train loss = 4.2629\n",
            "Step 1700 avg train loss = 4.2678\n",
            "Step 1800 avg train loss = 4.2923\n",
            "Step 1900 avg train loss = 4.2716\n",
            "Step 2000 avg train loss = 4.2761\n",
            "Step 2100 avg train loss = 4.3148\n",
            "Step 2200 avg train loss = 4.2881\n",
            "Step 2300 avg train loss = 4.2699\n",
            "Step 2400 avg train loss = 4.3139\n",
            "Validation loss after 13 epoch = 5.3644\n",
            "Step 0 avg train loss = 4.0577\n",
            "Step 100 avg train loss = 4.1405\n",
            "Step 200 avg train loss = 4.1497\n",
            "Step 300 avg train loss = 4.1604\n",
            "Step 400 avg train loss = 4.1758\n",
            "Step 500 avg train loss = 4.1736\n",
            "Step 600 avg train loss = 4.1823\n",
            "Step 700 avg train loss = 4.1856\n",
            "Step 800 avg train loss = 4.2179\n",
            "Step 900 avg train loss = 4.1874\n",
            "Step 1000 avg train loss = 4.1968\n",
            "Step 1100 avg train loss = 4.2222\n",
            "Step 1200 avg train loss = 4.2174\n",
            "Step 1300 avg train loss = 4.2175\n",
            "Step 1400 avg train loss = 4.2315\n",
            "Step 1500 avg train loss = 4.2371\n",
            "Step 1600 avg train loss = 4.2383\n",
            "Step 1700 avg train loss = 4.2266\n",
            "Step 1800 avg train loss = 4.2499\n",
            "Step 1900 avg train loss = 4.2366\n",
            "Step 2000 avg train loss = 4.2536\n",
            "Step 2100 avg train loss = 4.2439\n",
            "Step 2200 avg train loss = 4.2432\n",
            "Step 2300 avg train loss = 4.2592\n",
            "Step 2400 avg train loss = 4.2655\n",
            "Validation loss after 14 epoch = 5.3933\n",
            "Step 0 avg train loss = 4.0131\n",
            "Step 100 avg train loss = 4.1013\n",
            "Step 200 avg train loss = 4.0988\n",
            "Step 300 avg train loss = 4.1272\n",
            "Step 400 avg train loss = 4.1209\n",
            "Step 500 avg train loss = 4.1275\n",
            "Step 600 avg train loss = 4.1455\n",
            "Step 700 avg train loss = 4.1450\n",
            "Step 800 avg train loss = 4.1420\n",
            "Step 900 avg train loss = 4.1523\n",
            "Step 1000 avg train loss = 4.1660\n",
            "Step 1100 avg train loss = 4.1722\n",
            "Step 1200 avg train loss = 4.1657\n",
            "Step 1300 avg train loss = 4.1743\n",
            "Step 1400 avg train loss = 4.1944\n",
            "Step 1500 avg train loss = 4.2043\n",
            "Step 1600 avg train loss = 4.1986\n",
            "Step 1700 avg train loss = 4.1996\n",
            "Step 1800 avg train loss = 4.1933\n",
            "Step 1900 avg train loss = 4.1965\n",
            "Step 2000 avg train loss = 4.2143\n",
            "Step 2100 avg train loss = 4.1789\n",
            "Step 2200 avg train loss = 4.1946\n",
            "Step 2300 avg train loss = 4.2069\n",
            "Step 2400 avg train loss = 4.2358\n",
            "Validation loss after 15 epoch = 5.4246\n",
            "Step 0 avg train loss = 4.1673\n",
            "Step 100 avg train loss = 4.0547\n",
            "Step 200 avg train loss = 4.0693\n",
            "Step 300 avg train loss = 4.0738\n",
            "Step 400 avg train loss = 4.0841\n",
            "Step 500 avg train loss = 4.0999\n",
            "Step 600 avg train loss = 4.1131\n",
            "Step 700 avg train loss = 4.0992\n",
            "Step 800 avg train loss = 4.0871\n",
            "Step 900 avg train loss = 4.1142\n",
            "Step 1000 avg train loss = 4.1206\n",
            "Step 1100 avg train loss = 4.1252\n",
            "Step 1200 avg train loss = 4.1220\n",
            "Step 1300 avg train loss = 4.1445\n",
            "Step 1400 avg train loss = 4.1459\n",
            "Step 1500 avg train loss = 4.1337\n",
            "Step 1600 avg train loss = 4.1752\n",
            "Step 1700 avg train loss = 4.1666\n",
            "Step 1800 avg train loss = 4.1629\n",
            "Step 1900 avg train loss = 4.1651\n",
            "Step 2000 avg train loss = 4.1737\n",
            "Step 2100 avg train loss = 4.1539\n",
            "Step 2200 avg train loss = 4.1735\n",
            "Step 2300 avg train loss = 4.1523\n",
            "Step 2400 avg train loss = 4.1757\n",
            "Validation loss after 16 epoch = 5.4519\n",
            "Step 0 avg train loss = 3.9297\n",
            "Step 100 avg train loss = 4.0126\n",
            "Step 200 avg train loss = 4.0253\n",
            "Step 300 avg train loss = 4.0391\n",
            "Step 400 avg train loss = 4.0439\n",
            "Step 500 avg train loss = 4.0645\n",
            "Step 600 avg train loss = 4.0549\n",
            "Step 700 avg train loss = 4.0900\n",
            "Step 800 avg train loss = 4.0793\n",
            "Step 900 avg train loss = 4.0775\n",
            "Step 1000 avg train loss = 4.0889\n",
            "Step 1100 avg train loss = 4.0630\n",
            "Step 1200 avg train loss = 4.0886\n",
            "Step 1300 avg train loss = 4.1105\n",
            "Step 1400 avg train loss = 4.1256\n",
            "Step 1500 avg train loss = 4.1118\n",
            "Step 1600 avg train loss = 4.1088\n",
            "Step 1700 avg train loss = 4.1054\n",
            "Step 1800 avg train loss = 4.1225\n",
            "Step 1900 avg train loss = 4.1061\n",
            "Step 2000 avg train loss = 4.1228\n",
            "Step 2100 avg train loss = 4.1372\n",
            "Step 2200 avg train loss = 4.1323\n",
            "Step 2300 avg train loss = 4.1270\n",
            "Step 2400 avg train loss = 4.1334\n",
            "Validation loss after 17 epoch = 5.4837\n",
            "Step 0 avg train loss = 4.0440\n",
            "Step 100 avg train loss = 3.9772\n",
            "Step 200 avg train loss = 3.9905\n",
            "Step 300 avg train loss = 4.0043\n",
            "Step 400 avg train loss = 4.0068\n",
            "Step 500 avg train loss = 4.0165\n",
            "Step 600 avg train loss = 4.0387\n",
            "Step 700 avg train loss = 4.0457\n",
            "Step 800 avg train loss = 4.0179\n",
            "Step 900 avg train loss = 4.0531\n",
            "Step 1000 avg train loss = 4.0661\n",
            "Step 1100 avg train loss = 4.0614\n",
            "Step 1200 avg train loss = 4.0640\n",
            "Step 1300 avg train loss = 4.0802\n",
            "Step 1400 avg train loss = 4.0703\n",
            "Step 1500 avg train loss = 4.0460\n",
            "Step 1600 avg train loss = 4.0697\n",
            "Step 1700 avg train loss = 4.0769\n",
            "Step 1800 avg train loss = 4.0839\n",
            "Step 1900 avg train loss = 4.0770\n",
            "Step 2000 avg train loss = 4.0966\n",
            "Step 2100 avg train loss = 4.0775\n",
            "Step 2200 avg train loss = 4.0849\n",
            "Step 2300 avg train loss = 4.1133\n",
            "Step 2400 avg train loss = 4.0894\n",
            "Validation loss after 18 epoch = 5.5082\n",
            "Step 0 avg train loss = 3.9998\n",
            "Step 100 avg train loss = 3.9558\n",
            "Step 200 avg train loss = 3.9769\n",
            "Step 300 avg train loss = 3.9715\n",
            "Step 400 avg train loss = 3.9490\n",
            "Step 500 avg train loss = 3.9980\n",
            "Step 600 avg train loss = 4.0008\n",
            "Step 700 avg train loss = 3.9940\n",
            "Step 800 avg train loss = 4.0109\n",
            "Step 900 avg train loss = 4.0060\n",
            "Step 1000 avg train loss = 4.0087\n",
            "Step 1100 avg train loss = 4.0202\n",
            "Step 1200 avg train loss = 4.0125\n",
            "Step 1300 avg train loss = 4.0295\n",
            "Step 1400 avg train loss = 4.0254\n",
            "Step 1500 avg train loss = 4.0366\n",
            "Step 1600 avg train loss = 4.0455\n",
            "Step 1700 avg train loss = 4.0576\n",
            "Step 1800 avg train loss = 4.0540\n",
            "Step 1900 avg train loss = 4.0624\n",
            "Step 2000 avg train loss = 4.0473\n",
            "Step 2100 avg train loss = 4.0440\n",
            "Step 2200 avg train loss = 4.0534\n",
            "Step 2300 avg train loss = 4.0765\n",
            "Step 2400 avg train loss = 4.0659\n",
            "Validation loss after 19 epoch = 5.5362\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 400, padding_idx=2)\n",
            "  (lstm): LSTM(400, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=128, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4023\n",
            "Step 100 avg train loss = 7.8250\n",
            "Step 200 avg train loss = 7.0826\n",
            "Step 300 avg train loss = 6.8590\n",
            "Step 400 avg train loss = 6.7079\n",
            "Step 500 avg train loss = 6.6157\n",
            "Step 600 avg train loss = 6.5115\n",
            "Step 700 avg train loss = 6.4588\n",
            "Step 800 avg train loss = 6.3831\n",
            "Step 900 avg train loss = 6.3402\n",
            "Step 1000 avg train loss = 6.2948\n",
            "Step 1100 avg train loss = 6.2216\n",
            "Step 1200 avg train loss = 6.1758\n",
            "Step 1300 avg train loss = 6.1454\n",
            "Step 1400 avg train loss = 6.1283\n",
            "Step 1500 avg train loss = 6.0499\n",
            "Step 1600 avg train loss = 6.0247\n",
            "Step 1700 avg train loss = 6.0261\n",
            "Step 1800 avg train loss = 5.9836\n",
            "Step 1900 avg train loss = 5.9606\n",
            "Step 2000 avg train loss = 5.9391\n",
            "Step 2100 avg train loss = 5.9152\n",
            "Step 2200 avg train loss = 5.9022\n",
            "Step 2300 avg train loss = 5.8728\n",
            "Step 2400 avg train loss = 5.8519\n",
            "Validation loss after 0 epoch = 5.6733\n",
            "Step 0 avg train loss = 5.7023\n",
            "Step 100 avg train loss = 5.7328\n",
            "Step 200 avg train loss = 5.7244\n",
            "Step 300 avg train loss = 5.7013\n",
            "Step 400 avg train loss = 5.6960\n",
            "Step 500 avg train loss = 5.7002\n",
            "Step 600 avg train loss = 5.6611\n",
            "Step 700 avg train loss = 5.6550\n",
            "Step 800 avg train loss = 5.6492\n",
            "Step 900 avg train loss = 5.6442\n",
            "Step 1000 avg train loss = 5.6368\n",
            "Step 1100 avg train loss = 5.6299\n",
            "Step 1200 avg train loss = 5.5984\n",
            "Step 1300 avg train loss = 5.5849\n",
            "Step 1400 avg train loss = 5.5605\n",
            "Step 1500 avg train loss = 5.5807\n",
            "Step 1600 avg train loss = 5.5840\n",
            "Step 1700 avg train loss = 5.5296\n",
            "Step 1800 avg train loss = 5.5472\n",
            "Step 1900 avg train loss = 5.5346\n",
            "Step 2000 avg train loss = 5.5158\n",
            "Step 2100 avg train loss = 5.5128\n",
            "Step 2200 avg train loss = 5.5088\n",
            "Step 2300 avg train loss = 5.4913\n",
            "Step 2400 avg train loss = 5.4905\n",
            "Validation loss after 1 epoch = 5.4120\n",
            "Step 0 avg train loss = 5.3730\n",
            "Step 100 avg train loss = 5.3563\n",
            "Step 200 avg train loss = 5.3515\n",
            "Step 300 avg train loss = 5.3500\n",
            "Step 400 avg train loss = 5.3400\n",
            "Step 500 avg train loss = 5.3386\n",
            "Step 600 avg train loss = 5.3290\n",
            "Step 700 avg train loss = 5.3296\n",
            "Step 800 avg train loss = 5.3612\n",
            "Step 900 avg train loss = 5.3523\n",
            "Step 1000 avg train loss = 5.3082\n",
            "Step 1100 avg train loss = 5.3089\n",
            "Step 1200 avg train loss = 5.3216\n",
            "Step 1300 avg train loss = 5.2978\n",
            "Step 1400 avg train loss = 5.3079\n",
            "Step 1500 avg train loss = 5.3146\n",
            "Step 1600 avg train loss = 5.2861\n",
            "Step 1700 avg train loss = 5.2960\n",
            "Step 1800 avg train loss = 5.2927\n",
            "Step 1900 avg train loss = 5.2708\n",
            "Step 2000 avg train loss = 5.2605\n",
            "Step 2100 avg train loss = 5.2534\n",
            "Step 2200 avg train loss = 5.2604\n",
            "Step 2300 avg train loss = 5.2743\n",
            "Step 2400 avg train loss = 5.2619\n",
            "Validation loss after 2 epoch = 5.2892\n",
            "Step 0 avg train loss = 5.1294\n",
            "Step 100 avg train loss = 5.1191\n",
            "Step 200 avg train loss = 5.1321\n",
            "Step 300 avg train loss = 5.1095\n",
            "Step 400 avg train loss = 5.1091\n",
            "Step 500 avg train loss = 5.1229\n",
            "Step 600 avg train loss = 5.1146\n",
            "Step 700 avg train loss = 5.1116\n",
            "Step 800 avg train loss = 5.1080\n",
            "Step 900 avg train loss = 5.1183\n",
            "Step 1000 avg train loss = 5.1070\n",
            "Step 1100 avg train loss = 5.0849\n",
            "Step 1200 avg train loss = 5.1083\n",
            "Step 1300 avg train loss = 5.0937\n",
            "Step 1400 avg train loss = 5.1064\n",
            "Step 1500 avg train loss = 5.0944\n",
            "Step 1600 avg train loss = 5.0899\n",
            "Step 1700 avg train loss = 5.1022\n",
            "Step 1800 avg train loss = 5.0878\n",
            "Step 1900 avg train loss = 5.0824\n",
            "Step 2000 avg train loss = 5.0657\n",
            "Step 2100 avg train loss = 5.1331\n",
            "Step 2200 avg train loss = 5.1054\n",
            "Step 2300 avg train loss = 5.0902\n",
            "Step 2400 avg train loss = 5.0703\n",
            "Validation loss after 3 epoch = 5.2324\n",
            "Step 0 avg train loss = 5.0786\n",
            "Step 100 avg train loss = 4.9287\n",
            "Step 200 avg train loss = 4.9257\n",
            "Step 300 avg train loss = 4.9590\n",
            "Step 400 avg train loss = 4.9518\n",
            "Step 500 avg train loss = 4.9382\n",
            "Step 600 avg train loss = 4.9572\n",
            "Step 700 avg train loss = 4.9459\n",
            "Step 800 avg train loss = 4.9467\n",
            "Step 900 avg train loss = 4.9565\n",
            "Step 1000 avg train loss = 4.9423\n",
            "Step 1100 avg train loss = 4.9230\n",
            "Step 1200 avg train loss = 4.9397\n",
            "Step 1300 avg train loss = 4.9609\n",
            "Step 1400 avg train loss = 4.9469\n",
            "Step 1500 avg train loss = 4.9456\n",
            "Step 1600 avg train loss = 4.9634\n",
            "Step 1700 avg train loss = 4.9259\n",
            "Step 1800 avg train loss = 4.9511\n",
            "Step 1900 avg train loss = 4.9285\n",
            "Step 2000 avg train loss = 4.9521\n",
            "Step 2100 avg train loss = 4.9684\n",
            "Step 2200 avg train loss = 4.9520\n",
            "Step 2300 avg train loss = 4.9504\n",
            "Step 2400 avg train loss = 4.9484\n",
            "Validation loss after 4 epoch = 5.2095\n",
            "Step 0 avg train loss = 4.7277\n",
            "Step 100 avg train loss = 4.8169\n",
            "Step 200 avg train loss = 4.8071\n",
            "Step 300 avg train loss = 4.8053\n",
            "Step 400 avg train loss = 4.8019\n",
            "Step 500 avg train loss = 4.8195\n",
            "Step 600 avg train loss = 4.8038\n",
            "Step 700 avg train loss = 4.8275\n",
            "Step 800 avg train loss = 4.8186\n",
            "Step 900 avg train loss = 4.8242\n",
            "Step 1000 avg train loss = 4.8007\n",
            "Step 1100 avg train loss = 4.8289\n",
            "Step 1200 avg train loss = 4.8057\n",
            "Step 1300 avg train loss = 4.8150\n",
            "Step 1400 avg train loss = 4.8164\n",
            "Step 1500 avg train loss = 4.8503\n",
            "Step 1600 avg train loss = 4.8219\n",
            "Step 1700 avg train loss = 4.8282\n",
            "Step 1800 avg train loss = 4.8472\n",
            "Step 1900 avg train loss = 4.8101\n",
            "Step 2000 avg train loss = 4.8301\n",
            "Step 2100 avg train loss = 4.8470\n",
            "Step 2200 avg train loss = 4.8083\n",
            "Step 2300 avg train loss = 4.8183\n",
            "Step 2400 avg train loss = 4.8298\n",
            "Validation loss after 5 epoch = 5.2055\n",
            "Step 0 avg train loss = 4.6173\n",
            "Step 100 avg train loss = 4.6568\n",
            "Step 200 avg train loss = 4.6956\n",
            "Step 300 avg train loss = 4.6825\n",
            "Step 400 avg train loss = 4.6839\n",
            "Step 500 avg train loss = 4.6862\n",
            "Step 600 avg train loss = 4.6935\n",
            "Step 700 avg train loss = 4.7037\n",
            "Step 800 avg train loss = 4.7234\n",
            "Step 900 avg train loss = 4.7086\n",
            "Step 1000 avg train loss = 4.7280\n",
            "Step 1100 avg train loss = 4.7211\n",
            "Step 1200 avg train loss = 4.7215\n",
            "Step 1300 avg train loss = 4.7231\n",
            "Step 1400 avg train loss = 4.7352\n",
            "Step 1500 avg train loss = 4.7258\n",
            "Step 1600 avg train loss = 4.7247\n",
            "Step 1700 avg train loss = 4.7210\n",
            "Step 1800 avg train loss = 4.7167\n",
            "Step 1900 avg train loss = 4.7216\n",
            "Step 2000 avg train loss = 4.7386\n",
            "Step 2100 avg train loss = 4.7191\n",
            "Step 2200 avg train loss = 4.7308\n",
            "Step 2300 avg train loss = 4.7362\n",
            "Step 2400 avg train loss = 4.7295\n",
            "Validation loss after 6 epoch = 5.2143\n",
            "Step 0 avg train loss = 4.4967\n",
            "Step 100 avg train loss = 4.5824\n",
            "Step 200 avg train loss = 4.5770\n",
            "Step 300 avg train loss = 4.6073\n",
            "Step 400 avg train loss = 4.6023\n",
            "Step 500 avg train loss = 4.5821\n",
            "Step 600 avg train loss = 4.6027\n",
            "Step 700 avg train loss = 4.6088\n",
            "Step 800 avg train loss = 4.6071\n",
            "Step 900 avg train loss = 4.6067\n",
            "Step 1000 avg train loss = 4.6221\n",
            "Step 1100 avg train loss = 4.6301\n",
            "Step 1200 avg train loss = 4.6302\n",
            "Step 1300 avg train loss = 4.6181\n",
            "Step 1400 avg train loss = 4.6172\n",
            "Step 1500 avg train loss = 4.6505\n",
            "Step 1600 avg train loss = 4.6231\n",
            "Step 1700 avg train loss = 4.6233\n",
            "Step 1800 avg train loss = 4.6405\n",
            "Step 1900 avg train loss = 4.6459\n",
            "Step 2000 avg train loss = 4.6493\n",
            "Step 2100 avg train loss = 4.6637\n",
            "Step 2200 avg train loss = 4.6425\n",
            "Step 2300 avg train loss = 4.6438\n",
            "Step 2400 avg train loss = 4.6461\n",
            "Validation loss after 7 epoch = 5.2345\n",
            "Step 0 avg train loss = 4.5057\n",
            "Step 100 avg train loss = 4.4964\n",
            "Step 200 avg train loss = 4.5077\n",
            "Step 300 avg train loss = 4.5161\n",
            "Step 400 avg train loss = 4.5153\n",
            "Step 500 avg train loss = 4.5260\n",
            "Step 600 avg train loss = 4.5185\n",
            "Step 700 avg train loss = 4.5190\n",
            "Step 800 avg train loss = 4.5210\n",
            "Step 900 avg train loss = 4.5432\n",
            "Step 1000 avg train loss = 4.5360\n",
            "Step 1100 avg train loss = 4.5590\n",
            "Step 1200 avg train loss = 4.5447\n",
            "Step 1300 avg train loss = 4.5484\n",
            "Step 1400 avg train loss = 4.5494\n",
            "Step 1500 avg train loss = 4.5325\n",
            "Step 1600 avg train loss = 4.5551\n",
            "Step 1700 avg train loss = 4.5559\n",
            "Step 1800 avg train loss = 4.5546\n",
            "Step 1900 avg train loss = 4.5681\n",
            "Step 2000 avg train loss = 4.5703\n",
            "Step 2100 avg train loss = 4.5479\n",
            "Step 2200 avg train loss = 4.5708\n",
            "Step 2300 avg train loss = 4.5673\n",
            "Step 2400 avg train loss = 4.5588\n",
            "Validation loss after 8 epoch = 5.2575\n",
            "Step 0 avg train loss = 4.4800\n",
            "Step 100 avg train loss = 4.4264\n",
            "Step 200 avg train loss = 4.4187\n",
            "Step 300 avg train loss = 4.4199\n",
            "Step 400 avg train loss = 4.4340\n",
            "Step 500 avg train loss = 4.4527\n",
            "Step 600 avg train loss = 4.4404\n",
            "Step 700 avg train loss = 4.4569\n",
            "Step 800 avg train loss = 4.4562\n",
            "Step 900 avg train loss = 4.4733\n",
            "Step 1000 avg train loss = 4.4654\n",
            "Step 1100 avg train loss = 4.4655\n",
            "Step 1200 avg train loss = 4.5027\n",
            "Step 1300 avg train loss = 4.4709\n",
            "Step 1400 avg train loss = 4.4676\n",
            "Step 1500 avg train loss = 4.4754\n",
            "Step 1600 avg train loss = 4.4837\n",
            "Step 1700 avg train loss = 4.4964\n",
            "Step 1800 avg train loss = 4.4928\n",
            "Step 1900 avg train loss = 4.4742\n",
            "Step 2000 avg train loss = 4.4999\n",
            "Step 2100 avg train loss = 4.4681\n",
            "Step 2200 avg train loss = 4.4924\n",
            "Step 2300 avg train loss = 4.4783\n",
            "Step 2400 avg train loss = 4.4943\n",
            "Validation loss after 9 epoch = 5.2754\n",
            "Step 0 avg train loss = 4.2336\n",
            "Step 100 avg train loss = 4.3511\n",
            "Step 200 avg train loss = 4.3681\n",
            "Step 300 avg train loss = 4.3397\n",
            "Step 400 avg train loss = 4.3713\n",
            "Step 500 avg train loss = 4.3796\n",
            "Step 600 avg train loss = 4.3920\n",
            "Step 700 avg train loss = 4.3778\n",
            "Step 800 avg train loss = 4.3816\n",
            "Step 900 avg train loss = 4.3859\n",
            "Step 1000 avg train loss = 4.4069\n",
            "Step 1100 avg train loss = 4.4107\n",
            "Step 1200 avg train loss = 4.4034\n",
            "Step 1300 avg train loss = 4.3945\n",
            "Step 1400 avg train loss = 4.4096\n",
            "Step 1500 avg train loss = 4.4292\n",
            "Step 1600 avg train loss = 4.4149\n",
            "Step 1700 avg train loss = 4.4073\n",
            "Step 1800 avg train loss = 4.4219\n",
            "Step 1900 avg train loss = 4.4168\n",
            "Step 2000 avg train loss = 4.4408\n",
            "Step 2100 avg train loss = 4.4232\n",
            "Step 2200 avg train loss = 4.4429\n",
            "Step 2300 avg train loss = 4.4264\n",
            "Step 2400 avg train loss = 4.4314\n",
            "Validation loss after 10 epoch = 5.3052\n",
            "Step 0 avg train loss = 4.0679\n",
            "Step 100 avg train loss = 4.2737\n",
            "Step 200 avg train loss = 4.2835\n",
            "Step 300 avg train loss = 4.3065\n",
            "Step 400 avg train loss = 4.3031\n",
            "Step 500 avg train loss = 4.3113\n",
            "Step 600 avg train loss = 4.3217\n",
            "Step 700 avg train loss = 4.3066\n",
            "Step 800 avg train loss = 4.3148\n",
            "Step 900 avg train loss = 4.3189\n",
            "Step 1000 avg train loss = 4.3407\n",
            "Step 1100 avg train loss = 4.3562\n",
            "Step 1200 avg train loss = 4.3371\n",
            "Step 1300 avg train loss = 4.3485\n",
            "Step 1400 avg train loss = 4.3647\n",
            "Step 1500 avg train loss = 4.3523\n",
            "Step 1600 avg train loss = 4.3602\n",
            "Step 1700 avg train loss = 4.3741\n",
            "Step 1800 avg train loss = 4.3640\n",
            "Step 1900 avg train loss = 4.3903\n",
            "Step 2000 avg train loss = 4.3647\n",
            "Step 2100 avg train loss = 4.3828\n",
            "Step 2200 avg train loss = 4.3678\n",
            "Step 2300 avg train loss = 4.3636\n",
            "Step 2400 avg train loss = 4.3780\n",
            "Validation loss after 11 epoch = 5.3374\n",
            "Step 0 avg train loss = 4.1806\n",
            "Step 100 avg train loss = 4.2266\n",
            "Step 200 avg train loss = 4.2401\n",
            "Step 300 avg train loss = 4.2223\n",
            "Step 400 avg train loss = 4.2504\n",
            "Step 500 avg train loss = 4.2576\n",
            "Step 600 avg train loss = 4.2517\n",
            "Step 700 avg train loss = 4.2779\n",
            "Step 800 avg train loss = 4.2727\n",
            "Step 900 avg train loss = 4.2747\n",
            "Step 1000 avg train loss = 4.2642\n",
            "Step 1100 avg train loss = 4.2626\n",
            "Step 1200 avg train loss = 4.2924\n",
            "Step 1300 avg train loss = 4.2941\n",
            "Step 1400 avg train loss = 4.2995\n",
            "Step 1500 avg train loss = 4.2985\n",
            "Step 1600 avg train loss = 4.3283\n",
            "Step 1700 avg train loss = 4.3317\n",
            "Step 1800 avg train loss = 4.3120\n",
            "Step 1900 avg train loss = 4.3245\n",
            "Step 2000 avg train loss = 4.3050\n",
            "Step 2100 avg train loss = 4.3261\n",
            "Step 2200 avg train loss = 4.3321\n",
            "Step 2300 avg train loss = 4.3333\n",
            "Step 2400 avg train loss = 4.2995\n",
            "Validation loss after 12 epoch = 5.3689\n",
            "Step 0 avg train loss = 3.9983\n",
            "Step 100 avg train loss = 4.1634\n",
            "Step 200 avg train loss = 4.1947\n",
            "Step 300 avg train loss = 4.2063\n",
            "Step 400 avg train loss = 4.2014\n",
            "Step 500 avg train loss = 4.1926\n",
            "Step 600 avg train loss = 4.2148\n",
            "Step 700 avg train loss = 4.2078\n",
            "Step 800 avg train loss = 4.2368\n",
            "Step 900 avg train loss = 4.2238\n",
            "Step 1000 avg train loss = 4.2245\n",
            "Step 1100 avg train loss = 4.2284\n",
            "Step 1200 avg train loss = 4.2186\n",
            "Step 1300 avg train loss = 4.2408\n",
            "Step 1400 avg train loss = 4.2398\n",
            "Step 1500 avg train loss = 4.2612\n",
            "Step 1600 avg train loss = 4.2374\n",
            "Step 1700 avg train loss = 4.2797\n",
            "Step 1800 avg train loss = 4.2634\n",
            "Step 1900 avg train loss = 4.2838\n",
            "Step 2000 avg train loss = 4.2659\n",
            "Step 2100 avg train loss = 4.2516\n",
            "Step 2200 avg train loss = 4.2725\n",
            "Step 2300 avg train loss = 4.2687\n",
            "Step 2400 avg train loss = 4.2819\n",
            "Validation loss after 13 epoch = 5.3945\n",
            "Step 0 avg train loss = 4.0700\n",
            "Step 100 avg train loss = 4.1193\n",
            "Step 200 avg train loss = 4.1229\n",
            "Step 300 avg train loss = 4.1187\n",
            "Step 400 avg train loss = 4.1553\n",
            "Step 500 avg train loss = 4.1485\n",
            "Step 600 avg train loss = 4.1475\n",
            "Step 700 avg train loss = 4.1741\n",
            "Step 800 avg train loss = 4.1715\n",
            "Step 900 avg train loss = 4.1588\n",
            "Step 1000 avg train loss = 4.1828\n",
            "Step 1100 avg train loss = 4.2007\n",
            "Step 1200 avg train loss = 4.1766\n",
            "Step 1300 avg train loss = 4.2048\n",
            "Step 1400 avg train loss = 4.2149\n",
            "Step 1500 avg train loss = 4.2264\n",
            "Step 1600 avg train loss = 4.2042\n",
            "Step 1700 avg train loss = 4.2115\n",
            "Step 1800 avg train loss = 4.2200\n",
            "Step 1900 avg train loss = 4.1981\n",
            "Step 2000 avg train loss = 4.2197\n",
            "Step 2100 avg train loss = 4.2273\n",
            "Step 2200 avg train loss = 4.2347\n",
            "Step 2300 avg train loss = 4.2447\n",
            "Step 2400 avg train loss = 4.2305\n",
            "Validation loss after 14 epoch = 5.4292\n",
            "Step 0 avg train loss = 4.1498\n",
            "Step 100 avg train loss = 4.0650\n",
            "Step 200 avg train loss = 4.0763\n",
            "Step 300 avg train loss = 4.0947\n",
            "Step 400 avg train loss = 4.0923\n",
            "Step 500 avg train loss = 4.0890\n",
            "Step 600 avg train loss = 4.1183\n",
            "Step 700 avg train loss = 4.1046\n",
            "Step 800 avg train loss = 4.1245\n",
            "Step 900 avg train loss = 4.1294\n",
            "Step 1000 avg train loss = 4.1524\n",
            "Step 1100 avg train loss = 4.1669\n",
            "Step 1200 avg train loss = 4.1534\n",
            "Step 1300 avg train loss = 4.1338\n",
            "Step 1400 avg train loss = 4.1487\n",
            "Step 1500 avg train loss = 4.1673\n",
            "Step 1600 avg train loss = 4.1707\n",
            "Step 1700 avg train loss = 4.1834\n",
            "Step 1800 avg train loss = 4.1754\n",
            "Step 1900 avg train loss = 4.1873\n",
            "Step 2000 avg train loss = 4.1936\n",
            "Step 2100 avg train loss = 4.1599\n",
            "Step 2200 avg train loss = 4.1868\n",
            "Step 2300 avg train loss = 4.2023\n",
            "Step 2400 avg train loss = 4.1757\n",
            "Validation loss after 15 epoch = 5.4660\n",
            "Step 0 avg train loss = 4.0273\n",
            "Step 100 avg train loss = 4.0220\n",
            "Step 200 avg train loss = 4.0549\n",
            "Step 300 avg train loss = 4.0614\n",
            "Step 400 avg train loss = 4.0537\n",
            "Step 500 avg train loss = 4.0514\n",
            "Step 600 avg train loss = 4.0865\n",
            "Step 700 avg train loss = 4.0546\n",
            "Step 800 avg train loss = 4.0985\n",
            "Step 900 avg train loss = 4.1136\n",
            "Step 1000 avg train loss = 4.0781\n",
            "Step 1100 avg train loss = 4.1131\n",
            "Step 1200 avg train loss = 4.1265\n",
            "Step 1300 avg train loss = 4.1093\n",
            "Step 1400 avg train loss = 4.0922\n",
            "Step 1500 avg train loss = 4.1161\n",
            "Step 1600 avg train loss = 4.1181\n",
            "Step 1700 avg train loss = 4.1335\n",
            "Step 1800 avg train loss = 4.1290\n",
            "Step 1900 avg train loss = 4.1249\n",
            "Step 2000 avg train loss = 4.1470\n",
            "Step 2100 avg train loss = 4.1427\n",
            "Step 2200 avg train loss = 4.1465\n",
            "Step 2300 avg train loss = 4.1532\n",
            "Step 2400 avg train loss = 4.1267\n",
            "Validation loss after 16 epoch = 5.4926\n",
            "Step 0 avg train loss = 4.0648\n",
            "Step 100 avg train loss = 3.9927\n",
            "Step 200 avg train loss = 3.9955\n",
            "Step 300 avg train loss = 3.9995\n",
            "Step 400 avg train loss = 4.0166\n",
            "Step 500 avg train loss = 4.0329\n",
            "Step 600 avg train loss = 4.0125\n",
            "Step 700 avg train loss = 4.0438\n",
            "Step 800 avg train loss = 4.0544\n",
            "Step 900 avg train loss = 4.0643\n",
            "Step 1000 avg train loss = 4.0626\n",
            "Step 1100 avg train loss = 4.0750\n",
            "Step 1200 avg train loss = 4.0636\n",
            "Step 1300 avg train loss = 4.0804\n",
            "Step 1400 avg train loss = 4.0882\n",
            "Step 1500 avg train loss = 4.0944\n",
            "Step 1600 avg train loss = 4.0834\n",
            "Step 1700 avg train loss = 4.1077\n",
            "Step 1800 avg train loss = 4.0756\n",
            "Step 1900 avg train loss = 4.0918\n",
            "Step 2000 avg train loss = 4.0872\n",
            "Step 2100 avg train loss = 4.0858\n",
            "Step 2200 avg train loss = 4.0997\n",
            "Step 2300 avg train loss = 4.1257\n",
            "Step 2400 avg train loss = 4.1121\n",
            "Validation loss after 17 epoch = 5.5328\n",
            "Step 0 avg train loss = 3.9079\n",
            "Step 100 avg train loss = 3.9593\n",
            "Step 200 avg train loss = 3.9547\n",
            "Step 300 avg train loss = 3.9700\n",
            "Step 400 avg train loss = 4.0013\n",
            "Step 500 avg train loss = 3.9737\n",
            "Step 600 avg train loss = 3.9953\n",
            "Step 700 avg train loss = 4.0029\n",
            "Step 800 avg train loss = 4.0087\n",
            "Step 900 avg train loss = 4.0131\n",
            "Step 1000 avg train loss = 4.0181\n",
            "Step 1100 avg train loss = 4.0232\n",
            "Step 1200 avg train loss = 4.0233\n",
            "Step 1300 avg train loss = 4.0317\n",
            "Step 1400 avg train loss = 4.0616\n",
            "Step 1500 avg train loss = 4.0395\n",
            "Step 1600 avg train loss = 4.0304\n",
            "Step 1700 avg train loss = 4.0634\n",
            "Step 1800 avg train loss = 4.0594\n",
            "Step 1900 avg train loss = 4.0613\n",
            "Step 2000 avg train loss = 4.0799\n",
            "Step 2100 avg train loss = 4.0716\n",
            "Step 2200 avg train loss = 4.0788\n",
            "Step 2300 avg train loss = 4.0840\n",
            "Step 2400 avg train loss = 4.0640\n",
            "Validation loss after 18 epoch = 5.5573\n",
            "Step 0 avg train loss = 3.9781\n",
            "Step 100 avg train loss = 3.9200\n",
            "Step 200 avg train loss = 3.9366\n",
            "Step 300 avg train loss = 3.9145\n",
            "Step 400 avg train loss = 3.9230\n",
            "Step 500 avg train loss = 3.9579\n",
            "Step 600 avg train loss = 3.9589\n",
            "Step 700 avg train loss = 3.9782\n",
            "Step 800 avg train loss = 3.9825\n",
            "Step 900 avg train loss = 4.0048\n",
            "Step 1000 avg train loss = 3.9992\n",
            "Step 1100 avg train loss = 3.9936\n",
            "Step 1200 avg train loss = 4.0119\n",
            "Step 1300 avg train loss = 4.0024\n",
            "Step 1400 avg train loss = 4.0293\n",
            "Step 1500 avg train loss = 4.0182\n",
            "Step 1600 avg train loss = 4.0272\n",
            "Step 1700 avg train loss = 4.0067\n",
            "Step 1800 avg train loss = 4.0090\n",
            "Step 1900 avg train loss = 4.0225\n",
            "Step 2000 avg train loss = 4.0266\n",
            "Step 2100 avg train loss = 4.0301\n",
            "Step 2200 avg train loss = 4.0415\n",
            "Step 2300 avg train loss = 4.0565\n",
            "Step 2400 avg train loss = 4.0321\n",
            "Validation loss after 19 epoch = 5.5895\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 500, padding_idx=2)\n",
            "  (lstm): LSTM(500, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=128, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4104\n",
            "Step 100 avg train loss = 7.8140\n",
            "Step 200 avg train loss = 7.1067\n",
            "Step 300 avg train loss = 6.9097\n",
            "Step 400 avg train loss = 6.7177\n",
            "Step 500 avg train loss = 6.5911\n",
            "Step 600 avg train loss = 6.5139\n",
            "Step 700 avg train loss = 6.4147\n",
            "Step 800 avg train loss = 6.3649\n",
            "Step 900 avg train loss = 6.3038\n",
            "Step 1000 avg train loss = 6.2399\n",
            "Step 1100 avg train loss = 6.1846\n",
            "Step 1200 avg train loss = 6.1361\n",
            "Step 1300 avg train loss = 6.1052\n",
            "Step 1400 avg train loss = 6.0749\n",
            "Step 1500 avg train loss = 6.0425\n",
            "Step 1600 avg train loss = 6.0194\n",
            "Step 1700 avg train loss = 5.9650\n",
            "Step 1800 avg train loss = 5.9335\n",
            "Step 1900 avg train loss = 5.9212\n",
            "Step 2000 avg train loss = 5.8957\n",
            "Step 2100 avg train loss = 5.8850\n",
            "Step 2200 avg train loss = 5.8551\n",
            "Step 2300 avg train loss = 5.8543\n",
            "Step 2400 avg train loss = 5.8184\n",
            "Validation loss after 0 epoch = 5.6485\n",
            "Step 0 avg train loss = 5.8281\n",
            "Step 100 avg train loss = 5.7175\n",
            "Step 200 avg train loss = 5.7072\n",
            "Step 300 avg train loss = 5.6913\n",
            "Step 400 avg train loss = 5.6363\n",
            "Step 500 avg train loss = 5.6574\n",
            "Step 600 avg train loss = 5.6538\n",
            "Step 700 avg train loss = 5.6532\n",
            "Step 800 avg train loss = 5.6453\n",
            "Step 900 avg train loss = 5.6162\n",
            "Step 1000 avg train loss = 5.6160\n",
            "Step 1100 avg train loss = 5.5937\n",
            "Step 1200 avg train loss = 5.5852\n",
            "Step 1300 avg train loss = 5.5843\n",
            "Step 1400 avg train loss = 5.5713\n",
            "Step 1500 avg train loss = 5.5722\n",
            "Step 1600 avg train loss = 5.5399\n",
            "Step 1700 avg train loss = 5.5537\n",
            "Step 1800 avg train loss = 5.5514\n",
            "Step 1900 avg train loss = 5.5409\n",
            "Step 2000 avg train loss = 5.5255\n",
            "Step 2100 avg train loss = 5.4920\n",
            "Step 2200 avg train loss = 5.5099\n",
            "Step 2300 avg train loss = 5.4721\n",
            "Step 2400 avg train loss = 5.4798\n",
            "Validation loss after 1 epoch = 5.4089\n",
            "Step 0 avg train loss = 5.4125\n",
            "Step 100 avg train loss = 5.3591\n",
            "Step 200 avg train loss = 5.3388\n",
            "Step 300 avg train loss = 5.3616\n",
            "Step 400 avg train loss = 5.3527\n",
            "Step 500 avg train loss = 5.3481\n",
            "Step 600 avg train loss = 5.3444\n",
            "Step 700 avg train loss = 5.3326\n",
            "Step 800 avg train loss = 5.3339\n",
            "Step 900 avg train loss = 5.3152\n",
            "Step 1000 avg train loss = 5.3282\n",
            "Step 1100 avg train loss = 5.3124\n",
            "Step 1200 avg train loss = 5.3176\n",
            "Step 1300 avg train loss = 5.2889\n",
            "Step 1400 avg train loss = 5.3018\n",
            "Step 1500 avg train loss = 5.3203\n",
            "Step 1600 avg train loss = 5.2899\n",
            "Step 1700 avg train loss = 5.2979\n",
            "Step 1800 avg train loss = 5.3036\n",
            "Step 1900 avg train loss = 5.3054\n",
            "Step 2000 avg train loss = 5.2615\n",
            "Step 2100 avg train loss = 5.2804\n",
            "Step 2200 avg train loss = 5.2600\n",
            "Step 2300 avg train loss = 5.2708\n",
            "Step 2400 avg train loss = 5.2673\n",
            "Validation loss after 2 epoch = 5.3074\n",
            "Step 0 avg train loss = 5.0767\n",
            "Step 100 avg train loss = 5.1266\n",
            "Step 200 avg train loss = 5.1151\n",
            "Step 300 avg train loss = 5.1240\n",
            "Step 400 avg train loss = 5.1216\n",
            "Step 500 avg train loss = 5.1241\n",
            "Step 600 avg train loss = 5.1294\n",
            "Step 700 avg train loss = 5.0884\n",
            "Step 800 avg train loss = 5.1153\n",
            "Step 900 avg train loss = 5.1383\n",
            "Step 1000 avg train loss = 5.1243\n",
            "Step 1100 avg train loss = 5.1352\n",
            "Step 1200 avg train loss = 5.1264\n",
            "Step 1300 avg train loss = 5.1205\n",
            "Step 1400 avg train loss = 5.1058\n",
            "Step 1500 avg train loss = 5.1228\n",
            "Step 1600 avg train loss = 5.1138\n",
            "Step 1700 avg train loss = 5.0996\n",
            "Step 1800 avg train loss = 5.0850\n",
            "Step 1900 avg train loss = 5.1024\n",
            "Step 2000 avg train loss = 5.1001\n",
            "Step 2100 avg train loss = 5.0977\n",
            "Step 2200 avg train loss = 5.1067\n",
            "Step 2300 avg train loss = 5.1118\n",
            "Step 2400 avg train loss = 5.0855\n",
            "Validation loss after 3 epoch = 5.2516\n",
            "Step 0 avg train loss = 4.8916\n",
            "Step 100 avg train loss = 4.9340\n",
            "Step 200 avg train loss = 4.9251\n",
            "Step 300 avg train loss = 4.9643\n",
            "Step 400 avg train loss = 4.9438\n",
            "Step 500 avg train loss = 4.9536\n",
            "Step 600 avg train loss = 4.9610\n",
            "Step 700 avg train loss = 4.9635\n",
            "Step 800 avg train loss = 4.9538\n",
            "Step 900 avg train loss = 4.9599\n",
            "Step 1000 avg train loss = 4.9603\n",
            "Step 1100 avg train loss = 4.9615\n",
            "Step 1200 avg train loss = 4.9598\n",
            "Step 1300 avg train loss = 4.9628\n",
            "Step 1400 avg train loss = 4.9625\n",
            "Step 1500 avg train loss = 4.9733\n",
            "Step 1600 avg train loss = 4.9727\n",
            "Step 1700 avg train loss = 4.9474\n",
            "Step 1800 avg train loss = 4.9597\n",
            "Step 1900 avg train loss = 4.9616\n",
            "Step 2000 avg train loss = 4.9618\n",
            "Step 2100 avg train loss = 4.9740\n",
            "Step 2200 avg train loss = 4.9539\n",
            "Step 2300 avg train loss = 4.9563\n",
            "Step 2400 avg train loss = 4.9462\n",
            "Validation loss after 4 epoch = 5.2255\n",
            "Step 0 avg train loss = 4.8789\n",
            "Step 100 avg train loss = 4.8030\n",
            "Step 200 avg train loss = 4.7898\n",
            "Step 300 avg train loss = 4.8188\n",
            "Step 400 avg train loss = 4.7895\n",
            "Step 500 avg train loss = 4.8342\n",
            "Step 600 avg train loss = 4.8247\n",
            "Step 700 avg train loss = 4.8340\n",
            "Step 800 avg train loss = 4.8207\n",
            "Step 900 avg train loss = 4.8372\n",
            "Step 1000 avg train loss = 4.8188\n",
            "Step 1100 avg train loss = 4.8174\n",
            "Step 1200 avg train loss = 4.8070\n",
            "Step 1300 avg train loss = 4.8299\n",
            "Step 1400 avg train loss = 4.8296\n",
            "Step 1500 avg train loss = 4.8325\n",
            "Step 1600 avg train loss = 4.8128\n",
            "Step 1700 avg train loss = 4.8312\n",
            "Step 1800 avg train loss = 4.8536\n",
            "Step 1900 avg train loss = 4.8203\n",
            "Step 2000 avg train loss = 4.8576\n",
            "Step 2100 avg train loss = 4.8289\n",
            "Step 2200 avg train loss = 4.8614\n",
            "Step 2300 avg train loss = 4.8477\n",
            "Step 2400 avg train loss = 4.8676\n",
            "Validation loss after 5 epoch = 5.2284\n",
            "Step 0 avg train loss = 4.5773\n",
            "Step 100 avg train loss = 4.6798\n",
            "Step 200 avg train loss = 4.7082\n",
            "Step 300 avg train loss = 4.6748\n",
            "Step 400 avg train loss = 4.7208\n",
            "Step 500 avg train loss = 4.6965\n",
            "Step 600 avg train loss = 4.7072\n",
            "Step 700 avg train loss = 4.7018\n",
            "Step 800 avg train loss = 4.7185\n",
            "Step 900 avg train loss = 4.7290\n",
            "Step 1000 avg train loss = 4.7098\n",
            "Step 1100 avg train loss = 4.7224\n",
            "Step 1200 avg train loss = 4.7319\n",
            "Step 1300 avg train loss = 4.7295\n",
            "Step 1400 avg train loss = 4.7316\n",
            "Step 1500 avg train loss = 4.7341\n",
            "Step 1600 avg train loss = 4.7190\n",
            "Step 1700 avg train loss = 4.7110\n",
            "Step 1800 avg train loss = 4.7179\n",
            "Step 1900 avg train loss = 4.7443\n",
            "Step 2000 avg train loss = 4.7150\n",
            "Step 2100 avg train loss = 4.7446\n",
            "Step 2200 avg train loss = 4.7489\n",
            "Step 2300 avg train loss = 4.7345\n",
            "Step 2400 avg train loss = 4.7348\n",
            "Validation loss after 6 epoch = 5.2331\n",
            "Step 0 avg train loss = 4.8415\n",
            "Step 100 avg train loss = 4.5721\n",
            "Step 200 avg train loss = 4.5975\n",
            "Step 300 avg train loss = 4.6016\n",
            "Step 400 avg train loss = 4.5927\n",
            "Step 500 avg train loss = 4.6195\n",
            "Step 600 avg train loss = 4.6020\n",
            "Step 700 avg train loss = 4.6284\n",
            "Step 800 avg train loss = 4.6068\n",
            "Step 900 avg train loss = 4.6244\n",
            "Step 1000 avg train loss = 4.6261\n",
            "Step 1100 avg train loss = 4.6268\n",
            "Step 1200 avg train loss = 4.6069\n",
            "Step 1300 avg train loss = 4.6294\n",
            "Step 1400 avg train loss = 4.6227\n",
            "Step 1500 avg train loss = 4.6318\n",
            "Step 1600 avg train loss = 4.6364\n",
            "Step 1700 avg train loss = 4.6440\n",
            "Step 1800 avg train loss = 4.6583\n",
            "Step 1900 avg train loss = 4.6565\n",
            "Step 2000 avg train loss = 4.6325\n",
            "Step 2100 avg train loss = 4.6490\n",
            "Step 2200 avg train loss = 4.6406\n",
            "Step 2300 avg train loss = 4.6380\n",
            "Step 2400 avg train loss = 4.6417\n",
            "Validation loss after 7 epoch = 5.2567\n",
            "Step 0 avg train loss = 4.5436\n",
            "Step 100 avg train loss = 4.4922\n",
            "Step 200 avg train loss = 4.4902\n",
            "Step 300 avg train loss = 4.5199\n",
            "Step 400 avg train loss = 4.5199\n",
            "Step 500 avg train loss = 4.5139\n",
            "Step 600 avg train loss = 4.5100\n",
            "Step 700 avg train loss = 4.5091\n",
            "Step 800 avg train loss = 4.5325\n",
            "Step 900 avg train loss = 4.5307\n",
            "Step 1000 avg train loss = 4.5282\n",
            "Step 1100 avg train loss = 4.5397\n",
            "Step 1200 avg train loss = 4.5475\n",
            "Step 1300 avg train loss = 4.5560\n",
            "Step 1400 avg train loss = 4.5652\n",
            "Step 1500 avg train loss = 4.5537\n",
            "Step 1600 avg train loss = 4.5599\n",
            "Step 1700 avg train loss = 4.5678\n",
            "Step 1800 avg train loss = 4.5613\n",
            "Step 1900 avg train loss = 4.5457\n",
            "Step 2000 avg train loss = 4.5818\n",
            "Step 2100 avg train loss = 4.5654\n",
            "Step 2200 avg train loss = 4.5745\n",
            "Step 2300 avg train loss = 4.5649\n",
            "Step 2400 avg train loss = 4.5682\n",
            "Validation loss after 8 epoch = 5.2793\n",
            "Step 0 avg train loss = 4.1581\n",
            "Step 100 avg train loss = 4.3905\n",
            "Step 200 avg train loss = 4.4177\n",
            "Step 300 avg train loss = 4.4165\n",
            "Step 400 avg train loss = 4.4440\n",
            "Step 500 avg train loss = 4.4392\n",
            "Step 600 avg train loss = 4.4577\n",
            "Step 700 avg train loss = 4.4636\n",
            "Step 800 avg train loss = 4.4497\n",
            "Step 900 avg train loss = 4.4558\n",
            "Step 1000 avg train loss = 4.4725\n",
            "Step 1100 avg train loss = 4.4647\n",
            "Step 1200 avg train loss = 4.4746\n",
            "Step 1300 avg train loss = 4.4898\n",
            "Step 1400 avg train loss = 4.4802\n",
            "Step 1500 avg train loss = 4.4724\n",
            "Step 1600 avg train loss = 4.4944\n",
            "Step 1700 avg train loss = 4.4806\n",
            "Step 1800 avg train loss = 4.4810\n",
            "Step 1900 avg train loss = 4.5078\n",
            "Step 2000 avg train loss = 4.4798\n",
            "Step 2100 avg train loss = 4.4784\n",
            "Step 2200 avg train loss = 4.4975\n",
            "Step 2300 avg train loss = 4.5086\n",
            "Step 2400 avg train loss = 4.5145\n",
            "Validation loss after 9 epoch = 5.3026\n",
            "Step 0 avg train loss = 4.3879\n",
            "Step 100 avg train loss = 4.3463\n",
            "Step 200 avg train loss = 4.3374\n",
            "Step 300 avg train loss = 4.3608\n",
            "Step 400 avg train loss = 4.3780\n",
            "Step 500 avg train loss = 4.3618\n",
            "Step 600 avg train loss = 4.3782\n",
            "Step 700 avg train loss = 4.3804\n",
            "Step 800 avg train loss = 4.3948\n",
            "Step 900 avg train loss = 4.3831\n",
            "Step 1000 avg train loss = 4.3858\n",
            "Step 1100 avg train loss = 4.3975\n",
            "Step 1200 avg train loss = 4.4239\n",
            "Step 1300 avg train loss = 4.4028\n",
            "Step 1400 avg train loss = 4.3959\n",
            "Step 1500 avg train loss = 4.4076\n",
            "Step 1600 avg train loss = 4.4203\n",
            "Step 1700 avg train loss = 4.4108\n",
            "Step 1800 avg train loss = 4.4262\n",
            "Step 1900 avg train loss = 4.4142\n",
            "Step 2000 avg train loss = 4.4230\n",
            "Step 2100 avg train loss = 4.4381\n",
            "Step 2200 avg train loss = 4.4578\n",
            "Step 2300 avg train loss = 4.4329\n",
            "Step 2400 avg train loss = 4.4334\n",
            "Validation loss after 10 epoch = 5.3355\n",
            "Step 0 avg train loss = 4.1833\n",
            "Step 100 avg train loss = 4.2862\n",
            "Step 200 avg train loss = 4.2857\n",
            "Step 300 avg train loss = 4.2926\n",
            "Step 400 avg train loss = 4.2991\n",
            "Step 500 avg train loss = 4.3355\n",
            "Step 600 avg train loss = 4.3363\n",
            "Step 700 avg train loss = 4.3314\n",
            "Step 800 avg train loss = 4.3262\n",
            "Step 900 avg train loss = 4.3328\n",
            "Step 1000 avg train loss = 4.3232\n",
            "Step 1100 avg train loss = 4.3425\n",
            "Step 1200 avg train loss = 4.3417\n",
            "Step 1300 avg train loss = 4.3405\n",
            "Step 1400 avg train loss = 4.3359\n",
            "Step 1500 avg train loss = 4.3534\n",
            "Step 1600 avg train loss = 4.3499\n",
            "Step 1700 avg train loss = 4.3575\n",
            "Step 1800 avg train loss = 4.3692\n",
            "Step 1900 avg train loss = 4.3625\n",
            "Step 2000 avg train loss = 4.3554\n",
            "Step 2100 avg train loss = 4.3652\n",
            "Step 2200 avg train loss = 4.3823\n",
            "Step 2300 avg train loss = 4.3568\n",
            "Step 2400 avg train loss = 4.3828\n",
            "Validation loss after 11 epoch = 5.3643\n",
            "Step 0 avg train loss = 3.9015\n",
            "Step 100 avg train loss = 4.2156\n",
            "Step 200 avg train loss = 4.2325\n",
            "Step 300 avg train loss = 4.2363\n",
            "Step 400 avg train loss = 4.2456\n",
            "Step 500 avg train loss = 4.2602\n",
            "Step 600 avg train loss = 4.2600\n",
            "Step 700 avg train loss = 4.2783\n",
            "Step 800 avg train loss = 4.2670\n",
            "Step 900 avg train loss = 4.2730\n",
            "Step 1000 avg train loss = 4.2804\n",
            "Step 1100 avg train loss = 4.2945\n",
            "Step 1200 avg train loss = 4.2802\n",
            "Step 1300 avg train loss = 4.2655\n",
            "Step 1400 avg train loss = 4.2836\n",
            "Step 1500 avg train loss = 4.3148\n",
            "Step 1600 avg train loss = 4.3065\n",
            "Step 1700 avg train loss = 4.3043\n",
            "Step 1800 avg train loss = 4.3097\n",
            "Step 1900 avg train loss = 4.3220\n",
            "Step 2000 avg train loss = 4.2960\n",
            "Step 2100 avg train loss = 4.3156\n",
            "Step 2200 avg train loss = 4.3082\n",
            "Step 2300 avg train loss = 4.3340\n",
            "Step 2400 avg train loss = 4.3314\n",
            "Validation loss after 12 epoch = 5.4011\n",
            "Step 0 avg train loss = 4.2097\n",
            "Step 100 avg train loss = 4.1546\n",
            "Step 200 avg train loss = 4.1888\n",
            "Step 300 avg train loss = 4.2055\n",
            "Step 400 avg train loss = 4.1842\n",
            "Step 500 avg train loss = 4.1929\n",
            "Step 600 avg train loss = 4.1959\n",
            "Step 700 avg train loss = 4.2058\n",
            "Step 800 avg train loss = 4.2134\n",
            "Step 900 avg train loss = 4.2351\n",
            "Step 1000 avg train loss = 4.2454\n",
            "Step 1100 avg train loss = 4.2207\n",
            "Step 1200 avg train loss = 4.2419\n",
            "Step 1300 avg train loss = 4.2376\n",
            "Step 1400 avg train loss = 4.2236\n",
            "Step 1500 avg train loss = 4.2341\n",
            "Step 1600 avg train loss = 4.2361\n",
            "Step 1700 avg train loss = 4.2438\n",
            "Step 1800 avg train loss = 4.2593\n",
            "Step 1900 avg train loss = 4.2627\n",
            "Step 2000 avg train loss = 4.2648\n",
            "Step 2100 avg train loss = 4.2647\n",
            "Step 2200 avg train loss = 4.2852\n",
            "Step 2300 avg train loss = 4.2904\n",
            "Step 2400 avg train loss = 4.2588\n",
            "Validation loss after 13 epoch = 5.4329\n",
            "Step 0 avg train loss = 3.9968\n",
            "Step 100 avg train loss = 4.1199\n",
            "Step 200 avg train loss = 4.1053\n",
            "Step 300 avg train loss = 4.1341\n",
            "Step 400 avg train loss = 4.1318\n",
            "Step 500 avg train loss = 4.1580\n",
            "Step 600 avg train loss = 4.1598\n",
            "Step 700 avg train loss = 4.1517\n",
            "Step 800 avg train loss = 4.1523\n",
            "Step 900 avg train loss = 4.1582\n",
            "Step 1000 avg train loss = 4.1723\n",
            "Step 1100 avg train loss = 4.1901\n",
            "Step 1200 avg train loss = 4.1927\n",
            "Step 1300 avg train loss = 4.1922\n",
            "Step 1400 avg train loss = 4.2144\n",
            "Step 1500 avg train loss = 4.2117\n",
            "Step 1600 avg train loss = 4.2004\n",
            "Step 1700 avg train loss = 4.2220\n",
            "Step 1800 avg train loss = 4.2221\n",
            "Step 1900 avg train loss = 4.2202\n",
            "Step 2000 avg train loss = 4.1999\n",
            "Step 2100 avg train loss = 4.2317\n",
            "Step 2200 avg train loss = 4.2206\n",
            "Step 2300 avg train loss = 4.2274\n",
            "Step 2400 avg train loss = 4.2367\n",
            "Validation loss after 14 epoch = 5.4609\n",
            "Step 0 avg train loss = 4.1878\n",
            "Step 100 avg train loss = 4.0696\n",
            "Step 200 avg train loss = 4.0643\n",
            "Step 300 avg train loss = 4.1074\n",
            "Step 400 avg train loss = 4.1168\n",
            "Step 500 avg train loss = 4.1210\n",
            "Step 600 avg train loss = 4.1072\n",
            "Step 700 avg train loss = 4.1094\n",
            "Step 800 avg train loss = 4.1289\n",
            "Step 900 avg train loss = 4.1048\n",
            "Step 1000 avg train loss = 4.1479\n",
            "Step 1100 avg train loss = 4.1435\n",
            "Step 1200 avg train loss = 4.1333\n",
            "Step 1300 avg train loss = 4.1374\n",
            "Step 1400 avg train loss = 4.1694\n",
            "Step 1500 avg train loss = 4.1767\n",
            "Step 1600 avg train loss = 4.1574\n",
            "Step 1700 avg train loss = 4.1465\n",
            "Step 1800 avg train loss = 4.1458\n",
            "Step 1900 avg train loss = 4.1754\n",
            "Step 2000 avg train loss = 4.1502\n",
            "Step 2100 avg train loss = 4.1709\n",
            "Step 2200 avg train loss = 4.1770\n",
            "Step 2300 avg train loss = 4.1867\n",
            "Step 2400 avg train loss = 4.1882\n",
            "Validation loss after 15 epoch = 5.4983\n",
            "Step 0 avg train loss = 4.1218\n",
            "Step 100 avg train loss = 4.0318\n",
            "Step 200 avg train loss = 4.0299\n",
            "Step 300 avg train loss = 4.0406\n",
            "Step 400 avg train loss = 4.0497\n",
            "Step 500 avg train loss = 4.0483\n",
            "Step 600 avg train loss = 4.0781\n",
            "Step 700 avg train loss = 4.0655\n",
            "Step 800 avg train loss = 4.0720\n",
            "Step 900 avg train loss = 4.0732\n",
            "Step 1000 avg train loss = 4.0911\n",
            "Step 1100 avg train loss = 4.1002\n",
            "Step 1200 avg train loss = 4.0899\n",
            "Step 1300 avg train loss = 4.0931\n",
            "Step 1400 avg train loss = 4.1244\n",
            "Step 1500 avg train loss = 4.1223\n",
            "Step 1600 avg train loss = 4.1194\n",
            "Step 1700 avg train loss = 4.1170\n",
            "Step 1800 avg train loss = 4.1561\n",
            "Step 1900 avg train loss = 4.1252\n",
            "Step 2000 avg train loss = 4.1402\n",
            "Step 2100 avg train loss = 4.1437\n",
            "Step 2200 avg train loss = 4.1330\n",
            "Step 2300 avg train loss = 4.1470\n",
            "Step 2400 avg train loss = 4.1463\n",
            "Validation loss after 16 epoch = 5.5334\n",
            "Step 0 avg train loss = 3.7316\n",
            "Step 100 avg train loss = 4.0013\n",
            "Step 200 avg train loss = 3.9938\n",
            "Step 300 avg train loss = 4.0058\n",
            "Step 400 avg train loss = 4.0110\n",
            "Step 500 avg train loss = 4.0128\n",
            "Step 600 avg train loss = 4.0476\n",
            "Step 700 avg train loss = 4.0376\n",
            "Step 800 avg train loss = 4.0620\n",
            "Step 900 avg train loss = 4.0469\n",
            "Step 1000 avg train loss = 4.0585\n",
            "Step 1100 avg train loss = 4.0540\n",
            "Step 1200 avg train loss = 4.0533\n",
            "Step 1300 avg train loss = 4.0616\n",
            "Step 1400 avg train loss = 4.0754\n",
            "Step 1500 avg train loss = 4.0883\n",
            "Step 1600 avg train loss = 4.0759\n",
            "Step 1700 avg train loss = 4.0898\n",
            "Step 1800 avg train loss = 4.0750\n",
            "Step 1900 avg train loss = 4.0744\n",
            "Step 2000 avg train loss = 4.1101\n",
            "Step 2100 avg train loss = 4.0871\n",
            "Step 2200 avg train loss = 4.0985\n",
            "Step 2300 avg train loss = 4.0938\n",
            "Step 2400 avg train loss = 4.1244\n",
            "Validation loss after 17 epoch = 5.5626\n",
            "Step 0 avg train loss = 4.0586\n",
            "Step 100 avg train loss = 3.9622\n",
            "Step 200 avg train loss = 3.9616\n",
            "Step 300 avg train loss = 3.9661\n",
            "Step 400 avg train loss = 3.9781\n",
            "Step 500 avg train loss = 3.9821\n",
            "Step 600 avg train loss = 3.9901\n",
            "Step 700 avg train loss = 3.9958\n",
            "Step 800 avg train loss = 3.9904\n",
            "Step 900 avg train loss = 4.0086\n",
            "Step 1000 avg train loss = 4.0141\n",
            "Step 1100 avg train loss = 4.0295\n",
            "Step 1200 avg train loss = 4.0179\n",
            "Step 1300 avg train loss = 4.0372\n",
            "Step 1400 avg train loss = 4.0217\n",
            "Step 1500 avg train loss = 4.0407\n",
            "Step 1600 avg train loss = 4.0298\n",
            "Step 1700 avg train loss = 4.0544\n",
            "Step 1800 avg train loss = 4.0632\n",
            "Step 1900 avg train loss = 4.0674\n",
            "Step 2000 avg train loss = 4.0524\n",
            "Step 2100 avg train loss = 4.0640\n",
            "Step 2200 avg train loss = 4.0670\n",
            "Step 2300 avg train loss = 4.0740\n",
            "Step 2400 avg train loss = 4.0513\n",
            "Validation loss after 18 epoch = 5.6016\n",
            "Step 0 avg train loss = 3.9841\n",
            "Step 100 avg train loss = 3.9164\n",
            "Step 200 avg train loss = 3.9314\n",
            "Step 300 avg train loss = 3.9329\n",
            "Step 400 avg train loss = 3.9385\n",
            "Step 500 avg train loss = 3.9649\n",
            "Step 600 avg train loss = 3.9697\n",
            "Step 700 avg train loss = 3.9678\n",
            "Step 800 avg train loss = 3.9723\n",
            "Step 900 avg train loss = 3.9918\n",
            "Step 1000 avg train loss = 3.9726\n",
            "Step 1100 avg train loss = 3.9727\n",
            "Step 1200 avg train loss = 3.9829\n",
            "Step 1300 avg train loss = 3.9852\n",
            "Step 1400 avg train loss = 3.9998\n",
            "Step 1500 avg train loss = 4.0064\n",
            "Step 1600 avg train loss = 4.0153\n",
            "Step 1700 avg train loss = 4.0046\n",
            "Step 1800 avg train loss = 4.0104\n",
            "Step 1900 avg train loss = 3.9953\n",
            "Step 2000 avg train loss = 4.0229\n",
            "Step 2100 avg train loss = 4.0129\n",
            "Step 2200 avg train loss = 4.0377\n",
            "Step 2300 avg train loss = 4.0442\n",
            "Step 2400 avg train loss = 4.0593\n",
            "Validation loss after 19 epoch = 5.6320\n",
            "Saving best model with best embedding dimension...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NvVH3KCO9_UW",
        "outputId": "7cfe354d-4565-49d0-9837-5976f53a364d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# second hyperparameter tuning: hidden size: 100- 500 \n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "# single grid search for the hyperparameter tuning\n",
        "param_grid_hid_size = {\"hidden_size\": [300,400,500]}    # tried 100, 200 before.\n",
        "\n",
        "# list of parameters=========== \n",
        "epoch_num = 20\n",
        "embedding_size = 300 # find the best embedding size 5.2010 after 5 epoch\n",
        "learning_rate=0.001\n",
        "overall_min_val_loss = 20\n",
        "# Loop over embedding size:\n",
        "for hidden_size in param_grid_hid_size[\"hidden_size\"]:\n",
        "  \n",
        "    embedding_size = embedding_size\n",
        "    hidden_size = hidden_size # output of dimension \n",
        "    num_layers = 2\n",
        "    lstm_dropout = 0.1\n",
        "    # input_size = lookup.weight.size(1)\n",
        "    vocab_size = len(train_dict)\n",
        "\n",
        "    options = {\n",
        "        'num_embeddings': len(train_dict),\n",
        "        'embedding_dim': embedding_size,\n",
        "        'padding_idx': train_dict.get_id('<pad>'),\n",
        "        'input_size': embedding_size,\n",
        "        'hidden_size': hidden_size,\n",
        "        'num_layers': num_layers,\n",
        "        'lstm_dropout': lstm_dropout,\n",
        "        'bias': True,\n",
        "        'bid': False \n",
        "    }\n",
        "\n",
        "    model = LSTMModel(options).to(current_device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=train_dict.get_id('<pad>'))\n",
        "    model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(model_parameters, lr=learning_rate)\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    plot_cache = []\n",
        "    min_val_loss = 20   \n",
        "\n",
        "    for epoch_number in range(epoch_num):\n",
        "\n",
        "    # do train \n",
        "    avg_loss=0\n",
        "    if not load_pretrained:\n",
        "        model.train()\n",
        "        train_log_cache = []\n",
        "        for i, (inp, target) in enumerate(loaders['train']):\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_log_cache.append(loss.item())\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
        "                print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
        "                train_log_cache = []\n",
        "\n",
        "    #do valid\n",
        "    valid_losses = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(loaders['valid']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            valid_losses.append(loss.item())\n",
        "        avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
        "        print('Validation loss after {} epoch = {:.{prec}f}'.format(epoch_number, avg_val_loss, prec=4))\n",
        "        best = avg_val_loss < min_val_loss\n",
        "        if best:\n",
        "            min_val_loss = avg_val_loss\n",
        "            best_model = model\n",
        "            print(\"update best model with this parameter to :\")\n",
        "            print(best_model)\n",
        "\n",
        "    plot_cache.append((avg_loss, avg_val_loss))\n",
        "\n",
        "\n",
        "    if load_pretrained:\n",
        "        break\n",
        "\n",
        "    if (min_val_loss < overall_min_val_loss):\n",
        "    best_model_overall = best_model\n",
        "    overall_min_val_loss = min_val_loss\n",
        "    print(\"update overall best model to :\")\n",
        "    print(best_model_overall)\n",
        "    \n",
        "# save the best model in this single grid search:         \n",
        "print('Saving best model with best hidden size...')\n",
        "torch.save({\n",
        "'options': options,\n",
        "'loss_cache': plot_cache,\n",
        "'model_dict': best_model_overall.state_dict()\n",
        "        }, './hid_tune_best_LSTM.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4099\n",
            "Step 100 avg train loss = 7.6503\n",
            "Step 200 avg train loss = 7.1205\n",
            "Step 300 avg train loss = 6.9481\n",
            "Step 400 avg train loss = 6.7299\n",
            "Step 500 avg train loss = 6.5959\n",
            "Step 600 avg train loss = 6.4814\n",
            "Step 700 avg train loss = 6.3755\n",
            "Step 800 avg train loss = 6.3012\n",
            "Step 900 avg train loss = 6.2247\n",
            "Step 1000 avg train loss = 6.1656\n",
            "Step 1100 avg train loss = 6.1052\n",
            "Step 1200 avg train loss = 6.0663\n",
            "Step 1300 avg train loss = 6.0285\n",
            "Step 1400 avg train loss = 5.9922\n",
            "Step 1500 avg train loss = 5.9431\n",
            "Step 1600 avg train loss = 5.9030\n",
            "Step 1700 avg train loss = 5.8825\n",
            "Step 1800 avg train loss = 5.8530\n",
            "Step 1900 avg train loss = 5.8168\n",
            "Step 2000 avg train loss = 5.7784\n",
            "Step 2100 avg train loss = 5.7565\n",
            "Step 2200 avg train loss = 5.7259\n",
            "Step 2300 avg train loss = 5.7185\n",
            "Step 2400 avg train loss = 5.7055\n",
            "Validation loss after 0 epoch = 5.5290\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 5.4427\n",
            "Step 100 avg train loss = 5.5335\n",
            "Step 200 avg train loss = 5.5159\n",
            "Step 300 avg train loss = 5.5119\n",
            "Step 400 avg train loss = 5.5175\n",
            "Step 500 avg train loss = 5.5026\n",
            "Step 600 avg train loss = 5.4787\n",
            "Step 700 avg train loss = 5.4554\n",
            "Step 800 avg train loss = 5.4593\n",
            "Step 900 avg train loss = 5.4301\n",
            "Step 1000 avg train loss = 5.4231\n",
            "Step 1100 avg train loss = 5.4054\n",
            "Step 1200 avg train loss = 5.3733\n",
            "Step 1300 avg train loss = 5.3645\n",
            "Step 1400 avg train loss = 5.3550\n",
            "Step 1500 avg train loss = 5.3633\n",
            "Step 1600 avg train loss = 5.3374\n",
            "Step 1700 avg train loss = 5.3263\n",
            "Step 1800 avg train loss = 5.3229\n",
            "Step 1900 avg train loss = 5.3222\n",
            "Step 2000 avg train loss = 5.2895\n",
            "Step 2100 avg train loss = 5.2699\n",
            "Step 2200 avg train loss = 5.2679\n",
            "Step 2300 avg train loss = 5.2731\n",
            "Step 2400 avg train loss = 5.2633\n",
            "Validation loss after 1 epoch = 5.2606\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 5.1397\n",
            "Step 100 avg train loss = 5.0791\n",
            "Step 200 avg train loss = 5.0573\n",
            "Step 300 avg train loss = 5.0570\n",
            "Step 400 avg train loss = 5.0327\n",
            "Step 500 avg train loss = 5.0358\n",
            "Step 600 avg train loss = 5.0562\n",
            "Step 700 avg train loss = 5.0531\n",
            "Step 800 avg train loss = 5.0421\n",
            "Step 900 avg train loss = 5.0305\n",
            "Step 1000 avg train loss = 5.0268\n",
            "Step 1100 avg train loss = 5.0174\n",
            "Step 1200 avg train loss = 5.0098\n",
            "Step 1300 avg train loss = 4.9993\n",
            "Step 1400 avg train loss = 5.0077\n",
            "Step 1500 avg train loss = 5.0213\n",
            "Step 1600 avg train loss = 4.9785\n",
            "Step 1700 avg train loss = 5.0014\n",
            "Step 1800 avg train loss = 4.9807\n",
            "Step 1900 avg train loss = 5.0027\n",
            "Step 2000 avg train loss = 4.9883\n",
            "Step 2100 avg train loss = 4.9746\n",
            "Step 2200 avg train loss = 4.9813\n",
            "Step 2300 avg train loss = 4.9706\n",
            "Step 2400 avg train loss = 4.9184\n",
            "Validation loss after 2 epoch = 5.1541\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 4.7694\n",
            "Step 100 avg train loss = 4.7595\n",
            "Step 200 avg train loss = 4.7478\n",
            "Step 300 avg train loss = 4.7492\n",
            "Step 400 avg train loss = 4.7560\n",
            "Step 500 avg train loss = 4.7574\n",
            "Step 600 avg train loss = 4.7632\n",
            "Step 700 avg train loss = 4.7486\n",
            "Step 800 avg train loss = 4.7542\n",
            "Step 900 avg train loss = 4.7281\n",
            "Step 1000 avg train loss = 4.7470\n",
            "Step 1100 avg train loss = 4.7408\n",
            "Step 1200 avg train loss = 4.7567\n",
            "Step 1300 avg train loss = 4.7272\n",
            "Step 1400 avg train loss = 4.7395\n",
            "Step 1500 avg train loss = 4.7376\n",
            "Step 1600 avg train loss = 4.7607\n",
            "Step 1700 avg train loss = 4.7169\n",
            "Step 1800 avg train loss = 4.7630\n",
            "Step 1900 avg train loss = 4.7081\n",
            "Step 2000 avg train loss = 4.7493\n",
            "Step 2100 avg train loss = 4.7253\n",
            "Step 2200 avg train loss = 4.7502\n",
            "Step 2300 avg train loss = 4.7248\n",
            "Step 2400 avg train loss = 4.7259\n",
            "Validation loss after 3 epoch = 5.1226\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 4.4741\n",
            "Step 100 avg train loss = 4.4803\n",
            "Step 200 avg train loss = 4.4952\n",
            "Step 300 avg train loss = 4.5141\n",
            "Step 400 avg train loss = 4.5000\n",
            "Step 500 avg train loss = 4.5007\n",
            "Step 600 avg train loss = 4.5440\n",
            "Step 700 avg train loss = 4.5412\n",
            "Step 800 avg train loss = 4.4976\n",
            "Step 900 avg train loss = 4.5229\n",
            "Step 1000 avg train loss = 4.5425\n",
            "Step 1100 avg train loss = 4.5192\n",
            "Step 1200 avg train loss = 4.5280\n",
            "Step 1300 avg train loss = 4.5341\n",
            "Step 1400 avg train loss = 4.5197\n",
            "Step 1500 avg train loss = 4.5343\n",
            "Step 1600 avg train loss = 4.5381\n",
            "Step 1700 avg train loss = 4.5367\n",
            "Step 1800 avg train loss = 4.5439\n",
            "Step 1900 avg train loss = 4.5416\n",
            "Step 2000 avg train loss = 4.5388\n",
            "Step 2100 avg train loss = 4.5345\n",
            "Step 2200 avg train loss = 4.5394\n",
            "Step 2300 avg train loss = 4.5295\n",
            "Step 2400 avg train loss = 4.5709\n",
            "Validation loss after 4 epoch = 5.1462\n",
            "Step 0 avg train loss = 4.3837\n",
            "Step 100 avg train loss = 4.3057\n",
            "Step 200 avg train loss = 4.3158\n",
            "Step 300 avg train loss = 4.2948\n",
            "Step 400 avg train loss = 4.3173\n",
            "Step 500 avg train loss = 4.3366\n",
            "Step 600 avg train loss = 4.3305\n",
            "Step 700 avg train loss = 4.3099\n",
            "Step 800 avg train loss = 4.3415\n",
            "Step 900 avg train loss = 4.3177\n",
            "Step 1000 avg train loss = 4.3623\n",
            "Step 1100 avg train loss = 4.3501\n",
            "Step 1200 avg train loss = 4.3291\n",
            "Step 1300 avg train loss = 4.3666\n",
            "Step 1400 avg train loss = 4.3728\n",
            "Step 1500 avg train loss = 4.3527\n",
            "Step 1600 avg train loss = 4.3682\n",
            "Step 1700 avg train loss = 4.3785\n",
            "Step 1800 avg train loss = 4.3579\n",
            "Step 1900 avg train loss = 4.3822\n",
            "Step 2000 avg train loss = 4.3779\n",
            "Step 2100 avg train loss = 4.3613\n",
            "Step 2200 avg train loss = 4.3698\n",
            "Step 2300 avg train loss = 4.3592\n",
            "Step 2400 avg train loss = 4.3895\n",
            "Validation loss after 5 epoch = 5.2028\n",
            "Step 0 avg train loss = 4.0526\n",
            "Step 100 avg train loss = 4.1325\n",
            "Step 200 avg train loss = 4.1482\n",
            "Step 300 avg train loss = 4.1528\n",
            "Step 400 avg train loss = 4.1402\n",
            "Step 500 avg train loss = 4.1841\n",
            "Step 600 avg train loss = 4.1917\n",
            "Step 700 avg train loss = 4.1770\n",
            "Step 800 avg train loss = 4.1738\n",
            "Step 900 avg train loss = 4.1912\n",
            "Step 1000 avg train loss = 4.1658\n",
            "Step 1100 avg train loss = 4.1895\n",
            "Step 1200 avg train loss = 4.1859\n",
            "Step 1300 avg train loss = 4.2089\n",
            "Step 1400 avg train loss = 4.2021\n",
            "Step 1500 avg train loss = 4.2086\n",
            "Step 1600 avg train loss = 4.2127\n",
            "Step 1700 avg train loss = 4.2212\n",
            "Step 1800 avg train loss = 4.2368\n",
            "Step 1900 avg train loss = 4.2285\n",
            "Step 2000 avg train loss = 4.2108\n",
            "Step 2100 avg train loss = 4.2291\n",
            "Step 2200 avg train loss = 4.2241\n",
            "Step 2300 avg train loss = 4.2448\n",
            "Step 2400 avg train loss = 4.2500\n",
            "Validation loss after 6 epoch = 5.2643\n",
            "Step 0 avg train loss = 4.1608\n",
            "Step 100 avg train loss = 3.9926\n",
            "Step 200 avg train loss = 3.9853\n",
            "Step 300 avg train loss = 4.0101\n",
            "Step 400 avg train loss = 4.0226\n",
            "Step 500 avg train loss = 4.0400\n",
            "Step 600 avg train loss = 4.0514\n",
            "Step 700 avg train loss = 4.0365\n",
            "Step 800 avg train loss = 4.0351\n",
            "Step 900 avg train loss = 4.0683\n",
            "Step 1000 avg train loss = 4.0576\n",
            "Step 1100 avg train loss = 4.0519\n",
            "Step 1200 avg train loss = 4.0592\n",
            "Step 1300 avg train loss = 4.0794\n",
            "Step 1400 avg train loss = 4.0862\n",
            "Step 1500 avg train loss = 4.0734\n",
            "Step 1600 avg train loss = 4.0884\n",
            "Step 1700 avg train loss = 4.0832\n",
            "Step 1800 avg train loss = 4.0857\n",
            "Step 1900 avg train loss = 4.1060\n",
            "Step 2000 avg train loss = 4.1110\n",
            "Step 2100 avg train loss = 4.1013\n",
            "Step 2200 avg train loss = 4.0906\n",
            "Step 2300 avg train loss = 4.1083\n",
            "Step 2400 avg train loss = 4.1312\n",
            "Validation loss after 7 epoch = 5.3327\n",
            "Step 0 avg train loss = 3.7683\n",
            "Step 100 avg train loss = 3.8570\n",
            "Step 200 avg train loss = 3.8763\n",
            "Step 300 avg train loss = 3.8780\n",
            "Step 400 avg train loss = 3.8904\n",
            "Step 500 avg train loss = 3.9068\n",
            "Step 600 avg train loss = 3.9278\n",
            "Step 700 avg train loss = 3.9140\n",
            "Step 800 avg train loss = 3.9463\n",
            "Step 900 avg train loss = 3.9398\n",
            "Step 1000 avg train loss = 3.9402\n",
            "Step 1100 avg train loss = 3.9359\n",
            "Step 1200 avg train loss = 3.9579\n",
            "Step 1300 avg train loss = 3.9682\n",
            "Step 1400 avg train loss = 3.9625\n",
            "Step 1500 avg train loss = 3.9634\n",
            "Step 1600 avg train loss = 3.9992\n",
            "Step 1700 avg train loss = 3.9688\n",
            "Step 1800 avg train loss = 3.9685\n",
            "Step 1900 avg train loss = 4.0123\n",
            "Step 2000 avg train loss = 4.0018\n",
            "Step 2100 avg train loss = 3.9943\n",
            "Step 2200 avg train loss = 3.9933\n",
            "Step 2300 avg train loss = 3.9897\n",
            "Step 2400 avg train loss = 3.9900\n",
            "Validation loss after 8 epoch = 5.3975\n",
            "Step 0 avg train loss = 3.7222\n",
            "Step 100 avg train loss = 3.7571\n",
            "Step 200 avg train loss = 3.7694\n",
            "Step 300 avg train loss = 3.7698\n",
            "Step 400 avg train loss = 3.7991\n",
            "Step 500 avg train loss = 3.8114\n",
            "Step 600 avg train loss = 3.7970\n",
            "Step 700 avg train loss = 3.8228\n",
            "Step 800 avg train loss = 3.8290\n",
            "Step 900 avg train loss = 3.8350\n",
            "Step 1000 avg train loss = 3.8275\n",
            "Step 1100 avg train loss = 3.8465\n",
            "Step 1200 avg train loss = 3.8479\n",
            "Step 1300 avg train loss = 3.8568\n",
            "Step 1400 avg train loss = 3.8392\n",
            "Step 1500 avg train loss = 3.8794\n",
            "Step 1600 avg train loss = 3.8874\n",
            "Step 1700 avg train loss = 3.8756\n",
            "Step 1800 avg train loss = 3.8972\n",
            "Step 1900 avg train loss = 3.8759\n",
            "Step 2000 avg train loss = 3.8924\n",
            "Step 2100 avg train loss = 3.8987\n",
            "Step 2200 avg train loss = 3.8825\n",
            "Step 2300 avg train loss = 3.9162\n",
            "Step 2400 avg train loss = 3.8946\n",
            "Validation loss after 9 epoch = 5.4741\n",
            "Step 0 avg train loss = 3.7291\n",
            "Step 100 avg train loss = 3.6551\n",
            "Step 200 avg train loss = 3.6756\n",
            "Step 300 avg train loss = 3.6913\n",
            "Step 400 avg train loss = 3.6820\n",
            "Step 500 avg train loss = 3.7193\n",
            "Step 600 avg train loss = 3.6884\n",
            "Step 700 avg train loss = 3.7278\n",
            "Step 800 avg train loss = 3.7154\n",
            "Step 900 avg train loss = 3.7263\n",
            "Step 1000 avg train loss = 3.7529\n",
            "Step 1100 avg train loss = 3.7575\n",
            "Step 1200 avg train loss = 3.7585\n",
            "Step 1300 avg train loss = 3.7535\n",
            "Step 1400 avg train loss = 3.7745\n",
            "Step 1500 avg train loss = 3.7748\n",
            "Step 1600 avg train loss = 3.7892\n",
            "Step 1700 avg train loss = 3.7992\n",
            "Step 1800 avg train loss = 3.7850\n",
            "Step 1900 avg train loss = 3.7759\n",
            "Step 2000 avg train loss = 3.7892\n",
            "Step 2100 avg train loss = 3.7872\n",
            "Step 2200 avg train loss = 3.8131\n",
            "Step 2300 avg train loss = 3.8323\n",
            "Step 2400 avg train loss = 3.8356\n",
            "Validation loss after 10 epoch = 5.5322\n",
            "Step 0 avg train loss = 3.8113\n",
            "Step 100 avg train loss = 3.5682\n",
            "Step 200 avg train loss = 3.5750\n",
            "Step 300 avg train loss = 3.5833\n",
            "Step 400 avg train loss = 3.6055\n",
            "Step 500 avg train loss = 3.6171\n",
            "Step 600 avg train loss = 3.6419\n",
            "Step 700 avg train loss = 3.6146\n",
            "Step 800 avg train loss = 3.6351\n",
            "Step 900 avg train loss = 3.6484\n",
            "Step 1000 avg train loss = 3.6540\n",
            "Step 1100 avg train loss = 3.6774\n",
            "Step 1200 avg train loss = 3.6741\n",
            "Step 1300 avg train loss = 3.6976\n",
            "Step 1400 avg train loss = 3.6839\n",
            "Step 1500 avg train loss = 3.6895\n",
            "Step 1600 avg train loss = 3.7053\n",
            "Step 1700 avg train loss = 3.6926\n",
            "Step 1800 avg train loss = 3.7059\n",
            "Step 1900 avg train loss = 3.7257\n",
            "Step 2000 avg train loss = 3.7028\n",
            "Step 2100 avg train loss = 3.7292\n",
            "Step 2200 avg train loss = 3.7338\n",
            "Step 2300 avg train loss = 3.7201\n",
            "Step 2400 avg train loss = 3.7461\n",
            "Validation loss after 11 epoch = 5.6184\n",
            "Step 0 avg train loss = 3.3071\n",
            "Step 100 avg train loss = 3.4697\n",
            "Step 200 avg train loss = 3.4999\n",
            "Step 300 avg train loss = 3.5252\n",
            "Step 400 avg train loss = 3.5207\n",
            "Step 500 avg train loss = 3.5351\n",
            "Step 600 avg train loss = 3.5686\n",
            "Step 700 avg train loss = 3.5591\n",
            "Step 800 avg train loss = 3.5615\n",
            "Step 900 avg train loss = 3.5776\n",
            "Step 1000 avg train loss = 3.5719\n",
            "Step 1100 avg train loss = 3.5880\n",
            "Step 1200 avg train loss = 3.6035\n",
            "Step 1300 avg train loss = 3.5975\n",
            "Step 1400 avg train loss = 3.6062\n",
            "Step 1500 avg train loss = 3.6110\n",
            "Step 1600 avg train loss = 3.6164\n",
            "Step 1700 avg train loss = 3.6234\n",
            "Step 1800 avg train loss = 3.6323\n",
            "Step 1900 avg train loss = 3.6218\n",
            "Step 2000 avg train loss = 3.6716\n",
            "Step 2100 avg train loss = 3.6399\n",
            "Step 2200 avg train loss = 3.6409\n",
            "Step 2300 avg train loss = 3.6468\n",
            "Step 2400 avg train loss = 3.6594\n",
            "Validation loss after 12 epoch = 5.6740\n",
            "Step 0 avg train loss = 3.4354\n",
            "Step 100 avg train loss = 3.4094\n",
            "Step 200 avg train loss = 3.4397\n",
            "Step 300 avg train loss = 3.4415\n",
            "Step 400 avg train loss = 3.4573\n",
            "Step 500 avg train loss = 3.4640\n",
            "Step 600 avg train loss = 3.4705\n",
            "Step 700 avg train loss = 3.4894\n",
            "Step 800 avg train loss = 3.4910\n",
            "Step 900 avg train loss = 3.5019\n",
            "Step 1000 avg train loss = 3.5078\n",
            "Step 1100 avg train loss = 3.5457\n",
            "Step 1200 avg train loss = 3.5079\n",
            "Step 1300 avg train loss = 3.5296\n",
            "Step 1400 avg train loss = 3.5421\n",
            "Step 1500 avg train loss = 3.5358\n",
            "Step 1600 avg train loss = 3.5525\n",
            "Step 1700 avg train loss = 3.5517\n",
            "Step 1800 avg train loss = 3.5501\n",
            "Step 1900 avg train loss = 3.5790\n",
            "Step 2000 avg train loss = 3.5600\n",
            "Step 2100 avg train loss = 3.5644\n",
            "Step 2200 avg train loss = 3.5797\n",
            "Step 2300 avg train loss = 3.5731\n",
            "Step 2400 avg train loss = 3.5812\n",
            "Validation loss after 13 epoch = 5.7475\n",
            "Step 0 avg train loss = 3.2863\n",
            "Step 100 avg train loss = 3.3622\n",
            "Step 200 avg train loss = 3.3642\n",
            "Step 300 avg train loss = 3.3426\n",
            "Step 400 avg train loss = 3.3910\n",
            "Step 500 avg train loss = 3.4220\n",
            "Step 600 avg train loss = 3.4062\n",
            "Step 700 avg train loss = 3.4011\n",
            "Step 800 avg train loss = 3.4230\n",
            "Step 900 avg train loss = 3.4452\n",
            "Step 1000 avg train loss = 3.4464\n",
            "Step 1100 avg train loss = 3.4487\n",
            "Step 1200 avg train loss = 3.4500\n",
            "Step 1300 avg train loss = 3.4658\n",
            "Step 1400 avg train loss = 3.4717\n",
            "Step 1500 avg train loss = 3.4795\n",
            "Step 1600 avg train loss = 3.4666\n",
            "Step 1700 avg train loss = 3.4916\n",
            "Step 1800 avg train loss = 3.4915\n",
            "Step 1900 avg train loss = 3.5139\n",
            "Step 2000 avg train loss = 3.5037\n",
            "Step 2100 avg train loss = 3.4985\n",
            "Step 2200 avg train loss = 3.5241\n",
            "Step 2300 avg train loss = 3.5092\n",
            "Step 2400 avg train loss = 3.5168\n",
            "Validation loss after 14 epoch = 5.8012\n",
            "Step 0 avg train loss = 3.1319\n",
            "Step 100 avg train loss = 3.2800\n",
            "Step 200 avg train loss = 3.3174\n",
            "Step 300 avg train loss = 3.3142\n",
            "Step 400 avg train loss = 3.2987\n",
            "Step 500 avg train loss = 3.3539\n",
            "Step 600 avg train loss = 3.3492\n",
            "Step 700 avg train loss = 3.3694\n",
            "Step 800 avg train loss = 3.3564\n",
            "Step 900 avg train loss = 3.3689\n",
            "Step 1000 avg train loss = 3.3779\n",
            "Step 1100 avg train loss = 3.3759\n",
            "Step 1200 avg train loss = 3.3902\n",
            "Step 1300 avg train loss = 3.3965\n",
            "Step 1400 avg train loss = 3.4062\n",
            "Step 1500 avg train loss = 3.3951\n",
            "Step 1600 avg train loss = 3.4263\n",
            "Step 1700 avg train loss = 3.4413\n",
            "Step 1800 avg train loss = 3.4143\n",
            "Step 1900 avg train loss = 3.4398\n",
            "Step 2000 avg train loss = 3.4500\n",
            "Step 2100 avg train loss = 3.4363\n",
            "Step 2200 avg train loss = 3.4307\n",
            "Step 2300 avg train loss = 3.4724\n",
            "Step 2400 avg train loss = 3.4862\n",
            "Validation loss after 15 epoch = 5.8743\n",
            "Step 0 avg train loss = 3.2559\n",
            "Step 100 avg train loss = 3.2319\n",
            "Step 200 avg train loss = 3.2329\n",
            "Step 300 avg train loss = 3.2552\n",
            "Step 400 avg train loss = 3.2595\n",
            "Step 500 avg train loss = 3.2810\n",
            "Step 600 avg train loss = 3.2685\n",
            "Step 700 avg train loss = 3.3044\n",
            "Step 800 avg train loss = 3.3060\n",
            "Step 900 avg train loss = 3.3145\n",
            "Step 1000 avg train loss = 3.3244\n",
            "Step 1100 avg train loss = 3.3450\n",
            "Step 1200 avg train loss = 3.3607\n",
            "Step 1300 avg train loss = 3.3391\n",
            "Step 1400 avg train loss = 3.3500\n",
            "Step 1500 avg train loss = 3.3405\n",
            "Step 1600 avg train loss = 3.3485\n",
            "Step 1700 avg train loss = 3.3663\n",
            "Step 1800 avg train loss = 3.3645\n",
            "Step 1900 avg train loss = 3.3857\n",
            "Step 2000 avg train loss = 3.4084\n",
            "Step 2100 avg train loss = 3.3891\n",
            "Step 2200 avg train loss = 3.3910\n",
            "Step 2300 avg train loss = 3.3972\n",
            "Step 2400 avg train loss = 3.4180\n",
            "Validation loss after 16 epoch = 5.9382\n",
            "Step 0 avg train loss = 3.1351\n",
            "Step 100 avg train loss = 3.1690\n",
            "Step 200 avg train loss = 3.1953\n",
            "Step 300 avg train loss = 3.2114\n",
            "Step 400 avg train loss = 3.2002\n",
            "Step 500 avg train loss = 3.2336\n",
            "Step 600 avg train loss = 3.2433\n",
            "Step 700 avg train loss = 3.2336\n",
            "Step 800 avg train loss = 3.2417\n",
            "Step 900 avg train loss = 3.2495\n",
            "Step 1000 avg train loss = 3.2415\n",
            "Step 1100 avg train loss = 3.2660\n",
            "Step 1200 avg train loss = 3.2834\n",
            "Step 1300 avg train loss = 3.2966\n",
            "Step 1400 avg train loss = 3.3176\n",
            "Step 1500 avg train loss = 3.3167\n",
            "Step 1600 avg train loss = 3.3291\n",
            "Step 1700 avg train loss = 3.3274\n",
            "Step 1800 avg train loss = 3.3178\n",
            "Step 1900 avg train loss = 3.3335\n",
            "Step 2000 avg train loss = 3.3340\n",
            "Step 2100 avg train loss = 3.3309\n",
            "Step 2200 avg train loss = 3.3299\n",
            "Step 2300 avg train loss = 3.3410\n",
            "Step 2400 avg train loss = 3.3604\n",
            "Validation loss after 17 epoch = 6.0043\n",
            "Step 0 avg train loss = 3.2853\n",
            "Step 100 avg train loss = 3.1190\n",
            "Step 200 avg train loss = 3.1357\n",
            "Step 300 avg train loss = 3.1676\n",
            "Step 400 avg train loss = 3.1814\n",
            "Step 500 avg train loss = 3.1903\n",
            "Step 600 avg train loss = 3.1763\n",
            "Step 700 avg train loss = 3.1932\n",
            "Step 800 avg train loss = 3.1999\n",
            "Step 900 avg train loss = 3.1999\n",
            "Step 1000 avg train loss = 3.2263\n",
            "Step 1100 avg train loss = 3.2124\n",
            "Step 1200 avg train loss = 3.2228\n",
            "Step 1300 avg train loss = 3.2570\n",
            "Step 1400 avg train loss = 3.2456\n",
            "Step 1500 avg train loss = 3.2563\n",
            "Step 1600 avg train loss = 3.2409\n",
            "Step 1700 avg train loss = 3.2554\n",
            "Step 1800 avg train loss = 3.2732\n",
            "Step 1900 avg train loss = 3.2781\n",
            "Step 2000 avg train loss = 3.2878\n",
            "Step 2100 avg train loss = 3.2644\n",
            "Step 2200 avg train loss = 3.2989\n",
            "Step 2300 avg train loss = 3.2963\n",
            "Step 2400 avg train loss = 3.3218\n",
            "Validation loss after 18 epoch = 6.0666\n",
            "Step 0 avg train loss = 3.0786\n",
            "Step 100 avg train loss = 3.0703\n",
            "Step 200 avg train loss = 3.1080\n",
            "Step 300 avg train loss = 3.0987\n",
            "Step 400 avg train loss = 3.1110\n",
            "Step 500 avg train loss = 3.1162\n",
            "Step 600 avg train loss = 3.1442\n",
            "Step 700 avg train loss = 3.1542\n",
            "Step 800 avg train loss = 3.1599\n",
            "Step 900 avg train loss = 3.1698\n",
            "Step 1000 avg train loss = 3.1614\n",
            "Step 1100 avg train loss = 3.1674\n",
            "Step 1200 avg train loss = 3.1715\n",
            "Step 1300 avg train loss = 3.1744\n",
            "Step 1400 avg train loss = 3.1836\n",
            "Step 1500 avg train loss = 3.1990\n",
            "Step 1600 avg train loss = 3.1874\n",
            "Step 1700 avg train loss = 3.2311\n",
            "Step 1800 avg train loss = 3.2313\n",
            "Step 1900 avg train loss = 3.2201\n",
            "Step 2000 avg train loss = 3.2436\n",
            "Step 2100 avg train loss = 3.2652\n",
            "Step 2200 avg train loss = 3.2567\n",
            "Step 2300 avg train loss = 3.2652\n",
            "Step 2400 avg train loss = 3.2681\n",
            "Validation loss after 19 epoch = 6.1196\n",
            "update overall best model to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
            ")\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 400, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=400, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4098\n",
            "Step 100 avg train loss = 7.6492\n",
            "Step 200 avg train loss = 7.0818\n",
            "Step 300 avg train loss = 6.8396\n",
            "Step 400 avg train loss = 6.6375\n",
            "Step 500 avg train loss = 6.4900\n",
            "Step 600 avg train loss = 6.4086\n",
            "Step 700 avg train loss = 6.2855\n",
            "Step 800 avg train loss = 6.2186\n",
            "Step 900 avg train loss = 6.1665\n",
            "Step 1000 avg train loss = 6.1015\n",
            "Step 1100 avg train loss = 6.0557\n",
            "Step 1200 avg train loss = 6.0004\n",
            "Step 1300 avg train loss = 5.9636\n",
            "Step 1400 avg train loss = 5.9022\n",
            "Step 1500 avg train loss = 5.8735\n",
            "Step 1600 avg train loss = 5.8570\n",
            "Step 1700 avg train loss = 5.8130\n",
            "Step 1800 avg train loss = 5.7860\n",
            "Step 1900 avg train loss = 5.7499\n",
            "Step 2000 avg train loss = 5.7413\n",
            "Step 2100 avg train loss = 5.7078\n",
            "Step 2200 avg train loss = 5.6742\n",
            "Step 2300 avg train loss = 5.6488\n",
            "Step 2400 avg train loss = 5.6270\n",
            "Validation loss after 0 epoch = 5.4853\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 400, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=400, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 5.4978\n",
            "Step 100 avg train loss = 5.4801\n",
            "Step 200 avg train loss = 5.4537\n",
            "Step 300 avg train loss = 5.4182\n",
            "Step 400 avg train loss = 5.4334\n",
            "Step 500 avg train loss = 5.4009\n",
            "Step 600 avg train loss = 5.4067\n",
            "Step 700 avg train loss = 5.3802\n",
            "Step 800 avg train loss = 5.3669\n",
            "Step 900 avg train loss = 5.3725\n",
            "Step 1000 avg train loss = 5.3187\n",
            "Step 1100 avg train loss = 5.3181\n",
            "Step 1200 avg train loss = 5.3102\n",
            "Step 1300 avg train loss = 5.2929\n",
            "Step 1400 avg train loss = 5.2853\n",
            "Step 1500 avg train loss = 5.2878\n",
            "Step 1600 avg train loss = 5.2364\n",
            "Step 1700 avg train loss = 5.2652\n",
            "Step 1800 avg train loss = 5.2310\n",
            "Step 1900 avg train loss = 5.2376\n",
            "Step 2000 avg train loss = 5.2195\n",
            "Step 2100 avg train loss = 5.1981\n",
            "Step 2200 avg train loss = 5.1933\n",
            "Step 2300 avg train loss = 5.2065\n",
            "Step 2400 avg train loss = 5.1798\n",
            "Validation loss after 1 epoch = 5.2252\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 400, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=400, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 4.9563\n",
            "Step 100 avg train loss = 4.9419\n",
            "Step 200 avg train loss = 4.9624\n",
            "Step 300 avg train loss = 4.9590\n",
            "Step 400 avg train loss = 4.9417\n",
            "Step 500 avg train loss = 4.9319\n",
            "Step 600 avg train loss = 4.9172\n",
            "Step 700 avg train loss = 4.9420\n",
            "Step 800 avg train loss = 4.9540\n",
            "Step 900 avg train loss = 4.9483\n",
            "Step 1000 avg train loss = 4.9140\n",
            "Step 1100 avg train loss = 4.9100\n",
            "Step 1200 avg train loss = 4.9191\n",
            "Step 1300 avg train loss = 4.9099\n",
            "Step 1400 avg train loss = 4.9314\n",
            "Step 1500 avg train loss = 4.9077\n",
            "Step 1600 avg train loss = 4.9266\n",
            "Step 1700 avg train loss = 4.9105\n",
            "Step 1800 avg train loss = 4.9041\n",
            "Step 1900 avg train loss = 4.9077\n",
            "Step 2000 avg train loss = 4.8442\n",
            "Step 2100 avg train loss = 4.8740\n",
            "Step 2200 avg train loss = 4.8757\n",
            "Step 2300 avg train loss = 4.8494\n",
            "Step 2400 avg train loss = 4.8564\n",
            "Validation loss after 2 epoch = 5.1418\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 400, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=400, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 4.6708\n",
            "Step 100 avg train loss = 4.6182\n",
            "Step 200 avg train loss = 4.6018\n",
            "Step 300 avg train loss = 4.6213\n",
            "Step 400 avg train loss = 4.5899\n",
            "Step 500 avg train loss = 4.6245\n",
            "Step 600 avg train loss = 4.6162\n",
            "Step 700 avg train loss = 4.6388\n",
            "Step 800 avg train loss = 4.6055\n",
            "Step 900 avg train loss = 4.6350\n",
            "Step 1000 avg train loss = 4.5953\n",
            "Step 1100 avg train loss = 4.6177\n",
            "Step 1200 avg train loss = 4.6018\n",
            "Step 1300 avg train loss = 4.6222\n",
            "Step 1400 avg train loss = 4.6504\n",
            "Step 1500 avg train loss = 4.6123\n",
            "Step 1600 avg train loss = 4.6034\n",
            "Step 1700 avg train loss = 4.6200\n",
            "Step 1800 avg train loss = 4.6032\n",
            "Step 1900 avg train loss = 4.6230\n",
            "Step 2000 avg train loss = 4.6191\n",
            "Step 2100 avg train loss = 4.6030\n",
            "Step 2200 avg train loss = 4.6272\n",
            "Step 2300 avg train loss = 4.6126\n",
            "Step 2400 avg train loss = 4.6244\n",
            "Validation loss after 3 epoch = 5.1319\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 400, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=400, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 4.1984\n",
            "Step 100 avg train loss = 4.3257\n",
            "Step 200 avg train loss = 4.3248\n",
            "Step 300 avg train loss = 4.3606\n",
            "Step 400 avg train loss = 4.3569\n",
            "Step 500 avg train loss = 4.3419\n",
            "Step 600 avg train loss = 4.3553\n",
            "Step 700 avg train loss = 4.3596\n",
            "Step 800 avg train loss = 4.3687\n",
            "Step 900 avg train loss = 4.3636\n",
            "Step 1000 avg train loss = 4.3722\n",
            "Step 1100 avg train loss = 4.3623\n",
            "Step 1200 avg train loss = 4.3746\n",
            "Step 1300 avg train loss = 4.3710\n",
            "Step 1400 avg train loss = 4.4135\n",
            "Step 1500 avg train loss = 4.3609\n",
            "Step 1600 avg train loss = 4.3793\n",
            "Step 1700 avg train loss = 4.3827\n",
            "Step 1800 avg train loss = 4.3834\n",
            "Step 1900 avg train loss = 4.3835\n",
            "Step 2000 avg train loss = 4.3726\n",
            "Step 2100 avg train loss = 4.3558\n",
            "Step 2200 avg train loss = 4.3982\n",
            "Step 2300 avg train loss = 4.3978\n",
            "Step 2400 avg train loss = 4.3891\n",
            "Validation loss after 4 epoch = 5.1783\n",
            "Step 0 avg train loss = 4.3267\n",
            "Step 100 avg train loss = 4.0815\n",
            "Step 200 avg train loss = 4.1013\n",
            "Step 300 avg train loss = 4.1208\n",
            "Step 400 avg train loss = 4.1366\n",
            "Step 500 avg train loss = 4.1387\n",
            "Step 600 avg train loss = 4.1273\n",
            "Step 700 avg train loss = 4.1667\n",
            "Step 800 avg train loss = 4.1553\n",
            "Step 900 avg train loss = 4.1509\n",
            "Step 1000 avg train loss = 4.1352\n",
            "Step 1100 avg train loss = 4.1615\n",
            "Step 1200 avg train loss = 4.1634\n",
            "Step 1300 avg train loss = 4.1712\n",
            "Step 1400 avg train loss = 4.1358\n",
            "Step 1500 avg train loss = 4.1743\n",
            "Step 1600 avg train loss = 4.1838\n",
            "Step 1700 avg train loss = 4.1937\n",
            "Step 1800 avg train loss = 4.1910\n",
            "Step 1900 avg train loss = 4.2073\n",
            "Step 2000 avg train loss = 4.1915\n",
            "Step 2100 avg train loss = 4.2064\n",
            "Step 2200 avg train loss = 4.2135\n",
            "Step 2300 avg train loss = 4.2095\n",
            "Step 2400 avg train loss = 4.1995\n",
            "Validation loss after 5 epoch = 5.2598\n",
            "Step 0 avg train loss = 4.0770\n",
            "Step 100 avg train loss = 3.8953\n",
            "Step 200 avg train loss = 3.9058\n",
            "Step 300 avg train loss = 3.9239\n",
            "Step 400 avg train loss = 3.9259\n",
            "Step 500 avg train loss = 3.9415\n",
            "Step 600 avg train loss = 3.9482\n",
            "Step 700 avg train loss = 3.9858\n",
            "Step 800 avg train loss = 3.9854\n",
            "Step 900 avg train loss = 3.9786\n",
            "Step 1000 avg train loss = 3.9942\n",
            "Step 1100 avg train loss = 3.9807\n",
            "Step 1200 avg train loss = 3.9844\n",
            "Step 1300 avg train loss = 3.9762\n",
            "Step 1400 avg train loss = 4.0142\n",
            "Step 1500 avg train loss = 4.0333\n",
            "Step 1600 avg train loss = 3.9999\n",
            "Step 1700 avg train loss = 4.0310\n",
            "Step 1800 avg train loss = 4.0176\n",
            "Step 1900 avg train loss = 4.0273\n",
            "Step 2000 avg train loss = 4.0134\n",
            "Step 2100 avg train loss = 4.0241\n",
            "Step 2200 avg train loss = 4.0345\n",
            "Step 2300 avg train loss = 4.0351\n",
            "Step 2400 avg train loss = 4.0457\n",
            "Validation loss after 6 epoch = 5.3545\n",
            "Step 0 avg train loss = 3.6888\n",
            "Step 100 avg train loss = 3.7567\n",
            "Step 200 avg train loss = 3.7618\n",
            "Step 300 avg train loss = 3.7711\n",
            "Step 400 avg train loss = 3.7734\n",
            "Step 500 avg train loss = 3.7867\n",
            "Step 600 avg train loss = 3.8039\n",
            "Step 700 avg train loss = 3.8021\n",
            "Step 800 avg train loss = 3.8081\n",
            "Step 900 avg train loss = 3.8029\n",
            "Step 1000 avg train loss = 3.8465\n",
            "Step 1100 avg train loss = 3.8210\n",
            "Step 1200 avg train loss = 3.8431\n",
            "Step 1300 avg train loss = 3.8501\n",
            "Step 1400 avg train loss = 3.8391\n",
            "Step 1500 avg train loss = 3.8666\n",
            "Step 1600 avg train loss = 3.8492\n",
            "Step 1700 avg train loss = 3.8766\n",
            "Step 1800 avg train loss = 3.8715\n",
            "Step 1900 avg train loss = 3.8747\n",
            "Step 2000 avg train loss = 3.9033\n",
            "Step 2100 avg train loss = 3.8794\n",
            "Step 2200 avg train loss = 3.8816\n",
            "Step 2300 avg train loss = 3.8944\n",
            "Step 2400 avg train loss = 3.8788\n",
            "Validation loss after 7 epoch = 5.4317\n",
            "Step 0 avg train loss = 3.5293\n",
            "Step 100 avg train loss = 3.5914\n",
            "Step 200 avg train loss = 3.6155\n",
            "Step 300 avg train loss = 3.6266\n",
            "Step 400 avg train loss = 3.6419\n",
            "Step 500 avg train loss = 3.6547\n",
            "Step 600 avg train loss = 3.6716\n",
            "Step 700 avg train loss = 3.6686\n",
            "Step 800 avg train loss = 3.6737\n",
            "Step 900 avg train loss = 3.6960\n",
            "Step 1000 avg train loss = 3.6889\n",
            "Step 1100 avg train loss = 3.6950\n",
            "Step 1200 avg train loss = 3.7026\n",
            "Step 1300 avg train loss = 3.7058\n",
            "Step 1400 avg train loss = 3.7133\n",
            "Step 1500 avg train loss = 3.7117\n",
            "Step 1600 avg train loss = 3.7329\n",
            "Step 1700 avg train loss = 3.7520\n",
            "Step 1800 avg train loss = 3.7565\n",
            "Step 1900 avg train loss = 3.7602\n",
            "Step 2000 avg train loss = 3.7511\n",
            "Step 2100 avg train loss = 3.7588\n",
            "Step 2200 avg train loss = 3.7471\n",
            "Step 2300 avg train loss = 3.7601\n",
            "Step 2400 avg train loss = 3.7692\n",
            "Validation loss after 8 epoch = 5.5335\n",
            "Step 0 avg train loss = 3.3417\n",
            "Step 100 avg train loss = 3.4848\n",
            "Step 200 avg train loss = 3.4885\n",
            "Step 300 avg train loss = 3.4967\n",
            "Step 400 avg train loss = 3.5262\n",
            "Step 500 avg train loss = 3.5265\n",
            "Step 600 avg train loss = 3.5474\n",
            "Step 700 avg train loss = 3.5607\n",
            "Step 800 avg train loss = 3.5524\n",
            "Step 900 avg train loss = 3.5694\n",
            "Step 1000 avg train loss = 3.5705\n",
            "Step 1100 avg train loss = 3.5858\n",
            "Step 1200 avg train loss = 3.5875\n",
            "Step 1300 avg train loss = 3.5775\n",
            "Step 1400 avg train loss = 3.6043\n",
            "Step 1500 avg train loss = 3.6175\n",
            "Step 1600 avg train loss = 3.6140\n",
            "Step 1700 avg train loss = 3.6320\n",
            "Step 1800 avg train loss = 3.6224\n",
            "Step 1900 avg train loss = 3.6364\n",
            "Step 2000 avg train loss = 3.6624\n",
            "Step 2100 avg train loss = 3.6389\n",
            "Step 2200 avg train loss = 3.6535\n",
            "Step 2300 avg train loss = 3.6378\n",
            "Step 2400 avg train loss = 3.6603\n",
            "Validation loss after 9 epoch = 5.6182\n",
            "Step 0 avg train loss = 3.3034\n",
            "Step 100 avg train loss = 3.3584\n",
            "Step 200 avg train loss = 3.3782\n",
            "Step 300 avg train loss = 3.4030\n",
            "Step 400 avg train loss = 3.4027\n",
            "Step 500 avg train loss = 3.4284\n",
            "Step 600 avg train loss = 3.4111\n",
            "Step 700 avg train loss = 3.4428\n",
            "Step 800 avg train loss = 3.4594\n",
            "Step 900 avg train loss = 3.4710\n",
            "Step 1000 avg train loss = 3.4843\n",
            "Step 1100 avg train loss = 3.4743\n",
            "Step 1200 avg train loss = 3.4900\n",
            "Step 1300 avg train loss = 3.4779\n",
            "Step 1400 avg train loss = 3.5020\n",
            "Step 1500 avg train loss = 3.5063\n",
            "Step 1600 avg train loss = 3.5033\n",
            "Step 1700 avg train loss = 3.5028\n",
            "Step 1800 avg train loss = 3.5285\n",
            "Step 1900 avg train loss = 3.5348\n",
            "Step 2000 avg train loss = 3.5361\n",
            "Step 2100 avg train loss = 3.5453\n",
            "Step 2200 avg train loss = 3.5496\n",
            "Step 2300 avg train loss = 3.5588\n",
            "Step 2400 avg train loss = 3.5547\n",
            "Validation loss after 10 epoch = 5.7020\n",
            "Step 0 avg train loss = 3.3197\n",
            "Step 100 avg train loss = 3.2687\n",
            "Step 200 avg train loss = 3.2940\n",
            "Step 300 avg train loss = 3.3024\n",
            "Step 400 avg train loss = 3.2912\n",
            "Step 500 avg train loss = 3.3248\n",
            "Step 600 avg train loss = 3.3277\n",
            "Step 700 avg train loss = 3.3432\n",
            "Step 800 avg train loss = 3.3481\n",
            "Step 900 avg train loss = 3.3556\n",
            "Step 1000 avg train loss = 3.3667\n",
            "Step 1100 avg train loss = 3.3778\n",
            "Step 1200 avg train loss = 3.3893\n",
            "Step 1300 avg train loss = 3.3955\n",
            "Step 1400 avg train loss = 3.4064\n",
            "Step 1500 avg train loss = 3.4020\n",
            "Step 1600 avg train loss = 3.4201\n",
            "Step 1700 avg train loss = 3.4314\n",
            "Step 1800 avg train loss = 3.4327\n",
            "Step 1900 avg train loss = 3.4203\n",
            "Step 2000 avg train loss = 3.4670\n",
            "Step 2100 avg train loss = 3.4326\n",
            "Step 2200 avg train loss = 3.4685\n",
            "Step 2300 avg train loss = 3.4706\n",
            "Step 2400 avg train loss = 3.4718\n",
            "Validation loss after 11 epoch = 5.7811\n",
            "Step 0 avg train loss = 3.1593\n",
            "Step 100 avg train loss = 3.1740\n",
            "Step 200 avg train loss = 3.1943\n",
            "Step 300 avg train loss = 3.2210\n",
            "Step 400 avg train loss = 3.2295\n",
            "Step 500 avg train loss = 3.2266\n",
            "Step 600 avg train loss = 3.2484\n",
            "Step 700 avg train loss = 3.2586\n",
            "Step 800 avg train loss = 3.2983\n",
            "Step 900 avg train loss = 3.2702\n",
            "Step 1000 avg train loss = 3.2896\n",
            "Step 1100 avg train loss = 3.2868\n",
            "Step 1200 avg train loss = 3.2988\n",
            "Step 1300 avg train loss = 3.2955\n",
            "Step 1400 avg train loss = 3.3128\n",
            "Step 1500 avg train loss = 3.3274\n",
            "Step 1600 avg train loss = 3.3191\n",
            "Step 1700 avg train loss = 3.3373\n",
            "Step 1800 avg train loss = 3.3478\n",
            "Step 1900 avg train loss = 3.3784\n",
            "Step 2000 avg train loss = 3.3317\n",
            "Step 2100 avg train loss = 3.3659\n",
            "Step 2200 avg train loss = 3.3760\n",
            "Step 2300 avg train loss = 3.3654\n",
            "Step 2400 avg train loss = 3.3821\n",
            "Validation loss after 12 epoch = 5.8643\n",
            "Step 0 avg train loss = 3.0546\n",
            "Step 100 avg train loss = 3.0860\n",
            "Step 200 avg train loss = 3.1035\n",
            "Step 300 avg train loss = 3.1314\n",
            "Step 400 avg train loss = 3.1468\n",
            "Step 500 avg train loss = 3.1111\n",
            "Step 600 avg train loss = 3.1740\n",
            "Step 700 avg train loss = 3.1720\n",
            "Step 800 avg train loss = 3.1812\n",
            "Step 900 avg train loss = 3.2001\n",
            "Step 1000 avg train loss = 3.2121\n",
            "Step 1100 avg train loss = 3.2036\n",
            "Step 1200 avg train loss = 3.2392\n",
            "Step 1300 avg train loss = 3.2119\n",
            "Step 1400 avg train loss = 3.2444\n",
            "Step 1500 avg train loss = 3.2563\n",
            "Step 1600 avg train loss = 3.2646\n",
            "Step 1700 avg train loss = 3.2761\n",
            "Step 1800 avg train loss = 3.2711\n",
            "Step 1900 avg train loss = 3.2788\n",
            "Step 2000 avg train loss = 3.2643\n",
            "Step 2100 avg train loss = 3.3107\n",
            "Step 2200 avg train loss = 3.2955\n",
            "Step 2300 avg train loss = 3.2918\n",
            "Step 2400 avg train loss = 3.2972\n",
            "Validation loss after 13 epoch = 5.9623\n",
            "Step 0 avg train loss = 2.9659\n",
            "Step 100 avg train loss = 3.0193\n",
            "Step 200 avg train loss = 3.0386\n",
            "Step 300 avg train loss = 3.0568\n",
            "Step 400 avg train loss = 3.0749\n",
            "Step 500 avg train loss = 3.0801\n",
            "Step 600 avg train loss = 3.0783\n",
            "Step 700 avg train loss = 3.0918\n",
            "Step 800 avg train loss = 3.1381\n",
            "Step 900 avg train loss = 3.1109\n",
            "Step 1000 avg train loss = 3.1379\n",
            "Step 1100 avg train loss = 3.1388\n",
            "Step 1200 avg train loss = 3.1538\n",
            "Step 1300 avg train loss = 3.1400\n",
            "Step 1400 avg train loss = 3.1523\n",
            "Step 1500 avg train loss = 3.1817\n",
            "Step 1600 avg train loss = 3.1791\n",
            "Step 1700 avg train loss = 3.1988\n",
            "Step 1800 avg train loss = 3.1831\n",
            "Step 1900 avg train loss = 3.2086\n",
            "Step 2000 avg train loss = 3.2190\n",
            "Step 2100 avg train loss = 3.1977\n",
            "Step 2200 avg train loss = 3.2158\n",
            "Step 2300 avg train loss = 3.2463\n",
            "Step 2400 avg train loss = 3.2277\n",
            "Validation loss after 14 epoch = 6.0368\n",
            "Step 0 avg train loss = 2.9817\n",
            "Step 100 avg train loss = 2.9552\n",
            "Step 200 avg train loss = 2.9650\n",
            "Step 300 avg train loss = 2.9853\n",
            "Step 400 avg train loss = 2.9887\n",
            "Step 500 avg train loss = 3.0032\n",
            "Step 600 avg train loss = 3.0215\n",
            "Step 700 avg train loss = 3.0294\n",
            "Step 800 avg train loss = 3.0399\n",
            "Step 900 avg train loss = 3.0567\n",
            "Step 1000 avg train loss = 3.0624\n",
            "Step 1100 avg train loss = 3.0673\n",
            "Step 1200 avg train loss = 3.0825\n",
            "Step 1300 avg train loss = 3.0895\n",
            "Step 1400 avg train loss = 3.1259\n",
            "Step 1500 avg train loss = 3.0896\n",
            "Step 1600 avg train loss = 3.1016\n",
            "Step 1700 avg train loss = 3.1299\n",
            "Step 1800 avg train loss = 3.1363\n",
            "Step 1900 avg train loss = 3.1474\n",
            "Step 2000 avg train loss = 3.1495\n",
            "Step 2100 avg train loss = 3.1356\n",
            "Step 2200 avg train loss = 3.1607\n",
            "Step 2300 avg train loss = 3.1621\n",
            "Step 2400 avg train loss = 3.1593\n",
            "Validation loss after 15 epoch = 6.1278\n",
            "Step 0 avg train loss = 2.9548\n",
            "Step 100 avg train loss = 2.8902\n",
            "Step 200 avg train loss = 2.9097\n",
            "Step 300 avg train loss = 2.9183\n",
            "Step 400 avg train loss = 2.9435\n",
            "Step 500 avg train loss = 2.9313\n",
            "Step 600 avg train loss = 2.9565\n",
            "Step 700 avg train loss = 2.9946\n",
            "Step 800 avg train loss = 2.9731\n",
            "Step 900 avg train loss = 2.9919\n",
            "Step 1000 avg train loss = 2.9844\n",
            "Step 1100 avg train loss = 3.0177\n",
            "Step 1200 avg train loss = 3.0334\n",
            "Step 1300 avg train loss = 3.0319\n",
            "Step 1400 avg train loss = 3.0392\n",
            "Step 1500 avg train loss = 3.0507\n",
            "Step 1600 avg train loss = 3.0552\n",
            "Step 1700 avg train loss = 3.0480\n",
            "Step 1800 avg train loss = 3.0520\n",
            "Step 1900 avg train loss = 3.0781\n",
            "Step 2000 avg train loss = 3.0756\n",
            "Step 2100 avg train loss = 3.0740\n",
            "Step 2200 avg train loss = 3.0842\n",
            "Step 2300 avg train loss = 3.1047\n",
            "Step 2400 avg train loss = 3.0946\n",
            "Validation loss after 16 epoch = 6.1878\n",
            "Step 0 avg train loss = 2.9692\n",
            "Step 100 avg train loss = 2.8490\n",
            "Step 200 avg train loss = 2.8594\n",
            "Step 300 avg train loss = 2.8711\n",
            "Step 400 avg train loss = 2.8764\n",
            "Step 500 avg train loss = 2.8777\n",
            "Step 600 avg train loss = 2.8987\n",
            "Step 700 avg train loss = 2.9009\n",
            "Step 800 avg train loss = 2.9115\n",
            "Step 900 avg train loss = 2.9392\n",
            "Step 1000 avg train loss = 2.9389\n",
            "Step 1100 avg train loss = 2.9538\n",
            "Step 1200 avg train loss = 2.9782\n",
            "Step 1300 avg train loss = 2.9729\n",
            "Step 1400 avg train loss = 2.9739\n",
            "Step 1500 avg train loss = 2.9782\n",
            "Step 1600 avg train loss = 2.9799\n",
            "Step 1700 avg train loss = 3.0012\n",
            "Step 1800 avg train loss = 3.0020\n",
            "Step 1900 avg train loss = 3.0152\n",
            "Step 2000 avg train loss = 3.0033\n",
            "Step 2100 avg train loss = 3.0122\n",
            "Step 2200 avg train loss = 3.0447\n",
            "Step 2300 avg train loss = 3.0528\n",
            "Step 2400 avg train loss = 3.0611\n",
            "Validation loss after 17 epoch = 6.2703\n",
            "Step 0 avg train loss = 2.6015\n",
            "Step 100 avg train loss = 2.7929\n",
            "Step 200 avg train loss = 2.8007\n",
            "Step 300 avg train loss = 2.8053\n",
            "Step 400 avg train loss = 2.8242\n",
            "Step 500 avg train loss = 2.8374\n",
            "Step 600 avg train loss = 2.8434\n",
            "Step 700 avg train loss = 2.8758\n",
            "Step 800 avg train loss = 2.8585\n",
            "Step 900 avg train loss = 2.8912\n",
            "Step 1000 avg train loss = 2.8690\n",
            "Step 1100 avg train loss = 2.8939\n",
            "Step 1200 avg train loss = 2.8830\n",
            "Step 1300 avg train loss = 2.9047\n",
            "Step 1400 avg train loss = 2.9210\n",
            "Step 1500 avg train loss = 2.9172\n",
            "Step 1600 avg train loss = 2.9197\n",
            "Step 1700 avg train loss = 2.9678\n",
            "Step 1800 avg train loss = 2.9587\n",
            "Step 1900 avg train loss = 2.9517\n",
            "Step 2000 avg train loss = 2.9617\n",
            "Step 2100 avg train loss = 2.9888\n",
            "Step 2200 avg train loss = 2.9582\n",
            "Step 2300 avg train loss = 3.0080\n",
            "Step 2400 avg train loss = 2.9950\n",
            "Validation loss after 18 epoch = 6.3557\n",
            "Step 0 avg train loss = 2.8078\n",
            "Step 100 avg train loss = 2.7176\n",
            "Step 200 avg train loss = 2.7478\n",
            "Step 300 avg train loss = 2.7561\n",
            "Step 400 avg train loss = 2.7776\n",
            "Step 500 avg train loss = 2.7945\n",
            "Step 600 avg train loss = 2.7926\n",
            "Step 700 avg train loss = 2.8061\n",
            "Step 800 avg train loss = 2.8010\n",
            "Step 900 avg train loss = 2.8376\n",
            "Step 1000 avg train loss = 2.8438\n",
            "Step 1100 avg train loss = 2.8430\n",
            "Step 1200 avg train loss = 2.8473\n",
            "Step 1300 avg train loss = 2.8606\n",
            "Step 1400 avg train loss = 2.8584\n",
            "Step 1500 avg train loss = 2.8948\n",
            "Step 1600 avg train loss = 2.8853\n",
            "Step 1700 avg train loss = 2.8977\n",
            "Step 1800 avg train loss = 2.8820\n",
            "Step 1900 avg train loss = 2.9080\n",
            "Step 2000 avg train loss = 2.9208\n",
            "Step 2100 avg train loss = 2.9194\n",
            "Step 2200 avg train loss = 2.9315\n",
            "Step 2300 avg train loss = 2.9370\n",
            "Step 2400 avg train loss = 2.9421\n",
            "Validation loss after 19 epoch = 6.4216\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 500, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=500, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 10.4077\n",
            "Step 100 avg train loss = 7.6064\n",
            "Step 200 avg train loss = 7.1188\n",
            "Step 300 avg train loss = 6.8872\n",
            "Step 400 avg train loss = 6.7077\n",
            "Step 500 avg train loss = 6.5587\n",
            "Step 600 avg train loss = 6.4424\n",
            "Step 700 avg train loss = 6.3522\n",
            "Step 800 avg train loss = 6.2640\n",
            "Step 900 avg train loss = 6.1831\n",
            "Step 1000 avg train loss = 6.1223\n",
            "Step 1100 avg train loss = 6.0599\n",
            "Step 1200 avg train loss = 5.9943\n",
            "Step 1300 avg train loss = 5.9851\n",
            "Step 1400 avg train loss = 5.9378\n",
            "Step 1500 avg train loss = 5.9196\n",
            "Step 1600 avg train loss = 5.8563\n",
            "Step 1700 avg train loss = 5.8292\n",
            "Step 1800 avg train loss = 5.8014\n",
            "Step 1900 avg train loss = 5.7638\n",
            "Step 2000 avg train loss = 5.7581\n",
            "Step 2100 avg train loss = 5.7021\n",
            "Step 2200 avg train loss = 5.6820\n",
            "Step 2300 avg train loss = 5.6952\n",
            "Step 2400 avg train loss = 5.6331\n",
            "Validation loss after 0 epoch = 5.4937\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 500, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=500, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 5.7384\n",
            "Step 100 avg train loss = 5.4760\n",
            "Step 200 avg train loss = 5.4694\n",
            "Step 300 avg train loss = 5.4564\n",
            "Step 400 avg train loss = 5.4394\n",
            "Step 500 avg train loss = 5.4185\n",
            "Step 600 avg train loss = 5.3846\n",
            "Step 700 avg train loss = 5.3973\n",
            "Step 800 avg train loss = 5.3728\n",
            "Step 900 avg train loss = 5.3445\n",
            "Step 1000 avg train loss = 5.3464\n",
            "Step 1100 avg train loss = 5.3261\n",
            "Step 1200 avg train loss = 5.3276\n",
            "Step 1300 avg train loss = 5.2857\n",
            "Step 1400 avg train loss = 5.3209\n",
            "Step 1500 avg train loss = 5.2787\n",
            "Step 1600 avg train loss = 5.2963\n",
            "Step 1700 avg train loss = 5.2553\n",
            "Step 1800 avg train loss = 5.2516\n",
            "Step 1900 avg train loss = 5.2371\n",
            "Step 2000 avg train loss = 5.2500\n",
            "Step 2100 avg train loss = 5.2220\n",
            "Step 2200 avg train loss = 5.1821\n",
            "Step 2300 avg train loss = 5.1965\n",
            "Step 2400 avg train loss = 5.2011\n",
            "Validation loss after 1 epoch = 5.2352\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 500, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=500, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 5.1050\n",
            "Step 100 avg train loss = 4.9629\n",
            "Step 200 avg train loss = 4.9514\n",
            "Step 300 avg train loss = 4.9862\n",
            "Step 400 avg train loss = 4.9708\n",
            "Step 500 avg train loss = 4.9591\n",
            "Step 600 avg train loss = 4.9485\n",
            "Step 700 avg train loss = 4.9427\n",
            "Step 800 avg train loss = 4.9337\n",
            "Step 900 avg train loss = 4.9361\n",
            "Step 1000 avg train loss = 4.9320\n",
            "Step 1100 avg train loss = 4.9463\n",
            "Step 1200 avg train loss = 4.9101\n",
            "Step 1300 avg train loss = 4.8964\n",
            "Step 1400 avg train loss = 4.9356\n",
            "Step 1500 avg train loss = 4.9182\n",
            "Step 1600 avg train loss = 4.8843\n",
            "Step 1700 avg train loss = 4.9028\n",
            "Step 1800 avg train loss = 4.8957\n",
            "Step 1900 avg train loss = 4.8639\n",
            "Step 2000 avg train loss = 4.8747\n",
            "Step 2100 avg train loss = 4.8480\n",
            "Step 2200 avg train loss = 4.8580\n",
            "Step 2300 avg train loss = 4.8615\n",
            "Step 2400 avg train loss = 4.8667\n",
            "Validation loss after 2 epoch = 5.1417\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 500, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=500, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 4.7328\n",
            "Step 100 avg train loss = 4.6224\n",
            "Step 200 avg train loss = 4.6219\n",
            "Step 300 avg train loss = 4.5910\n",
            "Step 400 avg train loss = 4.6119\n",
            "Step 500 avg train loss = 4.6219\n",
            "Step 600 avg train loss = 4.6087\n",
            "Step 700 avg train loss = 4.5887\n",
            "Step 800 avg train loss = 4.6004\n",
            "Step 900 avg train loss = 4.6072\n",
            "Step 1000 avg train loss = 4.6042\n",
            "Step 1100 avg train loss = 4.5923\n",
            "Step 1200 avg train loss = 4.6117\n",
            "Step 1300 avg train loss = 4.5944\n",
            "Step 1400 avg train loss = 4.6115\n",
            "Step 1500 avg train loss = 4.6043\n",
            "Step 1600 avg train loss = 4.6114\n",
            "Step 1700 avg train loss = 4.5812\n",
            "Step 1800 avg train loss = 4.5925\n",
            "Step 1900 avg train loss = 4.5814\n",
            "Step 2000 avg train loss = 4.5873\n",
            "Step 2100 avg train loss = 4.5977\n",
            "Step 2200 avg train loss = 4.5885\n",
            "Step 2300 avg train loss = 4.5981\n",
            "Step 2400 avg train loss = 4.5930\n",
            "Validation loss after 3 epoch = 5.1347\n",
            "update best model with this parameter to :\n",
            "LSTMModel(\n",
            "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
            "  (lstm): LSTM(300, 500, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (projection): Linear(in_features=500, out_features=33178, bias=True)\n",
            ")\n",
            "Step 0 avg train loss = 4.3048\n",
            "Step 100 avg train loss = 4.3094\n",
            "Step 200 avg train loss = 4.2887\n",
            "Step 300 avg train loss = 4.3226\n",
            "Step 400 avg train loss = 4.3107\n",
            "Step 500 avg train loss = 4.3007\n",
            "Step 600 avg train loss = 4.3311\n",
            "Step 700 avg train loss = 4.3349\n",
            "Step 800 avg train loss = 4.3399\n",
            "Step 900 avg train loss = 4.3247\n",
            "Step 1000 avg train loss = 4.3379\n",
            "Step 1100 avg train loss = 4.3310\n",
            "Step 1200 avg train loss = 4.3613\n",
            "Step 1300 avg train loss = 4.3321\n",
            "Step 1400 avg train loss = 4.3506\n",
            "Step 1500 avg train loss = 4.3295\n",
            "Step 1600 avg train loss = 4.3580\n",
            "Step 1700 avg train loss = 4.3405\n",
            "Step 1800 avg train loss = 4.3327\n",
            "Step 1900 avg train loss = 4.3413\n",
            "Step 2000 avg train loss = 4.3332\n",
            "Step 2100 avg train loss = 4.3441\n",
            "Step 2200 avg train loss = 4.3529\n",
            "Step 2300 avg train loss = 4.3523\n",
            "Step 2400 avg train loss = 4.3593\n",
            "Validation loss after 4 epoch = 5.1925\n",
            "Step 0 avg train loss = 4.0341\n",
            "Step 100 avg train loss = 4.0648\n",
            "Step 200 avg train loss = 4.0773\n",
            "Step 300 avg train loss = 4.0565\n",
            "Step 400 avg train loss = 4.0659\n",
            "Step 500 avg train loss = 4.0704\n",
            "Step 600 avg train loss = 4.0727\n",
            "Step 700 avg train loss = 4.0718\n",
            "Step 800 avg train loss = 4.0730\n",
            "Step 900 avg train loss = 4.1037\n",
            "Step 1000 avg train loss = 4.1036\n",
            "Step 1100 avg train loss = 4.1140\n",
            "Step 1200 avg train loss = 4.1229\n",
            "Step 1300 avg train loss = 4.1157\n",
            "Step 1400 avg train loss = 4.1211\n",
            "Step 1500 avg train loss = 4.1316\n",
            "Step 1600 avg train loss = 4.1158\n",
            "Step 1700 avg train loss = 4.1222\n",
            "Step 1800 avg train loss = 4.1366\n",
            "Step 1900 avg train loss = 4.1232\n",
            "Step 2000 avg train loss = 4.1374\n",
            "Step 2100 avg train loss = 4.1356\n",
            "Step 2200 avg train loss = 4.1401\n",
            "Step 2300 avg train loss = 4.1441\n",
            "Step 2400 avg train loss = 4.1589\n",
            "Validation loss after 5 epoch = 5.2773\n",
            "Step 0 avg train loss = 3.7871\n",
            "Step 100 avg train loss = 3.8495\n",
            "Step 200 avg train loss = 3.8627\n",
            "Step 300 avg train loss = 3.8637\n",
            "Step 400 avg train loss = 3.8582\n",
            "Step 500 avg train loss = 3.8678\n",
            "Step 600 avg train loss = 3.8964\n",
            "Step 700 avg train loss = 3.8671\n",
            "Step 800 avg train loss = 3.9013\n",
            "Step 900 avg train loss = 3.9142\n",
            "Step 1000 avg train loss = 3.8942\n",
            "Step 1100 avg train loss = 3.9272\n",
            "Step 1200 avg train loss = 3.9077\n",
            "Step 1300 avg train loss = 3.9375\n",
            "Step 1400 avg train loss = 3.9307\n",
            "Step 1500 avg train loss = 3.9406\n",
            "Step 1600 avg train loss = 3.9097\n",
            "Step 1700 avg train loss = 3.9314\n",
            "Step 1800 avg train loss = 3.9388\n",
            "Step 1900 avg train loss = 3.9174\n",
            "Step 2000 avg train loss = 3.9537\n",
            "Step 2100 avg train loss = 3.9427\n",
            "Step 2200 avg train loss = 3.9539\n",
            "Step 2300 avg train loss = 3.9729\n",
            "Step 2400 avg train loss = 3.9640\n",
            "Validation loss after 6 epoch = 5.3755\n",
            "Step 0 avg train loss = 3.7822\n",
            "Step 100 avg train loss = 3.6365\n",
            "Step 200 avg train loss = 3.6531\n",
            "Step 300 avg train loss = 3.6741\n",
            "Step 400 avg train loss = 3.6637\n",
            "Step 500 avg train loss = 3.7043\n",
            "Step 600 avg train loss = 3.6737\n",
            "Step 700 avg train loss = 3.7231\n",
            "Step 800 avg train loss = 3.7235\n",
            "Step 900 avg train loss = 3.7163\n",
            "Step 1000 avg train loss = 3.7501\n",
            "Step 1100 avg train loss = 3.7475\n",
            "Step 1200 avg train loss = 3.7483\n",
            "Step 1300 avg train loss = 3.7670\n",
            "Step 1400 avg train loss = 3.7549\n",
            "Step 1500 avg train loss = 3.7761\n",
            "Step 1600 avg train loss = 3.7613\n",
            "Step 1700 avg train loss = 3.7767\n",
            "Step 1800 avg train loss = 3.7785\n",
            "Step 1900 avg train loss = 3.7836\n",
            "Step 2000 avg train loss = 3.8006\n",
            "Step 2100 avg train loss = 3.7794\n",
            "Step 2200 avg train loss = 3.7850\n",
            "Step 2300 avg train loss = 3.8056\n",
            "Step 2400 avg train loss = 3.8014\n",
            "Validation loss after 7 epoch = 5.4719\n",
            "Step 0 avg train loss = 3.5151\n",
            "Step 100 avg train loss = 3.4982\n",
            "Step 200 avg train loss = 3.5009\n",
            "Step 300 avg train loss = 3.5243\n",
            "Step 400 avg train loss = 3.5202\n",
            "Step 500 avg train loss = 3.5344\n",
            "Step 600 avg train loss = 3.5566\n",
            "Step 700 avg train loss = 3.5698\n",
            "Step 800 avg train loss = 3.5740\n",
            "Step 900 avg train loss = 3.5883\n",
            "Step 1000 avg train loss = 3.5904\n",
            "Step 1100 avg train loss = 3.5711\n",
            "Step 1200 avg train loss = 3.5960\n",
            "Step 1300 avg train loss = 3.6224\n",
            "Step 1400 avg train loss = 3.6314\n",
            "Step 1500 avg train loss = 3.6115\n",
            "Step 1600 avg train loss = 3.6116\n",
            "Step 1700 avg train loss = 3.6117\n",
            "Step 1800 avg train loss = 3.6321\n",
            "Step 1900 avg train loss = 3.6276\n",
            "Step 2000 avg train loss = 3.6327\n",
            "Step 2100 avg train loss = 3.6326\n",
            "Step 2200 avg train loss = 3.6578\n",
            "Step 2300 avg train loss = 3.6335\n",
            "Step 2400 avg train loss = 3.6607\n",
            "Validation loss after 8 epoch = 5.5715\n",
            "Step 0 avg train loss = 3.3935\n",
            "Step 100 avg train loss = 3.3383\n",
            "Step 200 avg train loss = 3.3612\n",
            "Step 300 avg train loss = 3.3737\n",
            "Step 400 avg train loss = 3.3933\n",
            "Step 500 avg train loss = 3.3982\n",
            "Step 600 avg train loss = 3.4095\n",
            "Step 700 avg train loss = 3.4026\n",
            "Step 800 avg train loss = 3.4239\n",
            "Step 900 avg train loss = 3.4404\n",
            "Step 1000 avg train loss = 3.4640\n",
            "Step 1100 avg train loss = 3.4526\n",
            "Step 1200 avg train loss = 3.4546\n",
            "Step 1300 avg train loss = 3.4692\n",
            "Step 1400 avg train loss = 3.4936\n",
            "Step 1500 avg train loss = 3.4688\n",
            "Step 1600 avg train loss = 3.4947\n",
            "Step 1700 avg train loss = 3.5107\n",
            "Step 1800 avg train loss = 3.5144\n",
            "Step 1900 avg train loss = 3.4911\n",
            "Step 2000 avg train loss = 3.5131\n",
            "Step 2100 avg train loss = 3.5350\n",
            "Step 2200 avg train loss = 3.5237\n",
            "Step 2300 avg train loss = 3.5331\n",
            "Step 2400 avg train loss = 3.5294\n",
            "Validation loss after 9 epoch = 5.6814\n",
            "Step 0 avg train loss = 3.0327\n",
            "Step 100 avg train loss = 3.2090\n",
            "Step 200 avg train loss = 3.2490\n",
            "Step 300 avg train loss = 3.2668\n",
            "Step 400 avg train loss = 3.2697\n",
            "Step 500 avg train loss = 3.2815\n",
            "Step 600 avg train loss = 3.2876\n",
            "Step 700 avg train loss = 3.3146\n",
            "Step 800 avg train loss = 3.3071\n",
            "Step 900 avg train loss = 3.3215\n",
            "Step 1000 avg train loss = 3.3224\n",
            "Step 1100 avg train loss = 3.3219\n",
            "Step 1200 avg train loss = 3.3379\n",
            "Step 1300 avg train loss = 3.3503\n",
            "Step 1400 avg train loss = 3.3554\n",
            "Step 1500 avg train loss = 3.3446\n",
            "Step 1600 avg train loss = 3.3939\n",
            "Step 1700 avg train loss = 3.3791\n",
            "Step 1800 avg train loss = 3.3890\n",
            "Step 1900 avg train loss = 3.3869\n",
            "Step 2000 avg train loss = 3.4056\n",
            "Step 2100 avg train loss = 3.3935\n",
            "Step 2200 avg train loss = 3.3943\n",
            "Step 2300 avg train loss = 3.4037\n",
            "Step 2400 avg train loss = 3.4180\n",
            "Validation loss after 10 epoch = 5.7895\n",
            "Step 0 avg train loss = 2.8903\n",
            "Step 100 avg train loss = 3.1383\n",
            "Step 200 avg train loss = 3.1143\n",
            "Step 300 avg train loss = 3.1353\n",
            "Step 400 avg train loss = 3.1768\n",
            "Step 500 avg train loss = 3.1719\n",
            "Step 600 avg train loss = 3.1761\n",
            "Step 700 avg train loss = 3.1903\n",
            "Step 800 avg train loss = 3.1938\n",
            "Step 900 avg train loss = 3.2128\n",
            "Step 1000 avg train loss = 3.1902\n",
            "Step 1100 avg train loss = 3.2145\n",
            "Step 1200 avg train loss = 3.2526\n",
            "Step 1300 avg train loss = 3.2469\n",
            "Step 1400 avg train loss = 3.2426\n",
            "Step 1500 avg train loss = 3.2509\n",
            "Step 1600 avg train loss = 3.2589\n",
            "Step 1700 avg train loss = 3.2584\n",
            "Step 1800 avg train loss = 3.2709\n",
            "Step 1900 avg train loss = 3.2852\n",
            "Step 2000 avg train loss = 3.2846\n",
            "Step 2100 avg train loss = 3.2778\n",
            "Step 2200 avg train loss = 3.2944\n",
            "Step 2300 avg train loss = 3.3308\n",
            "Step 2400 avg train loss = 3.3094\n",
            "Validation loss after 11 epoch = 5.8828\n",
            "Step 0 avg train loss = 3.0910\n",
            "Step 100 avg train loss = 3.0178\n",
            "Step 200 avg train loss = 3.0330\n",
            "Step 300 avg train loss = 3.0473\n",
            "Step 400 avg train loss = 3.0549\n",
            "Step 500 avg train loss = 3.0530\n",
            "Step 600 avg train loss = 3.0847\n",
            "Step 700 avg train loss = 3.0864\n",
            "Step 800 avg train loss = 3.0970\n",
            "Step 900 avg train loss = 3.1050\n",
            "Step 1000 avg train loss = 3.1211\n",
            "Step 1100 avg train loss = 3.1404\n",
            "Step 1200 avg train loss = 3.1259\n",
            "Step 1300 avg train loss = 3.1181\n",
            "Step 1400 avg train loss = 3.1375\n",
            "Step 1500 avg train loss = 3.1584\n",
            "Step 1600 avg train loss = 3.1662\n",
            "Step 1700 avg train loss = 3.1725\n",
            "Step 1800 avg train loss = 3.1680\n",
            "Step 1900 avg train loss = 3.1846\n",
            "Step 2000 avg train loss = 3.1896\n",
            "Step 2100 avg train loss = 3.1954\n",
            "Step 2200 avg train loss = 3.1878\n",
            "Step 2300 avg train loss = 3.2092\n",
            "Step 2400 avg train loss = 3.2150\n",
            "Validation loss after 12 epoch = 5.9675\n",
            "Step 0 avg train loss = 2.9783\n",
            "Step 100 avg train loss = 2.9048\n",
            "Step 200 avg train loss = 2.9429\n",
            "Step 300 avg train loss = 2.9448\n",
            "Step 400 avg train loss = 2.9676\n",
            "Step 500 avg train loss = 2.9684\n",
            "Step 600 avg train loss = 2.9781\n",
            "Step 700 avg train loss = 2.9828\n",
            "Step 800 avg train loss = 2.9920\n",
            "Step 900 avg train loss = 3.0052\n",
            "Step 1000 avg train loss = 3.0129\n",
            "Step 1100 avg train loss = 3.0453\n",
            "Step 1200 avg train loss = 3.0511\n",
            "Step 1300 avg train loss = 3.0580\n",
            "Step 1400 avg train loss = 3.0458\n",
            "Step 1500 avg train loss = 3.0590\n",
            "Step 1600 avg train loss = 3.0758\n",
            "Step 1700 avg train loss = 3.0930\n",
            "Step 1800 avg train loss = 3.0658\n",
            "Step 1900 avg train loss = 3.1115\n",
            "Step 2000 avg train loss = 3.1061\n",
            "Step 2100 avg train loss = 3.1086\n",
            "Step 2200 avg train loss = 3.1080\n",
            "Step 2300 avg train loss = 3.1236\n",
            "Step 2400 avg train loss = 3.1132\n",
            "Validation loss after 13 epoch = 6.0703\n",
            "Step 0 avg train loss = 2.8731\n",
            "Step 100 avg train loss = 2.8398\n",
            "Step 200 avg train loss = 2.8621\n",
            "Step 300 avg train loss = 2.8618\n",
            "Step 400 avg train loss = 2.8679\n",
            "Step 500 avg train loss = 2.8782\n",
            "Step 600 avg train loss = 2.8914\n",
            "Step 700 avg train loss = 2.9137\n",
            "Step 800 avg train loss = 2.9158\n",
            "Step 900 avg train loss = 2.9425\n",
            "Step 1000 avg train loss = 2.9437\n",
            "Step 1100 avg train loss = 2.9451\n",
            "Step 1200 avg train loss = 2.9310\n",
            "Step 1300 avg train loss = 2.9597\n",
            "Step 1400 avg train loss = 2.9745\n",
            "Step 1500 avg train loss = 2.9727\n",
            "Step 1600 avg train loss = 2.9810\n",
            "Step 1700 avg train loss = 2.9899\n",
            "Step 1800 avg train loss = 3.0147\n",
            "Step 1900 avg train loss = 3.0164\n",
            "Step 2000 avg train loss = 3.0084\n",
            "Step 2100 avg train loss = 3.0050\n",
            "Step 2200 avg train loss = 3.0206\n",
            "Step 2300 avg train loss = 3.0476\n",
            "Step 2400 avg train loss = 3.0498\n",
            "Validation loss after 14 epoch = 6.1553\n",
            "Step 0 avg train loss = 2.7818\n",
            "Step 100 avg train loss = 2.7490\n",
            "Step 200 avg train loss = 2.7735\n",
            "Step 300 avg train loss = 2.7666\n",
            "Step 400 avg train loss = 2.7970\n",
            "Step 500 avg train loss = 2.8040\n",
            "Step 600 avg train loss = 2.8197\n",
            "Step 700 avg train loss = 2.8474\n",
            "Step 800 avg train loss = 2.8349\n",
            "Step 900 avg train loss = 2.8583\n",
            "Step 1000 avg train loss = 2.8626\n",
            "Step 1100 avg train loss = 2.8696\n",
            "Step 1200 avg train loss = 2.8801\n",
            "Step 1300 avg train loss = 2.8791\n",
            "Step 1400 avg train loss = 2.9030\n",
            "Step 1500 avg train loss = 2.9135\n",
            "Step 1600 avg train loss = 2.9102\n",
            "Step 1700 avg train loss = 2.9090\n",
            "Step 1800 avg train loss = 2.9311\n",
            "Step 1900 avg train loss = 2.9086\n",
            "Step 2000 avg train loss = 2.9217\n",
            "Step 2100 avg train loss = 2.9261\n",
            "Step 2200 avg train loss = 2.9566\n",
            "Step 2300 avg train loss = 2.9619\n",
            "Step 2400 avg train loss = 2.9721\n",
            "Validation loss after 15 epoch = 6.2485\n",
            "Step 0 avg train loss = 2.5668\n",
            "Step 100 avg train loss = 2.6929\n",
            "Step 200 avg train loss = 2.6929\n",
            "Step 300 avg train loss = 2.7125\n",
            "Step 400 avg train loss = 2.7135\n",
            "Step 500 avg train loss = 2.7303\n",
            "Step 600 avg train loss = 2.7504\n",
            "Step 700 avg train loss = 2.7528\n",
            "Step 800 avg train loss = 2.7709\n",
            "Step 900 avg train loss = 2.7720\n",
            "Step 1000 avg train loss = 2.7981\n",
            "Step 1100 avg train loss = 2.7916\n",
            "Step 1200 avg train loss = 2.7920\n",
            "Step 1300 avg train loss = 2.8145\n",
            "Step 1400 avg train loss = 2.8174\n",
            "Step 1500 avg train loss = 2.8180\n",
            "Step 1600 avg train loss = 2.8438\n",
            "Step 1700 avg train loss = 2.8491\n",
            "Step 1800 avg train loss = 2.8554\n",
            "Step 1900 avg train loss = 2.8658\n",
            "Step 2000 avg train loss = 2.8525\n",
            "Step 2100 avg train loss = 2.8779\n",
            "Step 2200 avg train loss = 2.8815\n",
            "Step 2300 avg train loss = 2.8795\n",
            "Step 2400 avg train loss = 2.8964\n",
            "Validation loss after 16 epoch = 6.3413\n",
            "Step 0 avg train loss = 2.6056\n",
            "Step 100 avg train loss = 2.5963\n",
            "Step 200 avg train loss = 2.6145\n",
            "Step 300 avg train loss = 2.6291\n",
            "Step 400 avg train loss = 2.6377\n",
            "Step 500 avg train loss = 2.6703\n",
            "Step 600 avg train loss = 2.6745\n",
            "Step 700 avg train loss = 2.6891\n",
            "Step 800 avg train loss = 2.6998\n",
            "Step 900 avg train loss = 2.7105\n",
            "Step 1000 avg train loss = 2.7068\n",
            "Step 1100 avg train loss = 2.7122\n",
            "Step 1200 avg train loss = 2.7520\n",
            "Step 1300 avg train loss = 2.7555\n",
            "Step 1400 avg train loss = 2.7477\n",
            "Step 1500 avg train loss = 2.7717\n",
            "Step 1600 avg train loss = 2.7634\n",
            "Step 1700 avg train loss = 2.7909\n",
            "Step 1800 avg train loss = 2.7942\n",
            "Step 1900 avg train loss = 2.7838\n",
            "Step 2000 avg train loss = 2.8128\n",
            "Step 2100 avg train loss = 2.8115\n",
            "Step 2200 avg train loss = 2.8254\n",
            "Step 2300 avg train loss = 2.8114\n",
            "Step 2400 avg train loss = 2.8193\n",
            "Validation loss after 17 epoch = 6.4270\n",
            "Step 0 avg train loss = 2.5140\n",
            "Step 100 avg train loss = 2.5560\n",
            "Step 200 avg train loss = 2.5445\n",
            "Step 300 avg train loss = 2.5535\n",
            "Step 400 avg train loss = 2.5887\n",
            "Step 500 avg train loss = 2.6163\n",
            "Step 600 avg train loss = 2.6158\n",
            "Step 700 avg train loss = 2.6324\n",
            "Step 800 avg train loss = 2.6554\n",
            "Step 900 avg train loss = 2.6444\n",
            "Step 1000 avg train loss = 2.6562\n",
            "Step 1100 avg train loss = 2.6605\n",
            "Step 1200 avg train loss = 2.6738\n",
            "Step 1300 avg train loss = 2.6762\n",
            "Step 1400 avg train loss = 2.6952\n",
            "Step 1500 avg train loss = 2.6882\n",
            "Step 1600 avg train loss = 2.7029\n",
            "Step 1700 avg train loss = 2.7159\n",
            "Step 1800 avg train loss = 2.7199\n",
            "Step 1900 avg train loss = 2.7224\n",
            "Step 2000 avg train loss = 2.7396\n",
            "Step 2100 avg train loss = 2.7458\n",
            "Step 2200 avg train loss = 2.7488\n",
            "Step 2300 avg train loss = 2.7504\n",
            "Step 2400 avg train loss = 2.7764\n",
            "Validation loss after 18 epoch = 6.5052\n",
            "Step 0 avg train loss = 2.2892\n",
            "Step 100 avg train loss = 2.4944\n",
            "Step 200 avg train loss = 2.5011\n",
            "Step 300 avg train loss = 2.5263\n",
            "Step 400 avg train loss = 2.5102\n",
            "Step 500 avg train loss = 2.5455\n",
            "Step 600 avg train loss = 2.5584\n",
            "Step 700 avg train loss = 2.5731\n",
            "Step 800 avg train loss = 2.5781\n",
            "Step 900 avg train loss = 2.5899\n",
            "Step 1000 avg train loss = 2.5859\n",
            "Step 1100 avg train loss = 2.6234\n",
            "Step 1200 avg train loss = 2.6151\n",
            "Step 1300 avg train loss = 2.6376\n",
            "Step 1400 avg train loss = 2.6130\n",
            "Step 1500 avg train loss = 2.6328\n",
            "Step 1600 avg train loss = 2.6496\n",
            "Step 1700 avg train loss = 2.6566\n",
            "Step 1800 avg train loss = 2.6552\n",
            "Step 1900 avg train loss = 2.6707\n",
            "Step 2000 avg train loss = 2.6854\n",
            "Step 2100 avg train loss = 2.6866\n",
            "Step 2200 avg train loss = 2.6947\n",
            "Step 2300 avg train loss = 2.7072\n",
            "Step 2400 avg train loss = 2.6940\n",
            "Validation loss after 19 epoch = 6.6090\n",
            "Saving best model with best hidden size...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c0b13b17a497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m'loss_cache'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplot_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m'model_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_model_overall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         }, './drive/My Drive/NLP/hid_tune_best_LSTM.pt')\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_overall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/My Drive/NLP/hid_tune_best_LSTM.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MQux1ZwmIFbb",
        "outputId": "e4634760-7dcd-4178-e657-138781521114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1RZK_pPW8Bvw"
      },
      "source": [
        "#### Performance Variation Based on Hyperparameter Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IktjeUOat0Ol",
        "outputId": "a83b952b-996e-482a-9957-0dbc540067e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# embedding_dim: 100-200-300-400-500 with default hidden_size: 128\n",
        "# [5.2549,5.2085,5.2010,5.2055,5.2255]\n",
        "# 6 - 5 - 5 - 5 - 4 epoch]\n",
        "\n",
        "with open('tune_val_loss.pkl', 'rb') as f:\n",
        "    tune_val_loss = pickle.load(f)\n",
        "\n",
        "plot_emb = tune_val_loss[0]\n",
        "perp_emb = [2**(i/np.log(2)) for i in plot_emb] \n",
        "\n",
        "emb = np.array([100,200,300,400,500])\n",
        "plt.plot(hid, perp_emb, color='b', linestyle='dashed', marker='o', \n",
        "         label='best validation ppl' )\n",
        "\n",
        "plt.legend()\n",
        "plt.xticks(np.arange(100, 600, step=100))\n",
        "plt.title('Best PPL for Varying Embedding Dimension')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRG+MMXHOEr0xxsQ5S/TGGBPn/h8HKPXw1AfntwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LcBmcCR_8Bvy",
        "outputId": "b10812e1-d0c7-4051-d72a-b784a6518e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# hidden_size: 100-200-300-400-500 with best embedding_dim: 300\n",
        "# 5.2207 - 5.1723 - 5.1226 - 5.1319 - 5.1347\n",
        "# 7 - 4 - 3 - 3 - 3\n",
        "\n",
        "plot_hid = tune_val_loss[1]\n",
        "perp_hid = [2**(i/np.log(2)) for i in plot_hid] \n",
        "\n",
        "hid = np.array([100,200,300,400,500])\n",
        "plt.plot(hid, perp_hid, color='g', linestyle='dashed', marker='o', label='best validation ppl' )\n",
        "\n",
        "plt.legend()\n",
        "plt.xticks(np.arange(100, 600, step=100))\n",
        "plt.title('Best PPL for Varying Hidden Size ')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGMMYAnBGGOMwxKCMcYYwBKCMcYYx/8DLybv3nGYv5oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZtUgQcLw8Bv1"
      },
      "source": [
        "### II.2 Learned Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EcC--G6w8Bv3"
      },
      "source": [
        "#### Utilities\n",
        "\n",
        "Below is code to use [UMAP](https://umap-learn.readthedocs.io/en/latest/) to find a 2-dimensional representation of a weight matrix, and plot the resulting 2-dimensional points that correspond to certain words.\n",
        "\n",
        "Use `!pip install umap-learn` to install UMAP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TDmYE5Zx8Bv4",
        "outputId": "23b1e427-27cb-4022-b00f-dfecc24dcfa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# best parameter: \n",
        "options = {'bias': True,\n",
        "  'bid': False,\n",
        "  'embedding_dim': 300,\n",
        "  'hidden_size': 300,\n",
        "  'input_size': 300,\n",
        "  'lstm_dropout': 0.1,\n",
        "  'num_embeddings': 33178,\n",
        "  'num_layers': 2,\n",
        "  'padding_idx': 2}\n",
        "    \n",
        "model = LSTMModel(options)\n",
        "model.load_state_dict(torch.load('best_emb_dim_300_hidden_size_300_LSTM.pt',map_location=lambda storage, loc: storage)['model_dict'])\n",
        "# MD5 (best_emb_dim_300_hidden_size_300_LSTM.pt) = 177997a030a1a74a27c5ec63c557a5f2\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
              "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WA8Ot3wi0O8T",
        "outputId": "9a0b3186-d1cc-4e8b-b9bc-8eaa4f65b890",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip  install adjustText"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: adjustText in /Users/lexili24/miniconda3/lib/python3.7/site-packages (0.7.3)\n",
            "Requirement already satisfied: numpy in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from adjustText) (1.15.4)\n",
            "Requirement already satisfied: matplotlib in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from adjustText) (3.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from matplotlib->adjustText) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from matplotlib->adjustText) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from matplotlib->adjustText) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from matplotlib->adjustText) (2.7.5)\n",
            "Requirement already satisfied: six in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->adjustText) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /Users/lexili24/miniconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->adjustText) (40.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQK27bsS8Bv-",
        "outputId": "36537d31-2101-4293-ef81-7a865327bc42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "%pylab inline \n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "from adjustText import adjust_text\n",
        "\n",
        "colors = ['red','gold','limegreen','cornflowerblue','mediumpurple',\n",
        "          'darkred','lightcoral',\n",
        "          'darkgoldenrod','wheat',\n",
        "         'darkgreen','lightgreen',\n",
        "          'midnightblue','lightsteelblue',\n",
        "         'indigo','thistle']\n",
        "\n",
        "def umap_plot(weight_matrix, word_ids):\n",
        "    # darker color indicates best, \n",
        "    # light color indicates worst\n",
        "    reduced = umap.UMAP(min_dist=0.0001).fit_transform(weight_matrix.detach().cpu().numpy()) \n",
        "    # transfer tensor back to cpu\n",
        "    plt.figure(figsize=(20,20))\n",
        "    texts = []\n",
        "    for i, iid in enumerate(word_ids): \n",
        "        token = train_dict.get_token(iid)\n",
        "        to_plot = reduced[iid, :]\n",
        "        plt.scatter(to_plot[0], to_plot[1], color = colors[i],marker = '*', s = 350)\n",
        "        texts.append(plt.annotate(token, (to_plot[0], to_plot[1])))\n",
        "        for j, word_list in enumerate([word_ids[iid]['best'],word_ids[iid]['worst']]):\n",
        "            to_plot = reduced[word_list, :]\n",
        "            plt.scatter(to_plot[:, 0], to_plot[:, 1], color = colors[5+2*i+j])\n",
        "            # now annotate:\n",
        "            for k,w in enumerate(word_list):\n",
        "                current_point = to_plot[k]\n",
        "                texts.append(plt.annotate(train_dict.get_token(w), (current_point[0], current_point[1])))\n",
        "    adjust_text(texts, force_text=0.05, arrowprops=dict(arrowstyle=\"-|>\",\n",
        "                                                    color='r', alpha=0.5))\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/lexili24/miniconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['split']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SDAT-P2L8BwC"
      },
      "source": [
        "#### II.2.1 Word Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pq1WyoUK8BwD",
        "colab": {}
      },
      "source": [
        "def cos_similarity(weight_matrix, words):\n",
        "#make sure at least appear in the text once \n",
        "    for word in words:\n",
        "        if word not in vocab:\n",
        "            raise NotImplementedError(\"selected token must appeared in the corpus once, please replace {}\".format(word))\n",
        "\n",
        "    # define my cosine similarity. each input is 1 x emb_dim. Therefore evaluate along x'axis returns a scalar \n",
        "    cos = nn.CosineSimilarity(dim = 0, eps = 1e-6)\n",
        "\n",
        "    token_list = defaultdict(lambda: defaultdict(float))\n",
        "    id_list = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "    for w in words:\n",
        "        wid = train_dict.get_id(w)\n",
        "        temp_list = list()\n",
        "        for i in range(len(weight_matrix)):\n",
        "            if i == wid:\n",
        "                continue\n",
        "            else: \n",
        "                dis = cos(weight_matrix[wid], weight_matrix[i])\n",
        "                temp_list.append(tuple((i, dis.item())))\n",
        "        temp_list = sorted(temp_list, key = lambda x: x[-1])\n",
        "        id_list[wid]['worst'] = [x[0] for x in temp_list[:10]]\n",
        "        id_list[wid]['best'] = [x[0] for x in temp_list[-10:]]\n",
        "        token_list[w]['worst'] = [tuple((train_dict.get_token(x[0]) , x[1])) for x in temp_list[:10]]\n",
        "        token_list[w]['best'] = [tuple((train_dict.get_token(x[0]) , x[1] )) for x in temp_list[-10:]]\n",
        "    return id_list, token_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O9OXVOFX8BwI"
      },
      "source": [
        "#### II.2.2 Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ThaWEAgk8BwK",
        "colab": {}
      },
      "source": [
        "weight_matrix_lkup = model.lookup.weight\n",
        "input_words = ['productive', 'teenager','south','happy','smart']\n",
        "# some verbs, and nouns\n",
        "lkup_id_list, lkup_token_list = cos_similarity(weight_matrix_lkup, input_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pqtEzK2y8Bw5",
        "outputId": "f3e5ce63-1740-4e6d-dcdf-cc5f29501400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "lkup_token_list['happy']['best']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('concerned', 0.21331222355365753),\n",
              " ('confront', 0.21622921526432037),\n",
              " ('Keats', 0.21778753399848938),\n",
              " ('stairs', 0.22033384442329407),\n",
              " ('kitsunetsuki', 0.22119159996509552),\n",
              " ('weapons', 0.22614535689353943),\n",
              " ('computation', 0.22790561616420746),\n",
              " ('recipients', 0.23518744111061096),\n",
              " ('standards', 0.24916522204875946),\n",
              " ('powerful', 0.2532723844051361)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xtxt08B68Bw_",
        "outputId": "8ab7f26e-ebfb-474c-94b4-ee7f8fe74599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "lkup_token_list['happy']['worst']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sculpture', -0.2643663287162781),\n",
              " ('hotel', -0.24333719909191132),\n",
              " ('Lemieux', -0.23501640558242798),\n",
              " ('Bologna', -0.22776520252227783),\n",
              " ('went', -0.21404962241649628),\n",
              " ('dynasties', -0.21294936537742615),\n",
              " ('McEnroe', -0.20979204773902893),\n",
              " ('Court', -0.209650456905365),\n",
              " ('polls', -0.20813582837581635),\n",
              " ('vocalization', -0.20567774772644043)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyW51O608BxE",
        "outputId": "bdb69313-cb13-4d63-ed29-fdb67ea9821e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "umap_plot(weight_matrix_lkup, lkup_id_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/lexili24/miniconda3/lib/python3.7/site-packages/numba/compiler.py:602: NumbaPerformanceWarning: \n",
            "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
            "\n",
            "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
            "\n",
            "File \"../../../../miniconda3/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
            "    @numba.njit(parallel=True)\n",
            "    def nn_descent(\n",
            "    ^\n",
            "\n",
            "  self.func_ir.loc))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIMAAARiCAYAAAA3EzfQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3X10VNW9//H3JCEJTwYwiiAKaAWEJCQ8CcFAAHmooFUUFdFCsfWKxar3iooURKrWKi1WtLVSf8Lt5SoCSisqVZAICBYSSMKDQEQjKhYVJCSEAEnm90d0rhFUlMAI836txXJmnz37fM+sQ1z5sPc+gWAwiCRJkiRJkiJDVLgLkCRJkiRJ0rFjGCRJkiRJkhRBDIMkSZIkSZIiiGGQJEmSJElSBDEMkiRJkiRJiiCGQZIkSZIkSRHEMEiSJEmSJCmCGAZJkiRJkiRFEMMgSZIkSZKkCGIYJEmSJEmSFEFiwnHSxMTEYIsWLcJx6m+1Z88e6tatG+4ypKPOe12RwntdkcJ7XZHA+1yRwntd31dOTs6nwWDwlG/rF5YwqEWLFmRnZ4fj1N8qKyuLzMzMcJchHXXe64oU3uuKFN7rigTe54oU3uv6vgKBwHuH089lYpIkSZIkSRHEMEiSJEmSJCmCGAZJkiRJkiRFEMMgSZIkSZKkCGIYJEmSJEmSFEEMgyRJkiRJkiKIYZAkSZIkSVIEMQySJEmSJEmKIIZBkiRJkiRJEcQwSJIkSZIkKYIYBkmSJEmSJEUQwyBJkiRJkqQIYhgkSZIkSZIUQQyDJEmSJEmSIohhkCRJkiRJUgQxDJIkSZIkSYoghkGSJEmSJEkRxDBIkiRJkiQpghgGSZIkSZIkRRDDIEmSJEmSpAhiGCRJkiRJkhRBDIMkSZIkSZIiiGGQJEmSJElSBDEMkiRJkiRJiiCGQZIkSZIkSRHEMEiSJEmSJCmCGAZJkiRJkiRFEMMgSZIkSZKkCGIYJEmSJEmSFEEMgyRJkiRJkiKIYZAkSZIkSVIEMQySJEmSJEmKIIZBkiRJkiRJEcQwSJIkSZIkKYIYBkmSJEmSJEUQwyBJkiRJkqQIYhgkSZIkSZIUQQyDJEmSJEmSIohhkCRJkmrMvHnz2LBhQ+h9ZmYm2dnZYaxIkiR9lWGQJEmSakR5eflBYZAkSfrhMQySJElSSGFhIeeeey6/+MUvaNeuHf369WPv3r3k5ubStWtXUlJSuPTSS/nss8+Aqpk/d911Fz179uR3v/sd//jHPxgzZgypqals2bIFgNmzZ9OlSxdatWrF0qVLw3l5kiQJwyBJkiR9RUFBAb/85S9Zv349DRo0YO7cufz0pz/ld7/7Hfn5+SQnJ3PPPfeE+u/atYvXX3+dcePGcfHFF/PQQw+Rm5vL2WefDVTNGFq5ciUPP/xwtc9JkqTwMAySJElSNS1btiQ1NRWAjh07smXLFnbt2kXPnj0BGD58OEuWLAn1v/LKK79xvMGDB4fGKiwsPDpFS5Kkw2YYJEmSpGri4uJCr6Ojo9m1a9c39q9bt+5hjRcdHU15efmRFyhJko6IYZAkSZIOVlEBwSAACQkJNGzYMLTfz9/+9rfQLKGvql+/PsXFxcesTEmS9N0ZBkmSJKma+MpKuPdeWL061DZjxgzGjBlDSkoKubm5TJgw4ZCfveqqq3jooYdIS0sLbSAtSZJ+WGLCXYAkSZLCa+abMxn3/Di27txKywZnMKt/D1i/HioruW3iRAgEAHjzzTcP+mxWVla19927d6/2aPkvH09MTHTPIEmSfgCcGSRJkhTBZr45k+v/dj3v7XyPYDBI55ytbH7pafLrH4D33oN33w13iZIkqYYZBkmSJEWwcc+Po3R/KYEg/OItGLoF9ldWsGnlq/DZZ7BoUbhLlCRJNcxlYpIkSRFs686todcFDeCeU6pWhdUu38OQ0aOhfv0wVidJko4GwyBJkqQIdmajM6uWiAUgq+n/tTdv1Bz69g1fYZIk6ahxmZgkSVIEu+/S+6gTW6daW53YOtx36X1hqkiSJB1thkGSJEkRbFjXYTxx7RM0b9ScAAGaN2rOE9c+wbCuw8JdmiRJOkoMgyRJkiLcsK7DKPxdIZXTKin8XeE3BkEPP/wwpaWl3zrmz3/+82qPmJckST8chkGSJEk6bIcbBv31r3+lbdu2B7VXVFQcjbIkSdJ3YBgkSZKkQ9qzZw8DBw6kffv2JCUlcc8997Bt2zZ69epFr169ABg1ahSdOnWiXbt23H333aHPZmZmkp2dDUC9evWYMGEC5513HitWrODOO++kbdu2pKSkcNttt4Xl2iRJimQ+TUySJEmHtGDBApo2bcqLL74IQFFREU899RSLFy8mMTERgPvuu49GjRpRUVFBnz59yM/PJyUlpdo4e/bsISkpiUmTJrFz506uu+46Nm7cSCAQYNeuXcf8uiRJinTODJIkSdIhJScns3DhQu644w6WLl1KQkLCQX2effZZOnToQFpaGuvXrz/kPkHR0dFcdtllAJx00knEx8fz85//nOeee446deoc1F+SJB1dhkGSJEk6pFatWpGTk0NycjJjx45l0qRJ1Y6/++67TJ48mUWLFpGfn8/AgQMpKys7aJz4+Hiio6MBiImJYeXKlVx22WXMmzePAQMGHJNrkSRJ/8dlYpIkSTqkbdu20ahRI6655hrq1avH9OnTqV+/PsXFxSQmJrJ7927q1q1LQkIC27dv5+WXXyYzM/MbxywpKaG0tJQLL7yQrl278qMf/ejYXIwkSQoxDJIkSdIhrV27ljFjxtCxtJRGwK+feYYVK1bw4x//mCZNmrB48WLS0tJo164dZ511Ft27d//WMYuLi/nJT35CWVkZwWCQKVOmHP0LkSRJ1RgGSZIkKeS557L57W9fYtu2z2jatCG/H3kXfde8DLGxcO65dOrUiZtuuinUf/r06YccJysrK/S6pKQk9LpJkyasXLnyaJUvSZIOg3sGSZIkCagKgsaMeZYPP/yMYBCCW7eyY/z9bP6sAg4cgFWrwl2iJEmqAYZBkiRJAuC3v32JvXsPANBp/4fcvvsN6h8oZe2KjVUdXnoJKivDWKEkSaoJLhOTJEkSANu2fRZ6nbb/37wRewafRcdzUvl+LuvSperA/v0QHx+mCiVJUk0wDJIkSRIATZs25MMPqwKhafU6htpPP70h3HhjuMqSJEk1zGVikiRJAmDs2AupXbtWtbbatWsxduyFYapIkiQdDc4MkiRJEgCDB3cCqPY0sbFjLwy1S5KkE4NhkCRJkkIGD+5k+CNJ0gnOZWKSJEmSJEkRxDBIkiRJkiQpghgGSZIkSZIkRRDDIEmSJEmSpAhiGCRJkiRGjhzJqaeeSlJSUqht/PjxpKSkkJqaSr9+/di2bVsYK5QkSTXFMEiSJEmMGDGCBQsWVGsbM2YM+fn55ObmMmjQICZNmhSm6iRJUk064jAoEAjEBwKBlYFAIC8QCKwPBAL31ERhkiRJOnZ69OhBo0aNqrWddNJJodd79uwhEAgc67IkSdJREFMDY+wDegeDwZJAIFALWBYIBF4OBoNv1sDYkiRJCqNx48bx3//93yQkJLB48eJwlyNJkmrAEc8MClYp+fxtrc//BI90XEmSJIXffffdx/vvv8+wYcN49NFHw12OJEmqATWyZ1AgEIgOBAK5wMfAq8Fg8F81Ma4kSZKOkWAQ9u372sNXX301c+fOPYYFSZKko6UmlokRDAYrgNRAINAAeD4QCCQFg8F1X+4TCASuB64HaNy4MVlZWTVx6hpXUlLyg61Nqkne64oU3uuKFEd6r9crKKDO/PlE794dGueDDz6gWbNmADz33HOcfPLJ/n1SWPkzXZHCe11HWyAYrNkVXYFA4G5gTzAYnPx1fTp16hTMzs6u0fPWlKysLDIzM8NdhnTUea8rUnivK1Ic6b0+MzWVeps2sW7fPmacdhp3/OY3vPTSS2zatImoqCiaN2/O448/zumnn15zRUvfkT/TFSm81/V9BQKBnGAw2Onb+tXE08RO+XxGEIFAoDZwAbDxSMeVdGIJBAJce+21offl5eWccsopDBo06DuNs23bNi6//PJv7JOVlfWdx5WkSLR45lp+1uIRhgXu5My340gZMJxxP/sZm2+6ieuuuYa5c+eybt068vPzeeGFFwyCJEk6QdTEnkFNgMWBQCAfWEXVnkHza2BcSSeQunXrsm7dOvbu3QvAq6+++p1/qSgvL6dp06bMmTPnaJQoSRFl8cy1PHr9i3zyXhFtKSSwp5h3XljFtrd3wMcfV/2RJEknpJp4mlh+MBhMCwaDKcFgMCkYDE6qicIknXh+/OMf8+KLLwLw9NNPM3To0NCxlStXkp6eTlpaGunp6WzatAmA6dOnM2TIEC666CL69etHYWEhSUlJABQWFpKRkUGHDh3o0KEDy5cvD41XUlLC5ZdfTps2bRg2bBg1vSRWko53/z1uMftKDwDQjxw+JJGFFck8tKUD/P73cMYZYa5QkiQdLTWygbQkHY6rrrqKSZMmMWjQIPLz8xk5ciRLly4FoE2bNixZsoSYmBgWLlzIXXfdFXpqzYoVK8jPz6dRo0YUFhaGxjv11FN59dVXiY+Pp6CggKFDh/LFfmRr1qxh/fr1NG3alO7du/PGG29w/vnnH/NrlqQfqk+3FoVe38O1QACAwDYgqkYeOCtJkn6gDIMkHTMpKSkUFhby9NNPc+GFF1Y7VlRUxPDhwykoKCAQCHDgwIHQsb59+9KoUaODxjtw4ACjR48mNzeX6OhoNm/eHDrWpUuX0BNwUlNTKSwsNAySpC9JPDOBT977IhAKVGuXJEknNv/ZR9IxdfHFF3PbbbdVWyIGMH78eHr16sW6det44YUXKCsrCx2rW7fuIceaMmUKjRs3Ji8vj+zsbPbv3x86FhcXF3odHR1NeXl5DV+JJB3ffnpfL+Lq1KrWFlenFj+9r1eYKpIkSceKM4MkHTsffsh1l15KQkICycnJZGVlhQ4VFRWFNpSePn36YQ1XVFREs2bNiIqKYsaMGVRUVByFoiXpxNRrWDJQtXfQp1uLSDwzgZ/e1yvULkmSTlyGQZKOiRYVFTB+PKf36sXNN9980PHbb7+d4cOH84c//IHevXsf1pg33ngjl112GbNnz6ZXr15fO4NIknRovYYlG/5IkhSBAuF4wk6nTp2CX2zy+kOTlZVFZmZmuMuQjrqjfa9vmDmTZePGsXvrVk5v0oQBrVvTsE0bCAZh6lSIMYvWseHPdUUK73VFAu9zRQrvdX1fgUAgJxgMdvq2fv42JqnGbZg5k1euv57y0lLOBNpu28Z727dTnpDAKQ0awNtvQ5s24S5TkiRJkiKSG0hLqnHLxo2jvLQUgLOBvUCwooKdr74KZWWQnx/W+iRJkiQpkjkzSFKN2711a+j14i+1x+zZQ+uHHoL4+GNflCRJkiQJcGaQpKPgpDPPPGR7nebNoVkzSEw8xhVJkiRJkr5gGCSpxp1/333E1KlTrS2mTh3Ov+++MFUkSZIkSfqCYZCkGtd22DD6PfEEJzVvDoEAJzVvTr8nnqDtsGHhLk2SJEmSIp57Bkk6KtoOG2b4I0mSJEk/QM4MkiRJkiRJiiCGQZIkSZIkSRHEMEjSEcnKymL58uXhLkOSJEmSdJgMgyQdEcMgSZIkSTq+GAZJEebBBx/kkUceAeDWW2+ld+/eACxatIhrrrmGV155hW7dutGhQweGDBlCSUkJAC1atODuu++mQ4cOJCcns3HjRgoLC3n88ceZMmUKqampLF26NGzXJUmSJEk6PIZBUoTp0aNHKLTJzs6mpKSEAwcOsGzZMpKTk7n33ntZuHAhq1evplOnTvzhD38IfTYxMZHVq1czatQoJk+eTIsWLbjhhhu49dZbyc3NJSMjI1yXJUmSJEk6TIZBUoTp2LEjOTk5lJaWEhcXR7du3cjOzmbp0qXUrl2bDRs20L17d1JTU5kxYwbvvfde6LODBw8OjVFYWBimK5AkSZIkHYmYcBcg6diqVasWLVq04OWXXyY9PZ2UlBQWL17Mli1baNmyJX379uXpp58+5Gfj4uIAiI6Opry8/FiWLUmSJEmqIc4MkiJQjx49WPz00wxo3pyMjAwef/xxUlNT6dq1K2+88QZvv/02AKWlpWzevPkbx6pfvz7FxcXHomxJkiRJUg0wDJIiUGanTozYuZPO2dk0btiQ+Ph4MjIyOOWUU5g+fTpDhw4lJSWFrl27snHjxm8c66KLLuL55593A2lJkiRJOk64TEyKAO9/XMxbWz9j774KasdA5zXraTVgALVKSyE7u9rsn969e7Nq1aqDxvjyHkGdOnUiKysLgFatWpGfn3+0L0GSJEmSVEOcGSSd4N7/uJi8LTvYu68CgJNee4U9S5ezt2EjOPlkmDcPKirCXKUkSZIk6VgxDJJOcG9t/YyKyiAApy19hTNemceBuvWJ2bEDPvsMdu+Gjz4Kc5WSJEmSpGPFZWLSCe6LGUEAn3boxr/T+0B0NOwqoPnAflBZCVHmwpIkSZIUKfwNUDrB1Y6LDr0ur1u/KggCAoHPGw2CJEmSJCmi+FugdII798yGREcFqrVFRwWoHevEQEmSJEmKRIZB0gnujFPr0/7sk0MzhGrHRdP+7JOpFeNff0mSJEmKRE4NkCLAGafW54xT61dr27IhTMVIx9B9993HtGnTOOmkk4iKiuIvf/kLV155JdnZ2SQmJoa7PEmSJCksDIMkSSekFStWMH/+fJ544gn69evHp59+yv79+8NdliRJkhR2rhORJJ2QPvroIxITE4mNjQUgMTGRpk2bAjB16lQ6dOhAcnIyGzduBGDlypWkp6eTlpZGeno6mzZtAuDCCy8kPz8fgLS0NCZNmgTA+PHj+etf/0pWVhaZmZlcfvnltGnThmHDhhEMBo/15UqSJEmHzTBIknRC6tevH++//z7XXnstN954I6+//nroWGJiIqtXr2bUqFFMnjwZgDZt2rBkyRLWrFnDpEmTuOuuuwDo0aMHS5cuZffu3cTExPDGG28AsGzZMjIyMgBYs2YNDz/8MBs2bOCdd94J9ZEkSZJ+iAyDJEknpHr16pGTk8N//dd/ccopp3DllVcyffp0AAYPHgxAx44dKSwsBKCoqIghQ4aQlJTErbfeyvr16wHIyMhgyZIlLFu2jIEDB1JSUkJpaSmFhYW0bt0agC5dutCsWTOioqJITU0NjSlJkiT9ELlnkCTphBUdHU1qaiqZmZkkJyczY8YMAOLi4kLHy8vLgaplX7169eL555+nsLCQzMxMADp37kx2djZnnXUWffv25dNPP2XatGl07NgxdJ4vxvvqmJIkSdIPkTODJEknpE2bNvF2Xh513n0XgNzcXJo3b/61/YuKijj99NMBQjOIAGJjYznjjDN49tln6dq1KxkZGUyePDm0REySJEk63hgGSZJOSHs+/ZRFF13E2zfdRKekJDZs2MDEiRO/tv/tt9/O2LFj6d69OxUVFdWOZWRk0LhxY+rUqUNGRgYffPCBYZAkSZKOW4FwPPGkU6dOwezs7GN+3sPxxVNhpBOd97pONNvWz6IgayJluz+gTnxTUt7rQMLu2ny0bRtNfvtbSEsLd4nSUeXPdUUC73NFCu91fV+BQCAnGAx2+rZ+zgySJB33tq2fxfqXRlO2+31iiys4/fl3KM16juJau6iMi4Nly8JdoiRJkvSDYRgkSTruFWRNpLJ8L68VH+Dh9XtZ9lE5z0btZ1P2AqL27YONG2H//nCXKUmSJP0g+DQxSdJxr2z3B7xWfIA/frqffafCP06tao9nL7P6DuPijAugVq3wFilJkiT9QDgzSJJ03Is/qRnTPzvAvq9sg1cGvHdgFzRpAoFAWGqTJEmSfmgMgyRJx71zMifySfn/JUGZH8Ko9dCiGMrL9oaxMkmSJOmHxzBIknTca9ruSprWTwy9jy+Hq1bA+OfhtJsnMrVpU/KnTQsd37x5MxdeeCE/+tGPOPfcc7niiivYvn17OEqXJEmSjjnDIEnSCeF3VzxMndg6APzzTHgzAMVtokm78McM+dGPmPboowCUlZUxcOBARo0axdtvv81bb73FqFGj+OSTT8JZviRJknTMuIG0JOmEMKzrMADGPT+OrTu3Mj8qyFOnp1OnqIT3UlN5/733APjf//1funXrxkUXXRT6bK9evcJSsyRJkhQOhkGSpBPGsK7DQqFQ3SejWP2v9WysqGDKihW8ungxAOvWraNjx47hLFOSJEkKK8MgSdIJKVCnDkPefJMlb7/NBQ0a8NOf/pR169aFuyxJkiQp7NwzSJJ04jrnHCpr16Zbt258+umnfPLJJ7Rr146cnJxwVyZJkiSFjWGQJOmEt3HjRioqKjj55JO5+uqrWb58OS+++GLo+IIFC1i7dm0YK5T0bbKysli+fHno/YgRI5gzZ04YK5Ik6fjlMjFJ0glp7969pKamUlJSQt26dZkxYwbR0dHUrl2b+fPnc8stt3DLLbdQq1YtUlJS+OMf/xjukqUTUsHeAs6pfc4Rj5OVlUW9evVIT0+vgaokSYpszgySJJ2QKioqyM3N5a9//St5eXkMHDgwdKxNmzYsWLCAgoICNmzYwDPPPEPjxo3DWK10YtpatpWr3rqKTTs2MXDgQNq3b09SUhKzZs1i0aJFpKWlkZyczMiRI9m3bx8ALVq04NNPPwUgOzubzMxMCgsLefzxx5kyZQqpqaksXboUgCVLlpCens5ZZ53lLCFJkr4DwyBJkiQdFa9+9ioAf3z+jzRt2pS8vDzWrVvHgAEDGDFiBLNmzWLt2rWUl5fz5z//+WvHadGiBTfccAO33norubm5ZGRkAPDRRx+xbNky5s+fz5133nlMrkmSpBOBYZAkSZKOivk75wNQ0KSAhQsXcscdd7B06VIKCwtp2bIlrVq1AmD48OEsWbLkO49/ySWXEBUVRdu2bdm+fXuN1i5J0onMMEiSJEk1btu+bfx7/78BKGlawovLXyQ5OZmxY8fy97///Ws/FxMTQ2VlJQBlZWXfeI64uLjQ62AwWANVS5IUGQyDJEmSVOMW7VpEgAAABz45wJv73+Saa67htttuY/ny5RQWFvL2228D8Le//Y2ePXsCVUvCcnJyAJg7d25ovPr161NcXHyMr0KSpBOTYZAkSZJq3As7XmBfsGpT6KLNRUzudQtTmzRh8m9+w7333stTTz3FkCFDSE5OJioqihtuuAGAu+++m5tvvpmMjAyio6ND41100UU8//zz1TaQliRJ34+PlpckSdL3cvs7t7OyeOUhj+2r3Bd63axdHa7vVpcm28t569pKbqt1GyRCwvQEABLrJ4aWfGVkZLB58+aDxmvVqhX5+fmh919sIv2FkpKSI74eSZIihTODJEmS9L1cd9p11ImqQ1llGcUVxdX+7A/uByB+byVD//djYvce4MPGATos+TfF5bspriimrLKMOlF1uO6068J8JZIkRRbDIEmSJH0vreu0Zm7buVzQ4ALio+IPOt743/v5r4e20npTKbUOBKldWsmZ75dx+of7iY+K54IGFzC37Vxa12kdhuolSYpcLhOTJEnS91Y7ujb3tryXV3a+wqStk9hXuY9Kqp4GVqe0gs2t67Lx3NrULq2kfnEF9fZUEh+IY+KZE+nbqG+Yq5ckKTIZBkmSJOmI9WvUj6S6SYx+ezRb920lSJB3z6rNu2fVDvWJIooz487k0R89SpO4JmGsVpKkyOYyMUmSJNWIpnFNSYhJIEjwkMcrqSQhJsEgSJKkMDMMkiRJUo3YXb6bt0rf+sY+G0o3UFxefIwqkiRJh2IYJEmSpBqxpGgJMYH/24UgPiqek2NOrra5dK1ALZYULQlHeZIk6XOGQZIkSaoRL+x4gb2VewkQID4Qz+imo1mQvIDRTUcTF4gjQIDSylJe2PFCuEuVJCmiGQZJkiTpiO2p2MOakjXEBmI5LfY0preeztBThxIViGLoqUOZ0XoGjWMbExuIZXXJakorSsNdsiRJEcswSJIkSUfsjd1vUEEF/Rr2Y3bb2ZxT55xqx8+pcw5z2s6hb8O+VFDBst3LwlSpJEny0fKSJEk6Yi3jWzLl7Cn0SOjxtX1qR9VmUotJXNDwAprE+kQxSZLCxTBIkiRJR+yc2udwTu1zvr0jfGNgJEmSjj6XiUmSJEmSJEUQwyBJkiRJkqQIYhgkSZIkSZIUQQyDJEmSJEmSIohhkCRJkiRJUgQxDJIkSZIkSYoghkGSJEmSJEkRxDBIkiRJkiQpghgGSZIkSZIkRRDDIEmSJEmSpAhiGCRJkiRJkhRBDIMkSZIkSZIiiGGQJEmSJElSBDEMkiRJkiRJiiCGQZIkSZIkSRHEMEiSJEmSJCmCGAZJkiRJkiRFEMMgSZIkSZKkCGIYJEmSJEmSFEEMgyRJkiRJkiKIYZAkSZIkSVIEMQySJEmSJEmKIIZBkiRJkiRJEcQwSNJR0aJFCz799NNwlyFJkiRJ+grDIEk/OOXl5Uf9HIWFhSQlJR3180iSJEnSD41hkKQjtmfPHgYOHEj79u1JSkpi1qxZAEydOpUOHTqQnJzMxo0bAVi5ciXp6emkpaWRnp7Opk2bAJg+fTpDhgzhoosuol+/fgA89NBDdO7cmZSUFO6+++5vPNfh+mDH0Q+aJOmHbPv27Vx99dWcddZZdOzYkW7duvH888+HuyxJknQMGQZJOmILFiygadOm5OXlsW7dOgYMGABAYmIiq1evZtSoUUyePBmANm3asGTJEtasWcOkSZO46667QuOsWLGCGTNm8Nprr/HKK69QUFDAypUryc3NJScnhyVLlnztuQ7H9l0V3DNrNx8XVQBQUVHBL37xC9q1a0e/fv3Yu3cv06ZNo3PnzrRv357LLruM0tJSAEaMGMENN9xARkYGrVq1Yv78+UBViPWTn/yEAQMG0Lp1a+655x4Axo8fzx//+MfQuceNG8cjjzxyBN+yJB25YDDIJZdcQo8ePXjnnXfIycnhmWee4YMPPgh3aZIk6RgyDJJ0xJKTk1m4cCF33HEHS5cuJSEhAYDBgwcD0LFjRwoLCwEoKipiyJAhJCUlceutt7J+/frQOH379qVRo0a+tACDAAAgAElEQVQAvPLKK7zyyiukpaXRoUMHNm7cSEFBwdee63Bkb9lf9d+3q/5bUFDAL3/5S9avX0+DBg2YO3cugwcPZtWqVeTl5XHuuefy5JNPhj5fWFjI66+/zosvvsgNN9xAWVkZUDXbaebMmeTm5jJ79myys7O57rrrmDFjBgCVlZU888wzDBs27Pt8vZJUY1577TViY2O54YYbQm3NmzfnpptuoqKigjFjxoRmZP7lL38BICsri8zMTC6//HLatGnDsGHDCAaD4boESZJUA2LCXYCk41+rVq3IycnhpZdeYuzYsaFlXnFxcQBER0eH9gEaP348vXr14vnnn6ewsJDMzMzQOHXr1g29DgaDjB07lv/4j/846HxfPdeECRMOq87lG/dV/XfTPtqmQ8uWLUlNTQX+L7Bat24dv/71r9m1axclJSX0798/9PkrrriCqKgozjnnHM4666zQ0re+ffty8sknA1UB2LJly7jllls4+eSTWbNmDdu3byctLS3UR5LCZf369XTo0OGQx5588kkSEhJYtWoV+/bto3v37qGf52vWrGH9+vU0bdqU7t2788Ybb3D++ecfy9IlSVINMgySdMS2bdtGo0aNuOaaa6hXrx7Tp0//2r5FRUWcfvrpAN/Yr3///owfP55hw4ZRr149PvzwQ2rVqkV5eTmNGjTgms/bv2mML/t0dwU7SyoB2FFcyWclFaGwCqoCq7179zJixAjmzZtH+/btmT59OllZWaE+gUCg2phfvP+69p///OdMnz6df//734wcOfKw6pSkY+mXv/wly5YtIzY2lubNm5Ofn8+cOXOAqp/XBQUFxMbG0qVLF5o1awZAamoqhYWFhkGSJB3HXCYm6YitXbuWLl26kJqayn333cevf/3rr+17++23M3bsWLp3705FRcXX9uvXrx9XX3013bp1Izk5mcsvv5zi4mLWrl3L+DZtGN+8Ob+9995vPNeX5byzny8imwCwdusBYoJBWLYMKitD/YqLi2nSpAkHDhxg5syZ1caYPXs2lZWVbNmyhXfeeYfWrVsD8Oqrr7Jz50727t3LvHnz6N69OwCXXnopCxYsYNWqVdVmGElSuLRr147Vq1eH3j/22GMsWrSITz75hGAwyNSpU8nNzSU3N5d33333oJmeUH22pyRJOj45M0jSEevfv/9BYccXewQBdOrUKTTDplu3bmzevDl07De/+Q1QtUHziBEjqo1x8803c/PNN1drO/vMM+k/cCAUF/Obfv3YX6sWux9+mGBREYGEBOL79CE2OfmgGpdv3MeBz7OnAxWwpmAvP9m1Cx59FBo3rlbPeeedR/PmzUlOTqa4uDh0rHXr1vTs2ZPt27fz+OOPEx8fD8D555/Ptddey9tvv83VV19Np06dAIiNjaVXr140aNCA6Ojow/gmJeno6t27N3fddRd/nTKFn996K0Boo/z+/fvz5z//md69e1OrVi02b94cmskpSZJOLIZBko4vBQVQVgZnnUXF7NkcmD+f4LnnQlQUMyq7UfD6ybDiUwJR1cOX/RVf2uw0GCQ5byXJZ5zP8g9r8e79r/B+9+ugAXwWgDsev4Yb+tc/6NTdu3dnypQpB7WfeuqpPProowe1V1ZW8uabbzJ79uwjv25JqgGBQID5993H6lGjSJ0yhdjTTqNu3br87ne/Y8iQIRQWFtKhQweCwSCnnHIK8+bN+8bxJkyYQKdOnbj44ouP0RVIkqSaYBgk6fiyYgXs3g1bt1KxfTuxO3YQ/f777BswgD6l2WytdRrFB2pRETj0k26iy/eTsWwGrd9ezicnN6cyKppmm//FG+0voTK+Ngl1oriwY+0jLnPDhg0MGjSISy+9lHPOOeeIx5Ok72vjvo0sL1tOcWUxp+yEH89aTv+OHel/ySVw1VXV+t5///3cf//91doyMzOrbfb/5fB70qRJR7V2SZJ0dLhnkKTjy2mnwZVXwnXXsa9zZ/ZefDH7P9/E9PSKTxmz839ov6+A2K+Jus98P59WBcvZenoS0RXlJOz+mOjKCprueo9OP4pl0tAEzkw8+MPTp0/n8ssvP6h9xIgRh5wV1LZtW9555x1+//vfH9n1SmFUWFhIUlLSURl727Ztob9Tubm5vPTSS9/6maysLAYNGgTAP/7xDx544IEjrmPEiBGhDZNPRBv3bWRR6SKKK4uJ2l9Oy2kL+LD8Qz5t3gBefRV27Qp3iZIkKQycGSTp+DJwYOhlMCeHYFFRtcNxlDMsaiWbenVkRtYeDpRD5ZcmCb3bshNP/OKp0PvoYCX1Kkq4ckBjOrc68hlBkg5P06ZNQyFMbm4u2dnZXHjhhYf9+YsvvtilSYdhedlyyimnVnEZaY8t5pS1H1J2cl12fLiexLLGVZvofx6wSZKkyOHMIEnHrfg+faBWreqNtWoR36cPnc+JY+KVCZySEMVXnvweEgjAKQ1jGPuzMwyCpK9RUVHBL37xC9q1a0e/fv3Yu3cvubm5dO3alZSUFC699FI+++wzAB555BHatm1LSkoKV32+/GjixIlce+219O7dm3POOYdp06YB/zfraP/+/UyYMIFZs2aRmprKrFmzWLlyJenp6aSlpZGens6mTZsOqmv69OmMHj0aqHrSX1JSEu3bt6dHjx6huseMGUPnzp1JSUnhL3/5CwDBYJDRo0fTtm1bBg4cyMcff3zUv8NwKq6s2gS/9s49fJLSjBW/vpA1ozJZNSodJkyAzze8lyRJkcWZQZKOW188Naxs0aJDPk0s8aRo6sUH2P41qyCCQagXH8XJ9X3Sl/R1CgoKePrpp5k2bRpXXHEFc+fO5cEHH2Tq1Kn07NmTCRMmcM899/Dwww/zwAMP8O677xIXF8euLy0/ys/P580332TPnj2kpaUx8Esz/GJjY5k0aRLZ2dmhJZe7d+9myZIlxMTEsHDhQu666y7mzp37tTVOmjSJf/7zn5x++umh8z755JMkJCSwatUq9u3bR/fu3enXrx9r1qxh06ZNrF27lu3bt9O2bVtGjhx5lL698KsfVZ/iymJ2Nz+Z3c1PrtZOQkoYK5MU6QoLC1m+fDlXX331UT/PoEGDWLdu3VE9j3S8MQySdFyLTU4+5KPkAfaUVfLexxXf+PnCj8sp3VdJnTgnSkqH0rJlS1JTUwHo2LEjW7ZsYdeuXfTs2ROA4cOHM2TIEABSUlIYNmwYl1xyCZdccklojJ/85CfUrl2b2rVr06tXL1auXBka81CKiooYPnw4BQUFBAIBDhw48I01du/enREjRnDFFVcwePBgAF555RXy8/NDS9GKioooKChgyZIlDB06lOjoaJo2bUrv3r2//5dzHEiPT2dR6SLKKQ+1xRBDenx6GKuSpKqQ5n//93+Pehgk6dD87UfSCSuv8ADRX/opFxsDJ9UJVNtcOjq6qp+kQ4uLiwu9jo6Orjbj56tefPFFfvnLX5KTk0PHjh0pL68KIAJfWav51fdfNX78eHr16sW6det44YUXKCsr+8b+jz/+OPfeey/vv/8+qamp7Nixg2AwyNSpU8nNzSU3N5d3332Xfv36Hdb5TyRt4trQp06fqplAVM0I6lOnD23i2oS5MknHs68+YGDy5MlMnDiRzMxMbrnlFtLT00lKSmLlypUAvP7666SmppKamkpaWhrFxcXceeedLF26lNTUVKZMmUJhYSEZGRl06NCBDh06sHz5cgAqKyu58cYbadeuHYMGDeLCCy8MBf05OTn07NmTjh070r9/fz766KNQe/v27enWrRuPPfbYMf52pOODYZCkE9byTfvY9/k/hsfGwOCutXloeAMGd61Nrc8DoX0HYPnGfeErUjrOJCQk0LBhQ5YuXQrA3/72N3r27EllZSXvv/8+vXr14sEHH2TXrl2UlJQA8Pe//52ysjJ27NhBVlYWnTt3rjZm/fr1KS4uDr0vKiri9NNPB6r2Bvo2W7Zs4bzzzmPSpEkkJiby/vvv079/f/785z+HZhVt3ryZPXv20KNHD5555hkqKir46KOPWLx4cU18LT9obeLaMDJhJDc3vJmRCSMNgiQdVXv27GH58uX86U9/Ci3DnTx5Mo899hi5ubksXbqU2rVr88ADD5CRkUFubi633norp556Kq+++iqrV69m1qxZ/OpXvwLgueeeo7CwkLVr1/LXv/6VFStWAHDgwAFuuukm5syZQ05ODiNHjmTcuHEA/OxnP+ORRx4J9ZV0MJeJSTohle0PUrCtnJhoSKgTxegf16PZ54+M75NSm9ZNazH1pRJ2761k87Zyyg4Eia8VObMFpO9swwZS33iDZSkpzJgxgxtuuIHS0lLOOussnnrqKSoqKrjmmmsoKioiGAxy66230qBBAwC6dOnCwIED2bp1K+PHj6dp06YUFhaGhu7VqxcPPPAAqampjB07lttvv53hw4fzhz/84bCWcY0ZM4aCggKCwSB9+vShffv2pKSkUFhYSIcOHQgGg5xyyinMmzePSy+9lNdee43k5GRatWoVWu4mSaoZQ4cOBaBHjx7s3r2bXbt20b17d/7zP/+TYcOGMXjwYJo1a3bQ5w4cOMDo0aPJzc0lOjqazZs3A7Bs2TKGDBlCVFQUp512Gr169QJg06ZNrFu3jr59+wJVDw5o0qQJRUVF1ZYzX3vttbz88svH4tKl44phkKQT0tqt+6kMwnk/imVYj7rEfSXoaZYYw6ShCfzP63t4c/N+1r63n84/ivua0aTIsHHfRpaXLae4spj6UfVJb5LOurw8eOEFmDOHC+rX54Kbb4ZGjXjzzTcP+vyyZcsOOW6rVq144oknqrW1aNEitJlno0aNWLVqVbXjX/wSAPCb3/wGgMzMTDIzMwEYMWIEI0aMAKr+1firAoEA999/P/fff/9Bx77YqFqS9P3ExMRQWVkZev/l5byHWhp85513MnDgQF566SW6du3KwoULDxpzypQpNG7cmLy8PCorK4mPjweqngJ5KMFgkHbt2h00+2fXrl0RtRxY+r5cJibphNSkYTSjL6zHyD71DgqCvhBXK8B1F9Rj9IX1aNLQJ4opsm3ct5FFpYtCjyIvrizmXxuf5eP7boNnn4VmzSAmBv797zBXKkkKt8aNG/Pxxx+zY8cO9pWVse7ZZwl8HtrMmjULqPoHgoSEBBISEtiyZQvJycnccccddOrUiY0bNx5yiXCTJk2Iiorib3/7GxUVVQ8BOf/885k7dy6VlZVs376drKwsAFq3bs0nn3xSbdnY+vXradCgAQkJCaF/oJg5c+ax+lqk44ozgySdkJqdHEOzk7+9H0D7FrFHtxjpOLC8bHm1J04B/OjZN9n3r/fhjE7w0UewZw988AG0bXvY406cOLGGK5UkhVutWrWYMGEC3bt0YWR8PDft3cvKoiIAGjZsSHp6Ort37+b//b//B8DDDz/M4sWLiY6Opm3btvz4xz8mKiqKmJgY2rdvz4gRI7jxxhu57LLLmD17Nr169aJu3boAXHbZZSxatIikpCRatWrFeeedR0JCArGxscyZM4df/epXFBUVUV5ezi233EK7du146qmnGDlyJHXq1KF///5h+56kHzLDIEmSFJoR9GXZt/Unp7yCX+3+CWzYACtXwu7dYahOkhRO+9eupWzRIoJFRQQSEojv04df/exn/KqsDNavB6D7T37C33Nzueyyy/jtb39b7fNTp0495LiLFi2q9j4/Pz/0+osxoqKimDx5MvXq1WPHjh106dKF5ORkAFJTU1myZMlB43bs2JG8vLzQe/9hQjqYYZAkSaJ+VP1DBkL1YhvA2WdX/bnoojBUJkkKp/1r17L3hRfg86czBj/7jH1TpxK1c2fVL5OtW0NREXwpfKlpgwYNYteuXezfv5/x48dz2mmnHbVzSZHCMEiSJJEen86i0kXVlorFEEN6fHoYq5IkhVvZokWhIAiAigqidu9mf3w8MR06wKZNsHcvFBSQ9dprEFXz29J+sU+QpJpjGCRJkmgT1wag+tPE4tND7ZKkyBT8fC+gkFq1KD/33KrX//mfUFkJ27fDzp1HJQiSdHQYBkmSJKAqEDL8kSR9WSAh4eBA6PN2oCoAatKk6o+k44bRrSRJkiTpkOL79IFatao31qpV1S7puOXMIEmSJEnSIcV+/uSurz5N7It2SccnwyBJkiRJ0teKTU42/JFOMC4TkyRJkiRJiiCGQZIkSZIkSRHEMEiSJEmSJCmCGAZJkiRJkiRFEMMgSZIkSZKkCGIYJEmSJEmSFEEMgyRJkiRJkiKIYZAkSWFWr16943JsSZIkHZ8MgyRJOs5UVFSEuwRJkiQdxwyDJEmqAf/zP/9Dly5dSE1N5T/+4z+oqKigXr16jBs3jvbt29O1a1e2b98OwLvvvku3bt3o3Lkz48ePD42RlZXFoEGDQu9Hjx7N9OnTAWjRogWTJk3i/PPPZ/bs2WzZsoUBAwbQsWNHMjIy2Lhx4zeOLUmSJH3BMEiSpCP01ltvMWvWLN544w1yc3OJjo5m5syZ7Nmzh65du5KXl0ePHj2YNm0aADfffDOjRo1i1apVnHbaaYd9nvj4eJYtW8ZVV13F9ddfz9SpU8nJyWHy5MnceOONRzS2JEmSIkdMuAuQJOl4t2jRInJycujcuTMAe/fu5dRTTyU2NjY006djx468+uqrALzxxhvMnTsXgGuvvZY77rjjsM5z5ZVXAlBSUsLy5csZMmRI6Ni+ffuOaGxJkiRFDmcGSZJ0hILBIMOHDyc3N5fc3Fw2bdrExIkTqVWrFoFAAIDo6GjKy8tDn/mi/ctiYmKorKwMvS8rK6t2vG7dugBUVlbSoEGD0Plyc3N56623vnFsSdLhmThxIpMnTwZgwoQJLFy48DuPMW/ePDZs2BB6/33HkaSjxTBIkqQj1KdPH+bMmcPHH38MwM6dO3nvvfe+tn/37t155plnAJg5c2aovXnz5mzYsIF9+/ZRVFTEokWLDvn5k046iZYtWzJ79mygKozKy8v7xrElSd/dpEmTuOCCC77z574aBn3fcSTpaDEMkiTpCLVt25Z7772XIb17c83ZZ9O3b18++uijr+3/xz/+kccee4zOnTtTVFQUaj/jjDO44oorSElJYdiwYaSlpX3tGDNnzuTJJ5+kffv2tGvXjr///e/fOLYknUjuuOMO/vSnP4XeT5w4kd///veMGTOGpKQkkpOTmTVrVuj4gw8+SHJyMu3bt+fOO+8EYNq0aXTu3Jn27dtz2WWXUVpaetB5RowYwZw5c8jOziY1NZXU1FSSk5NDMzAPNcby5cv5xz/+wZgxY0hNTWXLli2hcaBqaXFaWhrJycmMHDkytMy3RYsW3H333XTo0IHk5OTQgwEk6WgwDJIk6XvYtn4Wrz92Lv/8bX1ef+xcep6yk9cvuID/6dWLnOXL6dq1KyUlJaH+l19+eejJYC1btmTFihWsWrWKO++8s1q/Bx98kE2bNjF//nyee+45RowYAUBhYSGJiYmhfi1btmTBggXk5eWxYcMGJkyY8K1jSzp2HnzwQR555BEAbr31Vnr37g1UBQHXXHMNr7zyCt26daNDhw4MGTIk9Hd10qRJdO7cmaSkJK6//nqCwSAAmZmZ3HLLLaSnp5OUlMTKlSuBqpmIl1xyCSkpKXTt2pX8/HygKhwZOXIkmZmZnHXWWaFa9uzZw8CBA2nfvj1JSUnVApPjyVVXXVWt9meffZbExERyc3PJy8tj4cKFjBkzho8++oiXX36ZefPm8a9//Yu8vDxuv/12AAYPHsyqVavIy8vj3HPP5cknn/za83Xq1Cm0LHfAgAHcdtttXztGeno6F198MQ899BC5ubmcffbZoXHKysoYMWIEs2bNYu3atZSXl/PnP/85dDwxMZHVq1czatSo0FI1SToaDIMkSfqOtq2fxfqXRlO2+30gSNSWQsrv+k9Ktr8FlZVQWBjuEiWFWY8ePVi6dCkA2dnZlJSUcODAAZYtW0ZycjL33nsvCxcuZPXq1XTq1Ik//OEPAIwePZpVq1axbt069u7dy/z580Nj7tmzh+XLl/OnP/2JkSNHAnD33XeTlpZGfn4+999/Pz/96U9D/Tdu3Mg///lPVq5cyT333MOBAwdYsGABTZs2JS8vj3Xr1jFgwIBj+K3UnLS0ND7++GO2bdtGXl4eDRs2JDc3l6FDhxIdHU3jxo3p2bMnq1atYuHChfzsZz+jTp06ADRq1AiAdevWkZGRQXJyMjNnzmT9+vXfet5nn32W1atX88ADD3yvMTZt2kTLli1p1aoVAMOHD2fJkiWh44MHDwaqHjpQ6P9LJB1FhkGSJH1HBVkTqSzfC0CDwnKS5u4nunQ/Oz9eVdXhS/tESIpMHTt2JCcnh+LiYuLi4ujWrRvZ2dksXbqU2rVrs2HDBrp3705qaiozZswI7TO2ePFizjvvPJKTk3nttdeqhQtDhw4FqoKm3bt3s2vXLpYtW8a1114LQO/evdmxY0doiejAgQOJi4sjMTGRU089le3bt5OcnMzChQu54447WLp0KQkJCcf4m6k5l19+OXPmzGHWrFlcddVVoVlUXxUMBg+5sf6IESN49NFHWbt2LXffffdBm/Z/1f9n787Dqqr2P46/DzMomoZ21RTIn4bKgQOCoCCSOJZaTqlXb1I3p9Kmq2XZYF69mtJkk2lOFSVlDrfU9GKSaTiA4DySiNNVnBBkkOH8/iDPlXBKwYPweT0Pj3uvvfZa332e/Xg2X9Zea+fOnbzxxhssWLAAW1vbm2rjajFe4ujoCJRedEBEpKwpGSQiIvIn5Z4/YtnOrm3DwVA7TjW1o6AgCwoKYN8+K0YnIhWBvb09Hh4ezJ07lzZt2tC2bVvWrFlDSkoKnp6edOzY0fLa0a5du5g9eza5ubk89dRTLFy4kO3btzNkyJASyYU/JjQMBsMVkwuX6l1KLMD/kgtNmzYlMTERo9HIyy+/zIQJE8rpEyh//fv3Z8GCBSxcuJC+nToRFhZGTEwMhYWFpKens3btWlq1akWnTp2YM2eOZU6gM2fOAJCZmUm9evXIz8+/7oT7GRkZ9O/fn88//5w6depYyq/WhqurK5mZmaXa8fLyIjU1lQMHDgDwxRdf0K5du1v+LERE/iwlg0RERP4kpxr3WrYv1rAh3dueYy3tOfxoY5g5E4YPt2J0IlJRhIWFERUVRVhYGG3btmXGjBmYTCaCg4NZv369JSGQnZ3Nvn37LIkfNzc3srKyLBMOX3Jpjpx169ZRs2ZNatasSVhYmCUJERcXh5ubGzVq1LhqTMeOHcPFxYVBgwYxevRotmzZUh6Xflu0aNGCnPPnGWhnx18+/JCeDz2Ej48Pvr6+tG/fnqlTp/KXv/yFLl260KNHDwICAjCZTJa5eP75z38SFBREx44d8fLyumZfS5Ys4dChQwwZMsQykfS12ujfvz/Tpk3Dz8+PlJQUS7mTkxNz586lb9++GI1GbGxsGK7vDBGxAjtrByAiInKnaRI+np3LR1peFQOwsXOmSfh4cHIq/hGRKq9taCjfTZxI68BAqtWsiZOTE23btqVOnTrMmzePAQMGWFaSmjhxIk2bNmXIkCEYjUY8PDwIDAws0V6tWrVo06YN58+fZ86cOUDxRNGPP/44Pj4+uLi4MH/+/GvGtH37dsaMGYONjQ329vYlJi+uyA6fzGR32llyLlxkVUIazRrVoqHtRZL694f9+yEzE8PJk0ybNo1p06aVOn/s2LGWVcQuGTFiBCNGjChVd/z48ZbtSxP/Q/H8Pn90tTZCQkJKLC1/eTsREREkJSWVOufyOYICAgKIi4srVUdEpKwoGSQiIvIn1W/RDyieOyj3/BGcatxLk/DxlnIRqXoWLUpg8uTlHDt2lvr1a/Hyi53pZT7D9n794PhxqFmTfZe9Qtq+fXs2b95cqp2JEycyceLEK/bRu3dvJk+eXKKsdu3aLF26tFTdyxMaUDzRMRQvX965c+c/e3lWdfhkJltTTlNYVPxKXE5eIf/9LJra8Sup5nYXeHhAWhocOwYNG1o3WBGRO4SSQSIiIjehfot+Sv6ICFCcCBoz5htycvIBSD+STtKIV2nZwh53jzqwZw9c5zUkubrdaWctiaBLCuztOXZvY5rY5BQngs6ehYMHISjISlGKiNxZlAwSEREREbkFkycvtySCnIsuMiXjJ/5SlMXqvZ480dILtmyBRx65pT6q8itDOXmFpcpOtmnPyTbtadLaHY4ehb17oVo1K0QnInJnUjJIREREROQWHDt21rJtBrY41MO1KI97M88Vj1g5dw6ys8HFxXpB3sGcHW2vmBBydrQFG5viV8P0epiIyJ+iZJCIiIiIyC2oX78WR48WJ4RybRyYX80XgHvr1+SxqU/DyZNw2TLv8uc0a1SrxJxBALY2Bpo1qmXFqERE7mxaWl5EKqx58+YxcuRIa4chIiJyTS+//CDOzvYlypyd7Rn7SjeoUwdatABbWytFd+drWNcV38Z3F48EonhEkG/ju2lY19XKkYmI3Lk0MkhEykVBQQF2dvovRkREKr9evQIASq4m9vKDlnK5dQ3rutKwritxcb8RHtDI2uGIiNzx9JuaSCX2+eefExUVhcFgwMfHh4kTJ/LEE0+Qnp6OnZ0dS5YsoVGjRkRGRlKjRg0SEhL473//y9SpU+nTpw8AU6dO5YsvvsDGxoauXbsyZcoUUlJSePrpp0lPT8fFxYVZs2bh5eVFZGQktWvXJikpCX9/f1xdXUlLS+O3334jLS2N5557jmeeeQaAL7/8kunTp3Px4kWCgoL4+OOPsbW1Ze7cuUyePJl69erRtGlTHDWsXkRE7gC9egUo+SMiIncMvSYmUknt3LmTSZMm8dNPP7F161bef/99Ro4cyWOPPca2bdvo0KGDJTEDcPz4cdatW8cPP/zA2LFjAVixYgVLlixh48aNbN26lRdffBGAoUOH8sEHH5CYmEhUVBRPPfWUpVCCsS0AACAASURBVJ19+/YRGxvL22+/DcCePXtYuXIlmzZt4s033yQ/P5/du3cTExPD+vXrSU5OxtbWlujoaI4fP84bb7zB+vXr+c9//sOuXbtu4ycmIiJV3a7oaGZ6eBBlY8NMDw92RUdbOyQREZFyoZFBIpXUTz/9RJ8+fXBzcwOgdu3axMfHs2jRIgA6derEnDlzLPUfeeQRbGxsaN68OSdOnAAgNjaWxx9/HJffVz+pXbs2WVlZ/Prrr/Tt29dybl5enmW7b9++2F42L8JDDz2Eo6Mjjo6O1K1blxMnTrB69WoSExMJDAwEICcnh7p167Jx40bCw8OpU6cOAP369WPfvn3l8fGIiIiUsCs6mlVDh1KQnQ3A+UOHWDV0KADNBw60ZmgiIiJlTskgkUrKbDZjMBiuWefy45e/jmU2m6/aRlFREXfddRfJyclXbLNatWol9i9v19bWloKCAsxmM4MHD2by5Mkl6i5ZsuS6MYuIiJSHdePGWRJBdkABUJCdzbpx45QMEhGRSkeviYlUUhEREXzzzTecPn0agDNnztCmTRsWLFgAFI/6CQ0NvWYbl0YPZf/+cHzmzBlq1KiBp6cn3377LVCcMNq6deufjm3hwoWcPHnS0u6hQ4cICgoiLi6O06dPk5+fb+lDRESkvJ1PSwPAAQgEWgPNgb8cOgRLlsBPP0FhoRUjFBERKTtKBolUUi1atGDcuHG0a9cOPx8f5vfty4whQ5g7dy4+Pj6sWrWK999//5ptdOnShR49ehAQEIDJZCIqKgqA6OhoZs+eja+vLy1atGDp0qV/KrbmzZszceJEOnXqhI+PDx07duT48ePUq1eP8ePH07p1azp06IC/v/9NX7+IwPjx44mKiuL1118nNjb2qvWWLFlSYo6u69W/WddrNzIykoULF95we6mpqXh7e1/xWHh4OAkJCX86Rqm6ajQqXqHqIpAEOAPngSbVq8PXX8PKlVaMTkREpGzpNTGRSmLRooRSS9oOHjyYwX36wOzZEBcHqan89NNPAMTFxdHo9wffefPmlWgrKyvLsj127FjLhNKXeHp68uOPP5aK4Y/tjB8/vsT+jh07LNv9+vWjX79+pdp4/PHHefzxx693uSLyJ0yYMOGax5csWUK3bt1o3rz5DdUvrzhErCl00iTLnEG5FCeEHAC39u3B0RH++le4bE48ERGRO5lGBolUAosWJTBmzDccPXoWsxmOHj3LmDHfsPyzFTBxImzdCvffD3v3wu/zAYlI5TRp0iTuv/9+OnTowN69e4GSI27Gjh1L8+bN8fHxYfTo0fz666/8+9//ZsyYMZhMJlJSUkrU9/Dw4I033sDf3x+j0ciePXsASE9Pp2PHjvj7+zNs2DDc3d05depUqdE6UVFRlsTwteK4ZO3atbRp04b77rvPUjcrK4uIiAhLDJePRiwoKGDw4MH4+PjQp08fy2utl1u1ahWtW7fG39+fvn37lkh4i1zSfOBAOs2cSQ13dzAYKHR350c7O+rY2mL28mLMF1/g7e2N0WgkJiYGKP7DxvLlyy1tREZG8t1331FYWMiYMWMIDAzEx8eHTz/91FqXJSIickVKBolUApMnLycnJ79E2V8yT3LXC6Pgt9+gqAgyM4t/zpyxUpQiUt4SExNZsGABSUlJLFq0iM2bN5c4fubMGRYvXszOnTvZtm0br776Km3atKFHjx5MmzaN5ORkGjduXKpdNzc3tmzZwogRIyyvi7755pu0b9+eLVu20LNnT9J+n2/lRlwpjkuOHz/OunXr+OGHHyyjEp2cnFi8eDFbtmxhzZo1/OMf/7BMdL93716GDh3Ktm3bqFGjBh9//HGJvk6dOsXEiROJjY1ly5YtBAQE8M4779xwrFK1NB84kKGpqYwuKmJoairLHRwgNJQfa9UieetWtm7dSmxsLGPGjOH48eP079/fkhi6ePEiq1ev5sEHH2T27NnUrFmTzZs3s3nzZmbNmsXBgwetfHUiIiL/o2SQSCVw7NjZUmUHbe9iQLWuEBUFkZHwf/8HNWooGSRSif3yyy/07NkTFxcXatSoQY8ePUocr1GjBk5OTjz55JMsWrQIFxeXG2q3V69eALRs2ZLU1FQA1q1bR//+/YHi+cVq1ap1w3FeK45HHnkEGxsbmjdvzokTJ4DiiepfeeUVfHx86NChA0ePHrUca9iwISEhIQAMGjSIdevWlehrw4YN7Nq1i5CQEEwmE/Pnz+fQoUM3HKtUbfkGA7zwAqv27WPAgAHY2tpyzz330K5dOzZv3kzXrl356aefyMvLY8WKFYSFheHs7MyqVav4/PPPMZlMBAUFcfr0afbv32/tyxEREbHQnEEilUD9+rU4evQPCSGDgboN6kDDhsU/7doVjxCyUQ5YpDIzGAxXPWZnZ8emTZtYvXo1CxYs4MMPP7TMI3Ytjo6OANja2lJQUABgGZlzpT6Kioos+7m5uX8qjkt9Xd5HdHQ06enpJCYmYm9vj4eHh6XdP17vH/fNZjMdO3bk66+/vu51ilzN1e53JycnwsPDWblyJTExMQwYMMBS/4MPPqBz5863M0wREZEbpt8KRSqIwyczWZWQxtL1B1mVkMbhk5k3fO7LLz+Is7N9iTJnZ3tefvnBkhWVCBKp1MLCwli8eDE5OTlkZmby/ffflzielZVFRkYGDz74IO+99x7JyckAuLq6kpl54//nAISGhvLNN98AxXPynD1bnJC+5557OHnyJKdPnyYvL48ffvih1LlXi+NqMjIyqFu3Lvb29qxZs6bEyJ60tDTi4+MB+PrrrwkNDS1xbnBwMOvXr+fAgQMAZGdns2/fvj91rSJhYWHExMRQWFhIeno6a9eupVWrVgD079+fuXPn8ssvv1iSP507d+aTTz4hP7/4Fe59+/Zx4cIFq8UvIiLyRxoZJFIBHD6ZydaU0xQWFf/lMSevkK0ppwFoWNe1eNLna/y1v1evAIBSq4ldKheRqsHf359+/fphMpnwbNSI9q1blziemZnJww8/TG5uLmazmXfffRco/mV2yJAhTJ8+/YaXdn/jjTcYMGAAMTExtGvXjnr16uHq6oq9vT2vv/46QUFBeHp64uXlVercq8VxNQMHDqR79+4EBARgMplKtNmsWTPmz5/PsGHDaNKkCSNGjChxbp06dZg3bx4DBgwgLy8PgIkTJ9K0adMbuk4RgJ49exIfH4+vry8Gg4GpU6fyl7/8BYBOnTrx2GOP0aNHDxwcHAB48sknSU1Nxd/fH7PZTJ06dViyZIk1L0FERKQEw9WGvZangIAAc0JCwm3v90bExcURHh5u7TCkilmVkEZOXqFl3+nEcRzPnabmqWP45Z+C48fhhRfgvvvKrE/d61JVVNZ7PT/zCAVn92IuzMFg64xdrfuxd723+ODJkzBzJtStC0OHlkv/eXl52NraYmdnR3x8PCNGjLjuCB8pX5X1Xhe5nO5zqSp0r8vNMhgMiWaz+bqjAjQySKQCuDwRRFERxnffwCHjHFmNPOH/6kNWFtSpY70ARaRCyc88Qv7p7WAu/r/DXJjz+74Z++1pMG8eXLxY/H9HOUlLS+PRRx+lqKgIBwcHZs2aVW59iYiIiEjZ0gQiIhWAs6Pt/3ZsbEh+ZRqf7krGzobi18M8PMDV9Zb7efLJJ9m1a9cttyMi1lVwdq8lEWRhLoTnn4ORIyEnB9zdi0cIFRZeuZFb1KRJE5KSkti6dSubN28mMDCwXPoRERERkbKnZJBIBdCsUS1sbf43J1B+jZq8bW9PNX9f+O03CCibuX8+++wzmjdvXiZtiQCcO3eOjz/+2NphVDnmwpwrlheGeEPPnuDgAIcPQ14enDlzm6MTERERkYpOySCRCqBhXVd8G99tGSHk7GhLno0Ntca9CAMHgr8/AOnp6fTu3ZvAwEACAwNZv349AOPHj2fw4MF06tQJDw8PFi1axIsvvojRaKRLly6W1UzCw8O5NF/X5s2bad26Nf7+/vTt25es318n8fDw4NSpUwAkJCRY3lV+5plnmDBhAgArV64kLCysxPLRUgXlbr/jkkGF5TRK5nYz2DpfsdzcIQxefx0++gieew66dgU7vREuIiIiIiUpGSRSQTSs60qngEY8HOJJp4BGxYuH2dvDo49C/foAPPvsszz//PNs3ryZ7777jieffNJyfkpKCsuWLWPp0qUMGjSIBx54gO3bt+Ps7MyyZctK9HXq1Cm+/PJLYmNj2bJlCwEBAbzzzjvXjG/KlCnExMSwZs0annnmGebOnYuNlqqvui7uh1Qfxr44kpSUFEwmE2PGjGHatGkEBgbi4+PDG2+8Yan+5Zdf0qpVK0wmE8OGDbMkZapXr864cePw9fUlODiYEydOAPD9998TFBSEn58fHTp0sJSnp6fTsWNH/P39GTZsGO7u7pbk5dX66Nq1q2V1q0tLkN/p7GrdDwbbkoUG2+JyAGdn8PWFQYOgVq3bH6CIiIiIVGj6TU7kDhIbG8vIkSMxmUz06NGD8+fPk5mZCRT/wmtvb4/RaKSwsJAuXboAYDQaSU1NLdHOhg0bSE1NJSQkBJPJxPz58zl06NA1+3ZxcWHWrFl07NiRkSNH0rhx43K5RrlDnP8WgCljm9O4cWOSk5Pp2LEj+/fvZ9OmTSQnJ5OYmMjatWvZvXs3MTExrF+/nuTkZGxtbYmOjgbgwoULBAcHs3XrVsLCwiyTEIeGhrJhwwaSkpLo378/U6dOBeDNN9+kffv2bNmyhZ49e5KWlgZwzT5yc3Px9vZm48aNhIaG3u5PqlzYu96L/d1Gywghg60z9ncb/7eamIiIiIjINWjsuMgdpKioiPj4eJydS78i4ujoCICNjQ329vYYDAbLfkFBQYm6ZrOZgIAAVq9eXaodOzs7y+tfubm5JY5t376du+++m2PHjpXJ9cgdLGNe8b+ZCwEXAFatWsWqVavw8/MDICsri/3797Nt2zYSExMtEwzn5ORQt25dABwcHOjWrRsALVu25D//+Q8AR44coV+/fhw/fpyLFy/i6ekJwLp161i8eDEAXbp0odbvo15Wr1591T5sbGzo3bt3OX4Y1mHveq+SPyIiIiJyUzQySOQO0qlTJz788EPLfnJy8k21ExwczI4dOzhw4AAA2dnZ7Nu3DyieMygxMRGA7777znLOoUOHePvtt0lKSmLFihVs3LjxZi9D7nQXU6HgcPF2wVEwF89JZTabefnll0lOTiY5OZkDBw7w97//HbPZzODBgy3le/fuZfz48QAlEpe2traWxOWoUaMYOXIk27dv59NPP7UkJs1m8xVDulYfDg4O2NraXvE8EREREZGqSMkgkQoqOzube++91/LzzjvvMH36dBISEvDx8aF58+bMmDHjptquU6cOL730EgMGDMDHx4fg4GD27NkDwBtvvMGzzz5L27ZtLb9Am81m/v73vxMVFUX9+vWZPXs2Tz75ZKmRQ1JFZP4vSehazYbM8+kAdO7cmTlz5lgmIz969CgnT54kIiKChQsXcvLkSQDOnDlz3dcSMzIyaNCgAQDz58+3lIeGhvLNN98AxSORzp49C3BTfYiIiIiIVFV6TUykgrraSl0xMTGlyi6NgLjk0i/jfzwWFxdn2fb39+eFF14o1Vbbtm0to4QuFxsba9lu2bIl27dvv1roUtllzANzcSLw7rtyCfFzxNvbm65du/JEjx5M8vLix7vuwsnVlS+//JLmzZszceJEOnXqRFFREfb29nz00Ue4u7tftYvx48fTt29fGjRoQHBwMAcPHgSKk5UDBgwgJiaGdu3aUa9ePVxdXXFzc/vTfYiIiIiIVFWGqw25L08BAQHmS8tbVzRxcXGWpbRFKjPd63JNR/pC9mrgCt8R5hww5/1v3+AIBmc4Ughz8+CMGV5wgoZ24BIB935bZmHl5eVha2uLnZ0d8fHxjBgx4rqvS+pel6pC97pUBbrPparQvS43y2AwJJrN5oDr1dPIIBERKc1tHBzZCAUngIvXrmvOg115EA04A47AoSJwr1/cThlKS0vj0UcfpaioCAcHB8vqYyIiIiIicuOUDBIRkdKcTHDfbvjvcMhcBObsK9c7C3wPbKQ4CWQL2NjCASNErgObamUaVpMmTUhKSirTNkVEREREqholg0RE5MpsqkH9LyCjG/z3yeLXwygsWccFaAdEAKcNkOoAJ7qAuRkYXG5/zCIiIiIicl1KBomIyLXV7AfOQXCkC1zcD1w2ubkj4A5gA55NoeePYO8ORUXw+5LxIiIiIiJSsWhpeRERuT4HD7C9mxKJoBKKio/b/756l42+XkREREREKio9rYuIyPUVnoXc66wCmbsZCs/dnnhEREREROSmKRkkIiLXl/U94PC/fUM1sP1L8b8WDr/XExERERGRiuyWk0EGg6GhwWBYYzAYdhsMhp0Gg+HZsghMREQqkIx5YM4CDGBwhjr/gv87Wvyvwbm43JxVXE9ERERERCq0shgZVAD8w2w2NwOCgacNBkPzMmhXREQqgsJMyP4FDI5g1wjcN0DtZ8BgU/yv+wawa1h8PHstFGVZO2IREREREbmGW04Gmc3m42azecvv25nAbqDBrbYrIiIVxIUVQAG49of7doGTT8njTj5w325w7VdcL2u5NaIUEREREZEbVKZLyxsMBg/AD9hYlu2KiIgVOTSDe7+H6t2uXsfGBerPhxp9wc799sUmIiIiIiJ/msFsNpdNQwZDdeBnYJLZbF50heNDgaEA99xzT8sFCxaUSb9lLSsri+rVq1s7DJFyp3tdqgrd61JV6F6XqkD3uVQVutflZj3wwAOJZrM54Hr1yiQZZDAY7IEfgJVms/md69UPCAgwJyRcZ4liK4mLiyM8PNzaYYiUO93rUlXoXpeqQve6VAW6z6Wq0L0uN8tgMNxQMqgsVhMzALOB3TeSCBIREREREREREespi9XEQoC/Ae0NBkPy7z8PlkG7IiIiIiIiIiJSxm55Ammz2bwOMJRBLCIiIiIiIiIiUs7KYmSQiIiIiIiIiIjcIZQMEhERERERERGpQpQMEhEREasJDw+noq4wKiIiIlJZKRkkIiIiIiIiIlKFKBkkIiJSSV24cIGHHnoIX19fvL29iYmJITExkXbt2tGyZUs6d+7M8ePHAZg1axaBgYH4+vrSu3dvsrOzAfj222/x9vbG19eXsLAwAHJzc3n88ccxGo34+fmxZs0aAObNm0evXr3o0qULTZo04cUXX7TEMmLECAICAmjRogVvvPHGbf4kRERERORyt7yamIiIiFRMP/74I/Xr12fZsmUAZGRk0LVrV5YuXUqdOnWIiYlh3LhxzJkzh169ejFkyBAAXn31VWbPns2oUaOYMGECK1eupEGDBpw7dw6Ajz76CIDt27ezZ88eOnXqxL59+wBITk4mKSkJR0dH7r//fkaNGkXDhg2ZNGkStWvXprCwkIiICLZt24aPj48VPhURERERUTJIRESkkjIajYwePZqXXnqJbt26UatWLXbs2EHHjh0BKCwspF69egDs2LGDV199lXPnzpGVlUXnzp0BCAkJITIykkcffZRevXoBsG7dOkaNGgWAl5cX7u7ulmRQREQENWvWBKB58+YcOnSIhg0b8s033zBz5kwKCgo4fvw4u3btUjJIRERExEqUDBIREamkmjZtSmJiIsuXL+fll1+mY8eOtGjRgvj4+FJ1IyMjWbJkCb6+vsybN4+4uDgAZsyYwcaNG1m2bBkmk4nk5GTMZvNV+3R0dLRs29raUlBQwMGDB4mKimLz5s3UqlWLyMhIcnNzy/x6RUREROTGaM4gERGRSurYsWO4uLgwqHt3Ro8ezcaNG0lPT7ckg/Lz89m5cycAmZmZ1KtXj/z8fKKjoy1tpKSkEBQUxIQJE3Bzc+Pw4cOEhYVZ6uzbt4+0tDTuv//+q8Zx/vx5qlWrRs2aNTlx4gQrVqwox6sWERERkevRyCAREZFKYk30dj4ft4ZTaRm4NapJs0ftSf3mLcKysvi4USPemTkTOzs7nnnmGTIyMigoKOC5556jRYsW/POf/yQoKAh3d3eMRiOZmZkAjBkzhv3792M2m4mIiMDX1xcvLy+GDx+O0WjEzs6OefPmlRgR9Ee+vr74+fnRokUL7rvvPkJCQm7XRyIiIiIiV2C41lDv8hIQEGBOSEi47f3eiLi4OMLDw60dhki5070uVUVVudfXRG/nw6HLyMvOB8CGQiIcdvFoYDb1PGvBiy+C0WjlKKU8VZV7Xao23edSVehel5tlMBgSzWZzwPXq6TUxERGRSuDzcWssiSAn8nicVfhf3Mmm7fng6Ai7dlk5QhERERGpKJQMEhERqQROpWVYtu/mPNXJIR87XM6nw4ULkJhoxehEREREpCLRnEEiIiKVgFujmqQfKk4IHaUO79MLG4po3MCGjs93hoyM67QgIiIiIlWFRgaJiIhUAo9NegBHF/sSZfYujvR46xFo1Qo6drRSZCIiIiJS0SgZJCIiUgk8MNDIyJkPUce9JgYD1HGvyciZD/HAQE0aLSIV17x58xg5cmSp8vHjxxMVFWWFiEREqgYlg0RErCQuLo5u3brd9Pn/+te/yjAaqQweGGhkbuozfF/0GnNTn1EiSERuWEFBgbVDEBGR20jJIBGR26SwsLBM21MySERELpeamoqXlxeDBw/Gx8eHPn36kJ2dzYQJEwgMDMTb25uhQ4diNpsBCA8P55VXXqFdu3a8//77fP/99wQFBeHn50eHDh04ceIEAD///DMmkwmTyYSfnx+ZmZnExcURFhZGz549ad68OcOHD6eoqAiAVatW0bp1a/z9/enbty9ZWVkAbN68mTZt2uDr60urVq3IzMwsEf+yZcto3bo1p06dKlGekpJCly5daNmyJc888wx79uwB4Ntvv8Xb2xtfX1/CwsLK9bMVEalslAwSESkjjzzyCC1btqRFixbMnDkTgOrVq/P6668TFBREfHw8P/74I15eXoSGhrJo0SLLuRcuXOCJJ54gMDAQPz8/li5dChQPn+/VqxddunShSZMmvPjiiwCMHTuWnJwcTCYTAwcOvP0XKyIiFdLevXsZOnQo27Zto0aNGnz88ceMHDmSzZs3s2PHDnJycvjhhx8s9c+dO8fPP//MP/7xD0JDQ9mwYQNJSUn079+fqVOnAhAVFcVHH31EcnIyv/zyC87OzgBs2rSJt99+m+3bt5OSksKiRYs4deoUEydOJDY2li1bthAQEMA777zDxYsX6devH++//z5bt24lNjbW0g7A4sWLmTJlCsuXL8fNza3ENQ0dOpQPPviAxMREhg8fzlNPPQXAhAkTWLlyJVu3buXf//53eX+0IiKVilYTExEpI3PmzKF27drk5OQQGBhI7969uXDhAt7e3kyYMIHc3FyaNGnCTz/9xP/93//Rr18/y7mTJk2iffv2zJkzh3PnztGqVSs6dOgAQHJyMklJSTg6OnL//fczatQopkyZwocffkhycrK1LldERCqghg0bEhISAsCgQYOYPn06np6eTJ06lezsbM6cOUOLFi3o3r07QInvoiNHjtCvXz+OHz/OxYsX8fT0BCAkJIQXXniBgQMH0qtXL+69914AWrVqxX333QfAgAEDWLduHU5OTuzatcsSw8WLF2ndujV79+6lXr16BAYGAlCjRg1Lv2vWrCEhIYFVq1aVKAfIysri119/pW/fvpZ9e3t7S1yRkZE8+uij9OrVq2w/SBGRSk4jg0REysj06dPx9fUlODiYw4cPs3//fmxtbenduzcAe/bswdPTkyZNmmAwGBg0aJDl3FWrVjFlyhRMJhPh4eHk5uaSlpYGQEREBDVr1sTJyYnmzZtz6NAhq1yfiIhUfAaDodT+U089xcKFC9m+fTtDhgwhNzfXcrxatWqW7VGjRjFy5Ei2b9/Op59+aqk3duxYPvvsM3JycggODra8pnWlvsxmMx07diQ5OZnk5GR27drF7NmzMZvNpepfct9995GZmcm+fftKHSsqKuKuu+6ytPfZZ5+xe/duAGbMmMHEiRM5fPgwJpOJ06dP38QnJiJSNSkZJCJSBuLi4oiNjSU+Pp6tW7fi5+dHbm4uTk5O2NraWupd7UHYbDbz3XffWR5209LSaNasGQCOjo6Wera2tprkU0REriotLY34+HgAvv76a0JDQwFwc3MjKyuLhQsXXvXcjIwMGjRoAMD8+fMt5SkpKRiNRl566SUCAgIsyaBNmzZx8OBBioqKiImJITQ0lODgYNavX8+BAwcAyM7OZt++fXh5eXHs2DE2b94MQGZmpuX7zN3dnUWLFvHYY4+xc+fOEjHVqFEDT09Pvv32W6D4+3Lr1q2WuIKCgpgwYQJubm4cPnz41j48EZEqRMkgEZEykJGRQa1atXBxcmJfYiIbNmwoVcfLy4uDBw+SkpICFD+kX9K5c2c++OADy6SeSUlJ1+3T3t6e/Pz8MroCERGpDJo1a8bn8+Yx1NMT3y1bGDFiBEOGDMFoNPLII49YXtO6kvHjx9O3b1/atm1bYt6e9957zzJRs7OzM127dgWgdevWjB07Fm9vbzw9PenZsyd16tRh3rx5DBgwAB8fH8tIIgcHB2JiYhg1ahS+vr507NixxAil+++/n+joaPr27Wv5nrwkOjqa2bNn4+vry+OPP26ZV2/MmDEYjUa8vb0JCwvD19e3LD9KEZFKTXMGiYiUgS5duvDpJ58wzt0dv+rVCQ4KKlXHycmJmTNn8tBDD+Hm5kZoaCg7duwA4LXXXuO5557Dx8cHs9mMh4dHiQk+r2To0KH4+Pjg7+9PdHR0uVyXiIhUXNEbohm3eBxpZ9JoVLsRzwU/h6vZzCfNmsGFC1CtGjg7M3HiRCZOnFjq/Li4uBL7Dz/8MA8//HCpeh988MEV+3dxcSEmJqZUefv27S0jgC4XGBhY6o8lkZGRREZGAuDn58euXbuA4sTUJZ6envz48B+OAgAAIABJREFU44+WmMPDwwFKLMQgIiJ/jpJBIiI36fKHcPdaDfki+CFC69QBW1v6TJgAjRpZltO9pEuXLpbh9Zdzdnbm008/LVV++UMyUCJB9NZbb/HWW2+V3QWJiMgdI3pDNEO/GEr2xWwADp05xKIZL/KPI/awYwc0bgyHD8PZs1C7tpWjFRGRikaviYmI3IRLD+GHzhzCXGQmaHMaaV/PZJt9JtjYQEKCtUMUEZFKbNzicZZE0CWmjHyq1zNDUVFxIigvD06eLJf+w8PDrzuCVUREKi4lg0REbsLlD+FTNsPTuyDPXMjuhNjih++1a4sfxkVERMpB2pm0UmUfGKFH2xx47TV45BHw9ISLF60QnYiIVHR6TUxE5CZc/hA+thXYFEGNAqidd4F+L7wAOTlwlZXDREREblWj2o04dOZQqfJ73dyLk0CentCjhxUiExGRO4FGBomI3IRGtRv9b8cARbZwzhEKPdyhZUsIDVUySEREys2knpNwcXApUebi4MKknpOsFJGIiNxJlAwSEbkJeggXERFrGhg8kJl/m4l7bXcMGHCv7c7Mv81kYPBAa4cmIiJ3AL0mJiJyEy49bF++pO+knpP0EC4iIrfNwOCB+t4REZGbomSQiMhN0kO4iIiIiIjcifSamIiIiIhcUfXq1S3by5cvp0mTJqSllV7F6mrOnTvHxx9/XB6hiYiIyC1QMkhERERErmn16tWMGjWKH3/8kUaNGl3/BKCwsFDJIBERkQpKySARERERuapffvmFIUOGsGzZMho3bgxAZGQkCxcutNS5NIIoLi6OBx54gL/+9a8YjUbGjh1LSkoKJpOJMWPGWCV+ERERKU1zBomIiIjIFeXl5fHwww8TFxeHl5fXDZ2zadMmduzYgaenJ6mpqezYsYPk5ORyjlRERET+DI0MEhEREZErsre3p02bNsyePfuGz2nVqhWenp7lGJWIiIjcKiWDREREROSKbGxs+OaLL0jYtIl//etflnI7OzuKiooAMJvNXLx40XKsWrVqtz1OERER+XOUDBIRERGRK7I1m3H56CN+fPppoqOjLSOEPDw8SExMBGDp0qXk5+df8XxXV1cyMzNvW7wiIiJyYzRnkIiIiIhcUYfCQti9G9fUVFYtWEBojx64ubkxZMgQHn74YVq1akVERMRVRwPdfffdhISE4O3tTdeuXZk2bdptvgIRERG5EiWDRERERASANdHb+XzcGk6lZXB//QI+bNUF3N3hxAkaJCZy8OBBS90NGzZYtidPngxAeHg44eHhJdr86quvbkvsIiIicuP0mpiIiEglZWtri8lkwtvbm759+5Kdnf2n24iLi+PXX38th+ikolkTvZ0Phy4j/VAGruYsIo4u49CvBzi2fjcUFkJcHJw8ae0wRUREpAwoGSQiIlJJOTs7k5yczI4dO3BwcGDGjBl/ug0lg6qOz8etIS87HzDTlp3s5V4WFrZm1r7G8Pzz8OKLUKuWtcMUERGRMqBkkIiISBXQtm1bDhw4AMAjjzxCy5YtadGiBTNnzrTU+fHHH/H398fX15eIiAhSU1OZMWMG7777LiaTiV9++cVa4cttcCot4/ctA8sIIpaW7KERCSdqgq8vNG8O9vZWjVFERETKhuYMEhERqeQKCgpYsWIFXbp0AWDOnDnUrl2bnJwcAgMD6d27N0VFRQwZMoS1a9fi6enJmTNnqF27NsOHD6d69eqMHj3aylch5c2tUU3SD2VcsVxEREQqF40MEhERqaRycnIwmUwEBATQqFEj/v73vwMwffp0fH19CQ4O5vDhw+zfv58NGzYQFhaGp6cnALVr17Zm6GIFj016AEeXkiN/HF3seWzSA1aKSERERMqLRgaJiIhUUpfmDLpcXFwcsbGxxMfH4+LiQnh4OLm5uZjNZgwGg5UilYrggYFGAMtqYm6NavLYpAcs5SIiIlJ5KBkkIiJSmRUUwJEj4OEBQEZGBrVq1cLFxYU9e/ZYlgdv3bo1Tz/9NAcPHizxmpirqyvnz5+34gXI7fTAQKOSPyIiIlWAXhMTERGpzP79b5g4EU6fBqBLly4UFBTg4+PDa6+9RnBwMAB16tRh5syZ9OrVC19fX/r16wdA9+7dWbx4sSaQFhGpRFJTU/H29i5RlpCQwDPPPAPc/pUkb7W/6tWrlyo7duwYffr0uZWwRCo1jQwSERGpRI7tjGF/3Hhyzx/hpxfqcmH+e1SrdR98/z1ERuLo6MiKFSuueG7Xrl3p2rVribKmTZuybdu22xG6iIhYUUBAAAEBAUBxcqZ69eq0adPmtvRdHv3Vr1+fhQsXlll7IpWNRgaJiIhUEsd2xrBz+Uhyzx/G9mIRdX86zKnTm8h0PA9xcXDsmLVDFBGRCua3337Dz8+PadOm0a1bN1JTU5kxYwbvvvuuZVTot99+i7e3N76+voSFhQEwb948Ro4caWmnW7duxMXFAcUjdcaNG2dZrODEiRMApKen07t3bwIDAwkMDGT9+vVl0t8lp06donXr1ixbtuyKo59E5H80MkhERKSS2B83nqKCHOyzzXjGXcTpnJkCp0Kytq3GtXF3iI+H3r2tHaaIiFQQe/fupX///sydO5dz587x888/4+HhwfDhw6levTqjR48GwGg0snLlSho0aMC5c+eu2+6FCxcIDg5m0qRJvPjii8yaNYtXX32VZ599lueff57Q0FDS0tLo3Lkzu3fvvuX+AE6cOEGPHj2YOHEiHTt2JDU19aY/F5GqQMkgERGRSiL3/BEAHDLNpN9vS/bdBsy2NphtCqk3+kOoVs3KEYqISEWRnp7Oww8/zHfffUeLFi1KjbK5XEhICJGRkTz66KP06tXrum07ODjQrVs3AFq2bMl//vMfAGJjY9m1a5el3vnz58nMzLzl/vLz84mIiOCjjz6iXbt2160vIkoGiYiIVBpONe4l9/xhLtxjw4V7bC4rbwh33WXFyEREpKKpWbMmDRs2ZP369bRo0eKadWfMmMHGjRtZtmwZJpOJ5ORk7OzsKCoqstTJzc21bNvb22MwGACwtbWloKAAgKKiIuLj43F2di7T/uzs7GjZsiUrV65UMkjkBmnOIBERkUqiSfh4bOxKPmDb2DnTJHy8dQISEZEKy8HBgSVLlvD555/z1VdflTjm6upaYsROSkoKQUFBTJgwATc3Nw4fPoyHhwfJyckUFRVx+PBhNm3adN0+O3XqxIcffmjZT05OLpP+DAYDc+bMYc+ePUyZMuWmPxORqkQjg0RERCqJ+i2Kl4O/tJqYU417aRI+3lIuIiJyuWrVqvHDV18xqnNn+lyWROnevTt9+vRh6dKlfPDBB7z77rvs378fs9lMREQEvr6+AHh6emI0GvH29sbf3/+6/U2fPp2nn34aHx8fCgoKCAsLY8aMGWXSn62tLQsWLKB79+7UqFGDBx98sAw/KZHKx2A2m297pwEBAeaEhITb3u+NiIuLIzw83NphiJQ73etSVehel6pC97pUBbrPb86iRQlMnrycY8fOUr9+LV5++UF69QqAAwfgww8hKws++QTs7a0dqvxO97rcLIPBkGg2mwOuV0+vickda968eRy7Dcskjx8/nqioqHLvR0RERESkrC1alMCYMd9w9OhZzGY4evQsL46O4ZfXP4KJE8FshqIiSE+3dqgichspGSR3pMLCwmsmgwoLC29zRCIiIiIiFc/kycvJyckvUfbSf2Op/s7U4kSQk1Nx4X//a4XoRMRalAwSq0lNTcXLy4vBgwfj4+NDnz59yM7OZvXq1fj5+WE0GnniiSfIy8sDwMPDgwkTJhAaGsrXX39NQkICAwcOxGQykZOTU+L4t99+y6xZswgMDMTX15fevXuTnZ1NZmYmnp6e5OcXfyGeP38eDw8P8vPzr1hfREREROROduzY2VJl77oGMca5LXTsCLm5kJ0NR45YIToRsRYlg8Sq9u7dy9ChQ9m2bRs1atTgnXfeITIykpiYGLZv305BQQGffPKJpb6TkxPr1q1j0KBBBAQEEB0dTXJysmV5ykvH+/fvT69evdi8eTNbt26lWbNmzJ49G1dXV8LDw1m2bBkACxYsoHfv3tjb21+xvoiIiIjInax+/Vqlys7ZOpPh0RQGDYL33oN334WQECtEJyLWomSQWFXDhg0J+f2LZ9CgQaxevRpPT0+aNm0KwODBg1m7dq2lfr9+114R5/LjO3bsoG3bthiNRqKjo9m5cycATz75JHPnzgVg7ty5PP7449esLyIiIiLyZ2ScyCAlPoW9cXtJiU8h40SG1WJ5+eUHcXYuOTG0s7M9L7/8+2pbBgPUqwd3322F6ETEWrS0vFiVwWD4U/WrVat2w8cjIyNZsmQJvr6+zJs3j7i4OABCQkJITU3l559/prCwEG9v72vWFxERERG5URknMjix9wTmouJVmwvyCjix9wQANe+pedvj6dWreFGhK64mJiJVlkYGiVWlpaURHx8POTksnj+fDh06kJqayoEDBwD44osvaNeu3RXPdXV1JTMz86ptZ2ZmUq9ePfLz84mOji5x7LHHHmPAgAGWUUHXqy8iIiIiciNO/XbKkgi6xFxk5tRvp4p38vPht9/g11+LJ3C+DXr1CmDz5tc5evRdNm9+XYkgEdHIILGuZs2a8d2MGexcvpzm997L4E8+ITg4mL59+1JQUEBgYCDDhw+/4rmRkZEMHz4cZ2fn4oTSH/zzn/8kKCgId3d3jEZjicTRwIEDefXVVxkwYMAN1RcRERERuREFeQWlyhwO7sdpZxL86gJ79sDFi+DoCEFBYGtrhShFpKpTMkhum+gN0YxbPI60M2k0qt2I54Kfo2F+PlGurtCjR/Gylk5OREREkJSUVOr81NTUEvu9e/emd+/eVz0+YsQIRowYccVY1q1bR58+fbjrrruuW3/8+PE3fpEiIiIiUqXZOdqVSgjZ5Fyg2q4kOGgALy+4cAHuuUeJIBGxGiWD5LaI3hDN0C+Gkn2xeLn29BOH+OW9MQw9bl88aV3DhnDoEJw4UTyBXTkaNWoUK1asYPny5eXaj4iIiIhUPW73uZWYMwggz9sP84PtYMXi4tfDANq3v+W+/v3vf7Nr1y7Gjh17y22JSNWiZJDcFuMWj7MkggDa/he8sgpI860GOTmQlgbnzhW/P13OyaAPPvigXNsXERERkarr0iTRp347RUFeAXaOdrjd51ZcPmwYeHjA11+Dp+cNtVdQUICd3ZV/bevRowc9evQoq9Bv2LViEpE7gyaQltsi7Uxaif2VDeFf/vCP5ufhk09g/HgYPRruvdc6AYqIiIiIlJGa99SkcevG3B9+P41bN+Zszlm8vLwY/Pjj+Lz0EsNOnSLb3Z0JEyYQGBiIt7c3Q4cOxfz7hNLh4eG88sortGvXjvfff5/09HR69+5NYGAggYGBrF+/HoB58+YxcuRIAL7//nuCgoLw8/OjQ4cOnDhRvILZzz//jMlkwmQy4efnR2ZmJllZWURERODv74/RaGTp0qVA8bQLl1baBYiKirJMmfDHmKRiS0hI4JlnnrniMQ8PD06dOnWbI5KKRulcuS0a1W7EoTOHrliOvT00alT8IyIiIiJSCe3du5fZs2cTEhLCE088wcczZzJy5Ehef/11AP72t7/xww8/0L17dwDOnTvHzz//DMBf//pXnn/+eUJDQ0lLS6Nz587s3r27RPuhoaFs2LABg8HAZ599xtSpU3n77beJiorio48+IiQkhKysLJycnABYvHgxNWrU4NSpUwQHB9/QCKPLY5KKLSAggIAArRonV6eRQXJbTOo5CRcHlxJlLg4uTOo5yUoRiYhIRbV48WIMBgN79uwBiv9S/dVXX1mOJycn39K8b/qLqIhYQ8OGDQkJCQFg0KBBrFu3jjVr1hAUFITRaOSnn35i586dlvr9+vWzbMfGxjJy5EhMJhM9evTg/PnzpVa+PXLkCJ07d8ZoNDJt2jRLWyEhIbzwwgtMnz6dc+fOYWdnh9ls5pVXXsHHx4cOHTpw9OhRy0iia7k8Jil/qampeHl58eSTT+Lt7c3AgQOJjY0lJCSEJk2asGnTJjZt2kSbNm3w8/OjTZs27N27F4C4uDi6desGwOnTp+nUqRN+fn4MGzbMMgIN4Msvv6RVq1aYTCaGDRtGYWEhANWrV2fcuHH4+voSHBx8Q/eH3FmUDJLbYmDwQGb+bSbutd0xYMC9tjsz/zaTgcEDrR2aiIhUMF9//TWhoaEsWLAAKPtkkIiINRgMhlL7Tz31FAsXLmT79u0MGTKE3Nxcy/Fq1apZtouKioiPjyc5OZnk5GSOHj2Kq6trifZGjRrFyJEj2b59O59++qmlrbFjx/LZZ5+Rk5NDcHAwe/bsITo6mvT0dBITE0lOTuaee+4hNzcXOzs7ioqKLG1eHs8fY5Lb48CBAzz77LNs27aNPXv28NVXX7Fu3TqioqL417/+hZeXF2vXriUpKYkJEybwyiuvlGrjzTffJDQ0lKSkJHr06EFaWvEUHrt37yYmJob169eTnJyMra0t0dHRAFy4cIHg4GC2bt1KWFgYs2bNuq3XLeVPySC5bQYGDyT1rVSKZhWR+laqEkEiIlJKVlYW69evZ/bs2ZZk0NixY/nll18wmUy89dZbvP7668TExGAymYiJibnqX0ULCwsZPXo0RqMRHx+fUgsI5OTk0KVLFz3gishtkZaWRnx8PPC/pDeAm5sbWVlZLFy48KrndurUiQ8//NCyn5ycXKpORkYGDRo0AGD+/PmW8pSUFIxGIy+99BIBAQHs2bOHjIwM6tati729PWvWrOHQoeLpHO655x5OnjzJ6dOnycvL44cffrj1C5db4unpidFoxMbGhhYtWhAREYHBYMBoNJKamkpGRgZ9+/bF29ub559/vsToskvWrl3LoEGDAHjooYeoVasWAKtXryYxMZHAwEBMJhOrV6/mt99+A8DBwcEysqhly5akpqbenguW20ZzBomIiEiFsWTJErp06ULTpk2pXbs2W7ZsYcqUKURFRVl+KbnnnntISEiw/GJ0/vx51q5di52dHbGxsbzyyit89913zJw5k4MHD5KUlISdnR1nzpyx9JOVlUX//v157LHHeOyxx6xyrSJStTRr1oz58+czbNgwmjRpwogRIzh79ixGoxEPDw8CAwOveu706dN5+umn8fHxoaCggLCwMGbMmFGizvjx4+nbty8NGjQgODiYgwcPAvDee++xZs0abG1tad68OV27diUzM5Pu3bsTEBCAyWTCy8sLAHt7e15//XWCgoLw9PS0lIv1ODo6WrZtbGws+zY2NhQUFPDaa6/xwAMPsHjxYlJTUwkPD79iO38cmQZgNpsZPHgwkydPLnXM3t7eco6trS0FBQVlcDX/z96dx1VVrY8f/zDJIEgiauKEWE7AAYHjgBNIQuY8lLMSPzVNwSzHzCRTG/SqmYXZVyXNgXLWJq8K4YBXBhHRHFLRBC8K6hEQkAPn98eJfUFA0UAcnvfrxcuz91577bXpBJxnr/U84kkiwSAhhBBCPDE2btzIO++8A8DgwYPZuHEjPXr0uO85Go2GUaNGce7cOQwMDMjLywP0OTbGjRunlD+2sbFRzunTpw/Tpk1j2DCZpSqEeDwMDQ1LBHDmzZvHvHnzSrSNiIgotm1ra0tYWFiJdv7+/vj7+wP6n2t9+vQp0ebeWZGgDzAUzlK6V1BQUKlVqO4dk3iMsrKgjCV6RWeEhYaGltqmc+fOrF+/ng8++IBffvmFmzdvAuDj40OfPn2YPHkyderU4caNG2RkZNC4ceNKuQ3xZJFlYkIIIYR4IqSnp7N//35Gjx6Nvb09CxcuJCwsrFiiy9IUPhVNTExk165dSo4LnU5X6pNQ0CdU/eWXXx7YtxBCCFGVXsrOhunTITm51OPTpk1j5syZdOjQQUn+fK85c+YQGRmJm5sbe/bsodHfVZxbtWrFvHnz8PX1RaVS0a1bN65evVpp9yKeLDIzSIgyaFI1pF1IQ5urxdjUGFsHW6zrWlf1sIQQ4pm1efNmRo4cyTfffKPs69KlC4aGhsWq5lhZWRXbLuupqK+vLytWrMDLy0tZJlY4O2ju3Ll8/PHHvP3224SEhFTynQkhnnf29vYkJiZW9TDEEy4v4wram2fQ5Weju6uj/uVTbO/UCdLS4OTJYr/jir6nzp49q+z/+OOPAfDy8lKWjNWqVYs9e/YobZYsWaK8HjRoUKlV4jIzM5XXAwcOZODAgRVyj+LJITODhCiFJlVD6plUtLn6tbHaXC2pZ1LRpGqqeGRCCPHs2rhxI/369YM//4QtWwAYMGAAmzZtwtjYGBcXF5YsWYK3tzenTp1SEkiX9VR09OjRNGrUCJVKhYuLS7GKZKDPo5GTk8O0adMe630KIYQQ98rLuEJe+gl0+dkAvHA0GoOl/yL/BXOoVw8OH67iEYpnjcwMEqIUaRfS0BXolw5Y7vsJk5RL5Nd+kbwfM6CGAeTnw8yZYC0zhYQQ4p8o+hT0l7WzMb5tAQsXQk4OdO1aat4KgOjo6GLbpT0VNTY2ZvHixSxevLhY26IVUdasWVNBdyKEEEI8Ou3NM6D7+4GGJhP7H7eha2ILVy+C+YuQmgo3b8LflcCE+KckGCREKQpnBAHkNnmJ6seiMDp7irw6L4LWEqysoEaNKhyhEEI8/Qqfgip//F75C0I2k29ZFyNDQ4iPB2/vqh2kEEII8RgUzggCwNqSYwvn0a5BHgY3bmNs6gz//S8YGVXdAMUzR5aJCVEKY9P/xUnzHJpzfdw04jMz+GXPTn7/7Tfo1g3KSEr6TyxdupQ7d+5UeL9CCPEkKvoU1DAiBpM5KzC4doOCzGv6P3j37wdJ8CyEEOI5YGBkXnKnuRk0agxqNfTqJQ+jRYWSYJAQpbB1sMXA8H/BngLLGrx7/Sq+3V+jS6dO4OFx3/O1Wu19j5dFgkFCiOdJsaegZtXQ+rZH+/orFLS0h8aNwdgY7t6tsvEJIYQQj4txzeZgcM/MHwMj/X4hKoEsExOiFIVVwwqriX30xUccv3aVIcfjeLtjR9a++SYXLlzAwsKClStXolKpCA4OJiUlhaSkJGxtbfm///s//P39OX36NC1btiQpKYmvvvoKDw8P9uzZw5w5c8jNzaVp06asWbOG1atXk5KSgre3N7a2toSHh1fxd0EIISqXgZG5EhAqaKcqtp9GPlU1LCGEEOKxM7FqAKDk0TPAEJNazsp+ISqazAwSogzWda1p2r4pzb2as2HbBuzs7Nh06BDhFha0bt2ahIQEFixYwMiRI5VzYmNj2bFjBxs2bODrr7+mZs2aJCQkMHv2bGJjYwFIS0tj3rx57N27l7i4ODw8PFi8eDFBQUHY2dkRHh4ugSAhxHNBnoIKIYQQ/2Ni1QDzRj5YNOmJQTWrSgkEbdu2DQMDA06fPl0h/YWGhjJx4kQAtm/fzqlTp5RjXl5exMTEVMh1RMWTYJAQD+ngwYOMGDECgK5du5Keno5Goy8537t3b8zNzZV2gwcPBsDJyQmVSv/U+8iRI5w6dYoOHTrg6urKd999x6VLl6rgToQQomqZWDXApJazkifBwMhcnoIKIYQQlWjjxo107NiRTZs2VXjf9waDxJNNgkFCPCRdKclMDf5OJl29evX7tivc361bN+Lj44mPj+fUqVOsWrWqcgYrhBBPuKJPQc0b+UggSAghhKgkmZmZHDp0iFWrVinBoIiICLp06cIbb7xBs2bNmDFjBuvXr6dNmzY4Oztz/vx5AHbt2kXbtm1p3bo1r7zyCqmpqcX6Pnz4MDt37mTq1Km4uroq5/3444+0adOGZs2aceDAAQDy8/OZOnUqarUalUrFN998o4zPx8cHNzc3nJ2d2bFjx+P61jyXJBgkxEPq3Lkz69evB/Q/PG1tbalRSmb/jh078sMPPwBw6tQpTpw4AUC7du04dOgQf/75JwB37tzh7NmzAFhZWZGRkfE4bkMIIYQQQgjxHNm+fTuvvvoqzZo1w8bGhri4OACOHz/OF198wYkTJ1i3bh1nz57l6NGjjB49mi+//BLQf7Y5cuQIx44dY/DgwXz++efF+vb09KR3794sXLiQ+Ph4mjZtCugL6xw9epSlS5fy0UcfAbBq1Sqsra2Jjo4mOjqab7/9losXL2JmZsa2bduIi4sjPDyc9957r8wH7OKfk2CQEA8pODiYmJgYVCoVM2bM4Lvvviu13dtvv83169dRqVR89tlnqFQqrK2tqV27NqGhoQwZMgSVSkW7du2UNbtjx46le/fueHt7P85bEkIIISrMvZUxX3vtNW7dulXu9kIIISrHxo0blTQWgwcPZuPGjQCo1Wrq1auHqakpTZs2xdfXFwBnZ2eSkpIAuHLlCn5+fjg7O7Nw4UJOnjxZrmv2798fAHd3d6WvPXv2sHbtWlxdXWnbti3p6emcO3cOnU7H+++/j0ql4pVXXiE5ObnEDCRRcaSamBDlVPjDCyh1ymJwcHCxbTMzM77//nvMzMw4f/48Pj4+NG7cGNDnGoqOji7RR2BgIIGBgRU6biGEEOJxyc/PZ+nSpQwfPhwLCwsAfv755/uec297IYQQFS89PZ39+/eTmJiIgYEB+fn5GBgY8Nprr2Fqaqq0MzQ0VLYNDQ3RarWA/nPKu+++S+/evYmIiCjx2acshX0ZGRkpfel0Or788kv8/PyKtQ0NDeX69evExsZiYmKCvb09OTk5//TWRRkkGCREJblz5w7e3t7k5eWh0+kICQmhWrVqVT0sIYQQ4pH17duXv/76i5ycHCZNmsTYsWOxtLTk3Xff5bfffqNHjx6kpKTg7e2Nra0t4eHh2NvbExMTg7m5OW+88QZXrlwhPz+f2bNnk5qaWqK9EEKIird582ZGjhyp5OdBp8OrSxcOHjxYrvM1Gg3169cHKHNlRHlTXvj5+RESEkLXrl0xMTHh7Nmz1K9fH41LYFfaAAAgAElEQVRGQ506dTAxMSE8PFyK7FQyCQYJUUmsrKyklKIQQohnyurVq7GxsSE7Oxu1Ws2AAQPIysrCycmJuXPnKm3Cw8OxtbUtdu6vv/6KnZ0dP/30E6D/YGFtbc3ixYtLbS+EEKLibNy4kRkzZug3bt+Gr74iUKXigw0blPw+9xMcHMzrr79O/fr1adeuHRcvXizRZvDgwYwZM4Zly5axefPmMvsaPXo0SUlJuLm5odPpqF27Ntu3b2fYsGH06tULDw8PXF1dadGixSPfr3gwCQYJIYQQQohyWbZsGdu2bQPgr7/+4ty5cxgZGTFgwIAHnuvs7MyUKVOYPn06PXv2pFOnTpU9XCGEeK7dPXGCnH370Gk07OzbF7P69SE5GZYsgb/+YoBazYA//ih2TkREhPLay8sLLy8vAPr06UOfPn1KXMPf3x9/f38AOnToUKy0fNG+bG1tlbQbhoaGLFiwgAULFpToLyoq6tFuVjw0SSAthBBCCCEeKCIigr179xIVFcXx48dp3bo1OTk5mJmZYWRk9MDzmzVrRmxsLM7OzsycOVOZSSSEEKLi3T1xguxdu9BpNADobt4kd/ly8idNgpwcePllOHsW/s7jI54/MjNICCGEEEI8kEajoWbNmliYm3P61CmOHDlSarvCnBH3LvtKSUnBxsaG4cOHY2lpSWho6H3bCyGEeHQ5+/ZBXp6ybXz+PMYnT5JfrRpGNWpAZibk5kJKCjRqVIUjFVVFgkFCCCGEEOKBXn31Vb4JCeHjBg0wb9SIdu3aldpu7NixdO/enXr16hVLCH3ixAmmTp2KoaEhJiYmhISE3Le9EEKIR1c4I6iQ9uWX0b78Mmi1VAsIgIsX4fTpKhqdeBJIMEgIIYQQQpRKk6oh7UIa2lwtxqbG/Dh4BNVtfwELC6YsXQoWFmRmZhY7JzAwkMDAQGW7MEeEn59fiTLCpbUXQgjxzxlYW5cICAEY1KoFTZrov7p2rYKRiSeF5AwSQgghhBAlaFI1pJ5JRZurzydhFB+HdsOP5Ni+CHfvwn/+U8UjFEIIURYzHx8wMSm+08REv18IJBgkhBBCCCFKkXYhDV2BDgDzuChsNv4fBvl53D13Ee7cgV27ID+/ikcphBCiNNWcnTHv1QsDa2tAP1PIvFcvqjk7V/HIxJNClokJIYQQQogSCmcEAehMTLk1YAQFZuYY5N2lhuOL+kCQgUEVjlAIIcT9VHN2luCPKJMEg4QQQgghRAnGpsZKQCjH2a3Yfto3raphCSGEEKICyDIxIYQQ4gmUmprK0KFDcXBwwN3dnfbt27Nt2zZiYmIICgqq6uGJ54Ctgy0GhsVn/hgYGmDrICXghRBCiKedzAwSQgghnjA6nY6+ffsyatQoNmzYAMClS5fYuXMn/fr1w8PDo4pHKJ4H1nX1eSaKVhOzdbBV9gshhBDi6SUzg4QQQognzP79+6lWrRrjxo1T9jVu3JjAwEAiIiLo2bMnAMHBwSxatEhp4+TkRFJSEllZWfTo0QMXFxecnJwICwsDIDY2li5duuDu7o6fnx9Xr14FwMvLi3feeQdPT0+cnJw4evSo0v+IESPo2rUrL7/8Mt9++61yrYULF6JWq1GpVMyZM6fSvyeialjXtaZp+6Y092pO0/ZNJRAkhBBCPCNkZpAQQgjxhDl58iRubm4PbliGX3/9FTs7O3766ScANBoNeXl5BAYGsmPHDmrXrk1YWBizZs1i9erVAGRlZXH48GEiIyMJCAggMTERgISEBI4cOUJWVhatW7emR48eJCYmcu7cOY4ePYpOp6N3795ERkbSuXPnf37zQgghhBCi0snMICGEEOIJN2HCBFxcXFCr1eVq7+zszN69e5k+fToHDhzA2tqaM2fOkJiYSLdu3XB1dWXevHlcuXJFOWfIkCEAdO7cmdu3b3Pr1i0A+vTpg7m5Oba2tnh7e3P06FH27NnDnj17aN26NW5ubpw+fZpz586VGIelpWW57zE1NZWePXvi4uJCq1ateO2118p97oMsXbqUO3fuVFh/QgghhBBPO5kZJIQQQjxhHB0d2bJli7L91VdfkZaWViJXkLGxMQUFBcp2Tk4OAM2aNSM2Npaff/6ZmTNn4uvrS79+/XB0dCQqKqrUaxrcUyK8cLu0/TqdjpkzZ/LWW289+k3e48MPP6Rbt25MmjQJ0M9Iqgj5+fksXbqU4cOHY2FhUSF9CiGEEEI87WRmkBCVzMvLi5iYmKoehhDiKdK1a1dycnIICQlR9pU2s8Xe3p64uDgA4uLiuHjxIgApKSlYWFgwfPhwpkyZQlxcHM2bN+f69etKMCgvL4+TJ08qfRXmFTp48CDW1tZYW+tzw+zYsYOcnBzS09OJiIhArVbj5+fH6tWryczMBCA5OZlr166V696uX7/OgAEDUKvVqNVqDh06BMDVq1dp0KCB0k6lUgEQERFB586d6devH61atWLcuHFKAGzjxo04Ozvj5OTE9OnTlXMtLS358MMPadu2LfPnzyclJQVvb2+8vb3Jz8/H398fJycnnJ2dWbJkCQDffvstarUaFxcXBgwYoHy/U1NT6devHy4uLri4uHD48OFy3acQQgghxJNMZgYJIYQQTxgDAwO2b9/O5MmT+fzzz6lduzbVq1fns88+K9ZuwIABrF27FldXV9RqNc2aNQPgxIkTTJ06FUNDQ0xMTAgJCaFatWps3ryZoKAgNBoNWq2Wd955B0dHRwBq1qyJp6cnt2/fVvIIAbRp04YePXpw+fJlZs+ejZ2dHXZ2dvzxxx+0b98e0Adfvv/+e+rUqfPAe5s0aRKTJ0+mY8eOXL58GT8/P/744w8mTJjAoEGDWL58Oa+88gpvvvkmdnZ2ABw9epRTp07RuHFjXn31VbZu3YqnpyfTp08nNjaWmjVr4uvry/bt2+nbty9ZWVk4OTkxd+5cAFavXk14eDi2trbExsaSnJys5EQqXA7Xv39/xowZA8AHH3zAqlWrCAwMJCgoiC5durBt2zby8/OVAJgQQgghxNNMgkFClCEpKYmePXsqHxgWLVpEZmYmERERtG3blvDwcG7dusWqVavo1KkT+fn5TJ8+nd9++w0DAwPGjBlDYGBgsT737NnDnDlzyM3NpWnTpqxZs+ahcmoIIZ4f9erVY9OmTaUe8/LyAsDc3Jw9e/aUOG5vb4+fn1+J/a6urkRGRpba54ABA/jkk09K7G/WrBkrV64ssX/SpEnKkq6HsXfvXk6dOqVs3759m4yMDPz8/Lhw4QK//vorv/zyC61bt1Z+/rZp0wYHBwdAn9vo4MGDmJiY4OXlRe3atQEYNmwYkZGR9O3bFyMjIwYMGFDq9R0cHLhw4QKBgYH06NEDX19fABITE/nggw+4desWmZmZyvdv//79rF27FgAjIyNlxpQQQgghxNNMlokJ8Qi0Wi1Hjx5l6dKlfPTRRwCsXLmSixcvcuzYMRISEhg2bFixc9LS0pg3bx579+4lLi4ODw8PFi9eXBXDF0KIKlNQUEBUVBTx8fHEx8eTnJyMlZUVADY2NgwdOpR169ahVquVwFVZeYvKYmZmhpGRUanHatasyfHjx/Hy8uKrr75i9OjRAPj7+7N8+XJOnDjBnDlzlPxLQgghhBDPIgkGCfEI+vfvD4C7uztJSUmA/mn3uHHjMDbWT7izsbEpds6RI0c4deoUHTp0wNXVle+++45Lly491nELIURpIiIiSiSnBggODmZKQAD8618QHg6FS6Q0GvjyS7h9+6Gv5evry/Lly5Xt+Ph4QD8DpzBPT0ZGBufPn6dRo0aAfpnYxYsXKSgoICwsjI4dO9K2bVt+//130tLSyM/PZ+PGjXTp0qXUa1pZWZGRkQHoA/MFBQUMGDCAjz/+WMm5lJGRQb169cjLy2P9+vXKuT4+Pkrupvz8fG4/wj0LIYQQQjxpZJmYEGUoq0oPgKmpKaBfMqDVagHQ6XQlnl4XpdPp6NatGxs3bqykEQshRCWwsYFRo+DIEVi+HFq00AeF9u6FO3fg3XfBxKTUU+/cucNL9evjkJfHqWrVePfdd1m2bBkTJkxApVKh1Wrp3LkzK1asIDY2lokTJyo/e0ePHo1arSYiIoL27dszY8YMTpw4oSSTNjQ05JNPPsHb2xudTsdrr71Gnz59Sh3H2LFj6d69O/Xq1WPp0qW8+eabys/3wqVxH3/8MW3btqVx48Y4OzsrwaMvvviCsWPHsmrVKoyMjAgJCVFyJQkhhBBCPK0kGCREGerWrUv+f/9LxhdfUG3MGHbv3s2rr75aZntfX19WrFiBl5cXxsbG3Lhxo9jsoHbt2jFhwgT+/PNPXnrpJe7cucOVK1eUhK9CCPHEsrWFnj3Bx0cfFFq0CGrUgKgo2LgRRozg1IYN7J80iZz0dADMatXi9LJlNEtOhtRU+PprMDMD/le5rKipU6cyderUUi9vYWFR6jlDhw5l6NChJfbfm+Q5MDCwWA63wtlARY0fP57x48eX2F+3bl127NhR6riEEEIIIZ5WEgwSoojTuac5nHOYjIIMat4x4ZvWLTgwaxbbNm6kRYsW9z139OjRnD17FpVKhYmJCWPGjGHixInK8dq1axMaGsqQIUPIzc0FYN68eRIMEkI8PczN9V8vvghGRpCcDAsXcuXwYX5ds4aCu3eVptbp6eQEBXGja1dsGjWC//4X7O2rbuxCCCGEEEIhwSAh/nY69zT77uxDixbDvHyarNpPrXo66g3vzWsvucGUKSXOsbW1VXIGGRsbs3jx4hJJoSMiIpTXXbt2JTo6ujJvQwghKldBAXTpAhYW+q+sLBJmziwWCOoI2AEZOh2XoqOxadAAUlIeKRjk5eWlVE8TQgghhBAVQ4JBQvztcM5htGipdjsb15DfqRP/F5l21lwtSKXmsWNw9SrUq1fVwxRCiKrl6an/KuLU2LHFto8DfwK1gLq3b0NODiQllThPCCGEEEJUDakmJsTfMgr0yULrHL9CtYwcTr/uzjXXRly3rwGtWj1S1RwhhHge1Pi76lehDOC/wEkgplEjfY4hb++qGJoQQghRbvPnz8fR0RGVSoWrqyv/+c9/Sm0XGhpaLB1EUa+99hq3bt0CwNLSEoCkpCScnJwAiImJISgoqBJGL8TDkZlBQvzNytCKjIIMrnR6mSudXi62v4t1QBWOTAghnmwd58/n14CAYkvFAAxMTOi4YAE0aFBFIxNCCCHKJyoqit27dxMXF4epqSlpaWncvef3Wnn8/PPP9z3u4eGBh4fHow5TiAojM4OE+JunmSfG98RHjTHG06zsZQ2lPT1YunQpd+7ceeRx+Pv7s3nz5kc+v6gPP/yQvXv3VkhfQghRllbDhvHq6tWY1aql7DOrVYvua9bQatiwKhyZEEIIUT5Xr17F1tYWU1NTQJ8b1M7OjujoaDw9PXFxcaFNmzZkZOhXE6SkpPDqq6/y8ssvM23aNKUfe3t70tLSyrxOREQEPXv2BCA4OJiAgAC8vLxwcHBg2bJlSru1a9fSokULunXrxpAhQ1i0aFFl3LZ4jsnMICH+1sJUXy2ssJqYlaEVnmaeyv57lfX0YNCgQQwfPhwLC4vHOfxSzZ07t6qHIIR4TrQaNkwCP0IIIZ5avr6+zJ07l2bNmvHKK68waNAg2rdvz6BBgwgLC0OtVnP79m3Mzc0BiI+P59ixY5iamtK8eXMCAwNp2LDhQ1/39OnThIeHk5GRQfPmzRk/fjzHjx8nMjKSEydOoNVqcXNzw93dvaJvWTznZGaQEEW0MG1BgHUAk2pOIsA6oMxAEJT+9GDz5s2kpKTg7e2N99/5Mfbs2UP79u1xc3Pj9ddfJzMzE9A/NZg+fTpt2rShTZs2/Pnnn0rfkZGReHp64uDgoMwSyszMxMfHBzc3N5ydndmxYwegX4PcsmVLxowZg6OjI76+vmRnZwPFZxnFxsbSpUsX3N3d8fPzIz09vYK/e0IIIYQQQjydLC0tiY2NZeXKldSuXZtBgwbxzTffUK9ePdRqNQA1atTA2Fg/n8LHxwdra2vMzMxo1aoVly5deqTr9ujRA1NTU2xtbalTpw6pqakcPHiQDh06YG5ujpWVFb169aqw+xSikASDhHhEvr6+/PXXXzRr1oy3336b33//naCgIOzs7AgPDyc8PJy0tDTmzZvH3r17iYuLw8PDo1jp+Ro1anD06FEmTpzIO++8o+y/evUqBw8eZPfu3cyYMQMAMzMztm3bRlxcHOHh4bz33nvodDoAzp07x4QJEzh58iQvvPACW7ZsKTbWvLw8AgMD2bx5M7GxsQQEBPB///d/j+G7JIR4XmzdGoNaPZf69SejVs9l69aYqh6SEEII8VCMjIzw8vLio48+Yvny5WzduhUDA4NS2xY+EC48T6vVPtI1S+un8G98ISqTLBMT4hEVPj04cOAA4eHhDBo0iE8//bRYmyNHjnDq1Ck6dOgAwN27d2nfvr1yfMiQIcq/kydPVvb37dsXQ0NDWrVqRWpqKgA6nY7333+fyMhIDA0NSU5OVo41adIEV1dXANzd3UlKSio2jjNnzpCYmEi3bt0AyM/Px8zMrAK/G0KI59nWrTFMnfoD2dl5ACQn32Tq1B8A6N/fA3Q6SE+H3FyoX78qhyqEEEKU6syZMxgaGvLyy/pCMvHx8bRs2ZJff/2V6Oho1Go1GRkZyjKxytSxY0dCQkLIyclBq9Xy008/MWbMmEq/rni+SDBIiH+g8OmBl5cXzs7OfPfdd8WO63Q6unXrxsaNG0s9v+iThqKviz4hKHwysH79eq5fv05sbCwmJibY29uTk5NTor2RkZGyTKxoH46OjkRFRSn7IiIiHvJuhRCidJ988rMSCCp0NyuHTbPX0N/wChw5An/9BWo1FJkFKYQQQjwpMjMzCQwMpGZqKqnm5jRq1oyVK1fy5ptvEhgYSHZ2Nubm5o+lOItarVaSVjdu3BgPDw+sra0r/bri+SLLxIR4RGfOnOHcuXPK9omYGJo0bIiVlZVSZaBdu3YcOnRIyQd0584dzp49q5wTFham/Ft0xlBpNBoNderUwcTEhPDw8Idal9y8eXOuX7+uBIPy8vK4ePFiuc8XQoj7SUm5WWKfb+4FPjz7A2zaBFotmJlB48ZVMDohKpaRkRGurq44Ojri4uLC4sWLKSgoACAmJoagoKCH6s/Ly4uYGP2ySktLywofrxCidKdzT7Nas5ovbn7Bas1qqjtacHjWLH5Sq4lZvZqtW7dia2uLWq3myJEjHD9+nCNHjmBpaYm/vz/Lly9X+tq9ezdeXl6APp+nra0tQLFcoYmJiYD+//ndu3cD+mpiU6ZMUfpJTEzE3t4egEGDBnHmzBm2b9/OmTNnJIG0qHAyM0iIR1T49ODWrVvY6XRM1Grx+te/WNeyJd27d6devXqEh4cTGhrKkCFDyM3NBWDevHk0a9YMgNzcXNq2bUtBQUGZs4cKDRs2jF69euHh4YGrqystWpSd3Ppe1apVY/PmzQQFBaHRaNBqtXTv3v3Rb14IIYqws6tJcnLxgNAv5i+TU68B618AMjKgoAAaNXqs44qPjyclJYXXXnvtodrt3LmTU6dOKTnbhCjK3Nyc+Ph4AK5du8bQoUPRaDR89NFHeHh44OHh8djHpNPp0Ol0GBrKc14hyuN07mn23dmHFn2en8w8DZc3fUa9yBtYW9aB48ehTZsqHeOiRYuYOXMmOTk5jBo1Cjc3tyodj3j2GFRFcioPDw9d4ROQJ01ERIQS1RWiKE2qhrQLaWhztRibGmPrYIt1XWuIj4evvoKsLPD0hIkTy9Wfvb09MTExypODx03e6+J5UdZ7PSkpiZ49eypP6h4kNDQUX19f7Ozs7tvO39+fnj17MnDgwEcZ7lPp3pxBAObmJixc+Ab9OzWGkBA4cwY++wwaNHhs4woNDSUmJqbY09t/0u5JJz/XHw9LS0vlaT/AhQsXUKvVpKWl8fvvv7No0SJ2795NVlYWgYGBSmno4OBg+vTpQ3Z2Nm+++SanTp2iZcuWJCUl8dVXX+Hh4aH0nZaWRq9evfjggw/o0qULffr04ebNm+Tl5TFv3jz69OlDUlIS3bt3x9vbm6ioKGX2wJw5c8jNzaVp06asWbPmmZttJO9zURFWa1aTUaCfyU9+Pp1nbafW6f9yy7UpquqtQaOBL7+EKgywyntdPCoDA4NYnU73wCcT8vhAiHLQpGpIPZOKNlf/9ECbq+Va/EWyloXAwoVgbQ329vDHH/pEqUKIZ05oaCgpKSlVPYxHkpSURIsWLRg1ahQqlYqBAwdy584d9u3bR+vWrXF2diYgIECZwWhvb8/06dNp06YNbdq0UZa6Xr9+nQEDBqBWq1Gr1Rw6dAjQJ4leuPAN6teviYEB1K9fk4UL3yAz8xQqHx/cN28mOD2dS3fv4uPjg0qlwsfHh8uXLwP6ANr48ePx9vbGwcGB33//nYCAAFq2bIm/v79yH5aWlrz33nu4ubnh4+PD9evXgeLLbNLS0rC3t+fu3bt8+OGHhIWF4erqSlhYGEePHsXT05PWrVvj6enJmTNnSm0XGhrKxL8D+5cuXSpzzEFBQXh6euLg4MDmzZsr/z+keCI5ODhQUFDAtWvXiu2fP38+Xbt2JTo6mvDwcKZOnUpWVhYhISFYWFiQkJDArFmziI2NLXZeamoqPXr0YO7cufTo0eO+1UTPnDnDyJEjOXbsGNWrV79vBVMhxP8ogSAAAwNuNKvLJe/mFGRnwdWrkJkJ//1v1Q1QiMdAgkFClEPahTR0BcWDPCaXLnA3Oh5q19ZXybl6FW7cgL8/nDxI0fXEQoiqkZ+fz5gxY3B0dMTX15fs7Gzi4+Np164dKpWKfv36cfPmTTZv3kxMTAzDhg3D1dWV7OxsYmNj6dKlC+7u7vj5+XH16tWqvp37OnPmDGPHjiUhIYEaNWqwePFi/P39CQsLU2YuhISEKO1r1KjB0aNHmThxIu/8nfR50qRJTJ48mejoaLZs2cLo0aOV9v37exAd/SHJyUuIjv6Q5s3NmT9/Pvv37yc2IYGgDRuYOGkSI0eOJCEhgWHDhhXLrXLz5k3279/PkiVL6NWrF5MnT+bkyZOcOHFCWZKTlZWFm5sbcXFxdOnShY8++qjM+61WrRpz585l0KBBxMfHM2jQIFq0aEFkZCTHjh1j7ty5vP/++6W2K2rixIlljvnq1ascPHiQ3bt3y5Ky51xpM+337NnDp59+iqurK15eXuTk5HD58mUiIyMZPnw4ACqVCpVKpZyTl5eHj48Pn3/+uVIBtLCaqEql4pVXXilWTbRx48a0a9cOKF7B1NXVle++++6h8gsK8TyxMrT634ahIYkBHYmb9Apxn4+CJUvg/fdB/k4XzzgJBglRDoUzgorKbebItf/3rv4XxqJF+uVhffuCkVEVjFAI8SjOnTvHhAkTOHnyJC+88AJbtmxh5MiRfPbZZyQkJODs7MxHH33EwIED8fDwYP369cTHx2NsbExgYCCbN28mNjaWgIAAZs2aVdW3c18NGzakQ4cOAAwfPpx9+/bRpEkTJYfZqFGjiIyMVNoPGTJE+bcw+fzevXuZOHEirq6u9O7dm9u3bysJ8++1f/9+Bg4cqAS9bWxsiIqKYujQoQCMGDGCgwcPKu179eqFgYEBzs7O1K1bF2dnZwwNDXF0dCQpKQkAQ0NDJVgzfPjwYueXh0aj4fXXX8fJyUkJNj3I/cbct29fDA0NadWqlfLhXDx/Lly4gJGREXXq1Cm2X6fTsWXLFuLj44mPj+fy5cu0bNkSKF5BtChjY2Pc3d357bfflH1Fq4nGx8dTt25dpZpo9erVi12vW7duyvVOnTrFqlWrKvp2hXgmeJp5YnxP+lxjjPE07wAvvADNm0O1alU0OiEeDwkGCVEOxqal51o3NjUGAwOoVQvc3WHQIP1rIcRToUmTJri6ugLg7u7O+fPnuXXrFl26dAFKBkgKnTlzhsTERLp164arqyvz5s3jypUrj3XsD6usD5/laV/4uqCggKioKOXDZnJyMlZWVqWer9PpHnjNosdNTU0BfcCn8HXhtlZbMiBf9HxjY2OlmlPhh+TSzJ49G29vbxITE9m1a9d92z7MmKH0mSHi2Xf9+nXGjRvHxIkTS7zf/fz8+PLLL5X3xrFjxwDo3Lkz69evB/SVgxISEpRzDAwMWL16NadPn+bTTz8Fyl9N9EEVTIUQ/9PCtAU+Fj7KDCErQyt8LHxoYVr+Ai1CPO0kGCREOdg62GJgWPyPPANDA2wdZPqoEE+zoh/mjYyMuHXrVrnO0+l0ODo6KkGREydOsGfPnsoaZoWwuHyZxK+/BmDjxo288sorJCUlKR8c161bpwTBAMLCwpR/27dvD4Cvr2+xJMuFy7dK4+Pjww8//EB6ejoAN27cwNPTk02bNgH62Q4dO3Z8qHsoKChQcvNs2LBBOd/e3l7Ju1I0d4+VlVWxmUsajYb69esD+hxQZbUr6p+OWTx7srOzcXV1xalVKz5Wq3mzaVPmzJmjHC8MCs2ePZu8vDxUKhVOTk7Mnj0bgPHjx5OZmYlKpeLzzz+nzT0Vi4yMjNi0aRPh4eF8/fXXDBs2jJiYGGV2YlnVRGvXrq1UMFWpVLRr147Tp09X0ndBiKdfC9MWBFgHMKnmJAKsAyQQJJ47UlpeiHKwrmsNUHo1MSHEU8s8P19fDfDv/B3W1tbUrFmTAwcO0KlTp2IBkqIBg+bNm3P9+nWioqJo3749eXl5nD17FkdHxyq7l/sxvH6d4Bde4Oby5bT9+msaNG/OF198Qbt27Xj99dfRarWo1WrGjRunnJObm0vbtm0pKChg48aNACxbtowJEyagUqnQarV07tyZFStWlHpNR0dHZs2aRZcuXTAyMqJ169YsW7aMgIAAFi5cSO3atVmzZs1D3Uf16tU5efIk7u7uWFtbKwGrKVOm8MYbb7Bu3Tq6drQ7KiwAACAASURBVO2qtPf29lZytsycOZNp06YxatQoFi9efN92Rf3TMYun390TJ8jZtw+dRoOBtTXZ8fFUa94cQkPh3/8GOzul4lB6ejo2NjaAvgT9N998U6I/c3NzJcB4r8IqZdWqVSu2VKxwqea97q2GWJiwWgghhHgQKS1/DynhJ54X8l4Xz4syS8v/+Sc/dOzItLZtYfRoFp05Q2ZmJn379mXcuHHcuXMHBwcH1qxZQ82aNdmyZQvvv/8+5ubmREVFcebMGYKCgtBoNGi1Wt555x3GjBnzRJSWTzkZxrmIYHJuX8HCzA6Ho4058FsMg/v0gcGDwc/vvufb29sTExPzxCW5v7ektyhOfq5XvLsnTpC9axfk5f1vZ0EB1W/dwvjWLWjUCJKT4auv2PnvfzNt2jRWr16Np6dn1Q36GSfvc/G8kPe6eFTlLS0vM4OEEEI8N/66lsEfl2+SnaPF/sAe3u7kBU3t4eefmbJkCZiZAfqqPPcaMGAAAwYMULZdXV1LzSdUdPlRVUg5GcbJnydSoM3GQFtA7T0X0V68SE5BNTA3h507wcsLiiyRE0KULmffvmKBIKPz56l27BgFhobQurW+gmhuLly6RO/evendu3cVjlYIIYQoPwkGCSGEeC78dS2D4+fTydfmU+/3X6jz63Zu1LRFl5qGVaYG/vMfKJIz52l1LiKYAm02AHVO5mOmKSDbwZDOzcyhbl19xUONBu6pfFRUYfWuJ43MChKPm06jKbZd8OKLZPfogcHdu1R7/XU4fRr++EP//5QQQgjxFJFgkBBCiOfCH5dvkl+gw/RGGtWTL5Pc9TUMdHBbl4dTPUt9ZcBnQM7t/1U1S3UxIdXFpPAIDjPnlH6SEKJUBtbWxQJCusJS7i++CO3b67+EEEKIp5AEg4S4x9atMXzyyc+kpNzEzq4mM2e+Rv/+D1xyKYR4wmXn5gOQa1uHP4ePL3bMqUOTqhhSpTCr0YCc23+Vul8I8XDMfHxK5gwyMcHMx6fqBiWEEEJUACktL0QRW7fGMHXqDyQn30Sng+Tkm0yd+gNbtz6ZCc+FEOVnbmr0UPufVi97BWNobF5sn6GxOS97BVfNgIR4ilVzdsa8Vy8MrPXVQw2srTHv1Ytqzs5VPDIhRHlZWloW2w4NDWXixIkArFixgrVr1wLg5eXFPylylJKSUqXFI4R4WDIzSIgiPvnkZ7Kz84rt097JYXXwBvrbaSEnR594VQjx1GnZqKY+Z1DB/6poGhka0LJRzSocVcWzcxwEoFQTM6vRgJe9gpX9QoiHU83ZWYI/Qjyjxo0bVyH9aLVa7Ozs2Lx5c4X0J8TjIMEgIYpISbmpvHa9+1/GZsWRiyE6jSEsSQYnJwkGCfGUaljHCtDnDsrOzcfc1IiWjWoq+58ldo6DJPgjhBBCPEBwcDCWlpZMmTIFgO+//56goCBu377N6tWradOmDUePHuWdd94hOzsbc3Nz1qxZQ/PmzQkNDeWnn34iJyeHrKwsVq9eTc+ePUlMTKziuxKifCQYJEQRdnY1SU7WB4QuGFuTamiBTUEON61rg4UFqNVVPEIhxD/RsI7VMxn8EUIIIUTpsrOzcXV1VbZv3LhB7969S22blZXF4cOHiYyMJCAggMTERFq0aEFkZCTGxsbs3buX999/ny1btgAQFRVFQkICNjY2T2wlTiHKIjmDhChi5szXMDfXV965bWjOghqdOF69IX7NLECng+bNH6nfqVOn4ujoyNSpU//xGG/dusXXX3/9j/sRQgghhBDiWWdubk58fLzyNXfu3DLbDhkyBIDOnTtz+/Ztbt26hUaj4fXXX8fJyYnJkydz8uRJpX23bt2wsbGp9HsQojLIzCAhiiisGlZYTaxOfVvcpn1MY+0FOHoUGjZ8pH6/+eYbrl+/jqmpabH9Wq0WY+OH+9+wMBj09ttvP9JYhBBCCCGeVhk3snnTfhlplzXYNrJm5HxvvIdJTidRMQwMDEpsz549G29vb7Zt20ZSUhJeRVJGVK9e/TGPUIiKIzODhLhH//4eREd/SHLyEqKjPyQz+wyqBQvo8O9/M+LNN7l06RI+Pj6oVCp8fHy4fPkyAP7+/gQFBeHp6YmDg4OSQK53795kZWXRtm1bwsLC8Pf3591338Xb25vp06dz48YN+vbti0qlol27diQkJAD6NcwBAQF4eXnh4ODAsmXLAJgxYwbnz5/H1dW1QmYaCSGEEEI8caKj4eJFyM9XdoWvP8G1SxquX9Kg08H1SxqWj/2J8PUnqnCgT5bg4GAWLVpUqde4d5b6s1RFKywsDICDBw9ibW2NtbU1Go2G+vXrA/pKZEI8K2RmkBD3cfLkSebPn8+hQ4ewtbXlxo0bjBo1ipEjRzJq1ChWr15NUFAQ27dvB+Dq1ascPHiQ06dP07t3bwYOHMjOnTuxtLQkPj4egF9++YWzZ8+yd+9ejIyMCAwMpHXr1mzfvp39+/czcuRIpe3p06cJDw8nIyOD5s2bM378eD799FMSExOVNkIIIYQQz5wNGyAtDWrUgDZt4KWXWDfzKJ6TXizWLPdOHmtnhcvsoMfo3lnqT0UVLa0WtmwBb+/7NqtZsyaenp5KAmmAadOmMWrUKBYvXkzXrl3LdbmUlBRGjx7Nzz///I+HLkRlkWCQEPexf/9+Bg4ciK2tLQA2NjZERUWxdetWAEaMGMG0adOU9n379sXQ0JBWrVqRmppaZr+vv/46RkZGgP7JQ2ESuq5du5Keno5GowGgR48emJqaYmpqSp06de7bpxBCCCHEM6NhQ/2soOrVYeVKMDHB4K/WwIslmqZd1jz+8T1B5s+fz9q1a2nYsCG1a9fG1dUVNzc34uLiADh37hyDBw8mNjYWe3t7Ro0axa5du8jLy+PHH3+kRYsWZVbMOnnyJG+++SZ3796loKCALVu2MHv2bGWWerdu3ZgwYYJSRSs/P58ZM2YQERFBbm4uEyZM4K233uLq1asMGjSI27dvo9VqCQkJoVOnTpX2PdGkaki7kIY2V8vxX2K5s/hLLA5FgLk5/v7++Pv7A/qZVIUiIiJK7at9+/acPXtW2f74448BivUDYG9vr1QSs7Ozk0CQeOLJMjEh7kOn05VYO3yvoseL5gTS6XRlnlN0fXFp7Qr7LNqfkZERWq32wYMWQgghxDPN3t6etLS0hz4vIiKCw4cPV9g4kpKScHJyemCbDRs2KNsxMTEEBQU9uPMmTUCjgeRk6NEDNm+moHGTUpvaNrJ+qHE/S2JjY9m0aRPHjh1j69atREdHY2RkhLW1tTKLfM2aNcWCFra2tsTFxTF+/HhlSVlhxaxjx44xd+5c3n//fQBWrFjBpEmTiI+PJyYmhgYNGvDpp5/StGlT4uPjWbhwYbHxrFq1Cmtra6Kjo4mOjubbb7/l4sWLbNiwAT8/P+Lj4zl+/Hix6l4VTZOqIfVMKtpcLeTnY7HjB/L2/U5O/UYQEQEFBZV2bSGeJhIMEuI+fHx8+OGHH0hPTwf0pSg9PT3ZtGkTAOvXr6djx47/6BqdO3dm/fr1gP6PNFtbW2rUqFFmeysrKzIyMv7RNYUQQgjx/LlfMKiyHjjdGwzy8PBQ8iDeV4MGkJcHAwbAtGlga8vI+d4YGBZ/SGdqYcLI+fdf+vMsO3DgAP369cPCwoIaNWooJdNHjx7NmjVryM/PJywsjKFDhyrn9O/fHwB3d3elHHpZFbPat2/PggUL+Oyzz7h06RLm5ub3Hc+ePXtYu3Ytrq6utG3blvT0dM6dO4darWbNmjUEBwdz4sQJrKysKuG7oZd2IQ1dgQ6Du7m8OH8qlof2UVDNlJz0DLh+HS5dqrRrC/E0kWCQEPfh6OjIrFmz6NKlCy4uLrz77rssW7aMNWvWoFKpWLduHV988cU/ukZwcDAxMTGoVCpmzJjBd999d9/2tWrVokOHDjg5OUkCaSGEEOIZ9/3339OmTRtcXV156623yC+SUPl+x3/99Vfc3NxwcXHBx8eHpKQkVqxYwZIlS3B1deXAgQMPVdRixIgRdO3alZdffplvv/22xDiTkpLo1KkTbm5uuLm5KUGnGTNmcODAAVxdXVmyZAkRERH07NlT6be0YhkAn+zahfd//kO35csZMmIEixYtwnuYM3UaW1O7sTUGBlC7sTUTV/Z47vMFlTaLfcCAAfzyyy/s3r0bd3d3atWqpRwrnHledNZ5YcWsxMREdu3aRU5ODgBDhw5l586dmJub4+fnx/79++87Fp1Ox5dffqmUcb948SK+vr507tyZyMhI6tevz4gRI1i7dm1F3X4J2tzCwKYBuU1bcKvfCLKdWpNXwwZq1wZJuyAEIDmDhChh/ZH1zNo2i8s3LtPIphHz+81X1v8WKu0X4b3VBTIzM0t9fW87GxsbduzYUaK/omuYgWJjKPqETQghhBDPpj/++IOwsDAOHTqEiYkJb7/9tjKb+H7Hu3fvzpgxY4iMjKRJkybcuHEDGxsbxo0bh6WlJVOmTAH0S3rKW9QiISGBI0eOkJWVRevWrenRo0exsdapU4d///vfmJmZce7cOYYMGUJMTAyffvopixYtYvfu3UDJvCylFcs4fvw4YTt3EpWYiFarxc3NDXd3dwCsbMxZk1SOZWbPic6dO+Pv78+MGTPQarXs2rWLt956CzMzM/z8/Bg/fjyrVq16YD9lVcy6cOECDg4OBAUFceHCBRISEnBxcSlzlrqfnx8hISF07doVExMTzp49S/369UlLS6N+/fqMGTOGrKws4uLiGDlyZIV8D+5lbGqMNleLrlo1bg4bW2x/7fZNK+WaQjyNJBgkRBHrj6xn7Lqx3Ll7B4BLNy4xdp3+l8iwdsOqcmhCCCGEeM7s27eP2NhY1Go1ANnZ2dSpU+eBx48cOULnzp1p0kSfY8fGxqbMa5S3qEWfPn0wNzfH3Nwcb29vjh49WizvS15eHhMnTiQ+Ph4jI6NiCXfvp7RiGQcPHlSuB9CrV69y9fU8cnNzY9CgQbi6utK4ceNiSZmHDRvG1q1b8fX1fWA/ZVXMCgsL4/vvv8fExIQXX3yRDz/8EBsbG2WWevfu3ZkwYYLSfvTo0SQlJeHm5oZOp6N27drsevdd4uPj6REWhomJCZaWlpU6M8jWwZbUM6noCv6Xl9PA0ABbB9tKu6YQTyMJBglRxKxts5RAUKE7uXf4fMMMhtX00JeldHSsotEJIYQQ4nmi0+kYNWoUn3zySbH9hTM3yjq+c+fOBxbAKFTeohb39nfv9pIlS6hbty7Hjx+noKAAMzOzcl2/tGIZ9yvCIUqaNWsWs2bNKrH/4MGDBAQEKME+QMkRBPr8TYUztcqqmDVz5kxmzpxZou97Z6kXzmA3NDRkwYIFLFiwQH9Ap4P33qPPtWv0+de/wNcXDAz461oGe2Iuk52bj7mpES0b1aRhnYrJI2RdV59QvLCamLGpMbYOtsp+IYSe5AwSoojLNy4rr/0uw+Z/wzcHYdKvV2DuXPjxxyocnRBCCCGeJz4+PmzevJlr164B+kIWl4okvy3rePv27fn999+5ePGish8eXITifkUtduzYQU5ODunp6URERCizkQppNBrq1auHoaEh69atU3IXPUrhi44dOyp5azIzM/npp58e6nwB/fr1Y+3atUyaNKlqB3Lzpv6rUSP4/nv47jv+Sr7B8fPpZOfq3yPZufkcP5/OX9cqrkCKdV1rmrZvSnOv5jRt31QCQUKUQoJBQhTRyKaR8jrRBi5Xh2oFcNu2BpiaQps2VTg6IYQQQjxPWrVqxbx58/D19UWlUtGtWzeuXr36wOO1a9dm5cqV9O/fHxcXFwYNGgTol1tt27ZNSSB9r/sVtWjTpg09evSgXbt2zJ49Gzs7u2Lnvv3223z33Xe0a9eOs2fPKjOOVCoVxsbGuLi4sGTJknLdt1qtpnfv3ri4uNC/f388PDywtpYP8w9j27ZtJCQkYGtbxUujLl+G/HzIzARDQ9i+HV1QIKZ/JRVrll+g44/LN6tmjEI8pwyqYhqmh4eHLiYm5rFftzwiIiLw8vKq6mGIKnJvziBzLbx32hh/m/Y0rdNUPzuoYcOH6jM0NBRfX98SfzQ9yIoVK7CwsGDkyJGP3Mf9yHtdPC/kvS6eF/JeF5UlODi4WOLpxyEzMxNLS0vu3LlD586dWblyJW5ubvI+f9r88gts2wbNm4NKBU2a8OuJa2hrvEC+Wcky9X06NKmCQT6Z5L0uHpWBgUGsTqfzeFA7yRkkRBGFSaILq4nVqdOIVv5zaBpzA65ehb+rLJRXfn4+oaGhODk5lRrIyc/PL7aOu6hx48Ypr+/XhxBCPMuSkpLo2bNniaqODys0NJSYmBiWL19eQSMTQlSmsWPHcurUKXJychg1ahRubm5VPSTxKHx99V9F/t41vFWN/L+XiBVlblr638RCiMohwSAh7jGs3bBilcOSkpJwHuuHt0pFhKsrzZo1Y+3atURFRTFlyhS0Wi1qtZqQkBBMTU2xt7cnICCAPXv2MG7cOGJiYhg2bBjm5uZERUXRsmVL5fjEiRPJyMhg5cqV3L17l5deeol169ZhYWGhPIWzt7cv0UdhdQ0hhBBCiMoWHBz82K95b4Ji8ZQq5aFny0Y1OX4+nfwi1b6MDA1o2ajm4xyZEM89yRkkRDkknj3LoHfeISEhgRo1arB48WL8/f0JCwvjxIkTaLVaQkJClPZmZmYcPHiQ4cOH4+Hhwfr164mPj1eCOIXHBw8eTP/+/YmOjub48eO0bNmSVatWFbv2wIEDS+1DCCGeF/n5+YwZMwZHR0d8fX3Jzs7m/PnzvPrqq7i7u9OpUydOnz4NwPXr1xkwYABqtRq1Ws2hQ4eqePRCCCGKaljHCpemtZSZQOamRrg0rVVh1cSEEOUjwSAhyqFhw4Z06NABgOHDh7Nv3z6aNGlCs2bNABg1ahSRkZFK+8JEjWUpejwxMZFOnTrh7OzM+vXrOXnyZCXcgRBCPL3OnTvHhAkTOHnyJC+88AJbtmxh7NixfPnll8TGxrJo0SLefvttACZNmsTkyZOJjo5my5YtjB49uopHL4QQ4l4N61jh69GIPh2a4OvRSAJBQlQBWSYmRDkYGBg8VPvCChrlOe7v78/27dtxcXEhNDSUiIiIRxmiEOL/s3fvYVWV+f//n5u9EVAQNdI8g5OpHDag4glEELVSdPKUmZqMNU022umrpXU5mebkpL/yY3ayqTBzFA9plmWlwih5QC1EJcxM1NRURE4Cyt6s3x/kHlGsNA4Cr8d1ebX3ve51r/e9XeHmve6D1Fg+Pj4EBQUB0KlTJ9LT09m6dSvDhw931Llw4QIAGzZsIDU11VGek5Nz3dtai1R3JpOJ0aNHs3jxYgBsNhtNmzala9eufPrppxV67YSEBObOnVvmdfr3789//vMfGjRoUKExSMUwm80EBARgs9nw8fFh8eLFNGjQgOLiYp544gk2bdqEyWTC1dWV5cuX4+Pjg7e3Nx4eHjg5OdGkSRM++OADbrvtNke52WzGbrfz4osv8uc//7mquyhSq2hkkMjvcPToUbZt2wbA0qVL6dOnD+np6fzwww8ALF68mF69epV5roeHx6/+IpKbm0vTpk0pKipiyZIlN9SGiEhN5lKnjuO12WwmMzOTBg0akJyc7Pjz3XffAVBcXMy2bdsc5cePH8fDQ0+cpXapV68e+/bto6CgAICvvvqK5te5CUZF+Oyzz5QIqsbc3NxITk5m3759NGrUiNdffx2AuLg4Tpw4QUpKCnv37mX16tWl/p7j4+PZs2cPnTt35p///Gep8uTkZFauXMljjz1W6f0Rqe2UDBL5HTp06MCiRYuwWq1kZmby5JNP8v777zN8+HACAgJwcnIqtfvX5WJiYnjkkUcICgpyfCm73MyZM+natSt9+/alffv2N9SGiEiNVVzMvZmZsGuXo6h+/fr4+PiwYsUKAAzDYM+ePQD069ev1I5hycnJlRuvyE3i7rvvZt26dUDJg6yRI0c6jiUlJdGjRw+Cg4Pp0aMHBw4cAErW55o0aRIBAQFYrVZee+01AHbu3EmPHj0IDAykS5cu5Obmkp6eTs+ePenYsSMdO3Zk69atjvZzcnIYPHgwvr6+PPLIIxQXFwPg7e1NRkZGZX0EUoG6d+/O8ePHATh58iRNmzbFyankV8sWLVrQsOHVi0GHh4c7HqReLicnp8z6IlKxNE1M5HdwcnLirbfeKlUWFRXFt99+e1Xd9PT0Uu+HDh3K0KFDr3l8/PjxjB8//qp2Lt+548o2RERqC5ft2+mcnw9LloDV6ihfsmQJ48eP58UXX6SoqIj77ruPwMBA5s+fz9///nesVis2m43w8PCrfn6L1Ab33XcfM2bMIDo6mpSUFMaNG8eWLVsAaN++PZs3b8ZisbBhwwaeffZZVq1axcKFCzl8+DDffvstFouFzMxMLl68yIgRI4iLiyMkJIScnBzc3Nxo3LgxX331Fa6urhw8eJCRI0ey65ekbVJSEqmpqbRu3Zq77rqLjz76iGHDhlXlxyHlyG63s3HjRh588EEA7r33XsLCwtiyZQtRUVGMHj2a4ODgq8779NNPCQgIcLyPjIzEMAx+/PFHli9fXmnxi0gJJYOkUvz888888cQT7Ny507H9+rx58xwLMN+o2NhY+vXrR7NmzcopUhERqUoX9+6lcONGjOxsnAyDxnv20H/8eDh5EhITmTRpkqPu+vXrrzrfy8uLuLi4q8pjYmKIiYmpyNBFbipWq5X09HSWLl1K//79Sx3Lzs5m7NixHDx4EJPJRFFREVCy5tYjjzyCxVLyK0KjRo3Yu3cvTZs2JSQkBCgZmQdw/vx5JkyYQHJyMmazme+//97RfpcuXWjTpg0AI0eOJDExUcmgGqCgoICgoCDS09Pp1KkTffv2BUpGAh04cIBNmzaxadMmoqKiWLFiBVFRUUBJ0sdsNmO1WnnxxRcd7cXHx+Pl5cWhQ4eIiooiIiICd3f3KumbSG2kaWJS4QzDYPDgwURERHDo0CFSU1P55z//yalTp/5Qu3a7ndjYWE6cOFFOkZbN29ubffv2Veg1RESkJBFU8MknGNnZUFBAnS++wH7wIPbvvwebDZYvB02VFfndBg0axKRJk0pNEQOYNm0akZGR7Nu3j08++YTCwkKg5DvblZtmlFUG8Oqrr9KkSRP27NnDrl27uHjxouPYlfWvdyMOKc1sNhMUFERgYOBVU/LKkp6ejr+/P1AyVfazzz4rlzgurRl05MgRLl686FgzCMDFxYW7776bOXPm8Oyzz7JmzRrHsUtrA33wwQdlrhn1pz/9iSZNmpRa/F9EKp6SQVLh4uPjcXZ2LrWmTlBQEGFhYUyePBl/f38CAgIcT3ITEhKIjo521J0wYQKxsbFASWJmxowZhIWFsXTpUnbt2sWoUaO0lo6ISA1QuHEjFBVBcTF1du2i2NWVovbtueDpCSNHwtCh4KSvLiK/17hx4/jHP/5RamoOlIwMurSg9KXvWFCy5tZbb72FzWYDIDMzk/bt23PixAl27twJlGx8YbPZyM7OdqwTs3jxYux2u6OdpKQkDh8+THFxMXFxcYSFhVVwT2u2S0mYPXv28NJLLzF16tTffW55JoN+aRDPAweYP38+c+fOpaioiG+++cbxcLa4uJiUlBRat279u5s8ffo0hw8fvq5zROSP0zcqqXD79u2jU6dOV5V/9NFHjn/YNmzYwOTJkzl58uRvtufq6kpiYiKjR4+mc+fOLFmyhOTkZNzc3CoifBERqSRGdnbJCycnLoaGcjEiAltAAEXe3hAdDX37gotLlcYoUm2cPk0Ld3cef/zxqw49/fTTTJ06ldDQ0FJJnIceeohWrVphtVoJDAzkP//5D3Xq1CEuLo6JEycSGBhI3759KSws5NFHH2XRokV069aN77//nnr16jna6d69O1OmTMHf3x8fHx8GDx5cKV2uDS5fbNkwjDIfrF5y8eJF/vGPfxAXF0dQUBBxcXFkZmZyzz33YLVa6datGykpKUDJWpXjxo0jIiKCNm3aMH/+/Kuu3aq4GObPhyVLCA4IIDAwkGXLlnH69GkGDhyIv78/VqsVi8XChAkTfrMvkZGRBAUFERkZyezZs2nSpEk5fEIi8ntpzSCpMomJiYwcORKz2UyTJk3o1asXO3fudMxFv5YRI0ZUUoQiIlKZTJ6epRJCl5eLyLWlXUhja+FWcotz8XDyYM/2FfDssyUJ1F++N0VERBAREQGUJGsuX+Nn5syZAFgsFl555RVeeeWVUu2HhISwffv2UmVt27Z1JBIAXnrppauuc6UrN9GQ3+fSWj2FhYWcPHmSTZs2AaUfrGZkZBASEkJ4eLjjvDp16jBjxgx27drl2GVx4sSJBAcHs2bNGjZt2sQDDzzg2HUxLS2N+Ph4cnNzadeuHX8Ov4X0r1+kMOcn3C1NSRrSCzw8IDsb9uzhk08+cVzrrrvuKjP2a/2d614QqXoaGSQVzs/Pj927d19VbhhGmfUtFotjC1LAMY/9ksufPImISM3hGhUFzs6lC52dS8pFpExpF9LYmL+R3OJcAFySU7kwewbnyIWdO+Ea37ek+rg0TSwtLY3169fzwAMPYBjGNR+s/prExETGjBkDQO/evTl79izZvyThBwwYgIuLC15eXjTydOXrFRMpzDmGJd9O008Pk7d3E3nnDpb8nP70U91bItWckkFS4Xr37s2FCxf499tvO8p27txJw4YNiYuLw263c+bMGTZv3kyXLl1o3bo1qampXLhwgezsbDZu3HjNtj08PMjNza2MboiISAWrExCA28CBjpFAJk9P3AYOpM4V652IyP9sLdyKjZI1fm5ftZseM9dR6FGH9FsK4OxZyMio4gilPHXv3p2MjAzOnDlzzQerv6ascy4t8O1y2TRcW2EGRUUlD2RvTbNjmCCrucGZczuhSZOS0Ztar1OkWtM0Malwm6CZLgAAIABJREFUJpOJjxcuZNt99xH6z3+S5e7u2Fo+Ly+PwMBATCYTL7/8MrfddhsA9957L1arlbZt2xIcHHzNtmNiYnjkkUdwc3Nj27ZtWjdIRKSaqxMQoOSPyHW4NCIIwHLBxunAFridy8f80ykocoUffoBbb63CCKVcFBdDVhZpp09jt9u55ZZbCA8P5+2332bs2LFkZmayefNm5syZU2pU/ZUPTsPDw1myZAnTpk0jISEBLy+vMpdoMOw2wAzAyY6Xj9gsxGfqi1fVF5HqR8kgqRDHTufy3dFzFFyw424roPOqRQz29WXwPffAL0NTAebMmcOcOXOuOv/ll1/m5Zdfvqr8yvnFQ4cOZejQoeUev4iIiEh14OHk4UgIpd3ftaTQMLglxwm/81Hwy4M2qb4K8vOZ4uODX34+rzZtyqJFizCbzQwePJht27Zd9WD18u/LlxZnDgoKYurUqUyfPp2//OUvWK1W6taty6JFi8q8pslc9q+JrvVbVEQXRaQKKBkk5e7Y6Vz2HDqLvdjAVHSR25YvIuvYcfiTD57//S8MHgzu7lUdpoiIiEi118O1BxvzNzqmigFYTM50bhoFLu2rMDK5UfFL9vLBc/FkHM3Gq2V9kifOJSDzW3ByYsyUKdChA1Ay+r6sB6ve3t7s27cPgEaNGl21jtDHH3981TWnT59e6v3XX33A/s8mUGz731QwJ4sbbSNK1xOR6ktrBkm5++7oOezFBs452Vj/v3/QKGU3FBeT90M6nDlTspihiIiIiPxh7V3aE1U3Cg8nD6BkpFBU3SjaKxFULcUv2cuCh9dx5kg2hmHgfXQHma8v5nCOG7i6QmJipcTRzG8Efv0X4Fq/JWDCtX5L/PovoJmfdvUVqSk0MkjKXcEF+y+vDDIDOpHVLgBz0QWcLlygeZv6JYvOiYiIiEi5aO/SXsmfGuKD5+K5kF8EQDe+YyiJHLd7cWxjCj5D28GOHSVLLri6VngszfxGKPkjUoMpGSTlzs3FTMEFO0X1G3BswPBS5XRuVYWRiYiIiIjcvDKOZjteb6cD22mPG0W4ny8kfHIMnD8PFv0KJyJ/nKaJSbnr0KohZidTqTKzk4kOrRpWUUQiIiIiIjc/r1ael70zAU4U4AKtW4G/P3TtqmSQiJQLJYOk3LVs7EHgn24pGQlEyYigwD/dQsvGHlUcmYiIiIjIzeuBWZG41HUuVeZS15kHZkVWUUQiUlMprSwVomVjDyV/RERERESuQ+SoAID/7SbWypMHZkU6ykVEyouSQSIiIiIiIjeJyFEBSv6ISIXTNDERERERERERkVpEySARERERERERkVpEySARERERERERkVpEySARERERERERkVqkXBaQNplM7wHRwGnDMPzLo00RERERERERkaoyffp03N3dycnJITw8nD59+lR1SKWkp6cTHR3Nvn37rvvc8tpNLBZYAHxQTu2JiIiIiIiIiFS5GTNm/O66NpsNi6ViNm632+2YzeZyaatcpokZhrEZyCyPtkREREREREREqsKsWbNo164dffr04cCBAwDExMSwcuVKAKZMmYKvry9Wq5VJkyY5jj/11FNERkbyzDPPcP78ecaNG0dISAjBwcF8/PHHAOTn53PvvfditVoZMWIEXbt2ZdeuXQCMHz+ezp074+fnx/PPP++Ix9vbmxkzZhAWFsaKFSvYvXs3gYGBdO/enddff/2G+1kx6SoRERERERERkWpk9+7dLFu2jG+//RabzUbHjh3p1KmT43hmZiarV68mLS0Nk8lEVlaW49j333/Phg0bMJvNPPvss/Tu3Zv33nuPrKwsunTpQp8+fXjzzTdp2LAhKSkp7Nu3j6CgIMf5s2bNolGjRtjtdqKiokhJScFqtQLg6upKYmIiAFarlddee41evXoxefLkG+5rpSWDTCbTw8DDAE2aNCEhIaGyLn1d8vLybtrYRMqT7nWpLXSvV463336bJk2acM899wAQGxtL3bp1yczMZMeOHZhMJkaPHk3v3r159dVX6dKlC6GhoUybNg13d3eeeeYZ1q1bx88//8z999/PCy+8wJkzZyguLmbMmDH07t27int489O9LrWB7nOpLXSvV42VK1cSHBxMUlISAMHBwRw6dIiff/6Z/fv307BhQ2w2GwMGDKBbt250794dZ2dnfv75Z4KCgtiyZQsAq1atYunSpUyfPh2A3NxcVq5cyZo1axg6dKjj77ZNmzbs3r2bvLw81q5dy6effordbufs2bOsXLmSzMxMCgsLadWqFQkJCeTl5XHq1CkMwyAhIYH27duzcuXKG7pXKi0ZZBjGQmAhQOfOnY2IiIjKuvR1SUhI4GaNTaQ86V6XmuBSgmHx4sVAyRztpk2b0rVrVz799FPgj9/rDz30EE899RS+vr7lEXKN5enpyRNPPMG8efMAePTRR3nmmWf48MMP+eGHH8jIyCAkJITx48czcuRIdu/eTUREBBcuXKCoqIiIiAgWLVrE6NGjycvLIyAggHfeeQeA7OxsPD09q7J71YJ+rkttoPtcagvd61UjOTmZc+fOOT77tWvX0qxZMwoKCvDz8yMqKorU1FQ2btzIsmXLSEhIYNOmTcTGxtK5c2fHee7u7vznP/+hXbt2pdr/6KOPCAoKKlWvU6dO3HLLLaxdu5adO3fSsGFDYmJiaNOmDREREbi6utKnTx+8vLzIysrC1dXVcX6jRo2oV6/eDd0r2lpeRESqrXr16rFv3z4KCgoA+Oqrr2jevPl1tWGz2X71+L///W8lgn6H4OBgTp8+zYkTJ9izZw8NGzYkOTmZkSNHYjabadKkCb169WLnzp307NmTLVu2kJqaiq+vL02aNOHkyZNs27aNHj16EBAQwIYNG3jmmWfYsmWLEkEiIiJSKcLDw1m9ejUFBQXk5uayY/VqMAzH8by8PLKzs+nfvz/z5s0jOTm5zHbuvPNOXnvtNYxfzv32228BCAsLY/ny5QCkpqayd+9eAHJycqhXrx6enp6cOnWKzz//vMx2GzRogKenp2PK2JIlS264r+WSDDKZTEuBbUA7k8n0k8lkerA82hUREfktd999N+vWrQNg6dKljBw50nEsKSmJCRMmEBwcTI8ePRyLAMbGxjJ8+HAGDhxIv379KC4u5tFHH8XPz4/o6Gj69+/vWCQwIiLCsbCfu7s7zz33HIGBgXTr1o1Tp05Vcm9vbsOGDWPlypXExcVx3333Ob4AXal58+acO3eO9evXEx4eTs+ePVm+fDnu7u54eHhwxx13sHv3bgICApg6dep17eAhIiIicqM6duzIiBEjCAoM5KVevZhtseCZ+b+9snJzc4mOjsZqtdKrVy9effXVMtuZNm0aRUVFWK1W/P39mTZtGlAycvrMmTNYrVb+9a9/YbVa8fT0JDAwkODgYPz8/Bg3bhyhoaHXjPH999/n73//O927d8fNze3GO2sYRqX/6dSpk3Gzio+Pr+oQRCqF7nWpCerVq2fs2bPHGDp0qFFQUGAEBgYa8fHxxoABAwzDMIzs7Gxjw4YNhmEYxldffWUMGTLEMAzDeP/9943mzZsbZ8+eNQzDMFasWGHcfffdht1uN06ePGk0aNDAWLFihWEYhtGrVy9j586dhmEYBmCsXbvWMAzDmDx5sjFz5sxK7e/Nbt++fUZYt25Gu9tvN06cOGGsWrXK6Nevn2Gz2YzTp08brVq1Mk6ePGkYhmGMHTvWaNmypXHw4EFj+/btRosWLYwnnnjCMAzDOH78uFFQUGAYhmGsXr3a+POf/1xlfapO9HNdagPd51Jb6F6vHPs//NB4u3VrY47JZLzdurWx/8MPDePCBcN4913DGD3aMO6/3zC++qrcrmez2RzfcX744QejdevWxoULF8qtfcMwDGCX8TvyMtpNTEREqjWr1Up6ejpLly6lf//+pY5lZ2czffp0Hn/8cUwmE0VFRY5jffv2pVGjRgAkJiYyfPhwnJycuO2224iMjCzzWnXq1CE6OhqATp068dVXX1VQr6onv3btuOfwYTK9vGjatCmDBw9m27ZtBAYGYjKZePnll7ntttsA6NmzJ19++SW33347rVu3JjMzk549ewKwd+9eJk+ejJOTE87Ozrz55ptV2S0RERGpgVKXLOHLhx/Glp8PQM6RI+x88EEaL1uGl5sbtGsHWVmQkgJ9+pTLNfPz84mMjKSoqAjDMHjzzTepU6dOubR9vZQMEhGRam/QoEFMmjSJhIQEzp496yifNm0aQUFBvPbaa6Snp5daXK9evXqO18Y1pjNdydnZGZPJBIDZbP7N9YZquhP74ziYMJ3CnJ9w9WhOQEE//l9UFHh4QH4+prp1mTNnDnPmzLnq3AcffJAHHyyZVe7s7Mz58+cdx+68807uvPPOSuuHiIiI1D6Jzz3nSARd0ujCBQ5u2YLX3/8OP/0EdjscOFDyX7P5D1/Tw8PDsfxAVdMC0iIiUu2N+8tf+Mc//kFAQECp8uzsbLy8vICSdYKuJSwsjFWrVlFcXMypU6e0levvcGJ/HPs/m0BhzjHAwHVvOoVLF5LrXgCFhbBjR1WHKCIiInJNOUePXlV2APg6JwdmzYLXX4fnnoPRo8Gp5qVOal6PRESkdtm+nRYffMDjjz121aGnn36af//734SGhmK326/ZxNChQ2nRogX+/v787W9/o2vXrtrB6jccTJhOsa1kF7dbDtpo/bUNim3kpWwsSQatXVvyFE1ERETkJlS/VatfL69bt2SqWM+e8MvI8JpEySAREak2UpcsYaG3N3OdnFjo7U3K5Mnw5pslw3ePHQNKdv/69NNPAejevTuLFy/m66+/ZubMmaSnpwMQExPDggULHO06OTkxd+5cUlNTeffdd/n+++8do4wSEhLo3LkzULKd6CXDhg371dFGNV1hzk+O18UmOBLqTHpPZ9I7FsHjj8O999bIL04iIjXRrFmz8PPzw2q1EhQUxI4dO5g3bx75V0yhKcuV9fr3709WVla51RepKGGzZmGpW7dUmaVuXcJmzaqiiCqXkkEiIlItXFrkL+fIETAM6h45QuHMmWScPQsWC3zzzR9qPzo6mqCgIHr27Mm0adMcCx1L2Vzrt3C8Pne7hSxvM7nNzFz0bQ3du5f8qYFDqkVEappt27bx6aef8s0335CSksKGDRto2bLlDSeDPvvsMxo0aFBu9UUqiu+oUfRbuJD6rVuDyUT91q3pt3AhvqNGVXVolULf0kREpFq4fJG/AKAPgN1ORkICXLwImzfD71wIuiwJCQkkJyeTmppKTExMOURcs7WNmI6Txa1UmZPFjbYR06smIBERuSEnT57Ey8sLFxcXALy8vFi5ciUnTpwgMjLSscPm+PHj6dy5M35+fjz//PMAzJ8//6p63t7eZGRkcP78eQYMGEBgYCD+/v7ExcX9an2ADz74AKvVSmBgIGPGjAFgxYoV+Pv7ExgYSHh4eKV+NlLz+Y4axcPp6UwqLubh9PRakwgC7SYmIiLVxOWL/H0HpFPyj5jr+fO0HzwYcnJK1qix6J+2ytDMbwTA/3YTq9+CthHTHeUiIlI99OvXjxkzZnDHHXfQp08fRowYwWOPPcYrr7xCfHy8YyOGWbNm0ahRI+x2O1FRUaSkpJRZ75L169fTrFkz1q1bB5Rs6uDp6XnN+vv372fWrFl8/fXXeHl5kZmZCcCMGTP44osvaN68uaaTiZQjfWMWEZFqoX6rViVTxAAbkHupvHVrGDq0yuKqzZr5jVDyR0SkmnN3d2f37t1s2bKF+Ph4RowYwezZs6+qt3z5chYuXIjNZuPkyZOkpqZitVqv2W5AQACTJk3imWeeITo6mp49e/5qHJs2bWLYsGGOJFGjRo0ACA0NJSYmhnvvvZchQ4b8gZ6KyOU0TUxERKqF2r7In4iISEUxm81ERETwwgsvsGDBAlatWlXq+OHDh5k7dy4bN24kJSWFAQMGUFhY+Ktt3nHHHezevZuAgACmTp3KjBkzfrW+YRiYyth44K233uLFF1/k2LFjBAUFcfbs2evvoIhcRckgERGpFmr7In8iIiIV4cCBAxw8eNDxfs8333B78+Z4eHiQm1syDjcnJ4d69erh6enJqVOn+Pzzzx31L693uRMnTlC3bl1Gjx7NpEmT+OaXjR6uVT8qKorly5c7kj2XpokdOnSIrl27MmPGDLy8vDj2y+6hIvLHaJqYiIhUG76jRin5IyIiUo7y8vKYOHEiWVlZuDs58TcnJ0bcdx9t/Py4++67adq0KfHx8QQHB+Pn50ebNm0IDQ11nP/www+XqnfJ3r17mTx5Mk5OTjg7O/Pmm2/+an0/Pz+ee+45evXqhdlsJjg4mNjYWCZPnszBgwcxDIOoqCgCAwMr78MRqcFMxh/YeeVGde7c2di1a1elX/f3SEhIICIioqrDEKlwutelttC9LrWF7nWpDXSfl4/sU9lk/JiB7YINi4sFrzZeeDrbYd48OHoUnJ3hzTe1KUMV0r0uN8pkMu02DKPzb9XT/90iIiIiIiK1RPapbE4dOIVRXDIowJZ/gXMff4Xrji9xsZjA27skIfTTTyWvRaRG0ppBIiIiUi2sWbOG1NTUcmsvJiaGlStXllt7IiLVQcaPGY5EEIBbyk7c49dTkFMIFy+WJILOnoVDh6owShGpaBoZJCIiIjcNu92O2Wwu89iaNWuIjo7G19e3kqMSEak5bBdspd4XBHejILgbAA06NSsZEfTjj3DLLVURnohUEo0MEhERkUqRnp5O+/btGTt2LFarlWHDhpGfn4+3tzczZswgLCyMFStWcOjQIe666y46depEz549SUtLY+vWraxdu5bJkycTFBTEoUOHyqwHJSN+HnvsMXr06EGbNm0co38Mw2DChAn4+voyYMAATp8+7YhtypQp+Pr6YrVamTRpUpV8PiIilcHiUvZ4AIuLBTw8oEMHGDAAgoIqOTIRqUwaGSQiIiKV5sCBA7z77ruEhoYybtw43njjDQBcXV1JTEwESrYXfuutt2jbti07duzg0UcfZdOmTQwaNIjo6GiGDRv2q/UATp48SWJiImlpaQwaNIhhw4axevVqDhw4wN69ezl16hS+vr6MGzeOzMxMVq9eTVpaGiaTiaysrKr5cEREKoFXG69SawYBmJxMeLXxqsKoRKSyKRkkIiIilaZly5aOLYlHjx7N/PnzARgxYgRQssXx1q1bGT58uOOcCxcuXNXOb9W75557cHJywtfXl1OnTgGwefNmRo4cidlsplmzZvTu3RuA+vXr4+rqykMPPcSAAQOIjo4u516LiNw8PJt4Aly9m9gv5SJSOygZJCIiIpXGZDKV+b5evXoAFBcX06BBA5KTk3+1nd+q5+Li4nhtGJc9/b7i+gAWi4WkpCQ2btzIsmXLWLBggWOEkYhITeTZxFPJH5FaTmsGiYiISKU5evQo27Ztg1On2PHqq4SFhZU6Xr9+fXx8fFixYgVQksjZs2cPAB4eHuTm5v5mvWsJDw9n2bJl2O12Tp48SXx8PFAyyig7O5v+/fszb96830xEiYiIiFR3SgaJiIhIpenQoQPr5s9nma8vnfftY/xf/3pVnSVLlvDuu+8SGBiIn58fH3/8MQD33Xcfc+bMITg4mEOHDl2z3rUMHjyYtm3bEhAQwPjx4+nVqxcAubm5REdHY7Va6dWrF6+++mr5d1xERETkJqJpYiIiIlIh0i6ksbVwK7nFuXg4edD6Qmv8Cgt50c0NxoyBnBw4e5b09PRS5/n4+LB+/fqr2gsNDSU1NbVUWVn1YmNjS73Py8sDSqaILViwoMxYk5KSrqNnIiIiItWbRgaJiIhIuUu7kMbG/I3kFpdM6zKOHaPo33N4+MwpuHgRLBYoLoYffqjiSEVERERqHyWDREREpNxtLdyKDZvjvZPNTk7EHRSumAh33w0uLkoGiYiIiFQRTRMTERGRcndpRNAlOa1vIaf1LSVvGo4q+W9hIRQVVXJkIiIiIqKRQSIiIlLuPJw8frvc1RU8yq4nIiIiIhVHySAREREpdz1ce2C5YgCyBQs9XHtUUUQiIiIicommiYmIiEi5a+/SHqDUbmI9XHs4ykVERESk6igZJCIiIhWivUt7JX9EREREbkKaJiYiIiIiIiIiUosoGSQiIiIiIiIiUosoGSQiIiIiIiIiUosoGSQiIiIiIiIiUosoGSQiIiIiIiIiUosoGSQiIiIiIiIiUosoGSQiIiIiUgXGjRtH48aN8ff3L1X+2muv0a5dO/z8/Hj66acBOHv2LJGRkbi7uzNhwoRS9ePi4rBaraXqi4iI/Bolg0REREREqkBMTAzr168vVRYfH8/HH39MSkoK+/fvZ9KkSQC4uroyc+ZM5s6dW6r+2bNnmTx5Mhs3bmT//v2cOnWKjRs3VlofRESkelIySERERESkCoSHh9OoUaNSZW+++SZTpkzBxcUFgMaNGwNQr149wsLCcHV1LVX/xx9/5I477uDWW28FoE+fPqxataoSohcRkepMySARERERkZvE999/z5YtW+jatSu9evVi586dv1r/9ttvJy0tjfT0dGw2G2vWrOHYsWOVFK2IiFRXlqoOQERERERESthsNs6dO8f27dvZuXMn9957Lz/++CMmk6nM+g0bNuTNN99kxIgRODk50aNHD3788cdKjlpERKobjQwSEREREblJtGjRgiFDhmAymejSpQtOTk5kZGT86jkDBw5kx44dbNu2jXbt2tG2bdtKilZEpPyYzWaCgoIIDAykY8eObN26tapDqtGUDBIRERERqQqGgWtiIo2LihxF99xzD5s2bQJKpoxdvHgRLy+vX23m9OnTAJw7d4433niDhx56qOJiFhGpIG5ubiQnJ7Nnzx5eeuklpk6delUdu91eBZHVTEoGyQ3x9vb+zadU8+bNIz8/v5IiEhEREalepvXty66HHqLDwYO0aNGCd999l3HjxvHjjz/i7+/Pfffdx6JFixxTxLy9vXnqqaeIjY2lRYsWpKamAvD444/j6+tLaGgoU6ZM4Y477qjKbomI/GE5OTk0bNgQgISEBCIjI7n//vsJCAgA4JVXXsHf3x9/f3/mzZsHQHp6Oh06dOCvf/0rfn5+9OvXj4KCAgDmz5+Pr68vVquV++67D4DMzEzuuecerFYr3bp1IyUlBYDp06czbtw4IiIiaNOmDfPnz6/s7lcKrRkkFWbevHmMHj2aunXr/u5zbDYbFotuSxEREal5TuyP42DCdApzfqLBxcZM8WhJvYkTic7I4PV//Qt+2Tnsww8/LPP89PT0MsuXLl1aUSGLiFSagoICgoKCKCws5OTJk45RkgBJSUns27cPHx8fdu/ezfvvv8+OHTswDMOx4H7Dhg05ePAgS5cu5Z133uHee+9l1apVjB49mtmzZ3P48GFcXFzIysoC4Pnnnyc4OJg1a9awadMmHnjgAZKTkwFIS0sjPj6e3Nxc2rVrx/jx43F2dq6Sz6WiaGRQLXT+/HkGDBhAYGAg/v7+xMXFsXPnTnr06EFgYCBdunQhNzeX2NhYJkyY4DgvOjqahISEUm2lp6fTvn17xo4di9VqZdiwYeTn5zN//nxOnDhBZGQkkZGRALi7uzvOW7lyJTExMQDExMTw1FNPERkZyTPPPMP58+cZN24cISEhBAcH8/HHH1f4ZyIiIiJSkU7sj2P/ZxMozDmGyzk7TT87QtaxbeSd+Q6KiuCyX3pERGqjS9PE0tLSWL9+PQ888ACGYQDQpUsXfHx8AEhMTGTw4MHUq1cPd3d3hgwZwpYtWwDw8fEhKCgIgE6dOjmS6FarlVGjRvHhhx86Bh8kJiYyZswYAHr37s3Zs2fJzs4GYMCAAbi4uODl5UXjxo05depUpX0OlUVDMGqh9evX06xZM9atWwdAdnY2wcHBxMXFERISQk5ODm5ubr+7vQMHDvDuu+8SGhrKuHHjeOONN5g0aRKvvPIK8fHxvznPHUrmxG/YsAGz2cyzzz5L7969ee+998jKyqJLly706dOHevXq3XCfRURERKrSwYTpFNsKMNkNWuyyUeRmorCOQdHP23G3joMa+IuGiMiN6t69OxkZGZw5cwag1O+ClxJEZXFxcXG8NpvNjmli69atY/Pmzaxdu5aZM2eyf//+Mtu5NC33ynZsNtsf69BNSCODaqGAgAA2bNjAM888w5YtWzh69ChNmzYlJCQEgPr161/XVK2WLVsSGhoKwOjRo0lMTLzumIYPH47ZbAbgyy+/ZPbs2QQFBREREUFhYSFHjx697jZFREREbhaFOT8BYJhNHOpbhx/udOFwZB0O9LoAL78Mjz9exRGKiNwkcnNJ++477HY7t9xyy1WHw8PDWbNmDfn5+Zw/f57Vq1fTs2fPazZXXFzMsWPHiIyM5OWXXyYrK4u8vDzCw8NZsmQJULIukZeXF/Xr16+wbt1sNDKoFrrjjjvYvXs3n332GVOnTqVfv36ODOjlLBYLxcXFjveFhYVltnfluWW1dWX5lW1dmeldtWoV7dq1++3OiIiIiFQDrvVbUJhzrMxyEREpWTNoaLt23Hv2LB94ebFo0SLHgIHLdezYkZiYGLp06QLAQw89RHBw8DXXVbPb7YwePZrs7GwMw+DJJ5+kQYMGTJ8+nb/85S9YrVbq1q3LokWLKrJ7Nx0lg2qhEydO0KhRI0aPHo17vXqsf+UVMo4fZ+fOnYSEhJCbm4ubmxve3t688cYbFBcXc/z4cZKSksps7+jRo2zbto3u3buzdOlSwsLCAPDw8CA3N9cxTaxJkyZ89913tGvXjtWrV+Ph4VFme3feeSevvfYar732GiaTiW+//Zbg4OCK+TBEREREKkHbiOns/2wCxbYCR5mTxY22EdOrLigRkSp0ce9eCjduxMjOxuTpSeGiRThv2ACFhYwYNQoGDAAgIiKCiIiIUuc+9dRTPPXUU6XKvL292bdvn+P9pEmTHK+R1jpbAAAgAElEQVTLmr3SqFGjMtennT59eqn3l7dZk2iaWC20d+9eunTpQsfAQJL+3//jn25urJw1i4kTJxIYGEjfvn0pLCwkNDQUHx8fAgICmDRpEh07diyzvQ4dOrBo0SKsViuZmZmMHz8egIcffpi7777bsYD07NmziY6Opnfv3jRt2vSa8U2bNo2ioiKsViv+/v5Mmzat/D8EERERkUrUzG8Efv0X4Fq/JWDCtX5L/PovoJnfiKoOTUSk0l3cu5eCTz7B+GXBZvN//4vx8svYnZygeXO4xkAEKT8aGVQLHDudy3dHz1FwwY6bixnf4B6k7NgB77wDu3aB2Uwji4Xt27dfde6lOZRXujQELy8vDycnJ956662r6kycOJGJEyc63g8bNoxhw4ZdVS82NrbUezc3N95+++3r6KGIiIjIza+Z3wglf0REgMKNG0t2UgQoKsLy449gGNj378fs6wsnT0JWFjRoULWB1mBKBtVwx07nsufQWezFJSulFxTaSF+7gQZbPsEjOxPatQO7HZKT4d57qzhaERERERERqekujQgCwNmZwiFDoLgY0/nz1Ln//pJk0HVsaiTXT59uDffd0XOORBAAhoE5J5tDHToT1NAMqamQkwNOTnD+PFzn9u1XzssUERERERER+TUmT8/SCSEo+Z20RQu4xvIkUr6UDKrhCi7YSxc4OXGmay8AgkJ9wDDg3Dk4dQrc3KogQhGR6i02NpZdu3axYMGCqg5FREREpFpwjYqi4JNP/jdVDMDZGdeoqKoLqpbRAtI1nJvL1VvxlSo3maBRI+jQoSQTKyIiIiIiNd64ceNo3Lgx/v7+jrIRI0YQFBREUFAQ3t7eBAUFAZCUlOQoDwwMZPXq1Y5zXn31Vfz8/PD392fkyJEUFhZWel+k+qkTEIDbwIGYPD2BkpFCbgMHUicgoIojqz30238N16FVQ8xOplJlZicTHVo1rKKIRETKxwcffIDVaiUwMJAxY8Zw5MgRoqKisFqtREVFcfToUaBkJ8OVK1c6znN3dwcgISGBiIgIhg0bRvv27Rk1ahSGUTKtdsqUKfj6+mK1Wh3bkp45c4ahQ4cSEhJCSEgIX3/9dSX3WEREpPzExMSwfv36UmVxcXEkJyeTnJzM0KFDGTJkCAD+/v7s2rWL5ORk1q9fz9/+9jdsNhvHjx9n/vz57Nq1i3379mG321m2bFlVdEeqoToBAdR/4gk8n3+e+k88oURQJdM0sRquZWMPgFK7iXVo1dBRLiJSHe3fv59Zs2bx9ddf4+XlRWZmJmPHjuWBBx5g7NixvPfeezz22GOsWbPmV9v59ttv2b9/P82aNSM0NJSvv/4aX19fVq9eTVpaGiaTiaysLAAef/xxnnzyScLCwjh69Ch33nkn3333XWV0V0REpNyFh4c7dgi+kmEYLF++nE2bNgFQt25dx7HCwkJMpv89bLbZbBQUFODs7Ex+fj7NmjWr0LhFpHwoGVQLtGzsoeSPiNQomzZtYtiwYXh5eQHQqFEjtm3bxkcffQTAmDFjePrpp3+znS5dutCiRQsAgoKCSE9Pp1u3bri6uvLQQw8xYMAAoqOjAdiwYQOpqamOc3NycsjNzS3vromIiFS5LVu20KRJE9q2beso27FjB+PGjePIkSMsXrwYi8VC8+bNmTRpEq1atcLNzY1+/frRr1+/KoxcRH4vTRMTEZFqxzCMUk8ly3LpuNlspri42HHexYsXHXVcXFwcr81mMzabDYvFQlJSEkOHDmXNmjXcddddABQXF7Nt2zbH8Pnjx4/j4aFEu4iI1DxLly5l5MiRpcq6du3K/v372blzJy+99BKFhYWcO3eOjz/+mMOHD3PixAnOnz/Phx9+WEVRi8j1UDJIRESqnaioKJYvX87Zs2cByMzMpEePHo51CpYsWUJYWBgAt912G7t37wbg448/pujyXSvKkJeXR3Z2Nv3792fevHkkJycD0K9fv1I7hl0qFxERqUlsNhsfffQRI0aMKPN4hw4dqFevHvv27WPDhg34+Phw66234uzszJAhQ9i6dWslRywiN0LTxEREpNrx8/Pjueee45GQEP5ks/Fz797Mnz+fcePGMWfOHG699Vbef/99AAYMGMDLL79Mly5diIqKol69er/adm5uLn/+858pLCzEMAxeffVVAObPn8/f//53rFYrNpuN8PBw3nrrrQrvq4iISEUx5ecz+Nw5yMuDXzZY2LBhA+3bt3dMowY4fPgwLVu2xGKxcOTIEQ4cOIC3tzd2u53t27eTn5+Pm5sbGzdupHPnzlXVHRG5DkoGiYhItXBx714KN27EyM7G5OnJ/Q0aMDYsDJydYcECcHNzLHR5uUaNGrF9+3bH+5deegmAiIgIIiIiHOWXj/pJSkq6qh0vLy/i4uKuKo+JiSEmJuYP9ExERKTy3T9iBH/6/HNC8vIY6e1Nn3/9iwcffJBly5ZdNUUsMTGR2bNn4+zsjJOTE2+88QZeXl54eXkxbNgwOnbsiMViITg4mIcffriKeiQi10PJIBERueld3LuXgk8+gaIiMAycdu/G2LcPe3Aw5uJiOHgQrNaqDlNEROSmlrpkCYnPPUfO0aOMveUWulqtNOjRg0GFhTBmDACxsbFXnTdmzBjG/HL8Si+88AIvvPBCRYYtIhVAawaJiMhNr3DjxpJEEOCckoLbV1+BzYY9NRUuXIBvvqniCEVERG5uqUuW8OXDD5Nz5Ag+hoFPRgZHt28nMzkZTp3Sv6UitYxGBomIyE3PyM52vC7q0AFb06Y4XbiAKTubOv7+JQkhERERuabE557Dlp+PO9AUSAew28ndtYvQKVOgoKBK4xORyqVkkIiI3PRMnp7/SwjVqYPRuDF2wOTvD088UaWxiYiIVAc5R48CkAeU2u8rK4vQp5+uipBEpAppmpiIiDikLlnCQm9v5jo5sdDbm9QlS6o6JABco6JKFoq+nLNzSbmIiIj8pvqtWl1XuYjUbEoGiYgIUHotAQyDnCNH+PLhh2+KhFCdgADcBg7E5OkJlIwUchs4kDoBAVUcmYiISPUQNmsWlrp1S5VZ6tYlbNasKopIRKqSpomJiAjwv7UELmfLzyfx2Wfx7d8fjh6FAwdK1hQYO7bS46sTEKDkj4iIyA3yHTUKwLGbWP1WrQibNctRLiK1i5JBIiIC/G8tgUssQAjgefQoPPVUSWFBASghIyIiUi35jhql5I+IAJomJiIiv7hyzQAbsBv4r5sbaz/6iHfWrWPNl19ywNWVefPmkX/FKKLrsXbtWmbPnn3N4wkJCURHR99w+yIiIiIicm1KBomICFD2WgI/urjwTrNm3LV4MX+96y7u6t2bhiEhfzgZNGjQIKZMmfJHQxYRERERkRugZJCIiAAlQ8f7LVxI/datwWSifuvW+DzyCC07dKDOoEHw5JO43n47K5OSOHHiBJGRkURGRgIwfvx4OnfujJ+fH88//7yjTW9vb55//nk6duxIQEAAaWlpAMTGxjJhwgQAVqxYgb+/P4GBgYSHhzvOLS4uJj09naSkJHr06EFwcDA9evTgwIEDAPTv35+UlBQAgoODmTFjBgDTpk3j3//+d8V/YCIiIiIi1ZTWDBIREYcr1xLIy8vj/bAw7rjjDvr06cOI4cN5NDKSlxcsID4+Hi8vLwBmzZpFo0aNsNvtREVFkZKSgtVqBcDLy4tvvvmGN954g7lz516VqJkxYwZffPEFzZs3JysrC4CCggK2b9/OgQMH6N69O5s3b8ZisbBhwwaeffZZVq1aRXh4OFu2bMHb2xuLxcLXX38NQGJiIqNHj66Mj0tEREREpFrSyCAREbkmd3d3du/ezcKFC7n11lsZMXIksbGxV9Vbvnw5HTt2JDg4mP3795Oamuo4NmTIEAA6depEenr6VeeGhoYSExPDO++8g91uJzc3l2nTptGjRw/uvPNOsrOzGT58OP7+/jz55JPs378fgJ49e7J582YSExMZMGAAeXl55Ofnk56eTrt27Srk8xAREZHqx2w2ExQU5PhT1veR38Pd3b18AxOpQhoZJCIiv8psNhMREUFERAQBAQEsWrSo1PHDhw8zd+5cdu7cScOGDYmJiaGwsNBx3MXFxdGOzWa7qv233nqLHTt2sG7dOoKCgkhOTmbu3LnMnTsXKJn2FRkZyerVq0lPTyciIgKAkJAQdu3aRZs2bejbty8ZGRm88847dOrUqYI+CREREamO3NzcSE5OruowRG4qGhkkIiLXdODAAQ4ePOh4n5ycTOvWrfHw8CA3NxeAnJwc6tWrh6enJ6dOneLzzz+/rmscOnSIrl27MmPGDLy8vDh27Fip49nZ2TRv3hyg1KikOnXq0LJlS5YvX063bt3o2bMnc+fOpWfPnjfYWxEREaktCgsL+ctf/kJAQADBwcHEx8cDpdc1BIiOjiYhIaHUuRkZGXTv3p1169YBMGfOHEJCQrBaraXWThS5mWlkkIiIXFNeXh4TJ04kKysLi8XC7bffzsKFC1m6dCl33303TZs2JT4+nuDgYPz8/GjTpg2hoaHXdY3Jkydz8OBBDMMgKiqKwMBA/vvf/zqOP/3004wdO5ZXXnmF3r17lzq3Z8+ebNy4kbp169KzZ09++uknJYNERESklIKCAoKCggDw8fFh9erVvP766wDs3buXtLQ0+vXrx/fff/+bbZ06dYpBgwbx4osv0rdvX7788ksOHjxIUlIShmEwaNAgNm/eXGpTDJGbkZJBIiJyTZ06dWLr1q1XlU+cOJGJEyc63pe1jhBQak5+586dHU/WYmJiiImJAeCjjz666rxL09IAunfvXurL2cyZM0u9vvS+WbNmGIbxe7olIiIitUhZ08QSExMd32Xat29P69atfzMZVFRURFRUFK+//jq9evUC4Msvv+TLL78kODgYKHmQdvDgQSWD5KanZJCIiIiIiIjUKtd6gGSxWCguLna8v3wdRIvFQqdOnfjiiy8cySDDMJg6dSp/+9vfKjZgkXKmNYNERERERESk5rPbHS/Dw8NZsmQJAN9//z1Hjx6lXbt2eHt7k5ycTHFxMceOHSMpKclxjslk4r333iMtLY3Zs2cDcOedd/Lee++Rl5cHwPHjxzl9+nQldkrkxmhkkIiIiIiIiNRs69dDcjI88wyYTDz66KM88sgjBAQEYLFYiI2NxcXFhdDQUHx8fAgICMDf35+OHTuWasZsNrNs2TIGDhxI/fr1efTRR/nuu+/o3r07ULL9/Icffkjjxo2ropciv5uSQSIiIiIiIlJjnNgfx8GE6RTm/IRr/RYcfnMyLFkCTk5w/Di0aIGrq2uZax6aTCbHiKErXRr9U6dOHb744gtH+eOPP87jjz9eIX0RqSiaJiYiIiIiIiI1won9cez/bAKFOccAA0taOhfnvURunWywWKCMjTFEaiMlg0RERERERKRGOJgwnWJbAQC3ptpo9/lFTDYbean/hYIC2LQJioqqOEqRqqdpYiIiIiIiIlIjFOb85Hid1dKJggZ1MCwmLBeKaDr4L5CbC5ftFiZSWykZJCIiIiIiIjWCa/0Wv0wRgyIPJ4o8LpW3hL59qzAykZuLpomJiIiIiIhIjdA2YjpOFrdSZU4WN9pGTK+agERuUkoGiYiIiIiISI3QzG8Efv0XlIwEwoRr/Zb49V9AM78RVR2ayE1F08RERERERESkxmjmN0LJH5HfoJFBIiIiIiIiIlKrREREsGvXLgD69+9PVlZWFUdUuTQySERERERERERqHMMwMAwDJ6dfHwfz2WefVWgcdrsds9lcode4XhoZJCIiIiIiIiI1Qnp6Oh06dODRRx+lY8eOLF68mO7du9OxY0eGDx9OXl7eVed4e3uTkZEBwKxZs2jXrh19+vRh5MiRzJ07Fyg9kigjIwNvb2/H9Xr27EnHjh3p2LEjW7duBSAhIYHIyEjuv/9+AgICmDZtGv/3f//nuOZzzz3H/PnzK/Kj+FVKBomIiIiIiIhIjXHgwAEeeOAB/n/27jus6rr/4/jzcNiKhqKllmKlorIFxZGCM/coR2GuytuWZWlq5taG+muolXnfKVbcSmZmy25DIfcARUDFUSLuFRLIPHB+f5w8SW4FQXk9rstLvuMzvuc6neR9Pp/3+5dffuGzzz4jMjKS7du3ExAQwHvvvXfFdrGxsSxZsoQdO3bwzTffsG3btmuOVbVqVX755Re2b99OREQEw4cPt17bunUr06dPZ/fu3Tz99NMsWrQIgIKCApYsWUJoaOitP+xN0jYxERERERG5ouDgYGbNmkVAQADu7u7ExMTg5uZW0tMSEbmiWrVqERQUxA8//MDu3btp3rw5ALm5uTRt2vSK7datW0fPnj1xdnYGoFu3btccKy8vjxdffJG4uDiMRiP79u2zXmvcuDG1a9cGLKuPKleuzI4dOzh58iR+fn5Urlz5Vh7zligYJCIiIiIiIiJ3jXLlygGWnEHt2rVj8eLF193WYDBc9rytrS0FBQUAZGdnW8+///773HvvvezcuZOCggIcHR0vmccFzzzzDGFhYZw4cYIhQ4Zc95yKg7aJiYiIiIiUIcnJyXh4eDBw4EC8vb15/PHHyczMZPXq1fj5+eHl5cWQIUPIycm5Yh/nz5+nc+fO+Pj44OnpSURExG18AhGR6xPUpAm//forBw4cACAzM7PQyp1/atmyJcuXLycrK4v09HS+//576zV3d3diY2MB+Prrr63n09LSqFatGjY2NnzxxRfk5+dfsf+ePXvy888/s23bNjp06HCrj3dLFAwSERERESlj9u7dy9ChQ4mPj6dChQq89957DBo0iIiICBISEjCZTHzyySdXbP/zzz9TvXp1du7cSWJiIo8++ugl9xiNRnx9ffH09KRr167FUrZ5woQJREZGFnm/InIXMJmo8r//sdzPj2d698bb25ugoCCSkpKu2MTf35++ffvi6+vLY489xiOPPGK9NnLkSD755BOaNWtmTTYN8Pzzz7No0SKCgoLYt2/fJauBLmZvb09ISAh9+vQp8epi2iYmIiIiIlLGPPDAA9YcGv3792fq1KnUrl2bunXrAjBw4EA++ugjXnnllcu29/LyYuTIkYwePZouXboU+oXpAicnJ+Li4gr1N27cuCJ9jilTphRpfyJy58lNSCB79WrMaWkYKlakeps2JG7dCnPnwvbt1HBzI/qtt8DHp1C76Oho68/JycnWn8eNG2f9rJo0aZL1vIeHB/Hx8dbjadOmAVCnTp1C599++23Akm8tODi40JgFBQVs3ryZpUuX3sojFwmtDBIRERERKWMMBgPk5d10+7p16xIbG4uXlxdjx469ZlCmadOmHD16FICMjAzatGmDv78/Xl5erFixwnrfe++9h6enJ56ennzwwQfA32Win332WQYNGkT79u3JysoCYNCgQdbtGtu2baNZs2b4+PjQuHFj0tPTb/r5RORSx44d4/HHHy/paRSSm5BA1vffY05LA8CcmkrOp59ieu452LIFatcGe3vYtauEZwq7d+/m4Ycfpk2bNtSpU6ekp6OVQSIiIiIiZY1tSgrHBg6k+scfs3jxYtq2bcunn37KgQMHePjhh/niiy9o1arVFdsfO3aMSpUq0b9/f8qXL09YWNgV783Pz2f16tU8/fTTADg6OrJ8+XIqVKjAmTNnCAoKolu3bmzfvp2FCxeyZcsWzGYzTZo0oVWrVri6urJ//34WL15MaGgoH3/8McuWLaN///7WMXJzc+nbty8REREEBgby559/4uTkVGSvl4hA9erVC+XKKQ2yV68uFNg2/PknxoMHyQNs69eHlBTIzYWdO+HJJ2+4/4tXBt2qBg0a8PvvvxdZf7dKwSARERERkbvc4VPp7ElJJSsnn8zD+3nznns4vnkz/+fjwx8BAXz44YcEBQXRu3dvTCYTgYGBDBs27Ir9JSQkMGrUKGxsbLCzs7tsfqGsrCx8fX1JTk6mUaNGtGvXDrBU93njjTdYu3YtNjY2HD16lJMnT7J+/Xp69uxpzbfRq1cv1q1bR7du3ahduza+vr5ER0fTqFGjQls6wJIDqVq1agQGBgJQoUKFInrlRMqm0aNHU6tWLZ5//nnAEhRxcXFh4cKFJCYmsmvXLgYPHkxubi4FBQUsW7asRFa7XFgRZD2+5x7yGjcGwGniREhPh6NHLX9LIQoGiYiIiIjcxQ6fSmfnb2fJLzBDfj61Vn5HiqmAh7v14v8yzsH//R84O9OmTRt27NhxSfvL5dXo0KHDNSvhXMgZlJaWRpcuXfjoo48YPnw44eHhnD59mtjYWOzs7HB3dyc7Oxuz2XzFvhwcHKw/G41G6zaxC8xm8xXLQYvIjevXrx+vvPKKNRj01VdfMW/ePBYuXAjAvHnzePnllwkNDSU3N/eqFbSKk6FixUsCQhfOA+DiAh4et3lWdwblDBIREREpQhcqKDVs2BAfHx/ee+89CgoKbrif2bNnU79+fUJDQ4mOjmbjxo3FMFspC/akpJJfYMYmN4fay7+gRuJ2bID03w7B2bNwUbCnOFRMTubjCROYNWsWeXl5pKWlUbVqVezs7IiKiuLQoUOApaTzt99+S2ZmJufPn2f58uWXTUx9OR4eHhw7doxt27YBkJ6ejslkKrZnErnb+fn5cerUKY4dO8bOnTtxdXWlZs2a1utNmzblrbfe4t133+XQoUMlti3TsU0bsLMrfNLOznJerkorg0RERESK0MUVlE6dOsWTTz5JWloakydPLnSfyWTC1vbK/xT7+OOPWblyJbVr12bSpEmUL1+eZs2aFevc5e6UlWP5xt7p5DFMjuU49PQr3Gdrx+9mM/d7V4Nq1YpsrIur+pCXR154OHYrVuDVtSs+Pj4sWbKE0NBQunbtSkBAAL6+vnj89a29v78/gwYNovFfWzyeeeYZ/Pz8LtkSdjn29vZERETw0ksvkZWVhZOTE5GRkZQvX77Ink3kcoxGI15eXtbjfv36MWbMGD744AOGDh2Ks7NzkYwTExPD559/zuzZs4ukv+vxbJs2bB8/no1Vq9KvX79C15588kmaNGnCjz/+SIcOHfjPf/5D69atb9vcLrD/67W/uJqYY5s21vNyZYarLccsLgEBAeaYmJjbPu71iI6OvqT8m8jdSO91KSv0XpfbrXz58mRkZFiPf//9dwIDAzlz5gyLFi3ixx9/JDs7m/Pnz/Pdd9/RvXt3UlNTycvLY9q0aXTv3p1hw4axYMEC6tWrx5AhQ3j33XcxGo1UqVKFOXPm4OHhwbBhw0hJSQHggw8+IC8vj8DAQF566SUSEhIwmUxMmjSJ7t27l5rcDlIyVsWkWANCF3NyMNI+oOZlWtycC1V9LiRzNR45gn1MDEZPT4zly8Ps2Zd+g3+D9Jkupc0/P/MvcHd3JyYmBjc3t+vuKz8/H6PRCJSO9/qJ115jT1gYC5ycmLFtGzk5OXTp0oXExER+//13ateujcFg4JVXXsHd3Z1XXnmlROcrFgaDIdZsNgdc6z5tExMREREpRg8++CAFBQWcOnUKgE2bNrFo0SLWrFljraq0fft2oqKieO211zCbzcybN4/q1asTFRXFiBEjGDZsGCNGjCAuLo5HHnmEl19+mREjRrBt2zaWLVvGM888A8D06dNp3bo127ZtIyoqilGjRnH+/Hlrboe4uDhiYmK4//77S/Ilkdusfk1XjDaF8+kYbQzUr+lKWFgYL774YpGMc3FVH7tt27Bfvx6zrS2mEycgOxsOHCiScURKu9mzZ3Ps2DFCQkIICQkBYNWqVTRt2hR/f3969+5tDSC5u7szZcoUWrRowdKlSwkODmb06NE899xz1K1bl3Xr1gGW4FCXLl0A2Lp1K82aNcPPz49mzZqxd+/eIpl3+OZw3Ee7Y/OsDUHP38/5PVv5zWAg1GSi2rlzhe6NiIjA09MTX19fkpKSGDBgQJHMQW4fbRMTERERKWYXr8Ru164dlSpVsp6/XFWl++6776r9RUZGsnv3buvxn3/+SWZmJqtWreK7775j1qxZAGRnZ5OSkkLTpk2ZPn06R44coVevXloVVMY8UNUFwFpNzMnBSP2artbzReXiJK6G9HTya9bEkJuL4dw5uPde2LMH6tcv0jFFStqFqnkXjB07luHDh/Pee+8RFRWFm5sbZ86cYdq0aURGRlKuXDneffdd3nvvPSZMmACAo6Mj69evByyJmU0mE5988gmZmZlMnjyZyMjIQmN6eHiwdu1abG1tiYyM5I033mDZsmW39Bzhm8MZ+sVQMnMzLWMkHmX96RM0b9OG+uaKMG8e7m+/TWJiovU5x44de0tjSslSMEhERESkGP3+++8YjUaqVq0KYC2bDVyxqtK1FBQUsGnTpkIJO6OjozGbzSxbtox69eoVur9+/fqlIreD3D6ff/45s2bNwmAw4O3tTZ8+fZg2bRq5ublUrlyZ8PBwoGiDQRdX9cm96P1lqFABh6FD4a/tLyJ3k4vzxF3J5s2b2b17N82bNwcgNzeXpk2bWq/37du30P29evUiLy+PRo0aXTZnVlpaGgMHDmT//v0YDAby/lqRdyvGLR9nDQS5ZsPze2CXaz7fnthC/dfD4eGHoYSSREvx0DYxERERkeKQmsrpU6cYNmwYL7744mXLXl+pqtI/ubi4kJ6ebj1u3749c+fOtR5f+EWkQ4cOzJkzx7oS6UKZ8N9//50HH3yQ4cOH061bN+Lj44vsMaX02bVrF9OnT2fNmjXs3LmTDz/8kBYtWrB582Z27NhBv379mDFjRpGPe8WqPm3bQrly4OhY5GOK3AnMZjPt2rUjLi6OuLg4du/ezWeffWa9fvGXBAAODg6AJTn15arijR8/npCQEBITE/n++++v60uEa0n5I8X6c6o9DGwFzz4C4+r+CZ07Q716cJn/j8mdS8EgERERkVuQl36ErJTVZB78gayU1WRlZdG3bl0iHnyQp1u2pH379ldQU7AAACAASURBVEycOPGybUNDQ4mJiSEgIIDw8HBrVaV/6tq1K8uXL8fX15d169Yxe/ZsYmJi8Pb2pkGDBsybNw+w/IKQl5eHt7c3np6ejB8/HlBuh7JmzZo1PP7449bEtZUqVeLIkSN06NABLy8vZs6cya5du4p8XHsvL5y6dsVQsSJgWSnk1LWrqvpImXRxED8oKIgNGzZw4K+8WZmZmezbt++m+05LS6NGjRoAhIWF3fJcAWpWuiiZvA0kuUK+zT/Oy11F28REREREblJe+hHyziaA2VKpyWzK5Pzn07D7IQYj9vR94gno1s16/6BBgxg0aJD12M3NjU2bNl2274u3BtStW/eS1TwRERGFjqOjo3FycuLTTz+9pC/ldihbzGYz5c+fB7PZ+k3+Sy+9xKuvvkq3bt2Ijo5m0qRJxTK2vZeXgj9SpmRnZjKyVi3SbG3Z5uLCo48+yjvvvMPQoUPp2LEj1apVIyoqirCwMJ544glycnIAmDZtGnXr1r2pMV9//XUGDhzIe++9V2Rbfqf3nF4oZxCAs70z03tOL5L+pfRRMEhERETkJplS91oDQRQUYFywAmPMbgoedsfoUA22bSsUDBK5HdoFBBA3fjxpjzxCxcce448//ii0kmDRokUlPEORO1de+hFMqXsx52dhMDiQPf8DbH/ZALVrw9tvFwrAvvTSS9Z2Fyo9/tM/cwJFR0db/3Zzc7NeDw4Otpaab9q0aaGVRVOnTr3l5woNCgUsuYNS/kihZqWaTO853Xpe7j4KBomIiIjcJHN+1t8H2bnYJB/DXM4Jw6kzUN4RTp6E9HRwKdpEvSJXU//ECewbNCDqmWdY8MYbVGralEmTJtG7d29q1KhBUFAQBw8eLOlpitxxCq0Gzc/HZsVKWL+T/DqeGE+etHzmX6MaZGkWGhSq4E8ZomCQiIiIyE0yGJ3+Dgg5O5I37QUwmzGk52FrUweOHwdb/XNLip91tUJ6KvZfL8S9WSMeCgqiR14eTJ4MlSvTvXv3S9r9c+uiiFzZxatB7SbPx+bAYQqqucHh/ZBfHhIS7uhgkJQt+teJiIiIyE2yda1XKGcQADa22D7oBy73g3KnyG1w8WoF4zdrMBw6gjkvl3zHShgrVoHDh6Fy5ZKepsgd7+LVoHnDHsdwPgtD+nk4cRbbLDcogqpeIreLgkEiIiIiN8nO5X6Av/NHGJ2wda1nPS9yO1y8WsFw5hymTi0o8POAGjVw8u6pctAiRaTQatDqVTAD5r/OU7NNSU5N5IYpGCQiIiJyC+xc7lfwR0rUxasVTK88WfiiAkEiReayq0ENRmxd65XcpERukoJBIiIiIiJ3sEKrFf5xXkSKjlaDyt3EpqQnICIiIiIiN8/WtR4YjIVPltBqBYPBwFNPPWU9NplMVKlShS5duly1nbu7O15eXvj6+uLr68vw4cOLe6oiN8XO5X6carbBuXYXnGq2USBI7lhaGSQiIiIicgcrTasVypUrR2JiIllZWTg5OfHLL79Qo0aN62obFRWFm5vbDY9pMpmwVdU+EZEbopVBIiIiIiJ3uNK0WqFjx478+OOPACxevJgnnnjCei0jI4PBgwfj5eWFt7c3y5Ytu2pfwcHBjB49msaNG1O3bl3i4+MBCAsLo3fv3nTt2pX27dtjNpsZNWoUnp6eeHl5ERERYe1j5syZBAYG4u3tzcSJE4vhiUVE7jwKBomIiIiISJHp168fS5YsITs7m/j4eJo0aWK9NnXqVCpWrEhCQgLx8fG0bt3aei0kJMS6Tez999+3njeZTGzdupUPPviARYsWWc9v2rSJRYsWsWbNGr755hvi4uLYuXMnkZGRjBo1iuPHj7Nq1Sr279/P1q1biYuLIzY2lrVr196eF0JEpBTTekoRERERESky3t7eJCcns3jxYjp16lToWmRkJEuWLLEeu7q6Wn++0jaxXr16AdCoUSNOnDhhPd+uXTsqVaoEwPr163niiScwGo3ce++9tGrVim3btrF27VpWrVqFn58fYFmZtH//flq2bFl0DywicgdSMEhERERERIpUt27dGDlyJNHR0Zw9e9Z63mw2Y7jBcvcODg4AGI1G8vP/Luldrly5Qv1ejtlsZuzYsfzrX/+6oTFFRO522iYmIiIiUsRmz55N/fr1cXV15Z133rktY545c4bHH3/8towlci1DhgxhwoQJeHl5FTrfvn175s6daz1OTU0tkvFatmxJREQE+fn5nD59mrVr19K4cWM6dOjAggULyMjIAODo0aOcOnWqSMYUEbmTaWWQiIiISBH7+OOPWblyJbVr175tY7q5ufH111/ftvFErignh/u3bOHlAQMuufTmm2/ywgsv4OnpidFoZOLEidZtYCEhIRiNRsCy1ezzzz+/7iF79uzJpk2b8PHxwWAwMGPGDO677z7uu+8+9uzZQ9OmTQEoX748X375JVWrVi2CBxURuXMZrrSksjgFBASYY2Jibvu41yM6Oprg4OCSnoZIsdN7XcoKvdfldhs2bBgLFiygXr16DBkyhN9++425c+cyaNAgKlSoQExMDCdOnGDGjBk8/vjjZGRk0L17d1JTU8nLy2PatGl0796d5ORkOnbsSIsWLdi4cSM1atRgxYoVODk5ceDAAYYNG8bp06cxGo0sXbqUbdu2MW3aNBITEwkLC+O7774jMzOT3377jZ49ezJjxgwAPvvsM959912qV69OnTp1cHBwKLRSQ+RGHD6Vzp6UVLJy8nFyMNKgki33LwmDrVth5Eho0aJIx9NnupQVeq/LzTIYDLFmszngWvdpm5iIiIhIEZo3bx7Vq1cnKiqqUHJcgOPHj7N+/Xp++OEHxowZA4CjoyPLly9n+/btREVF8dprr1nzn+zfv58XXniBXbt2cc8991jLcIeGhvLCCy+wc+dONm7cSLVq1S6ZR1xcHBERESQkJBAREcHhw4c5duwYU6dOZfPmzfzyyy8kJSUV86shd7PDp9LZ+dtZsnIseXzyT5wie9I0MnYlQY0asGNHCc9QRESuRNvERERERG6THj16YGNjQ4MGDTh58iRgSXD7xhtvsHbtWmxsbDh69Kj1Wu3atfH19QUslZSSk5NJT0/n6NGj9OzZE7AEky6nTZs2VKxYEYAGDRpw6NAhzpw5Q6tWrawVmHr37s2+ffuK9Znl7rUnJZX8Akvg0iY7G/8pIzDm5pD6YB3KV7GDhAQwmcBWv3KIiJQ2+mQWERERuU0uVEWCv6sfhYeHc/r0aWJjY7Gzs8Pd3Z3s7OxL7jcajWRlZV2xatLVxjIajZhMputuK3I9LqwIAihwdCRhxETs/0yj3JFDPFBwFvLy4OxZuPfeEpyliIhcjoJBIiIiIsXtKkGYtLQ0qlatip2dHVFRURw6dOiqXVWoUIH777+fb7/9lh49epCTk1Oo3PbVNG7cmBEjRpCamoqLiwvLli27pNqTyPVycjAWCgidr/kQ54HsRoEQUFOrgkRESjHlDBIREREpJsacHFrt3Anr11/xntDQUGJiYggICCA8PBwPD49r9vvFF18we/ZsvL29adasGSdOnLiu+dSoUYM33niDJk2a0LZtWxo0aGDdSiZyo+rXdMVoYyh0zmhjoH7Nv3JlKRAkIlJq6RNaRERE5BblpR/BlLoXc34WBqMT+xPWY5dr4KkjR+C++2DbNsLCwgq1ycjIACwl4Tdt2nTZfhMTE60/jxw50vpznTp1WLNmTaF7U1JSrPcPGjSIQYMGWa/98MMP1p+ffPJJhg4dislkomfPnrRv3/6mnlnkgaouAIWqidWv6Wo9LyIipZeCQSIiInJdkpOT6dKlS6EAxfWKjo7G3t6eZs2aAZaKW87OzgwYMKCop3nb5aUfIe9sApgt22XMpkxMW1di89VGjNhDvXqQlFRqtsxMmjSJyMhIsrOzad++PT169CjpKckd7IGqLgr+iIjcgbRNTEREpIy73nwztyI6OpqNGzdaj4cNG3ZrgaCEhCKYVdEwpe61BoIAjCs3YvfBF5hPH7Ek0D16FDIyLH+XArNmzSIuLo6kpCRmz56NwWC4diMRuestX74cg8FAUlLSVe8LDg4mJiamWOcSFhbGiy++WKxjiJR1CgaJiIjcxZKTk/Hw8GDgwIF4e3vz+OOPk5mZibu7O1OmTKFFixYsXbqUuLg4goKC8Pb2pmfPnqSmpgIQGxuLj48PTZs25aOPPrL2+89/qHfp0oXo6GgAfv75Z/z9/fHx8aFNmzYkJyczb9483n//fXx9fVm3bh2TJk1i1qxZ7Nmzh8aNGxear7e3t3XsVq1a0ahRIzp06MDx48ctN+3fD97ecOBAMb96Fkk5SSxIW8CHqR+yIG0BSTmFf1Ey52cVOs5vH0Tuh6PInfwsjBoFjz8O/v6WlUEiIqXU4sWLadGiBUuWLLnlvm7HlwwicmsUDBIREbnL7d27l6FDhxIfH0+FChX4+OOPAXB0dGT9+vX069ePAQMG8O677xIfH4+XlxeTJ08GYPDgwcyePfuKOW3+6fTp0zz77LMsW7aMnTt3snTpUtzd3Rk2bBgjRowgLi6ORx55xHp//fr1yc3N5ffffwcgIiKCPn36kJeXx0svvcTXX39NbGwsQ4YMYdy4cZZGS5cW/rsYJeUksTpzNekF6QCkF6SzOnM1e/+Mh5QU2LcPg9GpcCNbIxgMGCpWhvr1oXNnGDkSHnqo2OcrInIzMjIy2LBhA5999lmhYNCMGTPw8vLCx8eHMWPGFGpTUFDAwIEDefPNNwEoX748EyZMoEmTJmzatInVq1fj5+eHl5cXQ4YMIScnh9WrV9OzZ09rH7/88gu9evUCYOHChdStW5dWrVqxYcOG2/DUImVbyW9cFxERkWL1wAMP0Lx5cwD69+/P7NmzAejbty9gKW1+7tw5WrVqBcDAgQPp3bv3JeefeuopVq5cedWxNm/eTMuWLalduzYAlSpVuub8+vTpw1dffcWYMWOIiIggIiKCvXv3kpiYSLt27QDLt8zVqlWzNLiQiDksDMaOve7X4WZszN6ICcuKnmqbf8djyVZyXJ0xnF4MBneoWRPbsc8XyhkEgMGIrWu9Yp2biEhR+fbbb3n00UepW7culSpVYvv27Zw8eZJvv/2WLVu24OzszB9//GG932QyERoaiqenpzVQf/78eTw9PZkyZQrZ2dnUqVOH1atXU7duXQYMGMAnn3zCyy+/zAsvvMDp06epUqUKCxcuZPDgwRw/fpyJEycSGxtLxYoVCQkJwc/Pr6ReDpEyQSuDRERE7nL/zAlz4bhcuXJXbWc2m6+YT8bW1paCggLrcXZ29jXbXEnfvn356quv2LdvHwaDgTp16mA2m2nYsCFxcXHExcWRkJDAqlWrIDkZDh+2NExJgUOHbmisG3VhRRBAVqVyOJ09T/kj5/ijRjlwcAA/P+xc7seuspd1hZDB6IRdZS/sXO4v1rmJiBSVxYsX069fPwD69evH4sWLiYyMZPDgwTg7OwOFg/v/+te/CgWCAIxGI4899hhgWZFau3Zt6tatC1i+ZFi7di0Gg4GnnnqKL7/8knPnzrFp0yY6duzIli1bCA4OpkqVKtjb21u/rBCR4qNgkIiIyF0uJSXFus3rQk6Ii1WsWBFXV1fWrVsHwBdffEGrVq245557qFixIuvXrwcgPDzc2sbd3Z24uDgKCgo4fPgwW7duBaBp06b8+uuvHDx4EMD6TbKLiwvp6elczkMPPYTRaGTq1KnWXwDq1avH6dOnrfPOy8tj165dsGzZ3w0NhsLHxcDF5u8qSefq3kvkR6H8d9l2Dv17Pd8uX06viRPZuHEjdi7341SzDc61u+BUs801A0FLly6lfv36hISEEB0dTZcuXYr1OUREruTs2bOsWbOGZ555Bnd3d2bOnElERAQFBQVXDO43a9aMqKgo6xcBYNl6bDQaAcsXA1cyePBgvvzySxYvXkzv3r2x/avKopLZi9xeCgaJiIjc5erXr8+iRYvw9vbmjz/+4LnnnrvknkWLFjFq1Ci8vb2Ji4tjwoQJgCWHwwsvvEDTpk1xcvo7N07z5s2pXbs2Xl5ejBw5En9/fwCqVKnC/Pnz6dWrFz4+PtbgTteuXVm+fLk1gfQ/9e3bly+//JI+ffoAYF9QwJqnnuKtESPw8fHB19fXUo0sLAwu/PKRlfX3lrFi0syxGbYX7arPreDIbGc7gse8SI/evRn27ruMvYGtamazmYKCAj777DM+/vhjoqKiinS+StoqIjfq66+/ZsCAARw6dIjk337j8OHD1K5dm0qVKrFgwQIyMzMBCm0Te/rpp+nUqRO9e/fGdJnk+B4eHiQnJ3Pgr0T/F75kAKhevTrVq1dn2rRpDBo0CIAmTZoQHR3N2bNnycvLY+ltyAknUtYpZ5CIiMhdzsbGhnnz5hU6l5ycXOjY19eXzZs3X9K2UaNG7Ny503o8adIkwPIN7sUrhS7WsWNHOnbsWOhc3bp1iY+Ptx5fnEQaYOTIkYwcOdJy0Ls3rFpFzcxMvrexAXt7sLWF11+3BIAutm8fuLpeOgmDAdq0ueUk0x4OHoAld1B6QTouNi6YDHbcO2IqHD5M2vbtuP41fkZGBt27dyc1NZW8vDymTZtG9+7dSU5OpmPHjoSEhLBp0yZ69OjB+vXrOXjwIN26daNz587W8c6fP89LL71EQkICJpOJSZMm0b17d8LCwoiJiWHu3LmApXrbyJEjCQ4Opnz58rz66qssXbqUf//735es/BIRuZrFixdbkkMfOwazZ8OQITz22GPs2bOHbt26ERAQgL29PZ06deKtt96ytnv11VdJS0vjqaeeuuT/B46OjixcuNAaLAoMDGTYsGHW66GhoZw+fZoGDRoAUK1aNSZNmkTTpk2pVq0a/v7+Cm6LFDMFg0RERKR0GTcOfv0VMjIs5dhzc698b06O5c/F7O3h3nst/RQBDwcPa1AI4NmsZ/Ft3Jjs7GyOHz/OmjVrAMsvP8uXL6dChQqcOXOGoKAgunXrBljyZyxcuNBayS0qKopZs2YREBBAdHS0te/p06fTunVrFixYwLlz52jcuDFt27a96vwuJG1t3bq1AkEicl2iwhP4fFwUZ1LSqF2zFxV3F8B30+DUKYiPZ/jw4dZ7/1lF7OLPrAuVJ8ESEL9YmzZt2LFjx2XHX79+Pc8++2yhc4MHD2bw4ME3+0gicoO0TUxEROQu5u7uTmJiYklP48b4+sKYMeDuDn/ln7huzs7Qpw/s2WPppxg4OTkRFxdHUlISP//8MwMGDMBsNmM2m3njjTfw9vambdu2HD16lJMnTwJQq1YtgoKCrtn3qlWreOedd/D19SU4OJjs7GxSUlKu2ubipK0iItcSFZ7A3KE/cvpQGmYzuB5KIPP18Rz+LQ1q14YtW+AqOX9uVaNGjYiPj6d///7FNoaIXJtWBomIiEjpk51tCepkZcH8+ZbVPxdVL7uE0QhOTvDZZ5Z2t0nTpk05c+YMp0+f5qeffuL06dPExsZiZ2eHu7u7NbnqtSq3XWA2m1m2bBn16hUuSx8bG3vZ6m1QOGmriMi1fD4uipzMvL+OChjAajLzHTm44TceqGZn+bw9cwaqVCmW8WNjY4ulXxG5MVoZJCIiIqXPmDHw9tvwwQewezfUqQM2V/hni42N5Xpi4m0NBAEkJSWRn59P5cqVSUtLo2rVqtjZ2REVFcWhmyh736FDB+bMmWOtxHNhi8WVqreJiNyoMylpFx3Z8CaDeJ+ehJ9vAgMHQocOxboySERKB60MEhERkdLn4sCPuztUrgx7917+3oICy/VatW7L1LKysvD9awua2Wxm0aJFGI1GQkND6dq1KwEBAfj6+uLh4XGNni41fvx4XnnlFby9vTGbzbi7u/PDDz8Uqt7m6elprd4mInKj3GpW5PShiwNCBrJwJLfWvRASUmLzEpHbS8EgERERKd1SUyEm5ur3bNsG587BPfcU+3SuVOHGzc2NTZs2XfbaP/M2XZyANTg4mODgYMCSj+jTTz+9pP3Vqrf9M2mriMjVDJgewtyhP160VQwcnO0YMP3WAkFDhgzhhx9+oGrVqoU+8+bMmcPcuXOxtbWlc+fOzJgxg19++YUxY8aQm5uLvb09M2fOpHXr1gA8+uijHD9+HJPJxCOPPMJHH32krbAixUDbxERERKR0+/57S4WwC8qVg/vus/x9gb295T4REbmqkFAvXpzfmSq1KmIwQJVaFXlxfmdCQr1uqd9Bgwbx888/FzoXFRXFihUriI+PZ9euXYwcORKwBM+///57EhISWLRoEU899ZS1zVdffcXOnTtJTEzk9OnTLF269JbmJSKXp5VBIiIiUrqFhVnKzBsM4OgIb70FL74Ic+dacgtlZ1uuh4XBRb9QiIjcyZJyktiYvZH0gnRcbFxo5tgMD4cb3356OSGhXrcc/Pmnli1bkpycXOjcJ598wpgxY3BwcACgatWqAPj5+VnvadiwIdnZ2eTk5ODg4ECFChUAMJlM5ObmYjAYinSeImKhlUEiIiJSeqWnw7p14OAANWvC5s0wfLglp9Dw4ZbjBx6wXF+71hIUEhG5wyXlJLE6czXpBekApBekszpzNUk5SSU8sxuzb98+1q1bR5MmTWjVqhXbtm275J5ly5bh5+dnDRiBJZl+1apVcXFx4fHHH7+dUxYpMxQMEhERkdJr5UowmaBfP0tVMW/vwte9vWHPHujb13LfTz+VzDxFRIrQxuyNmDBZDsxmKCjAkHGeuN9/tHzmbd9+R1T8MplMpKamsnnzZmbOnEmfPn2s1RIBdu3axejRoy/Jlfa///2P48ePk5OTw5o1a273tEXKBG0TExERkdKrfn1LLqAuXa58j7MzLFoEvXvftopiIiLF6cKKIADPsA3U/WYHf9asZFkVabMTXFzgww/BtnT/Onf//ffTq1cvDAYDjRs3xsbGhjNnzlClShWOHDlCz549+fzzz3nooYcuaevo6Ei3bt1YsWIF7dq1K4HZi9zdSvenh4iIiJRtXl6WP9fjagEjEZE7iIuNizUglDiwGekGA6bJ33PEzo64jJ1scHRk44YNAGzduhX7i5Psl6ScHFwuqrjYo0cP1qxZQ3BwMPv27SM3Nxc3NzfOnTtH586defvtt2nevLn1/oyMDNLT06lWrRomk4mffvqJRx55pCSeROSup2CQiIiIiIhIKdLMsRmrM1dbtorZ2HBoQFM87exouymDg7sOkdmpEx+/9dZ19WU2mzGbzdjY/J0hJD8/v8jLtT/Zty8PrVxJ+4wM7q9Rg8lTpjBkyBCGDBmCp6cn9vb2LFq0CIPBwNy5czlw4ABTp05l6tSpAKxatQqz2Uy3bt3IyckhPz+f1q1bM2zYsCKdp4hYKBgkIiIiIiJSilyoGmatJmZbkRqDx3KPcR0Zh8JJc3W13jtjxgw+//xzAP71r3/x0ksvceDAAXr06EGLFi3YsmUL3377LT4+Prz44ousWrWKDz/8EFtbW0aOHElGRgZVq1YlLCyMe++9l/fff59///vf2NnZ4eXlxZdffnnZOUaFJ/D5uCjOpKThVrMiY7s3wauHA9jYMPnNN+HhhwEu2/7NN9/kzTffvGy/l0syLSJFT8EgERERERGRUsbDwePSUvLP1GPjwYMY/yq3vnXrVsLDw9m6dSv5+fk0btyYVq1a4ezszO7du1m4cCHz5s3DZDKRlpaGv78/06ZNIycnh5CQEL777jvc3NwIDw9n/PjxzJ8/nxkzZnDo0CHs7e05d+7cZecWFZ7A3KE/kpOZB8A9h3Zx9qOtHOwcSO1qNpZk/sOHF+vrIyK3RtXERERERERE7gR2dmQ5O1sP161bx2OPPYazszMuLi706NGD9evXA/DQQw8RGBhovdfe3p6ePXsCsGfPHnbt2kXbtm3x9fXlnXfe4fDhwwA0bNiQ/v37Ex4ejp2d3WWn8fm4KGsgqCHJ9GYtBfkFHF6dADk5sGMHnD1bLC+BiBQNrQwSERERERG5A5mvUl6+XLlyhY6dnJww/LWiyGw24+3tzbp16y5p97///Y9ff/2VFStWMG3aNBITEy/JL3QmJc3682kq8h8exYQttucLaDnuOcjPh4oVb+XRRKSYaWWQiIiIiIjIHahly5YsX76crKwsMjIyWLFixXVV32rQoAFHjx5l69atAOTm5rJr1y7y8/M5cuQIrVu3ZubMmZw+fZrMzMxL2rvV/DvQcwpXTlGJP6iAuVYtS66gevVKfdl7kbJOwSAREREREZE7UOPGjXniiScIDAwkKCiI5557Di8vr2u2c3Bw4Ouvv+bVV1/Fx8cHPz8/tmzZgslk4sknn8Tb2xt/f39Gjx6Ni4vLJe0HTA/BwbnwFjIHZzsGTA8psmcTkeKlcK2IiIiIiMgdYtKkSYWOX3/9dV5//fVC5x5++GHi4uKsx7a2tpckg/b397fmF7rYhg0brjmHkFBLwOniamIDpodYz4tI6adgkIiIiIiIiNyQkFAvBX9E7mDaJiYiIiIiIiIiUoYoGCQiIiIiIiIiUoYoGCQiIiIiIiIiUoYoGCQiIiIiIiIiUoYoGCQiIiIiIiIiUoYoGCRSzD744AMyMzOLrD93d3fOnDlz0+2jo6Pp0qVLkc1HRERERERE7iwKBokUs6IOBt2o/Pz8EhtbRERERERESh8Fg0SK0Pnz5+ncuTM+Pj54enoyefJkjh07RkhICCEhIQA899xzBAQE0LBhQyZOnGht6+7uzsSJE/H398fLy4ukpCQAzp49S/v27fHz8+Nf//oXZrPZ2qZHjx40atSIhg0bMn/+fOv58uXLM2HCBJo0acKmTZv4+eef8fDwoEWLFnzzzTfW+3799Vd8fX3x9fXFz8+P9PT04n6JREREREREpIQpGCRShH7++WeqV6/Ozp07SUxM5JVXXqF69epERUURFRUFwPTp04mJiSE+Pp5ff/2V+Ph4a3s3qo7ImQAAIABJREFUNze2b9/Oc889x6xZswCYPHkyLVq0YMeOHXTr1o2UlBTr/QsWLCA2NpaYmBhmz57N2bNnAUtQytPTky1bthAQEMCzzz7L999/z7p16zhx4oS1/axZs/joo4+Ii4tj3bp1ODk53Y6XSUREREREREqQgkEiRcjLy4vIyEhGjx7NunXrqFix4iX3fPXVV/j7++Pn58euXbvYvXu39VqvXr0AaNSoEcnJyQCsXbuW/v37A9C5c2dcXV2t98+ePRsfHx+CgoI4fPgw+/fvB8BoNPLYY48BkJSURO3atalTpw4Gg8HaF0Dz5s159dVXmT17NufOncPW1rZoXxAREREREREpdRQMEilCdevWJTY2Fi8vL8aOHcuUKVMKXT948CCzZs1i9erVxMfH07lzZ7Kzs63XHRwcAEswx2QyWc8bDIZLxoqOjiYyMpJNmzaxc+dO/Pz8rH05OjpiNBqv2h5gzJgx/Oc//yErK4ugoCDr1jQRERERERG5eykYJFKEjh07hrOzM/3792fkyJFs374dFxcXay6eP//8k3LlylGxYkVOnjzJypUrr9lny5YtCQ8PB2DlypWkpqYCkJaWhqurK87OziQlJbF58+bLtvfw8ODgwYP89ttvACxevNh67bfffsPLy4vRo0cTEBCgYJCIiIiIiEgZoD0hIkUoISGBUaNGYWNjg6OtLYsGDCC6WTM6duxItWrViIqKws/Pj4YNG/Lggw/SvHnza/Y5ceJEnnjiCfz9/WnVqhU1a9YE4NFHH2XevHl4e3tTr149goKCLtve0dGR+fPn07lzZ9zc3GjRogWJiYmApdJZVFQURqORBg0a0LFjx6J7MURERERERKRUUjBI5BZ8800Mb7/9E8eOpVK9uitjx3ayJIROT4d58yAqinqjR/Ov11+3tgkLC7tsXxdyBAEEBAQQHR0NQOXKlVm1apX12vvvv2/9+UorizIyMgodP/roo5es+omOjmbOnDnX85giIiIiIiJyF1EwSOQmffNNDKNGfUVWVh4AR4+mMmrUVzj+cZpOe9dAaipUrQpJSXCFVTsiIiIiIiIit5tyBoncpLff/skaCLogKHU/DqNegwMHwN4enJ0hIaGEZigiIiIiIiJyKQWDRG7SsWOpl5yLt6vKBLvG8Npr4OUFubmQmWn5IyIiIiIiIlIKaJuYyE2qXt2Vo0cLB4TOGp1xrFEDWrSw/CkogLQ0cHIqoVmKiIiIiIiIFKaVQSI3aezYTjg52RU65+Rkx9ixnf4+YWMDrq5gMNzm2YmIiIiIiIhcXpEEgwwGw6MGg2GvwWA4YDAYxhRFnyKlXa9eAcyc2YcaNVwxGKBGDVdmzuxDr14BJT01ERERERERkSu65W1iBoPBCHwEtAOOANsMBsN3ZrN59632LVLa9eoVoOCPiBS5Tp068d///pd77rnnstfd3d2JiYnBzc3tNs9MRERERO4GRbEyqDFwwGw2/242m3OBJUD3IuhXRETkjmAymYq0v59++umKgSARERERkVtVFMGgGsDhi46P/HVORETkrjB16lQ8PDxo164dTzzxBLNmzSI4OJg33niDVq1a8eGHH3L69Gkee+wxAgMDCQwMZMOGDQCcP3+eIUOGEBgYiJ+fHytWrAAgLCyMXr168eijj1KnTh1ef/1163ju7u6cOXOG8+fP07lzZ3x8fPD09CQiIsJ6z5w5c/D398fLy4ukpKTb+4KIiIiIyB2tKKqJXS4zrvmSmwyGocBQgHvvvZfo6OgiGLroZWRklNq5iRQlvdelrLjV9/revXtZtGgRH330Efn5+QwdOpR77rmHc+fOsWvXLiZPngxAv3796NGjB15eXpw8eZInn3ySRYsW8e9//xt3d3cGDBhARkYGzz33HPb29iQlJbF582bmz5+Pvb09AwYMICAggKpVq5Kdnc2GDRuIi4vDYDDw4YcfFnqW7OxsUlNTee+99/j222957bXXGDVqVFG8XHIH0+e6lAV6n0tZofe6FLeiCAYdAR646Ph+4Ng/bzKbzfOB+QABAQHm4ODgIhi66EVHR1Na5yZSlPRel7LiVt/rcXFxhIaG0qFDBwD69OlD9erV2bNnD6+++iqtWrWynj979qy1nclkolGjRowcOZKdO3fy448/AmAwGHB3d+fkyZN07tyZLl26AODn50f16tVp0aIFjo6ONG/enPr16xMWFsbKlSvp0qWL9V5HR0dGjx5NjRo1cHJyYty4cfrvWfS5LmWC3udSVui9LsWtKIJB24A6BoOhNnAU6Ac8WQT9iojIDShfvjwZGRmFzs2bNw9nZ2cGDBhQQrO685nNlyx2tSpXrpz154KCAjZt2oSTk9Ml7ZctW0a9evUKnd+yZQsODg7WY6PReEnuobp16xIbG8tPP/3E2LFjad++PRMmTACwtr1cOxERERGRq7nlnEFms9kEvAj8D9gDfGU2m3fdar8iInLrhg0bpkDQLWrRogXff/892dnZZGRkWFf4/FP79u2ZO3eu9TguLg6ADh06MGfOHGtQaceOHdc99rFjx3B2dqZ///6MHDmS7du338KTiIiIiIhYFEUCacxm809ms7mu2Wx+yGw2Ty+KPkVE5NZNmjSJWbNmARAcHMzo0aNp3LgxdevWZd26dQDk5+czatQoAgMD8fb25tNPPwXg+PHjtGzZEl9fXzw9Pa33lzWBgYH07NSJ1x58kNBu3QgICKBixYqX3Dd79mxiYmLw9vamQYMGzJs3D4Dx48eTl5eHt7c3np6ejB8//rrHTkhIoHHjxvj6+jJ9+nTefPPNInsuERERESm7imKbmIiI3CFMJhNbt27lp59+YvLkyURGRvLZZ59RsWJFtm3bRk5ODs2bN6d9+/Z88803dOjQgXHjxpGfn09mZmZJT/+22B0ezvpx4/gzJYUKNWvS8s03ed1oxKFJE7JffZUWI0bw2muv8eyzzxZq5+bmVqja1wVOTk7WANvFBg0axKBBg6zHP/zwg/Xn5ORkwLKq6EKuootduA4QEBCgBJMiIiIickMUDBIRKUN69eoFQKNGjawBhVWrVhEfH8/XX38NQFpaGvv37ycwMJAhQ4aQl5dHjx498PX1Lalp3za7w8NZNXQopr8CX6ZDh0h/7jmiKlUi3WQibtMmHnv5Zfz9/Ut4piIiIiIiN0/BIBGRMuRySYfNZjNz5sy57AqUtWvX8uOPP/LUU08xatSouz7/0Ppx46yBIDugE2A0mXDOzKTh00/T22SCMWNKdI4iIiIiIreqSHIGiYhIKZKcDDdQXapDhw588skn5OXlAbBv3z7Onz/PoUOHqFq1Ks8++yxPP/10mUhe/GdKivXnPCAaWA8cycgAW1soKIBz50podiIiIiIiRUMrg0RE7hKZmZmEVK3K8xkZLCxXjrZjx15Xu2eeeYbk5GT8/f0xm81UqVKFb7/9lujoaGbOnImdnR3ly5fn888/L+YnKHkVatbkz0OHrMdn/vo7vVYtmDULsrPB0bFkJiciIiIiUkQUDBIRuYPlpR/BlLoXc34W57cswf6T7zAaHOhdowaMGAEGg/Xei5MMu7m5WXMG2djY8NZbb/HWW28V6nvgwIEMHDjwdjxGqdFi+vRCOYMAbJ2daTH9r0KZCgSJiIiIyF1A28RERO5QeelHyDubgDk/CzIyMf4ngoK8c+RXqQApKfDbbyU9xTtOg9BQ2s+fT4VatcBgoEKtWrSfP58GoaElPTURERERkSKjlUEiIncoU+peMOdDRiZ274ZBajoGZ0cKDiZhtLkHNm6Ehx8u6WnecRqEhir4IyIiIiJ3NQWDRETuUOb8LMsPTg7kvfwkuDhDTh7kmbCrFgzOziU6PxERERERKZ0UDBIRuUMZjE6WgJDRCG73WE462GMwOkGNGiU7ORERERERKbWUM0hE5A5l61oPDMbCJw1Gy3kREREREZEr0MogEZE7lJ3L/QDWamIGoxO2rvWs50VERERERC5HwSARkTuYncv9Cv6IiIiIiMgN0TYxEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgEREREREREZEyRMEgERGR28hgMPDUU09Zj00mE1WqVKFLly5XbRcXF8dPP/1U3NMTERERkTJAwSAREZHbqFy5ciQmJpKVlQXAL7/8Qo0aNa7Z7mrBIJPJVKRzFBEREZG7m4JBIiIit1nHjh358ccfAVi8eDFPPPGE9dr58+cZMmQIgYGB+Pn5sWLFCnJzc5kwYQIRERH4+voSERHBpEmTGDp0KO3bt2fAgAFkZ2czePBgvLy88PPzIyoqqqQeT0RERERKOQWDREREbrN+/fqxZMkSsrOziY+Pp0mTJtZr06dPp3Xr1mzbto2oqChGjRpFXl4eU6ZMoW/fvsTFxdG3b18AYmNjWbFiBf/973/56KOPAEhISGDx4sUMHDiQ7OzsEnk+ERERESndFAwSERG5zby9vUlOTmbx4sV06tSp0LVVq1bxzjvv4OvrS3BwMNnZ2aSkpFy2n27duuHk5ATA+vXrrbmIPDw8qFWrFvv27SveBxERERGRO5JtSU9ARESkLOrWrRsjR44kOjqas2fPWs+bzWaWLVtGvXr1Ct2/ZcuWS/ooV65coXYiIiIiItdDK4OkzJo+fToNGzbE29sbX1/fy/6idaMmTJhAZGRkEcxORO5qBQU8X60a7778Ml5eXoUudejQgTlz5liDOzt27ADAxcWF9PT0K3bZsmVLwsPDAdi3bx8pKSmXBJREREREREDBoLtGTk4Obdu2tSYWvZKwsDBefPHF2ziz0mnTpk388MMPbN++nfj4eCIjI3nggQeuq+3VqvZMmTKFtm3bFtU0ReQukZd+hKyU1WQe/AEKTJj++x/cfvyRZ2rVuuTe8ePHk5eXh7e3N56enowfPx6AkJAQdu/efcXP+eeff578/Hy8vLzo27cvYWFhODg4FPuziYiIiMidR9vE7gImk4kdO3aQl5dHXFxcSU/njnD8+HHc3Nysvyi5ubkBlmSsr776KhkZGbi5uREWFka1atUIDg6mWbNmbNiwgdatW7Nw4cL/Z+/O42u+8j+Ov272hCRoVKnaWhLZEwkiQjSIqZRSJjpaNIOWWqYtVVWlpnR+rXbQhVKlOpk2aq0qNZbQCJqE2IOGiGLSxJIFidzk/v5I3ZHalyzk/Xw8PNx77vd7vp9zfZOH+7nnfA6HDx/GwsKC8+fP4+rqyuHDhxk0aBARERH06tWLhIQERo4cyblz57C1tWXdunU4ODjw+uuvExsbS0FBAS+99BIvvPACJ0+eJDIykpycHIxGIzNnziQkJKQi3yIRuUsKc3+l8NRuMBUBkPX5W5i+/Yaixs2xjIuDXr0IDQ0lNDQUAHt7ez777LMr+qlVqxYJCQnXvI6dnR3z588viyGIiIiIyH1GM4PusrS0NNzc3Ojfvz/e3t706tWL8+fPs27dOvz8/PDy8iIqKoqCggJ+/vlnevbsCcDy5cuxt7fn4sWL5Ofn06RJEwBSU1Pp0qULLVq0ICQkhJSUFAAGDBjAK6+8QocOHRg0aBDPPvssycnJ+Pr6kpqaSqNGjcjKygIgMTHR/CFDSnTu3Jljx47RrFkzhg4dysaNGyksLGT48OEsWrSIpKQkoqKiGDdunPmcs2fPsnHjRiZMmICPjw8bN24EYMWKFYSHh2NtbW0+9uLFi0RGRjJ9+nR27tzJ2rVrsbe3Z+7cuTg7O5OQkEBCQgJz5szhyJEj/Pvf/yY8PJzk5GR27tyJr69vub8nIlI2jGcOlCSCTCYsl6zHav53GGysKM45CefOwfbtFR2iiIiIiFQxmhlUBg4cOMDcuXMJDg4mKiqKDz/8kM8++4x169bRrFkz+vXrx8yZMxk2bJi5FsRPP/2Ep6cnCQkJGI1G8zbDgwcPZtasWTRt2pRt27YxdOhQ1q9fD5TUhFi7di2WlpbExsYydepUvv/++wob972kevXqJCUl8dNPP7FhwwYiIyN588032bNnD506dQKgqKiIunXrms+5tJXzpccxMTF06NCBb775hqFDh5bq/8CBA9StW5fAwEAAnJycgJJdgnbt2sWiRYsAyM7O5tChQwQGBhIVFUVhYSFPPfWUkkEi9xFT0YWSB0XFGA4do6hzEORfhJw80pO/p3pCHWppJqCIiIiIlCMlg8rAI488QnBwMADPPvssf//732ncuDHNmjUDoH///nzyySf87W9/47HHHmP//v38/PPPvPLKK2zatImioiJCQkLIy8sjPj6e3r17m/suKCgwP+7duzeWlpblO7j7iKWlpXlphpeXF5988gkeHh5s2bLlqsdfvmtPt27dGDt2LKdPnyYpKYnHH3+81LEmkwmDwXBFHyaTiY8++ojw8PArXtu0aRMrV67kueeeY/To0fTr1+8ORygilYHB0r4kIWRliXFMf3N7/rlM9tdcjEXRv/DY25p6HpHX6UVERERE5O7RMrEycLUkwLWEhISwatUqrK2t6dixI3FxccTFxdGuXTuKi4upUaMGycnJ5j/79+83n3t5cuKPrKysKC4uBiA/P//2B3OfOnDgAIcOHTI/T05Opnnz5mRmZpqTQYWFhezdu/eq51evXp2WLVsycuRIIiIirkjKubm5ceLECXN9j9zcXIxGI+Hh4cycOZPCwkKgZHbXuXPnOHr0KA8++CCDBg3ir3/9K9u1bETkvmFV0xUMpX9HFBkLSNv5DYYiE1ZnznP867EQGwu/z/wUERERESlLSgaVgfT0dHNC4euvv6Zjx46kpaXxyy+/APDVV1/Rvn17oGQr4GnTphEUFETt2rU5deoUKSkpeHh44OTkROPGjfn222+BklklO3fuvKkYGjVqRFJSEgCLFy++20O85+Xl5dG/f38imjRhQJMm7Nu3j0mTJrFo0SLGjBmDj48Pvr6+xMfHX7OPyMhI/vWvf5VaPnaJjY0NMTExDB8+HB8fHzp16kR+fj4DBw7E3d0df39/PD09eeGFFzAajcTGxuLr64ufnx+LFy9m5MiRZTl8ESlH1o71sX7Aq2SGkKmY/HOZHPp5Ng7/3kDg7As0+/EidVcfg48/hm3bKjpcEREREakCtEysDLRwdeX4K6/QOzOTYh8fpk+fTuvWrenduzdGo5HAwEBefPFFAFq1akVGRgbt2rUDwNvbmwcffNA8uyg6OpohQ4bwzjvvUFhYSJ8+ffDx8blhDBMmTOCvf/0rU6ZMMdcfquoKc3/FeOYApqILuNe2Z9Ok17BasARq1YJ//hMMBlxcXNi0adMV58bGxl7R1qtXL0wmU6m2y3fyCQwMZOvWrVecN2XKFKZMmVKqrX///vTv3/+KY0Xk/mDtWB9rx/ps/KQ5+TnHShqDrDDaQuqPhfiE1AJHR2jbtsximDJlCm+88UaZ9S8iIiIi9w7DHz/MloeAgABTYmJiuV/3ZsTGxt7SzltLliTy7rs/cOLEGerVq8lLkU24+H8vM7hdO+jSBQYNKrtg5aaV2trZZMIiNgnLFT9h0cgVy7MX4B//gDp1KjrMcnWr97rIvaoy3esn9saw94dhFBt/LypdbKL+TgONL/jh4PIYfPBBSYK6DFSvXp28vLwy6Vsqh8p0r4uUFd3nUlXoXpfbZTAYkkwmU8CNjtMysTuwZEkio0cv5PjxM5hMYHs0FasJk7G/UADNmkFyMvxet0cqlnlrZ8Dym9VY//NfGCimOPskGI1wWf0gEZGyUs8jEo8nPsbO6RHAgF2NBrReUYhDr4GkWlsT2rMnvXr1ws3Njb59+5pnH77++uu4u7vj7e3NqFGjAMjMzOTpp58mMDCQwMBANm/eDJQsg33++efx8vLC29ubxYsX8/rrr3PhwgV8fX3p27cv586do2vXrvj4+ODp6UlMTExFvSUiIiIiUgG0TOwOvPvuD1y4UGh+/rfcbTxYfJ6zjo9CRgbk58PJk/DwwxUYpcBlWzsDRZ2DKG7eBEPWWSx+OQZnbSEtrUyXZ4iIXFLPI7LUzmGmMdXhuec4XrcuO3r3Zu/evdSrV4/g4GA2b96Mu7s7S5cuJSUlBYPBwNmzZwEYOXIkL7/8Mm3btiU9PZ3w8HD279/P3//+d5ydndm9ezcAZ86c4emnn+bjjz8mOTkZKKklV69ePVauXAlAdnZ2Ob8LIiIiIlKRlAy6AydOnCn1fESNLtQ05VO3OI9u3buXzDa5eLGCopPLmbd2BnigBqYHamACTOGhUL8DVMBySRERMwsLim1saNmyJfXr1wfA19eXtLQ0WrdujZ2dHQMHDqRr165EREQAsHbtWvbt22fuIicnh9zcXNauXcs333xjbq9Zs+YVl/Py8mLUqFGMGTOGiIgIQkJCyniAIiIiIlKZaJnYHahX7w//wTYYOGNhT3bDZtC9O4waBY0bV0xwUsrVtnbGYFnSbmEBf9gaXkSkItja2pofW1paYjQasbKy4ueff+bpp59m2bJldOnSBYDi4mK2bNlCcnIyycnJHD9+HEdHR0wmk3kTgmtp1qwZSUlJeHl5MXbsWCZNmlSm4xIRERGRykXJoDswduwT2Ntbl2qzt7dm7NgnKigiuZbLt3aGkplC1g94Ye1Yv4IjExG5vry8PLKzs3niiSeYNm2aealX586d+fjjj83HXav9zJmSWazW1tYUFpYsbT5x4gQODg48++yzjBo1iu3bt5fXcERERESkEtAysTvQs2dJge7LdxMbO/YJc7tULpe2dhYRuZfk5ubSvXt38vPzMZlM/POf/wRgxowZvPTSS3h7e2M0GmnXrh2zZs3izTff5KWXXsLT0xNLS0smTJhAz549GTx4MN7e3vj7+9OvXz9Gjx6NhYUF1tbWzJw5s4JHKSIiIiLlSVvL/4G28JOqQve6VBW616Wq0L0uVYHuc6kqdK/L7dLW8iIiIiIiIiIicgUlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0REREREREREqhAlg0RERERE5J40ceJEpk6dWtFhiIjcc5QMEhERERERERGpQpQMEhEREbmKyZMn4+Hhgbe3N76+vmzbtu2qx82fP59hw4bd9nViY2OJiIi4K32J3G8+/PBDPD098fT0ZNq0aUDJz6arqysdO3bkwIED5mNTU1Pp0qULLVq0ICQkhJSUFAC+/fZbPD098fHxoV27dhUyDhGRysaqogMQERERqWy2bNnC999/z/bt27G1tSUrK4uLFy9WdFgiVUpSUhLz5s1j27ZtmEwmWrVqxYgRI/jmm2/YsWMHRqMRf39/WrRoAcDgwYOZNWsWTZs2Zdu2bQwdOpT169czadIkfvzxRx5++GHOnj1bwaMSEakcNDNIRERE5A9OnjyJi4sLtra2ALi4uFCvXj0SEhJo06YNPj4+tGzZktzcXABOnDhBly5daNq0Ka+99pq5nyFDhhAQEICHhwcTJkwwt69evRo3Nzfatm3LkiVLrhrDihUraNWqFX5+fnTs2JGMjIwyHLFI5RMXF0ePHj2oVq0a1atXp2fPnmzdupUePXrg4OCAk5MT3bp1AyAvL4/4+Hh69+6Nr68vL7zwAidPngQgODiYAQMGMGfOHIqKiipySCIilYZmBomIiIj8QefOnZk0aRLNmjWjY8eOREZGEhQURGRkJDExMQQGBpKTk4O9vT0AycnJ7NixA1tbW1xdXRk+fDiPPPIIkydPplatWhQVFREWFsauXbto1qwZgwYNYv369Tz22GNERkZeNYa2bduydetWDAYDn3/+Oe+99x4ffPBBeb4NIhXKZDJdtd1gMFzRVlxcTI0aNUhOTr7itVmzZrFt2zZWrlyJr68vycnJPPDAA3c9XhGRe4lmBomIiIj8QfXq1UlKSmL27NnUrl2byMhIPvvsM+rWrUtgYCAATk5OWFmVfK8WFhaGs7MzdnZ2uLu7c/ToUQAWLlyIv78/fn5+7N27l3379pGSkkLjxo1p2rQpBoOBZ5999qox/Prrr4SHh+Pl5cX777/P3r17y2fwIpVEu3btWLZsGefT0jh/+DBLly6ldevWLF26lAsXLpCbm8uKFSuAkp/Hxo0b8+233wIliaSdO3cCJbWEWrVqxaRJk3BxceHYsWMVNiYRkcpCM4NERERErsLS0pLQ0FBCQ0Px8vLik08+ueqMBMC8nOzSeUajkSNHjjB16lQSEhKoWbMmAwYMID8/H7j6zIY/Gj58OK+88grdunUjNjaWiRMn3pVxidwr/P39GfjMM8QEBJBnYcHAsWNxdXUlMjISX19fGjZsSEjuB4FqAAAgAElEQVRIiPn46OhohgwZwjvvvENhYSF9+vTBx8eH0aNHc+jQIUwmE2FhYfj4+FTgqEREKgclg0RERET+4MCBA1hYWNC0aVOgZBlY8+bNWb16NQkJCQQGBpKbm2teJnY1OTk5VKtWDWdnZzIyMli1ahWhoaG4ublx5MgRUlNTefTRR/n666+ven52djYPP/wwAF9++eXdH6Tcl+bPn09iYiIff/xxuVxv2bJlNGvWDHd39+seN3HiRKpXr86oUaOue1x2RjZZh7MwFhixsrZgULEl9t26QVERPPEEsSdPMm7cOMaNG3fFuY0bN2b16tVXtF+rLpeISFWmZWIiIiIif5CXl0f//v3xd3Ojm6sr+/btY9KkScTExDB8+HB8fHzo1KmTeabP1fj4+ODn54eHhwdRUVEEBwcDYGdnx+zZs+natStt27alYcOGVz1/4sSJ9O7dm5CQEFxcXMpknCJ3atmyZezbt++u9JWdkU3GgQyMBUYAbOJiKdy0mfyataF6dVi2DK5RR0hERG6NZgaJiIiIANFboxm3dBzpp9NpUKsB700ax5/jjsNvv8GMGWBlhYuLC1u3bi113oABAxgwYID5+ffff29+PH/+/Kteq0uXLqSkpFzRfnlf3bt3p3v37nc8Lrm/PPXUUxw7doz8/HxGjhzJ4MGDmTdvHu+++y5169alWbNm5mWLmZmZvPjii6SnpwMwbdo0goODOXXqFM888wyZmZm0bNmS1atXk5SURF5eHhEREezZsweAqVOnkpeXx8SJE5kzZw6zZ8/m4sWLPPbYY3z11VckJyfz3XffsXHjRt555x0WL14MwEsvvURmZiYODg7MmTMHNzc3c/ypqan07t2b7du3A3Do0CH69OlDUlISWYezMBWXJHuqxa3FedViih2duZiSit2DjnD4MNauruX2XouI3M+UDBIREZEqL3prNIO/Gsz5i+cByDtxlGOvDeXQI21p+kBjSEuDxx6r2CBFgC+++IJatWpx4cIFAgMD6dq1KxMmTCApKQlnZ2c6dOiAn58fACNHjuTll1+mbdu2pKenEx4ezv79+3n77bdp27Ytb731FitXrmT27Nk3vG7Pnj0ZNGgQAG+++SZz585l+PDhdOvWjYiICHr16gWUFFOfNWsWTZs2Zdu2bQwdOpT169eb+3n00UdxdnYmOTkZX19f5s2bZ06AXpoRBHCxiSsnx74H1tZQXIxT25Kfv8KkpLvyPoqIVHVKBomIiEiVN27pOHMiyP00/F8CnLExsuq37TR1aQJ79igZJJXCjBkzWLp0KQDHjh3jq6++IjQ0lNq1awMQGRnJwYMHAVi7dm2pJVw5OTnk5uayadMmcx2drl27UrNmzRted8+ePbz55pucPXuWvLw8wsPDrzgmLy+P+Ph4evfubW4rKCi44riBAwcyb948PvzwQ2JiYvj5558BsLK1MieECus9Yj7eytYKHB1vGKOIiNw8JYNERESkyks/nV7q+Z4akG8Fj5zOgYIC2LULnnqqgqITKREbG8vatWvZsmULDg4O5oLk+/fvv+rxxcXFbNmy5aqFzq+2o52VlRXFxcXm55fXxBowYADLli3Dx8eH+fPnExsbe9Xr1ahRg+Tk5OuO4+mnn+btt9/m8ccfp0WLFjzwwAMAuDRxIeNAhnmpGIDBwoBLE9XMEhG521RAWkRERKq8BrUamB/vqwVjW8HbLWBytwYwdSpcVhNIpKJkZ2dTs2ZNHBwcSElJYevWrVy4cIHY2FhOnTpFYWEh3377rfn4zp07l9pV7FKSpl27dkRHRwOwatUqzpw5A0CdOnX47bffOHXqFAUFBaXqX+Xm5lK3bl0KCwvN5wI4OjqSm5sLgJOTE40bNzbHYDKZ2Llz5xXjsLOzIzw8nCFDhvD888+b253rOFPHtU7JTCBKZgTVca2Dcx3nO3vjRETkCkoGiYiISJU3ucdkHGwcSrU52Djw96enwEMPQYMG1zhTpPx06dIFo9GIt7c3748ezbR69WhsMDBx4kSCgoLo2LEj/v7+5uNnzJhBYmIi3t7euLu7M2vWLAAmTJjApk2b8Pf3Z82aNTT4/f62trbmrbfeolWrVkRERJQq/Pz3v/+dVq1a0alTp1Ltffr04f3338fPz4/U1FSio6OZO3cuPj4+eHh4sHz58quOpW/fvhgMBjp37lyq3bmOM48GPYprqCuPBj2qRJCISBnRMjERERGp8vq27gtQajexyT0mm9tFKsKG6N0sGLeBrPRsXBo4029yB1atWgW7d8Mnn4CVFdSuTeuwsFIzbC5xcXEhJibmivYHHniANWvWmJ9fqkEEMGLECEaMGHHFOUOGDGHIkCFXtAcHB1+xtfzq1auvOG7ixImlnsfFxREVFYWlpeWVAxcRkTKnZJCIiIgIJQkhJX+kstgQvZuPB6+k4HwhAJlHs5kzcAkP/rQCj/MpULs21KsHKSkQFlbB0d6aHj16kJqaWmqXMRERKV9KBomIiIiIVDILxm0wJ4IueTj/GEVfxkFkazh1qqTx0CEwmeAqBaFvVlpa2h1Eeusun4kkIiIVQ8kgEREREZFKJis9+4q2/TRkXEFDVkwbDqmpJcvFTpyA4mLQcisREbkFSgaJiIiIiFQyLg2cyTx6ZULIpYEz1KgBLVqU/BEREbkN2k1MREREROQuys7IJnVLKgdiD5C6JZXsjCuTOjfSb3IHbB2sS7XZOljTb3KHuxWmiIhUYZoZJCIiIiJyl2RnZJNxIANTsQkAY4GRjAMZAKW3Sb9BnZ8Ofb0ArthN7FK7iIjInVAySERERETkLsk6nGVOBAFQXIxlZianz2Xj/Ih9Sa2fPXvgzBmYPBlsba/ZV4e+Xkr+iIhImVAySERERETkLjEWGEs9NxgLqbZ5HdUSfoJHHgQHB7CxgWrVSv4WERGpAKoZJCIiIiJyl1jZlv6u1WRjS/ZTf+HMS6+Bs3NJMshkAl/fO9oOfv78+QwbNuyK9okTJzJ16lQA3nrrLdauXXvb17gd1atXNz/+4YcfaNq0Kenp6bfcT3JyMj/88MPdDE1ERC6jZJCIiIiIyF3i0sQFg0XpJI/BwoBzWBC89VbJsrCsLPDwuO1rGI3GGx8ETJo0iY4dO972de7EunXrGD58OKtXr6ZBgwa3fL6SQSIiZUvJIBERERGRu8S5jjN1XOuYZwhZ2VpRvX51/hL1F3yeeIKgH37gZxcXvJ56ijFjxtCyZUtatmzJL7/8AsCKFSto1aoVfn5+dOzYkYyMkuLTEydOZPDgwXTu3Jl+/fqVuubKlSsJCgoiKyurVPuAAQNYtGgRAI0aNWLChAn4+/vj5eVFSkoKAJmZmXTq1Al/f39eeOEFGjZseEU/t+qnn35i0KBBrFy5kkcffdR8naeffprAwEACAwPZvHkzAD///DNt2rTBz8+PNm3acODAAS5evMhbb71FTEwMvr6+xMTEsHHjRnx9fRk4cCB+fn7k5ubeUYwiIlWdagaJiIiIiNxFznWcS+0ctnjxYurVq8fKlSsByM7OJvfHH3FycuLnn39mwYIF/O1vf+P777+nbdu2bN26FYPBwOeff857773HBx98AEBSUhJxcXHY29szf/58AJYuXcqHH37IDz/8QM2aNa8bl4uLC9u3b+fTTz9l6tSpfP7557z99ts8/vjjjB07ltWrVzN79uw7GntBQQHdu3cnNjYWNzc3c/vIkSN5+eWXadu2Lenp6YSHh7N//37c3NzYtGkTVlZWrF27ljfeeIPFixczadIkEhMT+fjjjwF48skn+eSTTygsLCQgIAA7O7s7ilNEpKpTMkhEREREKp20tDQiIiLYs2cPsbGxTJ06le+//76iw7otXl5ejBo1ijFjxhAREUFISAgAzzzzjPnvl19+GYBff/2VyMhITp48ycWLF2ncuLG5n27dumFvb29+vmHDBhITE1mzZg1OTk43jKNnz54AtGjRgiVLlgAQFxfH0qVLAejSpcsNE0o3Ym1tTZs2bZg7dy7Tp083t69du5Z9+/aZn+fk5JCbm0t2djb9+/fn0KFDGAwGCgsLr9pvcHAwr7zyCi1btuSxxx6jfv36dxSniEhVp2ViIiIiIiJlqFmzZiQlJeHl5cXYsWOZNGkSAIbLCkhfejx8+HCGDRvG7t27+eyzz8jPzzcfU61atVL9NmnShNzcXA4ePHhTcdj+vo29paWlue6QyWS6/YFdhYWFBQsXLiQhIYEpU6aY24uLi9myZQvJyckkJydz/PhxHB0dGT9+PB06dGDPnj2sWLGi1Hgv9/rrr/P5559z8eJFWrdubV7mdr+ytLTE19cXHx8f/P39iY+Pv+7xaWlpeHp6llN0InI/UDJIRERERMrFmDFj+PTTT83PJ06cyAcffMDo0aPx9PTEy8uLmJiY6/Zx7tw5oqKiCAwMxM/Pj+XLlwMQEhJCcnKy+bjg4GB27dpVNgO5RSdOnMDBwYFnn32WUaNGsX37dgDzWGNiYggKCgJKlpA9/PDDAHz55ZfX7bdhw4YsWbKEfv36sXfv3tuKrW3btixcuBCANWvWcObMmdvq53IOhYWsnD+f6Oho5s6dC0Dnzp3NS74A87/V5eO9tPQNwNHRsVRdoNTUVLy8vHjmmWcICAi475NB9vb2JCcns3PnTt59913Gjh1b0SGJyH1GySARERERKRd9+vQplexZuHAhLi4u5g+9a9euZfTo0Zw8efKafUyePJnHH3+chIQENmzYwOjRozl37hwDBw40JxMOHjxIQUEB3t7eZT2km7J7925atmyJr68vkydP5s033wRK6uu0atWK6dOn889//hMoSZD17t2bkJAQXFxcbti3q6sr0dHR9O7dm9TU1FuObcKECaxZswZ/f39WrVpF3bp1cXR0vOV+LqlmMsF771FzyRJWr17NO++8w/Lly5kxYwaJiYl4e3vj7u7OrFmzAHjttdcYO3YswcHBFBUVmfvp0KED+/btMxeQnjZtGp6envz1r3/F3t6eP/3pT7cd470mJyfHvHzPZDLdMHman5/P888/j5eXF35+fmzYsAGA8+fP8+c//xlvb28iIyNp1aoViYmJAFSvXp1x48bh4+ND69atzYXLr1XQXETufYa7PTX0ZgQEBJgu/eKpbGJjYwkNDa3oMETKnO51qSp0r0tVca/c682bN2fdunVkZmYydOhQWrZsiZeXF1FRUQA899xz9O7dG29v76vWDAoICCA/Px8rq5LSl6dPn+bHH3+kYcOGeHt7s3//fsaPH0/9+vUZNmxYRQ71uho1akRiYuJNJXzKUkFBAZaWllhZWbFlyxaGDBlSaobVjSxZksi77/7AiRNneOQhJ+Z4nMXLKhdMJpgyBerWvavx3iv3+Z2ytLTEy8uL/Px8Tp48yfr162nRogWLFy9m1qxZrF69mqysLAIDA9m2bRsFBQXmn5cPPviAPXv2MG/ePFJSUujcuTMHDx7k448/5tChQ3z22Wfs2bMHX19ftm7dSkBAAAaDge+++44nn3yS1157DScnJ958803OnDlDjRo1zAXN9+/fby5oLmWrqtzrcvcZDIYkk8kUcKPjVEBaRERERMpNr169WLRoEf/973/p06fPLc9mMZlMLF68GFdX1yte69SpE8uXL2fhwoVU1i8eK5v09HT+/Oc/U1xcjI2NDXPmzLnpc5csSWT06IVcuFCIobiYNqnxHDx4Eqs/BdHcsRg2bYLIyDKM/v51aZkYwJYtW+jXrx979uwhLi6OZ555BktLS+rUqUP79u1JSEgoNQsuLi6O4cOHA+Dm5kbDhg05ePAgcXFxjBw5EgBPT89S59jY2BAREQGUFBj/z3/+A1y/oLmI3Nu0TExEREREyk2fPn349uuvWb5wIb169aJdu3bExMRQVFREZmYmmzZtomXLltc8Pzw8nI8++shc+HjHjh3m1wYOHMiIESMIDAykVq1aZT6WO5GWllbhs4IAmjZtyo4dO9i5cycJCQkEBgbe9LnvvvsDFy6U7P41Ji+ezvmHMRqLObg+CYxGiI+Hy5Z+ye0JCgoiKyuLzMzMmyr4fa1jrneutbW1uYj55QXGr1fQXETubUoGiYiIiEi58XB15Ym0NKIsLKhbty49evTA29sbHx8fHn/8cd577z0eeuiha54/fvx4CgsL8fb2xtPTk/Hjx5tfa9GiBU5OTjz//PPlMZQq78SJ/xWbnubYmqgaEbxeI4yx1q1Kloi9+ipY6OPGHSkoICUlhaKiIh544IGbSp62a9eO6OhooKR+Vnp6Oq6urqWKhe/bt4/du3ff8PK3UtBcRO4tWiYmIiIiImXm4u7d5K9bhyk7G4OjIw7nzjG2Y0ewsYGcHAxOTrz//vu8//77pc5r1KgRe/bsASA0NNRcO8Pe3p7PPvvsqtc6ceIExcXFdO7cuUzHJCXq1avJ8eMlCaF8gxUYoAALXB6uDb8nEOT2XLhwgWebNuVPZ8/yUZ06fPnll1haWtKjRw+2bNmCj48PBoPBnDxNS0sznzt06FBefPFFvLy8sLKyYv78+dja2jJ06FD69++Pt7c3fn5+eHt74+zsfN04LhU0f/jhh2ndujVHjhwp45GLSHlRMkhEREREysTF3bu5sGIFFBaCyYTl1q0UHzxIUatWWBYUwPbtcJcKpC5YsIBx48bx4YcfYqHZKOVi7NgnzDWDLrG3t2bs2CcqMKp707HfctmffoYLBUXY21hw8uvFPLhiMRQX0/e118DHBwCDwXDD5KmdnZ15Z73L2dnZ8a9//Qs7OztSU1MJCwujYcOGAOTl5ZmP69WrF7169QKge/fudO/evSyGXOHS0tLMRbcvmThxItWrV2fUqFEVGJlI+VAySERERETKRP66dSWJIMBu1SosTp/GVK0axuRkLBs1gjVr7loyqF+/fvTr1++u9CU3p2fPks1qLu0mVq9eTcaOfcLcLjfn2G+57Ew9RVGxCYqKqP3t1xTs/Jlst0dxzs+D5GRzMuhOnD9/ng4dOlBYWIjJZGLmzJnY2NjchRGIyL1IySARERERKROm7Gzz44stW2KysYGiIgwXL2Lbr5+KC98HevYMUPLnDu1PP1OSCALs/3ucuj+t4aJjDXKP/IpzdUtITITnnrvj+kuOjo7aZU9EzJQMEhEREZEyYXB2NieEii/fOcvZGVq3rqCoRCqXCwX/S4peeLgB297/AqvzedieyqT+QxaQmQk3sYuYiMitUDJIRERERMqEXVjY/2oGXWJtjV1YWMUFJVLJ2NtalkoIYTBgrOaIda0aENCg4gK7zxkMhltqF7nfqLqeiIiIiJQJGy8v7J98EsPvOxYZnJ2xf/JJbLy8KjgykcqjeYOaWFqUTkBYWhho3qBmBUVUNTzg7Ix9VlapttOnT+Ny+SxGkfuYZgaJiIiISJmx8fJS8kfKldFoxMrq3vmY88iDjgD/203M1pLmDWqa26VsVE9PZ0JhIYnTpxMwciSnT59m9erVjBw5sqJDEykXmhkkIiIildLLL7/MtGnTzM/Dw8MZOHCg+fmrr77Khx9+eM3zq1evDkBsbCwRERFXvP7dd9/xj3/84y5GLCJ3S1paGm5ubvTv3x9vb2969erF+fPnOXDgAO3bt6dFixaEh4dz8uRJAEJDQ3njjTdo374906dPZ8CAAQwZMoQOHTrQpEkTNm7cSFRUFM2bN2fAgAHm6wwZMoSAgAA8PDyYMGGCub1Ro0ZMmDABf39/vLy8SElJAeDcuXNERUURGBiIn58fy5cvB2D+/Pn07NmTLl260LRpU1577TVzX6tXr8bf3x8fHx/Cfl8i+cd+tm9ZT+eABnQPbkzngAZKBJWHHTto27Ytp6dM4YUmTXi8QwcmTJjAo48+yqxZs5g1a1ZFRyhSpu6dlLmIiIhUKW3atOHbb7/lb3/7G8XFxWRlZZGTk2N+PT4+vlSy6FZ169aNbt263Y1QRaQMHDhwgLlz5xIcHExUVBSffPIJX375JRs2bKB27drExMQwbtw4vvjiCwDOnj3Lxo0bARgwYABnzpxh/fr1fPfddzz55JNs3ryZzz//nMDAQJKTk/H19WXy5MnUqlWLoqIiwsLC2LVrF97e3gC4uLiwfft2Pv30U6ZOncrnn3/O5MmTefzxx/niiy84e/YsLVu2pGPHjgAkJyezY8cObG1tcXV1Zfjw4djZ2TFo0CA2bdpE48aNOX36NMA1+6lWrVoFvNNVR0pBCvH58eQas+kUt4I6zR6jc7N+dE5NhREjIDQUgBdffLFiAxUpB5oZJCIiIpVScHAw8fHxAOzduxdPT08cHR05c+YMBQUF7N+/n+bNmxMWFmb+9v7St/TXkpCQgJ+fH4cPH2b+/PkMGzYMKPngOGLECNq0aUOTJk1YtGgRAMXFxQwdOhQPDw8iIiJ44oknzK+JSNl65JFHCA4OBuDZZ5/lxx9/5MiRI3Tq1AlfX1/eeecdfv31V/PxkZGRpc5/8sknMRgMeHl5UadOHby8vLCwsMDDw4O0tDQAFi5ciL+/P35+fuzdu5d9+/aZz+/ZsycALVq0MB+/Zs0a/vGPf+Dr60toaCj5+fmkp6cDEBYWhrOzM3Z2dri7u3P06FG2bt1Ku3btaNy4MQC1atW6YT9SNlIKUlh3fh25xbk4pp/G+r+n+O34Ls6cSYcePcDNraJDFClXmhkkIiIilVK9evWwsrIiPT2d+Ph4goKCOH78OFu2bMHZ2Rlvb28cHBxYunQpTk5OZGVl0bp1a7p163bV3WDi4+MZPnw4y5cvp0GDBmzatKnU6ydPniQuLo6UlBS6detGr169WLJkCWlpaezevZvffvuN5s2bExUVVV5vgUiV9sefY0dHRxo1akRycvJVj//jrBpbW1sALCwszI8vPTcajRw5coSpU6eSkJBAzZo1GTBgAPn5+Vecb2lpidFoBMBkMrF48WJcXV1LXWvbtm2lrnHpHJPJdNXfR9fqR8pOfH48Rkr+Hb0WbMFgKmbHoGAuejRjwIPPVXB0IuVPM4NERESk0ro0O+hSMigoKMj8vE2bNphMJt544w28vb3p2LEjx48fJyMj44p+9u/fz+DBg1mxYgUNGlx9q+annnoKCwsL3N3dzX3ExcXRu3dvLCwseOihh+jQoUOZjldE/ic9PZ0tW7aAycTC6Ghat27N2bNnS9qAwsJC9u7de9v95+TkUK1aNZydncnIyGDVqlU3PCc8PJyPPvoIk8kEwI4dO657fFBQEBs3buTIkSMA5mVit9qP3Lnc4lzz4/jxEaz8aiCZvg3Its6/zlki9y8lg0RERKTSatOmDfHx8ezevRtPT09at27Nli1biI+PJzg4mOjoaDIzM0lKSiI5OZk6deqU+mb/krp162JnZ3fdD1yXf6t/6QPapb9FpPw1b96cb+bM4R8PP4zP9u0MHz6ct99+mzFjxuDj44Ovr695Kent8PHxwc/PDw8PD6KiosxL0q5n/PjxFBYW4u3tjaenJ+PHj7/u8bVr12b27Nn07NkTHx8f81K2W+2nos2YMYPmzZvz8MMPm5fX3oq0tDQ8PT1v+/oDBgy44yW6jhaXFeW+bLZWqXaRKkTLxERERKTSCg4O5oMPPqBJkyZYWlpSq1Ytzp49y969e5kzZw7R0dE8+OCDWFtbs2HDBo4ePXrVfmrUqMHcuXPp3Lkz1apVI/T3IqE30rZtW7788kv69+9PZmYmsbGx/OUvf7mLIxQRgOyMbLIOZ2EsMGJla8U5q3M0KCxkurMzdOwItWqBgwOPPfbYFUs8oWTXwMvNnz/f/LhRo0bs2bPnqq9d/vhyl2oEAQQEBJj7t7e357PPPrvi+AEDBpTapez77783P/7Tn/7En/70p1LHX6ufyurTTz9l1apVbNy4kcTExIoO57a0sWvDuvPrzEvFAKywoo1dmwqMSqTiaGaQiIiIVFpeXl40/e9/Gfz7NvGX2pydnXFxcaFv374kJiYSEBBAdHQ0btcpAFqnTh1WrFjBSy+9xLZt227q+k8//TT169fH09OTF154gVatWuHs7HzH4xKR/8nOyCbjQAbGgpIP6cYCI9X/MZVX//tfKCqCxo0hOxvy8io40qrpxRdf5PDhw3Tr1o0zZ86Y248ePUpYWBje3t6EhYWZC2BnZGTQo0cPfHx88PHxuWL21uHDh/Hz8yMhIYGioiJGjx5NYGAg3t7e5gSZyWRi2LBhuLu707VrV3777bc7HoebrRthDmHmmUCOFo6EOYThZqvC0VI1aWaQiIiIVBobonezYNwGstKzcXnEib/1tuLHp58GW1u4eBFsbEp9k+/i4mKuH/JHeb9/cAwNDTXPBGrQoIG5xkirVq3M3+T/cXbApXMtLCyYOnUq1atX59SpU7Rs2RIvL6+7N2ARIetwFqbi0ksyna2tCYj4M+TmQk4OXLgAV6kHJmVv1qxZrF69mg0bNpSa8TRs2DD69etH//79+eKLLxgxYgTLli1jxIgRtG/fnqVLl1JUVEReXp45iXTgwAH69OnDvHnz8PX1Zfbs2Tg7O5OQkEBBQQHBwcF07tyZHTt2cODAAXbv3k1GRgbu7u53pXi/m62bkj8iv1MySERERCqFDdG7+XjwSgrOF2KgmObpP3FmWippT7Sg0QNFcOQIVMDOOxEREZw9e5aLFy8yfvx4HnrooXKPQeR+dmlG0OWyXnwNgJr+deHgQdi5E6ytyzs0uY4tW7awZMkSAJ577jlee63k32z9+vUsWLAAKNlVzdnZmTNnzpCZmUn37t1ZvHgxHh4eAKxZs4Zdu3aZ6wFlZ2dz6NAhNm3axDPPPIOlpSX16tXj8ccfr4ARitzflAwSERGRSmHBuA0UnC8EIJwEupJAalFd0tfvoVHXhrB7d4Ukg/5Yi0RE7i4rW6urJoSsbK3AyQkCAkr+ABw+XM7Ryc0yXFaU+WqcnZ155JFH2Lx5szkZZDKZ+I6oPdYAACAASURBVOijjwgPDy917A8//HDD/kTkzqhmkIiIiFQKWenZ5sdrCGACz/Edbdh0rknJB8GLFyswOhEpKy5NXDBYlP7gb7Aw4NLEpYIikpvRpk0bvvnmGwCio6Np27YtAGFhYcycOROAoqIicnJyALCxsWHZsmUsWLCAf//73wCEh4czc+ZMCgtLvgg4ePAg586do127dnzzzTcUFRVx8uRJNmzYUN7DE7nvaWaQiIiIVAouDZzJPFqSECrGktM4cxpnchu6wegRFRydiJQV5zolRdkv303MpYmLuV0qB6utW2kaG0vi7wX9Z8yYQVRUFO+//z61a9dm3rx5AEyfPp3Bgwczd+5cLC0tmTlzJnXr1gWgWrVqfP/993Tq1Ilq1aoxcOBA0tLS8Pf3x2QyUbt2bZYtW0aPHj1Yv349Xl5eNGvWjPbt21fYuEXuV0oGiYiISKXQb3IHc82gS2wdrOk3uUMFRiUi5cG5jrOSP5XIvuho4saNIyc9HacGDYj9y1+oERNDsJUVwVOmANCoUSPWr19/xbl16tRh+fLlV7Tv2bMHgBo1apCQkGBunzJlClN+7/NyH3/88d0ajohchZaJiYiISKXQoa8Xw2Z3pXZDZwwGqN3QmWGzu9Khr3bvEhEpL/uio1kzeDA5R4+CyUSNo0e58N57ZJ09CyYT7N9f0SGKyF2gmUEiIiJSaXTo66Xkj4hIBYobNw7j+fMAuAN+wOmiIrI2bMClWzfYuhVatarQGEXkzikZJCIiIiIiIgDkpKebHx8AjgM2gMO5c7i1bw9W+ggpcj/QT7KIiIiIiIgA4NSgQckSMaAIuLTPo1PDhvDCCxUWl4jcXaoZJCKVXvXfd624U2lpaXh6et6VvkRERETuR20nT8bKwaFUm5WDA20nT66giESkLCgZJCJSjoxGY0WHICIiInJN7n370nn27JKZQAYDTg0b0nn2bNz79q3o0ETkLlIySETuGXl5eYSFheHv74+Xl5d529K0tDSaN2/OoEGD8PDwoHPnzly4cAGApKQkfHx8CAoK4pNPPjH3lZ+fz/PPP4+Xlxd+fn5s2LABgCeeeIJdu3YB4Ofnx6RJkwAYP348n3/+ObGxsYSGhtKrVy/c3Nzo27cvJpPJfK327dvTokULwsPDOXnyJAChoaG88cYbtG/fnunTp5fPmyUiIiJym9z79mVwWhqjiosZnJamRJDIfUjJIBG5Z9jZ2bF06VK2b9/Ohg0bePXVV82JmEOHDvHSSy+xd+9eatSoweLFiwF4/vnnmTFjBlu2bCnV16XE0O7du/n666/p378/+fn5tGvXjp9++omcnBysrKzYvHkzAHFxcYSEhACwY8cOpk2bxr59+zh8+DCbN2+msLCQ4cOHs2jRIpKSkoiKimLcuHHm6509e5aNGzfy6quvlvn7JCIiIiIicj0qIC0i9wyTycQbb7zBpk2bsLCw4Pjx42RkZADQuHFjfH19AWjRogVpaWlkZ2dz9uxZ2rdvD8Bzzz3HqlWrgJLkzvDhwwFwc3OjYcOGHDx4kJCQEGbMmEHjxo3p2rUr//nPfzh//jxpaWm4urpy8uRJWrZsSf369QHw9fUlLS2NGjVqsGfPHjp16gRAUVERdevWNcceGRlZPm+SiIiIiIjIDSgZJCL3jOjoaDIzM0lKSsLa2ppGjRqRn58PgK2trfk4S0tLLly4gMlkwmAwXLWvSzOK/igwMJDExESaNGlCp06dyMrKYs6cObRo0cJ8zB+vZTQaMZlMeHh4XDED6ZJq1ard8nhFRERERETKgpaJicg9Izs7m0aOjlifO8eGDRs4+vu2p9dSo0YNnJ2diYuLA0qSSZe0a9fO/PzgwYOkp6fj6uqKjY0NjzzyCAsXLqR169aEhIQwdepU8xKxa3F1dSUzM9OcDCosLGTv3r13MlwREREREZEyoWSQiNwz+rVoQfB33zHG35/o6Gjc3NxueM68efN46aWXCAoKwt7e3tw+dOhQioqK8PLyIjIykvnz55tn/ISEhFCnTh0cHBwICQnh119/vWEyyMbGhkWLFjFmzBh8fHzw9fUlPj7+zgYsIiIiIiJSBgzXWipRlgICAkyJiYnlft2bcWmnIJH7XWW910/sjeFQ7ETyc37Fzqk+TUMnUs/9z7B6NXz9NdjZQb16MHFiRYcq94jKeq+L3G2616Uq0H0uVYXudbldBoMhyWQyBdzoONUMEpFK48TeGPb+MIxiY8m28Pk5xzj47VCc9n9O9YJq8Nhj4OAA6elQUACX1e4RERERERGRm6NlYiJSaRyKnWhOBF1SbMznhGkXdO1akgA6dgwuXIATJyooShERERERkXubZgaJSKWRn/PrFW2F1Qwc8TtPs0GDwGSCjAw4ehQeeKACIpSqxNLSEi8vL4xGI82bN+fLL7/EwcHhjvpMTExkwYIFzJgx45bPXbZsGc2aNcPd3f2OYhARERER0cwgEak07JzqX7/dYICHHoJWrcDJqRwjk6rI3t6e5ORk9uzZg42NDbNmzSr1uslkori4+Jb6DAgIuK1EEJQkg/bt23db54qIiIiIXE7JIBGpNJqGTsTCyr5Um4WVPU1DJ1ZMQCK/CwkJ4ZdffiEtLY3mzZszdOhQ/P39OXbsGGvWrCEoKAh/f3969+5NXl4eAAkJCbRp0wYfHx9atmxJbm4usbGxREREADBx4kSioqIIDQ2lSZMmpZJECxYswNvbGx8fH5577jni4+P57rvvGD16NL6+vqSmplbI+yAiIiIi9wctExORSqOeRyTAlbuJ/d4uUhGMRiOrVq2iS5cuABw4cIB58+bx6aefkpWVxTvvvMPatWupVq0a//d//8eHH37I66+/TmRkJDExMQQGBpKTk4O9vf0VfaekpLBhwwZyc3NxdXVlyJAhHDx4kMmTJ7N582ZcXFw4ffo0tWrVolu3bkRERNCrV6/yfgtERERE5D6jZJCIVCr1PCKV/JFK4cKFC/j6+gIlM4P++te/cuLECRo2bEjr1q0B2Lp1K/v27SM4OBiAixcvEhQUxIEDB6hbty6BgYEAOF1jWWPXrl2xtbXF1taWBx98kIyMDNavX0+vXr1wcXEBoFatWmU9VBERERGpYpQMEhERuYpLNYP+qFq1aubHJpOJTp068fXXX5c6ZteuXRgMhhtew9bW1vzY0tISo9GIyWS6qXNFRERERG6XagaJiIjcptatW7N582Z++eUXAM6fP8/Bgwdxc3PjxIkTJCQkAJCbm4vRaLypPsPCwli4cCGnTp0C4PTp0wA4OjqSm5tbBqMQERERkapGySAREZHr2bMHLly46ku1a9dm/vz5PPPMM3h7e9O6dWtSUlKwsbEhJiaG4cOH4+PjQ6dOncjPz7+py3l4eDBu3Djat2+Pj48Pr7zyCgB9+vTh/fffx8/PTwWkRUREROSOGEwmU7lfNCAgwJSYmFju170ZsbGxhIaGVnQYch9atmwZzZo1w93d/aqvz5o1CwcHB/r163fV19PS0oiPj+cvf/nLLV13wIABVy06q3tdqoqbvdezM7LJOpyFscCIla0VLo0fwDkxDhYsgFdfhVatyj5YkTug3+tSFeg+l6pC97rcLoPBkGQymQJudJxmBoncJpPJRHFx8U0fv2zZMvbt23fV14xGIy+++OI1E0FQkgz697//fctxisiNZWdkk3EgA2NByVIu4/kCzn36BRfnfwU1akAl/QJDREREROR2KBkkcgvS0tJo3rw5Q4cOxd/fn6+++oqgoCD8/f3p3bs3eXl5ALz++uu4u7vj7e3NqFGjiI+P57vvvmP06NH4+vqSmppKaGgob7zxBu3bt2f69OlMnDiRqVOnAvx/e/ce7VVd54//uYEjIALqSIxkgqZkxE0GjUsQaF4Ku+Dla0YmmmMub+X8KjW7OCXjOLnU8VJWXy/fjBHMUmfUykEh7yOoCHgB0TlQYCoh9ztn//7AThKKiAc+evbjsdZZ67Pfn/1579f+rPeCw5P3+70ze/bsfOITn0ifPn3Sr1+/PP/88zn33HNz//33p2/fvrnsssuyfv36fOMb38gBBxyQ3r175yc/+UmSDSHVGWeckR49emTEiBF5+eWXa/Z9wXvFghcWpGx4baZsWeZ9l/9zOvz21izfoUPSqVMybVqyhXv+AADAu52nicHbNHPmzFx//fX5/ve/nyOPPDITJkxIu3btcvHFF+fSSy/NGWeckVtvvTXPPvtsiqLIokWLsvPOO+czn/nMJsu1Fi1alN///vdJkgsuuKCxfdSoUTn33HMzcuTIrFq1Kg0NDfnXf/3XXHLJJbnjjjuSJD/96U/TsWPHTJ48OatXr87gwYNz6KGH5oknnsjMmTMzffr0vPTSS+nRo0dOOumk7fodwXvNX2YEJUnKMmt2/0DW7NE1dQteTubNSxoakj/8Idlrr9oVCQAATUQYBG9T165dM2DAgNxxxx15+umnM3jw4CTJmjVrMnDgwHTo0CFt2rTJySefnBEjRuSII454076OPfbYTdqWLl2aefPmZeTIkUmSNm3avOFn77777kybNi233HJLkmTx4sV57rnnct999+W4445Ly5Yt06VLlxx00EHv9Jah2WvVutVfA6EWLbLoC//Y2L5rr87Jyy8nXbrUsEIAAGg6wiB4m9q1a5dkw3KsQw45JDfddNMm5zz66KO55557Mm7cuFx11VW59957N9vX623ppu5lWebKK6/MYYcdtlH7XXfdlaIotqgPYIPd9t4tL8186a9LxZIULYrstvduyU47bfgBAIBmwp5BsJUG9uyZTJiQ2c89lyRZsWJFZs2alWXLlmXx4sX51Kc+lcsvvzxTp05NkrRv3z5Lly59y347dOiQPfbYI7fddluSZPXq1VmxYsUmnz/ssMPy4x//OGvXrk2SzJo1K8uXL8/QoUMzbty4rF+/Pi+++GImTpzY1LcOzU7Hzh3T+UOd06r1hv8jadW6VTp/qHM6du5Y48oAAKDpmRkEmzH2kbE5/9bzM3fh3Oy565752oCvbXjjT3/Kbtdck8v69MnxxxyTl157qtiFF16Y9u3b57Of/WxWrVqVsixz2WWXJUk+//nP5x//8R9zxRVXNC7tejM33nhjvvKVr+S73/1u6urq8stf/jK9e/dOq1at0qdPn4wePTpf/epXU19fn379+qUsy3Tq1Cm33XZbRo4cmXvvvTe9evVK9+7d8/GPf3ybfkfQXHTs3FH4AwBAJRRbuiSlKfXv37+c8i59TO+kSZMybNiwWpfBu8DYR8bmlBtPyYo1Kxrbdtxhx4z72Pfy6d+/kLRokaxcmZx+etK/fw0r3TrGOlVhrFMVxjpVYJxTFcY6W6soisfKsnzLf6BaJgZv4vxbz98oCGq9Ljlh6orUfe+CZOHCpHXrpFWr5Nlna1ckAAAAvE3CIHgTcxfO3eh4XYvkgc7J+T1WJl/4QrLrrsnatUl9fW0KBAC2yr/8y7/UugQAqClhELyJPXfdc6Pj9S2S6X+X/PlDXZPPfS75zneSn/wkOe20GlUIAM3Lgvmrt2n/ZVmmoaFBGARA5QmD4E2MGTkmO+6w40ZtO+6wY8aMHPPXhtatN8wQAgDekUWvrMm4H/4h8+pfzYgRI9KnT5/07Nkz48ePT7du3fKtb30rAwcOTP/+/fP444/nsMMOywc/+MFcc801SZJly5bl4IMPTr9+/dKrV6/cfvvtSZL6+vp8+MMfzmmnnZZ+/frly1/+clauXJm+fftm1KhRtbxlAKgZTxODNzFqwIZfEF//NLExI8c0tgMATWf21GVJkrHX3Z4uXbrkzjvvTJIsXrw455xzTj7wgQ/k4Ycfztlnn53Ro0fnwQcfzKpVq/KRj3wkp556atq0aZNbb701HTp0yIIFCzJgwIB85jOfSZLMnDkz119/fX70ox8lSX75y19m6tSptblRAHgXEAbBZowaMEr4AwDbwTOTlyZJimVdM2HCP+ecc87JEUcckSFDhiRJY7DTq1evLFu2LO3bt0/79u3Tpk2bLFq0KO3atcu3vvWt3HfffWnRokXmzZuXl156KUnStWvXDBgwoDY3BgDvQsIgAABqasnCtVn26rokyU4t98zECY/kgYf/O+edd14OPfTQJEnr1q2TJC1atGh8/ZfjdevWZezYsXnllVfy2GOPpa6uLt26dcuqVauSJO3atdvOdwQA727vaM+goiiOKYriqaIoGoqieMvn2AMAwN96/sllSbHh9aLlL+VPsxvyxV698p3Ro/P4449vUR+LFy/O+973vtTV1WXixImZM2fOm55bV1eXtWvXNkXpAPCe9E43kJ6R5Mgk9zVBLQAAVNAzjy7N+rVlkuSPL87Mt0cNyl3DhmX697+fb3/721vUx6hRozJlypT0798/Y8eOzX777fem555yyinp3bu3DaQBqKx3tEysLMtnkqQoiqapBgCAZuk3N7yYP85a+YbvrVvb0Pj6wF32yum7H5B1bdvng6sW53/Gtsj5X7g3t166JMmS7NH9sFx11ejG8+vr6xtfP/zww2/Y/4wZMzY6vvjii3PxxRdv9b0AwHudR8sDALDN9T9k19S1bpG1axqyeuXGP+s3bBeUv3v56fSf/OOkocyahro0rGvIzv/7RFavbMjaNQ2pa90i/Q/ZtbY3AgDNQFGW5eZPKIoJSf7+Dd46vyzL2187Z1KSr5dlOWUz/ZyS5JQk6dy58z+MGzdua2veppYtW5addtqp1mXANmesUxXGOlXxXhjrZZksfXVdVq9cn7zBr6B9fn511rTrkKJI6lYsT93KFVncZc88d8TRad22Zdrv0iompFfbe2GcQ1Mw1tlaw4cPf6wsy7fc0/ktw6AtsSVh0Ov179+/nDJli07d7iZNmpRhw4bVugzY5ox1qsJYpyreS2N91hNLM3Hcy1m3tszmfhUtUqauVZnhX9g9++7ffvsVyLvWe2mcwzthrLO1iqLYojDIo+UBANiuuu/fPn/ftU3+85r5Wbxg7RsGQkWRdOy0Qz7zlS7psGvd9i8SAJqxd/po+ZFFUfwxycAkdxZF8bumKQsAgOasw651adOu5ZvODCrLpG27loIgANgG3unTxG5NcmsT1QIAQEWsWrE+L/9h1WbPeWnuqqxeuT6t27bcTlUBQDV4mhgAANtd/VPL07LlX3eDbrVDkR3bt0yrHf7a1rJVkf+dsbwW5QFAsyYMAgBgu3vm0aVZu2bDGrFWdUUGjvi7nHhBtwwc8XdpVbchEFq7usyzk5fWskwAaJZsIA0AwHa1ZlVD5r+wMi1bJTu2b5URJ++e3bq0TpL0Gbpz3r9P29z5f1/MiqXrMu/5lVmzuiE7tPZ/mADQVPytCgDAdjXnmeUpG5J992+fL5y7Z2MQ9Be7dWmdL5y7Z/bp2z5lQzLnaUvFAKApmRkEAMB2tUvnHTLi5N2z10favek5dTu0yCGjOmefvjul/S5+ZQWApuRvVgAAtqvdurTeZDbQm9lcYAQAbB3LxAAAAAAqRBgEAAAAUCHCIAAAAIAKEQYBAAAAVIgwCAAAAKBChEEAAAAAFSIMAgAAAKgQYRAAAABAhQiDAAAAACpEGAQAAABQIcIgAAAAgAoRBgEAAABUiDAIAAAAoEKEQQAAAAAVIgwCAAAAqBBhEAAAAECFCIMAAAAAKkQYBAAAAFAhwiAAAACAChEGAQAAAFSIMAgAAACgQoRBAAAAABUiDAIAAACoEGEQwGZMmjQpDz30UOPx6NGjc8stt2zz695www2ZP3/+Nr8OAABQPcIggM342zBoexEGAQAA24owCGi2li9fnhEjRqRPnz7p2bNnxo8fn3vuuSf7779/evXqlZNOOimrV69OknTr1i0LFixIkkyZMiXDhg1LfX19rrnmmlx22WXp27dv7r///iTJfffdl0GDBmXvvfdunCV02mmn5T//8z+TJCNHjsxJJ52UJLn22mvz7W9/O0nyi1/8IgceeGD69u2br3zlK1m/fn3Wr1+f0aNHp2fPnunVq1cuu+yy3HLLLZkyZUpGjRqVvn37ZuXKldv1ewMAAJo3YRDQbP32t79Nly5d8uSTT2bGjBk5/PDDM3r06IwfPz7Tp0/PunXr8uMf//hNP9+tW7eceuqpOfvsszN16tQMGTIkSfLiiy/mgQceyB133JFzzz03STJ06NDGsGjevHl5+umnkyQPPPBAhgwZkmeeeSbjx4/Pgw8+mKlTp6Zly5YZO3Zspk6dmnnz5mXGjBmZPn16TjzxxBx99NHp379/4/tt27bdxt8UAABQJcIgoNnq1atXJkyYkHPOOSf3339/6uvrs9dee6V79+5JkhNOOCH33Xff2+73c5/7XFq0aJEePXrkpZdeSpIMGTIk999/f55++un06NEjnTt3zosvvpiHH344gwYNyj333JPHHnssBxxwQPr27Zt77rknL7zwQvbee++88MILOfPMM/Pb3/42HTp0aNLvAAAA4G+1qnUBANtK9+7d89hjj+Wuu+7Keeedl0MPPfRNz23VqlUaGhqSJKtWrdpsv61bt258XZZlkuT9739/Xn311fz2t7/N0KFDs3Dhwtx8883Zaaed0r59+5RlmRNOOCEXXXTRJv09+eST+d3vfperr746N998c6677rqtuV0AAIAtYmYQ0GzNnz8/O+64Y774xS/m61//eh566KHU19dn9uzZSZIbb7wxH//4x5NsWBL22GOPJUl+9atfNfbRvn37LF26dIuuN3DgwFx++eUZOnRohgwZkksuuaRxadnBBx+cW265JS+//HKSZOHChZkzZ04WLFiQhoaGHHXUUfnBD36Qxx9//G1fFwAA4O0QBgHN1vTp0xs3bP73f/7nXDVsWG742c9yzDHHpFevXmnRokVOPfXUJMn3vve9fPWrX82QIUPSsmXLxj4+/elP59Zbb91oA+k3M2TIkKxbty777LNP+vXrl4ULFzaGQT169MiFF16YQw89NL17984hhxySF198MfPmzcuwYcPSt2/fjB49unHm0OjRo3PqqafaQBoAAGhylokBzcbYR8bm/FvPz9yFc7PnrntmzMgxmTZtWlJfn1x+efLkk9nn85/PE088sclnhwwZklmzZm3S3r179w19vO6811u2bFnj6y9/+cv58pe/nCSpq6vL8uXLNzr32GOPzbHHHrvJNf4yG+j1jjrqqBx11FGbv2EAAICtIAwCmoWxj4zNKTeekhVrViRJ5iyck1NuPCV/N2N2Dn94btKuXdK6dTJ3btKtW22LBQAAqCHLxIBm4fxbz28Mgv5izKQVKS7+12T58mTt2qRVq+Spp2pUIQAAwLuDmUFAszB34dxN2sb0TerKVZl/1teS6dOTadOS1zZwBgAAqCphENAs7LnrnpmzcM5GbQt2TLru2jUZMGDDT1kmq1fXqEIAAIB3B8vEgGZhzMgx2XGHHTdq23GHHTNm5Ji/NhRF0qbNdq4MAADg3UUYBDQLowaMyk+P/2m67to1RYp03bVrfnr8TzNqwKhalwYAAPCuYpkY0GyMGjBK+AMAAPAWzAwCAAAAqBBhEAAAAECFCIMAAAAAKkQYBAAAAFAhwiAAAACAChEGAQAAAFSIMAgAAACgQoRBAAAAABUiDAIAAACoEGEQAAAAQIUIgwAAAAAqRBgEAAAAUCHCIAAAAIAKEQYBAAAAVIgwCAAAAKBChEEAAAAAFSIMAgAAAKgQYRAAAABAhQiDAAAAACpEGAQAAABQIcIgAAAAgAoRBgEAAABUiDAIAAAAoEKEQQAAAAAVIgwCAAAAqBBhEAAAAECFCIMAAAAAKkQYBAAAAFAhwiAAAACAChEGAQAAAFSIMAgAAACgQoRBAAAAABUiDAIAAACoEGEQAAAAQIUIgwAAAAAqRBgEAAAAUCHCIAAAAIAKEQYBAAAAVIgwCAAAttCUKVNy1llnbfac+fPn5+ijj97qa1x++eVZsWLFVn8eAN6KMAgAgMoqyzINDQ1bfH7//v1zxRVXbPacLl265JZbbtnqmoRBAGxrwiAAACqlvr4+H/7wh3PaaaelX79+ufHGGzNw4MD069cvxxxzTJYtW5YkmTx5cgYNGpQ+ffrkwAMPzNKlSzNp0qQcccQRSZILLrggxx9/fA466KDsu++++dnPftbYf8+ePZMk69evzze+8Y0ccMAB6d27d37yk58kSSZNmpRhw4bl6KOPzn777ZdRo0alLMtcccUVmT9/foYPH57hw4dn/fr1GT16dHr27JlevXrlsssuq8E3BkBz06rWBQAAwPY2c+bMXH/99fn+97+fI488MhMmTEi7du1y8cUX59JLL825556bY489NuPHj88BBxyQJUuWpG3btpv0M23atDzyyCNZvnx59t9//4wYMWKj96+99tp07NgxkydPzurVqzN48OAceuihSZInnngiTz31VLp06ZLBgwfnwQcfzFlnnZVLL700EydOzG677ZbHHnss8+bNy4wZM5IkixYt2vZfDgDNnjAIAIDK6dq1awYMGJA77rgjTz/9dAYPHpwkWbNmTQYOHJiZM2dm9913zwEHHJAk6dChwxv289nPfjZt27ZN27ZtM3z48Dz66KPp27dv4/t33313pk2b1rhsbPHixXnuueeyww475MADD8wee+yRJOnbt2/q6+vzsY99bKP+995777zwwgs588wzM2LEiMYgCQDeCWEQAACV065duyQb9gw65JBDctNNN230/rRp01IUxVv287fn/O1xWZa58sorc9hhh23UPmnSpLRu3brxuGXLllm3bt0m/e+yyy558skn87vf/S5XX311br755lx33XVvWRcAbI49gwAAqKwBH/1oZt93X2bPnp0kWbFiRWbNmpX99tsv8+fPz+TJk5MkS5cufcOw5vbbb8+qVavy5z//OZMmTWqcSfQXhx12WH784x9n7dq1SZJZs2Zl+fLlm62pb8jmTgAAEf1JREFUffv2Wbp0aZJkwYIFaWhoyFFHHZUf/OAHefzxx9/xPQOAmUEAAFTTmjXp9F//ldv23z/H/p//kyWvhT0XXnhhunfvnvHjx+fMM8/MypUr07Zt20yYMGGTLg488MCMGDEic+fOzXe+85106dIl9fX1je+ffPLJqa+vT79+/VKWZTp16pTbbrtts2Wdcsop+eQnP5ndd989l19+eU488cTGJ55ddNFFTXf/AFRWUZbldr9o//79yylTpmz3626JvzzZAZo7Y52qMNapCmP9zf3611Ny0UV3Zf78V9Olyy4577xP5ciD9kmuuip57rmkKJJvfSvp3v1t9XvBBRdkp512yte//vVtVDl/yzinKox1tlZRFI+VZdn/rc4zMwgAgGbr17+ekm984+asXLlhmda8Py7ML0//Yfr2XJO9O7dLPvjBZO7c5IUX3nYYBADvVcIgAACarYsuuqsxCEqSVmnIrisX55aZLfLNPh9M5sxJVq1Kpk1LDj/8bfV9wQUXNHG1ALB9CIMAAGi25s9/daPjdUXL3Lrjh1OsT755ySXJ4sUbAqE32BwaAJorYRAAAM1Wly67ZN68V9+wPUnSsWPSu/d2rgoAasuj5QEAaLbOO+9Tadu2bqO2tm3rct55n6pRRQBQe2YGAQDQbB155IYHqmzyNLEj3/JBKwDQbAmDAABo1o48sr/wBwBexzIxAAAAgAoRBgEAAABUiDAIAAAAoEKEQQAAAAAVIgwCAAAAqBBhEAAAAECFCIMAAAAAKkQYBAAAAFAhwiAAAACAChEGAQAAAFSIMAgAAACgQoRBAAAAABUiDAIAAACoEGEQAAAAQIUIgwAAAAAqRBgEAAAAUCHCIAAAAIAKEQYBAAAAVIgwCAAAAKBChEEAAAAAFSIMAgAAAKgQYRAAAABAhQiDAAAAACpEGAQAAABQIcIgAAAAgAoRBgEAAABUiDAIAAAAoEKEQQAAAAAVIgwCAAAAqBBhEAAAAECFCIMAAAAAKkQYBAAAAFAhwiAAAACAChEGAQAAAFSIMAgAAACgQoRBAAAAABUiDAIAAACoEGEQAAAAQIUIgwAAAAAqRBgEAAAAUCHCIAAAAIAKEQYBAAAAVIgwCAAAAKBChEEAwDZVX1+fnj171roMAABeIwwCAAAAqBBhEADwln7+85+nd+/e6dOnT0aOHJm99tora9euTZIsWbIk3bp1y9q1azN79ux84hOfSJ8+fdKvX788//zzG/WzatWqnHjiienVq1f233//TJw4MUlyww035Mgjj8zhhx+efffdN9/85jcbP3P33Xdn4MCB6devX4455pgsW7Zs+904AEAzJAwCADbrqaeeypgxY3LvvffmySefzLXXXpthw4blzjvvTJKMGzcuRx11VOrq6jJq1KicfvrpefLJJ/PQQw9l991336ivq6++Okkyffr03HTTTTnhhBOyatWqJMnUqVMzfvz4TJ8+PePHj88f/vCHLFiwIBdeeGEmTJiQxx9/PP3798+ll166fb8AAIBmplWtCwAA3t3uvffeHH300dltt92SJLvuumtOPvnk/Nu//Vs+97nP5frrr8/PfvazLF26NPPmzcvIkSOTJG3atNmkrwceeCBnnnlmkmS//fZL165dM2vWrCTJwQcfnI4dOyZJevTokTlz5mTRokV5+umnM3jw4CTJmjVrMnDgwG1+zwAAzZkwCADYrLIsUxTFRm2DBw9OfX19fv/732f9+vXp2bNnlixZskV9vZnWrVs3vm7ZsmXWrVuXsixzyCGH5Kabbtr6GwAAYCOWiQEAm3XwwQfn5ptvzp9ffjlZsSILFy5MknzpS1/KcccdlxNPPDFJ0qFDh+yxxx657bbbkiSrV6/OihUrNupr6NChGTt2bJJk1qxZmTt3bj70oQ+96bUHDBiQBx98MLNnz06SrFixonEmEQAAW0cYBABs1kc+8pF8+5xzclWfPrnsgx/MP/3TPyVJRo0alVdffTXHHXdc47k33nhjrrjiivTu3TuDBg3Kn/70p436Ou2007J+/fr06tUrxx57bG644YaNZgT9rU6dOuWGG27Icccdl969e2fAgAF59tlnt82NAgBUhGViAMAmnl39bB5a9VCWNizNzmva5PCF9el8yCFJy5bJv/97kg37/xx99NHZeeedGz+377775t57792kvxkzZiTZsI/QDTfcsMn7o0ePzujRoxuP77jjjsbXBx10UCZPntxEdwYAgDAIANjIs6ufzT0r7sm6rEubBcvyoZ/elYXzFqflXv+Q3eavSGbNypn/7//lN7/5Te66665alwsAwNskDAIANvLQqoeyLuuSJB+8Y1re/8gLWbLnrvnz3GnZbXmnZPLkXHnllTWuEgCArSUMAgA2srRhaePrp0YPylMnDMwOS1Zmx1eW5UOrDk9a2HIQAOC9TBgEAGykfYv2GwVCKYqs6bhjWu/SOek4pHaFAQDQJPzXHgCwkUFtBqXV3/x/Uau0yqA2g2pUEQAATcnMIABgI/u13i9JGp8m1r5F+wxqM6ixHQCA9zZhEACwif1a7yf8AQBopiwTAwAAAKgQYRAAAABAhQiDAAAAACpEGAQAAABQIcIgAAAAgAoRBgEAAABUiDAIAAAAoEKEQQDwHjZp0qQ89NBDtS4DAID3EGEQALyHCYMAAHi7WtW6AADgr+rr63PEEUdkxowZSZJLLrkky5Yty6RJk9K3b988+uijWbJkSa677rq8733vyzXXXJOWLVvmF7/4Ra688srst99+OfXUUzN37twkyeWXX57BgwfnggsuyP/+7//mxRdfzKxZs3LppZfmkUceyW9+85u8//3vz3/913+lrq4u3bp1y7HHHpuJEycmSf7jP/4j++yzT+bMmZOTTjopr7zySjp16pTrr78+e+65Z82+JwAAtp6ZQQDwHrF8+fI89NBD+dGPfpSTTjop3bp1y6mnnpqzzz47U6dOzZAhQ/LVr341Z599diZPnpxf/epXOfnkkxs///zzz+fOO+/M7bffni9+8YsZPnx4pk+fnrZt2+bOO+9sPK9Dhw559NFHc8YZZ+RrX/takuSMM87Il770pUybNi2jRo3KWWedtd3vHwCApmFmEAC8Rxx33HFJkqFDh2bJkiVZtGjRJudMmDAhTz/9dOPxkiVLsnTp0iTJJz/5ydTV1aVXr15Zv359Dj/88CRJr169Ul9fv8l1jjvuuJx99tlJkocffji//vWvkyTHH398vvnNbzb9DQIAsF0IgwDgXaRVq1ZpaGhoPF61alXj66IoNjr3b4+TpKGhIQ8//HDatm27yXutW7dOkrRo0SJ1dXWNn2/RokXWrVv3hv2+0TU21w4AwLufZWIA8C7SuXPnvPzyy/nzn/+c1bNm5c833tj43vjx45MkDzzwQDp27JiOHTumffv2jTN/kuTQQw/NVVdd1Xg8derUt13DX64zfvz4DBw4MEkyaNCgjBs3LkkyduzYfOxjH3v7NwcAwLuCmUEAUEMTx07Pz8+fmAVzF2e3PTvmS2OG57vf/W6+2LdvzmxoyMi2bXPfa7N2dtlllwwaNKhxA+kk+fSnP52jjz46t99+e6688spcccUVOf3009O7d++sW7cuQ4cOzTXXXPO2alq9enU++tGPpqGhITfddFOS5IorrshJJ52UH/7wh40bSAMA8N4kDAKAGpk4dnquOuXOrF6xNknyypzFueof78i3z35fzjrooKRTp2Thwgw9/vhMeOCBHHXUUbnooos26qN79+6ZNm3aRm1/mdnzehdccMFGx8uWLXvT904//fR873vf26itW7duuffee9/uLQIA8C4kDAKAGvn5+RMbg6Ak6ZyF+fjKJ1Ne+koysleyenWydm0yc2YNqwQAoLkRBgFAjSyYu3ij49Wpy//kw3lkVY/86MTPJk89tSEImjs3kyZN2i41vf6pYgAANE/CIACokd327JhX5vw1EFqU9lmU9unUtWNyyCEbfsoyed2TvgAA4J3yNDEAqJEvjRme1jvWbdTWese6fGnM8L82FEVSVxcAAGgqZgYBQI0MH9UrSTZ5mthf2gEAYFsQBgFADQ0f1Uv4AwDAdmWZGAAAAECFCIMAAAAAKkQYBAAAAFAhwiAAAACAChEGAQAAAFTIOwqDiqL4YVEUzxZFMa0oiluLoti5qQoDAAAAoOm905lB/52kZ1mWvZPMSnLeOy8JAAAAgG3lHYVBZVneXZblutcOH0myxzsvCQAAAIBtpSn3DDopyW+asD8AAAAAmlhRluXmTyiKCUn+/g3eOr8sy9tfO+f8JP2THFm+SYdFUZyS5JQk6dy58z+MGzfundS9zSxbtiw77bRTrcuAbc5YpyqMdarCWKcKjHOqwlhnaw0fPvyxsiz7v9V5bxkGvWUHRXFCklOTHFyW5Yot+Uz//v3LKVOmvKPrbiuTJk3KsGHDal0GbHPGOlVhrFMVxjpVYJxTFcY6W6soii0Kg1q9w4scnuScJB/f0iAIAAAAgNp5p3sGXZWkfZL/LopialEU1zRBTQAAAABsI+9oZlBZlvs0VSEAAAAAbHtN+TQxAAAAAN7lhEEAAAAAFSIMAgAAAKgQYRAAAABAhQiDAAAAACpEGAQAAABQIcIgAAAAgAoRBgEAAABUiDAIAAAAoEKEQQAAAAAVIgwCAAAAqBBhEAAAAECFCIMAAAAAKkQYBAAAAFAhwiAAAACAChEGAQAAAFSIMAgAAACgQoRBAAAAABUiDAIAAACoEGEQAAAAQIUIgwAAAAAqRBgEAAAAUCHCIAAAAIAKEQYBAAAAVIgwCAAAAKBChEEAAAAAFSIMAgAAAKgQYRAAAABAhQiDAAAAACpEGAQAAABQIcIgAAAAgAoRBgEAAABUiDAIAAAAoEKEQQAAAAAVUpRluf0vWhSvJJmz3S+8ZXZLsqDWRcB2YKxTFcY6VWGsUwXGOVVhrLO1upZl2emtTqpJGPRuVhTFlLIs+9e6DtjWjHWqwlinKox1qsA4pyqMdbY1y8QAAAAAKkQYBAAAAFAhwqBN/bTWBcB2YqxTFcY6VWGsUwXGOVVhrLNN2TMIAAAAoELMDAIAAACoEGHQGyiK4gdFUUwrimJqURR3F0XRpdY1wbZQFMUPi6J49rXxfmtRFDvXuiZoakVRHFMUxVNFUTQUReGpHDQ7RVEcXhTFzKIoZhdFcW6t64FtoSiK64qieLkoihm1rgW2paIoPlAUxcSiKJ557feXr9a6JponYdAb+2FZlr3Lsuyb5I4k3611QbCN/HeSnmVZ9k4yK8l5Na4HtoUZSY5Mcl+tC4GmVhRFyyRXJ/lkkh5JjiuKokdtq4Jt4oYkh9e6CNgO1iX5/8qy/HCSAUlO9+c624Iw6A2UZbnkdYftkthYiWapLMu7y7Jc99rhI0n2qGU9sC2UZflMWZYza10HbCMHJpldluULZVmuSTIuyWdrXBM0ubIs70uysNZ1wLZWluWLZVk+/trrpUmeSfL+2lZFc9Sq1gW8WxVFMSbJl5IsTjK8xuXA9nBSkvG1LgKAt+X9Sf7wuuM/JvlojWoBoAkVRdEtyf5J/qe2ldAcVTYMKopiQpK/f4O3zi/L8vayLM9Pcn5RFOclOSPJ97ZrgdBE3mqsv3bO+dkwJXXs9qwNmsqWjHNopoo3aDOjGeA9riiKnZL8KsnX/mblCjSJyoZBZVl+YgtP/Y8kd0YYxHvUW431oihOSHJEkoPLsvQPCN6T3saf6dDc/DHJB153vEeS+TWqBYAmUBRFXTYEQWPLsvx1reuhebJn0BsoimLf1x1+JsmztaoFtqWiKA5Pck6Sz5RluaLW9QDwtk1Osm9RFHsVRbFDks8n+c8a1wTAViqKokhybZJnyrK8tNb10HwVJgJsqiiKXyX5UJKGJHOSnFqW5bzaVgVNryiK2UlaJ/nza02PlGV5ag1LgiZXFMXIJFcm6ZRkUZKpZVkeVtuqoOkURfGpJJcnaZnkurIsx9S4JGhyRVHclGRYkt2SvJTke2VZXlvTomAbKIriY0nuTzI9G/49miTfKsvyrtpVRXMkDAIAAACoEMvEAAAAACpEGAQAAABQIcIgAAAAgAoRBgEAAABUiDAIAAAAoEKEQQAAAAAVIgwCAAAAqBBhEAAAAECF/P90m0L3VMamSwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x1440 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z8a_-xZz8BxG"
      },
      "source": [
        "#### II.2.3 Projection Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vUnIC2tQ8BxG",
        "colab": {}
      },
      "source": [
        "weight_matrix_proj = model.projection.weight\n",
        "# some verbs, and nouns\n",
        "proj_id_list, proj_token_list = cos_similarity(weight_matrix_proj, input_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ThISdsEb8BxI",
        "outputId": "ea12572b-6804-41ca-8bc9-ac27911daba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "proj_token_list['productive']['best']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lifesize', 0.6370277404785156),\n",
              " ('defensible', 0.637245237827301),\n",
              " ('sprawling', 0.640779972076416),\n",
              " ('willed', 0.6415868401527405),\n",
              " ('clockwise', 0.6472915410995483),\n",
              " ('dose', 0.6574928760528564),\n",
              " ('cutaway', 0.6576105952262878),\n",
              " ('precaution', 0.6598490476608276),\n",
              " ('minded', 0.6629545092582703),\n",
              " ('soundstage', 0.6735890507698059)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YGTpi0718BxK",
        "outputId": "c1105aae-a0cb-4460-dd0a-fbd815e2acd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "proj_token_list['productive']['worst']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Kansas', 0.23528103530406952),\n",
              " ('Oregon', 0.23573540151119232),\n",
              " ('Cloud', 0.24489308893680573),\n",
              " ('Bright', 0.24528267979621887),\n",
              " ('Aden', 0.24741169810295105),\n",
              " ('Vietnamese', 0.24973073601722717),\n",
              " ('Tokyo', 0.2505605220794678),\n",
              " ('Cruise', 0.2509114742279053),\n",
              " ('Rhodesia', 0.25127601623535156),\n",
              " ('Heritage', 0.2524130344390869)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y80MFDgD8BxM",
        "outputId": "3c95ff32-4f08-4dc9-e1a7-b56d90875f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "umap_plot(weight_matrix_proj, proj_id_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/lexili24/miniconda3/lib/python3.7/site-packages/numba/compiler.py:602: NumbaPerformanceWarning: \n",
            "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
            "\n",
            "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
            "\n",
            "File \"../../../../miniconda3/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
            "    @numba.njit(parallel=True)\n",
            "    def nn_descent(\n",
            "    ^\n",
            "\n",
            "  self.func_ir.loc))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fHqB7SQ20O8y"
      },
      "source": [
        "### Observation:\n",
        "From the graph we can see that the embedding and projection layer visualizations are significantly different. The embedding layer cannot really differentiate each word, therefore no cluster is really formed as all words are scattered in the graph. However in the projection layer, words are clustered into groups. Taken for an example, we see a group of 'Utah, Bright, Tokyo, Kansas, Aden, and Oregon', which to me are ideally as the model seems to correctly seperates objectives with location names. However, not all best, worst of words selected are interpretable. For a full list of words produced from a list of words we chose from, reference below: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeHisDPAVc-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_words(word_list):\n",
        "    return [x[0] for x in word_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AarYtPeFVc-y",
        "colab_type": "code",
        "colab": {},
        "outputId": "f3ab7403-3b26-44ac-f226-d72cca44b6de"
      },
      "source": [
        "for word in input_words:\n",
        "    print('Word choices for {} in embedding layer are: '.format(word), get_words(lkup_token_list[word]['best']),get_words(lkup_token_list[word]['worst']))\n",
        "    print('Word choices for {} in projection layer are: '.format(word), get_words(proj_token_list[word]['best']),get_words(proj_token_list[word]['worst']))\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word choice productive in embedding layer are:  ['love', 'Stanisław', 'Margin', 'LeSportsac', 'flocked', '1738', 'Mariah', 'Giuseppe', 'disregard', 'greenish'] ['Raonic', 'heel', 'volley', 'upstaged', 'counsel', 'Amalthea', 'shares', 'reliquary', 'Bronson', 'Djedkare']\n",
            "Word choice productive in projection layer are:  ['lifesize', 'defensible', 'sprawling', 'willed', 'clockwise', 'dose', 'cutaway', 'precaution', 'minded', 'soundstage'] ['Kansas', 'Oregon', 'Cloud', 'Bright', 'Aden', 'Vietnamese', 'Tokyo', 'Cruise', 'Rhodesia', 'Heritage']\n",
            "\n",
            "\n",
            "Word choice teenager in embedding layer are:  ['RSPB', '1619', 'Shawn', 'insects', 'Pact', 'endured', 'Fouke', 'pope', 'landowner', 'vows'] ['Metro', 'Services', 'Attack', 'cal', 'Eternia', 'maiden', 'Draftees', 'financing', 'distinguishable', 'Lines']\n",
            "Word choice teenager in projection layer are:  ['Barbadian', 'botanist', 'taxonomic', 'Awali', '1900s', 'broodmare', 'unwillingness', 'descendant', 'Jesuit', 'pioneer'] [':', 'otherwise', 'An', 'Born', 'competing', 'Volume', '\"', 'Noël', 'involve', 'whereas']\n",
            "\n",
            "\n",
            "Word choice south in embedding layer are:  ['north', 'Schadla', 'portrait', 'BC', 'portrayal', 'restricted', 'paraspeckles', 'ardent', 'southwest', 'vis'] ['U.', 'Schilling', 'uncle', 'cyclone', 'Torres', 'Barfleur', 'Maccabi', 'hospitalised', 'pretends', 'Gen.']\n",
            "Word choice south in projection layer are:  ['760', 'Text', 'M4', 'inland', '<pad>', '<bos>', 'southeast', 'northeast', 'east', 'north'] ['deliberately', 'repeatedly', 'of', 'triangle', 'Utah', 'triggered', 'Knight', 'blacks', 'spun', 'viewed']\n",
            "\n",
            "\n",
            "Word choice happy in embedding layer are:  ['concerned', 'confront', 'Keats', 'stairs', 'kitsunetsuki', 'weapons', 'computation', 'recipients', 'standards', 'powerful'] ['sculpture', 'hotel', 'Lemieux', 'Bologna', 'went', 'dynasties', 'McEnroe', 'Court', 'polls', 'vocalization']\n",
            "Word choice happy in projection layer are:  ['dialogue', 'burning', 'SNL', 'wet', 'tempered', 'striking', 'sexual', 'trivial', 'obsolete', 'tight'] [',', 'Aden', '(', 'Berg', 'Standard', 'Glanville', 'Kaimanawa', 'Cardinal', 'Thailand', 'Brenda']\n",
            "\n",
            "\n",
            "Word choice smart in embedding layer are:  ['adequately', 'electroplating', '1623', 'Bolton', 'Walking', 'Ackroyd', 'seasonal', 'uptempo', 'Kurt', '13'] ['Stephanie', 'Precinct', 'forget', 'sparkling', 'Hibari.', 'pareiasaur', 'permanence', 'odes', 'Statistics', 'artist']\n",
            "Word choice smart in projection layer are:  ['curious', 'incidental', 'villainous', 'eerie', 'irresistible', 'ruthless', 'manses', 'revised', 'melancholy', 'soft'] [':', ',', 'failures', 'interference', '64', '59', 'cannons', 'scoreless', '/', 'Victory']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vx9TM9ui8BxQ"
      },
      "source": [
        "### II.3 Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PpWeHqeu8BxR",
        "colab": {}
      },
      "source": [
        "def get_logprob(seq, model):\n",
        "    \"\"\" Input: a sentence (string) \n",
        "      Output: the averaged log probability of the sentence.\n",
        "    \"\"\"\n",
        "    inp = [train_dict.get_id('<bos>')] + train_dict.encode_token_seq(seq.split(' '))\n",
        "    target = inp[1:] + [train_dict.get_id('<eos>')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        logits = model(torch.tensor([inp], dtype=torch.long))\n",
        "\n",
        "    num = len(inp)-1 # minus the <bos>\n",
        "    logp = 0\n",
        "    for i in range(num):\n",
        "    # get the correct next word from the tarfet list.\n",
        "      next_word = target[i]   \n",
        "    # get teh distribution of the next possible word. \n",
        "      prob_dist = torch.softmax(logits[0,i], dim= -1) \n",
        "    # get the prob for the correct next word. \n",
        "      logp += np.log(prob_dist[next_word]).item()\n",
        "\n",
        "    return logp/num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EYmrd7nOmLtl",
        "outputId": "978cb8a2-7f7c-490b-81fe-de4f896ff69b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# load the best model:\n",
        "embedding_size = 300\n",
        "hidden_size = 300\n",
        "\n",
        "options = {\n",
        "        'num_embeddings': len(train_dict),\n",
        "        'embedding_dim': embedding_size,\n",
        "        'padding_idx': train_dict.get_id('<pad>'),\n",
        "        'input_size': embedding_size,\n",
        "        'hidden_size': hidden_size,\n",
        "        'num_layers': num_layers,\n",
        "        'lstm_dropout': lstm_dropout,\n",
        "        'bias': True,\n",
        "        'bid': False \n",
        "    }\n",
        "model = LSTMModel(options)\n",
        "model.load_state_dict(torch.load(F'/content/drive/My Drive/NLP/best_emb_dim_300_hidden_size_300_LSTM.pt')['model_dict'])\n",
        "# MD5 (best_emb_dim_300_hidden_size_300_LSTM.pt) = 177997a030a1a74a27c5ec63c557a5f2\n",
        "model.eval()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
              "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yb12rDvnwco0",
        "outputId": "2264cb27-d005-4592-ffc4-938db0c2a654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oO3n49iHeOrQ",
        "outputId": "aac3dfff-b8fa-45bd-9dc2-b31fb77f9fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test the function: \n",
        "get_logprob(\"I love cats and dogs.\", model)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-9.40573251247406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7tUpJJzp8BxT"
      },
      "source": [
        "#### II.3.2 Highest and Lowest scoring sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mtyeXOcsQm-m",
        "colab": {}
      },
      "source": [
        "# get a list of all sentences in the validation datasets.\n",
        "wiki_valid = [' '.join(a for a in aaa) for aaa in datasets['valid']]\n",
        "\n",
        "# get the score for each sentence\n",
        "logp_valid = [get_logprob(seq, model) for seq in wiki_valid]\n",
        "\n",
        "# sort the logp\n",
        "sorted_logp_valid = [i for i in sorted(enumerate(logp_valid), key=lambda x:x[1])]\n",
        "\n",
        "# get ten sentences with the lowest score.\n",
        "low_idx = [l[0] for l in sorted_logp_valid[:10]]\n",
        "low_score = [l[1] for l in sorted_logp_valid[:10]]\n",
        "low_seq = [wiki_valid[i] for i in low_idx]\n",
        "\n",
        "# get ten sentences with the highest score.\n",
        "high_idx = [l[0] for l in sorted_logp_valid[-10:]]\n",
        "high_score = [l[1] for l in sorted_logp_valid[-10:]]\n",
        "high_seq = [wiki_valid[i] for i in high_idx]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9H4dxIV88BxU",
        "outputId": "f7d29cc8-254d-4f79-acbc-7983bcac549a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# print the higest scored sentences\n",
        "print(\"These are the sentences withe the highest score:\")\n",
        "[print(f'sentence: {i}') for i in high_seq]\n",
        "print(\"\\n\")\n",
        "# pritn the lowest scored sentences\n",
        "print(\"These are the sentences withe the lowest score:\")\n",
        "[print(f'sentence: {i}') for i in low_seq]\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These are the sentences withe the highest score:\n",
            "sentence: = = Post @-@ war period = =\n",
            "sentence: \" Daydream Interlude ( Fantasy Sweet Dub Mix ) \"\n",
            "sentence: The series depicts the everyday lives of office employees in the Scranton , Pennsylvania branch of the fictional Dunder Mifflin Paper Company .\n",
            "sentence: The VHS was a commercial success , being certified platinum by the Recording Industry Association of America ( RIAA ) , denoting shipments of over 100 @,@ 000 units .\n",
            "sentence: A Critical Guide to The X @-@ Files , Millennium & The Lone Gunmen , rated \" ...\n",
            "sentence: It originally aired on the Fox network in the United States on March 4 , 2012 .\n",
            "sentence: = = Post @-@ war career = =\n",
            "sentence: The Boat Race is a side @-@ by @-@ side rowing competition between the University of Oxford ( sometimes referred to as the \" Dark Blues \" ) and the University of Cambridge ( sometimes referred to as the \" Light Blues \" ) .\n",
            "sentence: This means that it was seen by 4 @.@ 0 % of all 18- to 49 @-@ year @-@ olds , and 11 % of all 18- to 49 @-@ year @-@ olds watching television at the time of the broadcast .\n",
            "sentence: = = Early life and education = =\n",
            "\n",
            "\n",
            "These are the sentences withe the lowest score:\n",
            "sentence: Acts Of Rebellion : The Ward Churchill Reader .\n",
            "sentence: Giovanni Bianco – Graphic Design , Art Direction\n",
            "sentence: unk> corroborated Blythe 's testimony that Blythe asked \" Are you okay ?\n",
            "sentence: A Cloud Drifting in Silent Darkness , written by <unk>\n",
            "sentence: > also enjoyed the support of the United Mine Workers and Louisville mayor Neville Miller .\n",
            "sentence: Sega of America packaged it with American Genesis consoles , replacing <unk> Beast .\n",
            "sentence: = Raid on Manila ( 1798 ) =\n",
            "sentence: Churchill <unk> About Academic Freedom – Free Speech Radio News February 9 , 2005\n",
            "sentence: will cost Sonic a life regardless of rings or other protection .\n",
            "sentence: any of Fringe 's eleven @-@ herbs and spices .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Iat6XrhD8BxW"
      },
      "source": [
        "#### II.3.3 Modified sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cUmH3BiQ8BxY",
        "outputId": "d7b7da0a-187d-412f-e3e8-a70fb1d54f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# choose the sentence \"= = Post @-@ war period = =\"\n",
        "original = '= = Post @-@ war period = ='\n",
        "mod_low = '= = Post @-@ war life = ='\n",
        "mod_high = '= = Post @-@ war tea = ='\n",
        "print(f'Original:  {original} \\nScore:  {get_logprob(original,model)}')\n",
        "print(f'\\nReplace period with life:  {mod_low} \\nScore:  {get_logprob(mod_low,model)}')\n",
        "print(f'\\nReplace period with tea:  {mod_high} \\nScore:  {get_logprob(mod_high,model)}')\n"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  = = Post @-@ war period = = \n",
            "Score:  -1.9523909240961075\n",
            "\n",
            "Replace period with life:  = = Post @-@ war life = = \n",
            "Score:  -1.8621020577847958\n",
            "\n",
            "Replace period with tea:  = = Post @-@ war tea = = \n",
            "Score:  -7.071487247478217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPUqVlmsc9KI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0c2db444-a212-4bfb-f340-21b4e9d56842"
      },
      "source": [
        "# a function to generate the mose possible next word base on the model.\n",
        "# This function is used to find a modified sentence with a better score\n",
        "\n",
        "def get_next_word(seq, model):\n",
        "  inp = [train_dict.get_id(i) for i in seq.split(' ')]\n",
        "  #inp = word\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(torch.tensor([inp], dtype=torch.long))\n",
        "\n",
        "  for i in range(len(inp)):\n",
        "    \n",
        "    prob_dist = torch.softmax(logits[0,i], dim= -1) \n",
        "    log_prob = np.log(prob_dist)\n",
        "    sorted_prob = [i for i in sorted(enumerate(log_prob), key=lambda x:x[1])]\n",
        "    \n",
        "  # the id of the word with the max probability\n",
        "  next_word_id = sorted_prob[-1][0]\n",
        "  \n",
        "  return next_word_id\n",
        "\n",
        "# use the function: \n",
        "new_word_id = get_next_word('= = Post @-@ war life',model)\n",
        "next_word = train_dict.decode_idx_seq([new_word_id])\n",
        "print(next_word)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['=']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCNDG2UlpszO",
        "colab_type": "text"
      },
      "source": [
        "### Observations:\n",
        "I think replacing \"period\" with \"life\" gives a better score because in our model, \"life\" is closer to 'war' than \"period\" in meaning and therefore, results in a smaller loss and better score. This may due to co-appearance of two words in our training set. When replacing \"period\" with \"tea\", the score drops. I think this is becaue \"tea\" is not related to war that much and rarely appear close to \"war\". Thus, our model thinks it's unlikely for them to coappear and thus a lower score is returned. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ElfxRup68Bxc"
      },
      "source": [
        "### II.4 Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0UQnM7M18Bxc",
        "colab": {}
      },
      "source": [
        "class LSTMModelHidden(nn.Module):\n",
        "    \"\"\"\n",
        "    This model integrates from the LSTM model but has a hidden layer as input and allows the model to \n",
        "    train from previous hidden layer\n",
        "    \"\"\"\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        # create each LM part here \n",
        "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
        "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], \n",
        "                            dropout=options['lstm_dropout'], batch_first=True, bias = options['bias'],\n",
        "                           bidirectional = options['bid'])\n",
        "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
        "        \n",
        "    def forward(self, encoded_input_sequence, hidden):\n",
        "        \"\"\"\n",
        "        Forward method process the input from token ids to logits\n",
        "        \"\"\"\n",
        "        embeddings = self.lookup(encoded_input_sequence)\n",
        "        lstm_outputs,hidden = self.lstm(embeddings,hidden)\n",
        "        # project of outputs \n",
        "        # rnn_outputs: tupple with second element being last hidden state. \n",
        "        logits = self.projection(lstm_outputs)\n",
        "        \n",
        "        return logits, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9Y_GVw10O9I",
        "outputId": "bd7896a8-1535-4a2d-84f9-7959d6967439",
        "colab": {}
      },
      "source": [
        "# Load the best model\n",
        "num_gpus = torch.cuda.device_count()\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "options = {'bias': True,\n",
        "  'bid': False,\n",
        "  'embedding_dim': 300,\n",
        "  'hidden_size': 300,\n",
        "  'input_size': 300,\n",
        "  'lstm_dropout': 0.1,\n",
        "  'num_embeddings': 33178,\n",
        "  'num_layers': 2,\n",
        "  'padding_idx': 2}\n",
        "    \n",
        "model = LSTMModelHidden(options)\n",
        "model.load_state_dict(torch.load('best_emb_dim_300_hidden_size_300_LSTM.pt',map_location=lambda storage, loc: storage)['model_dict'])\n",
        "model.eval()\n",
        "# MD5 (best_emb_dim_300_hidden_size_300_LSTM.pt) = 177997a030a1a74a27c5ec63c557a5f2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModelHidden(\n",
              "  (lookup): Embedding(33178, 300, padding_idx=2)\n",
              "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=300, out_features=33178, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDmoRR9h0O9M",
        "colab": {}
      },
      "source": [
        "#from torch.distributions.multinomial import Multinomial\n",
        "\n",
        "def generate_sentence():\n",
        "    # We always begin with <bos> and end at <eos>\n",
        "    begin_id = torch.tensor(train_dict.get_id('<bos>'))\n",
        "    end_id = torch.tensor(train_dict.get_id('<eos>'))\n",
        "\n",
        "    # this is the initialized hidden layer with all zeros\n",
        "    h = torch.zeros(options['num_layers'],1,options['hidden_size'])\n",
        "    c = torch.zeros(options['num_layers'],1,options['hidden_size'])\n",
        "\n",
        "    next_word = begin_id\n",
        "    tokens = list()\n",
        "    tokens.append(next_word)\n",
        "\n",
        "    while next_word != end_id:  # make sure both are type tensor\n",
        "        # Feeding in the hidden states at each state\n",
        "        output, (h,c) = model.forward(next_word.view(1,-1), (h,c)) \n",
        "        \n",
        "        # initialize a softmax function\n",
        "        m = nn.Softmax(dim=-1)\n",
        "        prob = m(output.view(-1))\n",
        "\n",
        "        # use multinomial to predict the next token\n",
        "        next_word = torch.multinomial(prob,1)\n",
        "        \n",
        "        tokens.append(next_word.item())\n",
        "\n",
        "    sentence = train_dict.decode_idx_seq(tokens)\n",
        "    return ' '.join(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HCwt0Pqq0O9Q",
        "colab": {}
      },
      "source": [
        "sentences = list()\n",
        "for _ in range(1000):\n",
        "    st = generate_sentence()\n",
        "    sentences.append(st)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fGrmvNc90O9T",
        "outputId": "156c52b2-0c86-4745-ba7f-570fe0481354",
        "colab": {}
      },
      "source": [
        "# an example of generated sentence \n",
        "item = np.random.randint(1000)\n",
        "sentences[item]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<bos> Researchers , like perhaps the oldest deity of the English language as an example of social life , and is similarly of human but secondary . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vg6pBDZw0O9X"
      },
      "source": [
        "#### II.4.3 Number of unique tokens and sequence length \n",
        "\n",
        "(1,000 samples vs. 1,000 randomly selected validation-set sequences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZGAUl-30O9X",
        "colab": {}
      },
      "source": [
        "# find the first 1000 sentences from validation samples\n",
        "valid_sentences = []\n",
        "samples = np.arange(len(datasets['valid']))\n",
        "np.random.shuffle(samples)\n",
        "for i in range(1000):\n",
        "    valid_sentences.append('<bos> '+' '.join(datasets['valid'][samples[i]])+' <eos>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFVEQR5n0O9d",
        "outputId": "493baae1-a908-4f3d-cdc6-f702e3187995",
        "colab": {}
      },
      "source": [
        "# unique set of validation sample\n",
        "unique_valid = len(set(' '.join(valid_sentences)))\n",
        "print('Number of unique words in the validation sequences is ', unique_valid)\n",
        "unique_generate = len(set(' '.join(sentences)))\n",
        "print('Number of unique words from sampling sequences is ', unique_generate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words in the validation sequences is  100\n",
            "Number of unique words from sampling sequences is  112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kyy0tkZ60O9f",
        "outputId": "9ba1e78a-5f41-4510-c568-357fce0db011",
        "colab": {}
      },
      "source": [
        "print('Avg length of validation sequences is ', sum([len(i) for i in valid_sentences])/len(valid_sentences))\n",
        "print('Avg length of sampling sequences is', sum([len(i) for i in sentences])/len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg length of validation sequences is  130.501\n",
            "Avg length of sampling sequences is 139.785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-p4962Q20O9i"
      },
      "source": [
        "From the comparision we can see that for both unique words and average length, validation and sampling sequences are almost similar, although average validation sequence length and number of unique words are lower than sampling sequences overall. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fd3bYBH78Bxl"
      },
      "source": [
        "#### II.4.4 Example Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RPWkp7I88Bxn",
        "outputId": "3945ec01-792f-4c4d-816a-92b4c746aa32",
        "colab": {}
      },
      "source": [
        "samples = np.arange(1000)\n",
        "np.random.shuffle(samples)\n",
        "print(sentences[samples[0]])\n",
        "print(sentences[samples[1]])\n",
        "print(sentences[samples[2]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bos> The Turin canon credits des education and public products in China ; the former initiated a small bottle bridge event linked to the church including the Byrds . <eos>\n",
            "<bos> unk> on a star that was a weaker surface and so the urn will make <unk> about discovering the foul jumps in the deep atmosphere ; this was later mixed and had originated from the Tech <unk> which made \" <unk> escaping back \" . <eos>\n",
            "<bos> After little changes , none more closely fused without Hurricane condoms may continue as <unk> , resulting in shrubby environments . <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4-5lt6HT0O9k"
      },
      "source": [
        "From those samples above, although the property of unique word and sentence length are consistent with human-generated sentences, but I can still tell that there are model generated since they hardly stay on topic, although they seem to be grammatically correct as the position of the word make sense. "
      ]
    }
  ]
}