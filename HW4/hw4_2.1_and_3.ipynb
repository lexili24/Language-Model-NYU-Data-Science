{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hd5joPrEfeTO"
   },
   "source": [
    "# Homework 4: Conversation Modeling and decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnq-52tzfeTP"
   },
   "source": [
    "# Part 1 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ly_vMsyZfeTQ"
   },
   "source": [
    "## 1.1 Attention visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMfR42QffeTR"
   },
   "outputs": [],
   "source": [
    "### set up the model and complete the corresponding task\n",
    "\n",
    "### the pretrained model was trained in ~2 hours, i.e. you can expect attention maps\n",
    "### to look quite 'hard' (less soft spreading) i.e. attending to some particular token in the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFWGbGjPfeTT"
   },
   "source": [
    "### You present here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-GGbhdZfeTU"
   },
   "outputs": [],
   "source": [
    "# this is some example attention map here, \n",
    "# *make sure you add text tokens on the axes to make it readable!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGaiODLcfeTW"
   },
   "source": [
    "![Imgur](https://i.imgur.com/xodciCU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1d0Z7fTfeTX"
   },
   "source": [
    "## 1.2 Encoder Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtjEANgMfeTX"
   },
   "outputs": [],
   "source": [
    "### add transformer encoder as optional encoder in seq2seq model.\n",
    "\n",
    "# code below can help you to start it, but feel free to start from scratch\n",
    "\n",
    "class EncoderTransformer(nn.Module):\n",
    "     def __init__(self):\n",
    "        \n",
    "        # you need to add more things here\n",
    "        \n",
    "        self.position_embed = nn.Embedding()\n",
    "        encoder_layer = nn.TransformerEncoderLayer()\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "\n",
    "    def forward(self, text_vec):\n",
    "        # some helpful directions below, check the MLM lab for more details\n",
    "        \n",
    "        # embedded = pos_embedded + embedded  # apply pos embedding\n",
    "        # attention_mask = ...\n",
    "        # output = self.transformer(embedded, src_key_padding_mask=attention_mask)\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XtAUIb1feTZ"
   },
   "source": [
    "## You present here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZBKzjjVfeTa"
   },
   "outputs": [],
   "source": [
    "# check pdf to see what you expected to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaFG961KfeTc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ab3ULUTNfeTe"
   },
   "source": [
    "# Part 2 Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0rjI3dTfeTf"
   },
   "source": [
    "# 2.1 Nucleus Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kavDSEtPajJP"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-RVddpWZamPx"
   },
   "outputs": [],
   "source": [
    "class ChatDictionary(object):\n",
    "    \"\"\"\n",
    "    Simple dict loader\n",
    "    \"\"\"\n",
    "    def __init__(self, dict_file_path):\n",
    "        self.word2ind = {}  # word:index\n",
    "        self.ind2word = {}  # index:word\n",
    "        self.counts = {}  # word:count\n",
    "\n",
    "        dict_raw = open(dict_file_path, 'r').readlines()\n",
    "        \n",
    "        for i, w in enumerate(dict_raw):\n",
    "            _word, _count = w.strip().split('\\t')\n",
    "            if _word == '\\\\n':\n",
    "                _word = '\\n'\n",
    "            self.word2ind[_word] = i\n",
    "            self.ind2word[i] = _word\n",
    "            self.counts[_word] = _count\n",
    "            \n",
    "    def t2v(self, tokenized_text):\n",
    "        return [self.word2ind[w] if w in self.counts else self.word2ind['__unk__'] for w in tokenized_text]\n",
    "\n",
    "    def v2t(self, list_ids):\n",
    "        return ' '.join([self.ind2word[i] for i in list_ids])\n",
    "    \n",
    "    def pred2text(self, tensor):\n",
    "        result = []\n",
    "        for i in range(tensor.size(0)):\n",
    "            if tensor[i].item() == '__end__'  or tensor[i].item() == '__null__':  # null is pad\n",
    "                break\n",
    "            else:\n",
    "                result.append(self.ind2word[tensor[i].item()])\n",
    "        return ' '.join(result)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YZzWjOZawpp"
   },
   "outputs": [],
   "source": [
    "RETOK = re.compile(r'\\w+|[^\\w\\s]|\\n', re.UNICODE)\n",
    "class ChatDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Json dataset wrapper\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_file_path, dictionary, dt='train'):\n",
    "        super().__init__()\n",
    "        \n",
    "        json_text = open(dataset_file_path, 'r').readlines()\n",
    "        self.samples = []\n",
    "        \n",
    "        for sample in tqdm(json_text):\n",
    "            sample = sample.rstrip()\n",
    "            sample = json.loads(sample)\n",
    "            _inp_toked = RETOK.findall(sample['text'])\n",
    "            _inp_toked_id = dictionary.t2v(_inp_toked)\n",
    "\n",
    "            sample['text_vec'] = torch.tensor(_inp_toked_id, dtype=torch.long)\n",
    "            \n",
    "            # train and valid have different key names for target\n",
    "            if dt == 'train':\n",
    "                _tar_toked = RETOK.findall(sample['labels'][0]) + ['__end__']\n",
    "            elif dt == 'valid':\n",
    "                _tar_toked = RETOK.findall(sample['eval_labels'][0]) + ['__end__']\n",
    "                \n",
    "            _tar_toked_id = dictionary.t2v(_tar_toked)\n",
    "            \n",
    "            sample['target_vec'] = torch.tensor(_tar_toked_id, dtype=torch.long)\n",
    "            \n",
    "            self.samples.append(sample)\n",
    "            \n",
    "    def __getitem__(self, i):\n",
    "        return self.samples[i]['text_vec'], self.samples[i]['target_vec']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qxoBJ9Za3mx"
   },
   "outputs": [],
   "source": [
    "def pad_tensor(tensors, sort=True, pad_token=0):\n",
    "    rows = len(tensors)\n",
    "    lengths = [len(i) for i in tensors]\n",
    "    max_t = max(lengths)\n",
    "        \n",
    "    output = tensors[0].new(rows, max_t)\n",
    "    output.fill_(pad_token)  # 0 is a pad token here\n",
    "    \n",
    "    for i, (tensor, length) in enumerate(zip(tensors, lengths)):\n",
    "        output[i,:length] = tensor\n",
    "\n",
    "    return output, lengths\n",
    "\n",
    "def argsort(keys, *lists, descending=False):\n",
    "    \"\"\"Reorder each list in lists by the (descending) sorted order of keys.\n",
    "    :param iter keys: Keys to order by.\n",
    "    :param list[list] lists: Lists to reordered by keys's order.\n",
    "                             Correctly handles lists and 1-D tensors.\n",
    "    :param bool descending: Use descending order if true.\n",
    "    :returns: The reordered items.\n",
    "    \"\"\"\n",
    "    ind_sorted = sorted(range(len(keys)), key=lambda k: keys[k])\n",
    "    if descending:\n",
    "        ind_sorted = list(reversed(ind_sorted))\n",
    "    output = []\n",
    "    for lst in lists:\n",
    "        if isinstance(lst, torch.Tensor):\n",
    "            output.append(lst[ind_sorted])\n",
    "        else:\n",
    "            output.append([lst[i] for i in ind_sorted])\n",
    "    return output\n",
    "\n",
    "def batchify(batch):\n",
    "    inputs = [i[0] for i in batch]\n",
    "    labels = [i[1] for i in batch]\n",
    "    \n",
    "    input_vecs, input_lens = pad_tensor(inputs)\n",
    "    label_vecs, label_lens = pad_tensor(labels)\n",
    "    \n",
    "    # sort only wrt inputs here for encoder packinng\n",
    "    input_vecs, input_lens, label_vecs, label_lens = argsort(input_lens, input_vecs, input_lens, label_vecs, label_lens, descending=True)\n",
    "\n",
    "    return {\n",
    "        \"text_vecs\": input_vecs,\n",
    "        \"text_lens\": input_lens,\n",
    "        \"target_vecs\": label_vecs,\n",
    "        \"target_lens\": label_lens,\n",
    "        'use_packed': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40392,
     "status": "ok",
     "timestamp": 1573601925164,
     "user": {
      "displayName": "Xiao Li",
      "photoUrl": "",
      "userId": "17628369663427228897"
     },
     "user_tz": 300
    },
    "id": "HU85v4Sla8v5",
    "outputId": "97719b4d-40aa-489e-84a3-281e1306f908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-12 23:33:20--  https://nyu.box.com/shared/static/sj9f87tofpicll89xbc154pmbztu5q4h\n",
      "Resolving nyu.box.com (nyu.box.com)... 107.152.27.197, 107.152.26.197\n",
      "Connecting to nyu.box.com (nyu.box.com)|107.152.27.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /public/static/sj9f87tofpicll89xbc154pmbztu5q4h [following]\n",
      "--2019-11-12 23:33:25--  https://nyu.box.com/public/static/sj9f87tofpicll89xbc154pmbztu5q4h\n",
      "Reusing existing connection to nyu.box.com:443.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://nyu.app.box.com/public/static/sj9f87tofpicll89xbc154pmbztu5q4h [following]\n",
      "--2019-11-12 23:33:25--  https://nyu.app.box.com/public/static/sj9f87tofpicll89xbc154pmbztu5q4h\n",
      "Resolving nyu.app.box.com (nyu.app.box.com)... 107.152.26.199, 107.152.27.199\n",
      "Connecting to nyu.app.box.com (nyu.app.box.com)|107.152.26.199|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://public.boxcloud.com/d/1/b1!1k-fAUednIkgGNFRT8QEFQFlIU0TkVF9_fR7svelV0wJdcKZw8D0BXT_H9pKKjNkwfOcoq4I0dLv9VNzVSH9eCeJmnRY1FmyTik3DHq-SoyWQPO58WpsCFPD2wRfvvdxark1UBRer5m0CRPxfgiq8zsq7_9xx_N-PiJAAEiGLrKedq-px7Zzr2byuTristcBVVJcIbxbpgs-3WJpsZ-LpN17PwxRJtPjYUht9FHQ3nXdVIvPS5hZTSCYq22_fdEDUKepcwwZwzipWClk2x5FlY9liyC3MXf56aCoRHRvCJeoneMSLkcavMIlAX3PShTDuEaXW9zWS7B0N02PC26E7li71xFYM4ZmZKfnnvfPoM2ZdcSqSvUzteRizJmmAao8uItUN5-QRwpC1tfbmgJ1J5vF9rPfmnoBb_yiR-2yk1yCdCoS4-0FHOWvez-VvUEADfufafxvDpHTabolXi4jQ2lZUyJXg-6G6dpljIyhAnkW2woA11dYGNXpCorgG084_sQu1HKgieEPkcsUJAzqs0q3KkEKblxH_-g2Q311LPKjxnEl3IKmdUVSPrK2Lw1sBWhyyhRZdF4u6SRDooPTykyu_VbLTGFgFFAiJtX2i0bc-Ayz8TFAVqiEr9c9s2LZEcTn8LBGP-ed7lUv5g5G860ESQV6m9OaIVcG5zuDC7BtwKR9OtRpl2t0kjLIDzcfRefTppem0W1qz4BmUldsqGB3OqwcVOX59KF5ClqSNzNhVSyKcXEFs_Rj-niTy1co6JlFvLVwoRhRKjwIr220DuayhSCIaAUNJi9hSk96zahqABgTjx8ggzCBiobUhQpmuEyxWdh0JVNUMvczhV-X8a6pzK4prCx2pMq8V5n8L1T4idRdsOrko6rWc_-b02TSUpoRV6E1CoplP3QiQJqcK1K5yz3v9OPIMFVnnL7bdtbdIwK6KYa-46bWpQHZ06MxGA75W3S002hH0jE2nZKQtNyXPjaaaYvehgFmTprk_Ez1VQfu4h-pY_2fzHJtoDoCB1Zu5UGwFmSBqYUsFVj3C149RGdd2cKd5K69DP1Km0BD59vqyWjVnLnrqI-txonX7P6pHVAR-tRx8z8AMPSNlSpUcPg3LJgxtKDVE-ta0RBdhZFKYRW-mSS19oyvmQOAG6SlhYJyatkfbghYLFLF8ICkgJACq4mzE1JNkcoZPqwHUXx5YyDctMCm6LreW8RmNqN9hPapVPvZRGnq5v_Mz1PWfR2yHSUpQu8T6qIpO6gafTsmbUKWqOfJdnb_VLfSUMJ2moAMpdQ7ehye-in5fC3Sj3eCTjdFeLwToL3ntp_04TDrXDgUmN1zuBKhjGF6Ctl4_x9Vb6mNTaBRWouuWdojmm1WQj-Yj2i-bjOz_wDGZ3M./download [following]\n",
      "--2019-11-12 23:33:26--  https://public.boxcloud.com/d/1/b1!1k-fAUednIkgGNFRT8QEFQFlIU0TkVF9_fR7svelV0wJdcKZw8D0BXT_H9pKKjNkwfOcoq4I0dLv9VNzVSH9eCeJmnRY1FmyTik3DHq-SoyWQPO58WpsCFPD2wRfvvdxark1UBRer5m0CRPxfgiq8zsq7_9xx_N-PiJAAEiGLrKedq-px7Zzr2byuTristcBVVJcIbxbpgs-3WJpsZ-LpN17PwxRJtPjYUht9FHQ3nXdVIvPS5hZTSCYq22_fdEDUKepcwwZwzipWClk2x5FlY9liyC3MXf56aCoRHRvCJeoneMSLkcavMIlAX3PShTDuEaXW9zWS7B0N02PC26E7li71xFYM4ZmZKfnnvfPoM2ZdcSqSvUzteRizJmmAao8uItUN5-QRwpC1tfbmgJ1J5vF9rPfmnoBb_yiR-2yk1yCdCoS4-0FHOWvez-VvUEADfufafxvDpHTabolXi4jQ2lZUyJXg-6G6dpljIyhAnkW2woA11dYGNXpCorgG084_sQu1HKgieEPkcsUJAzqs0q3KkEKblxH_-g2Q311LPKjxnEl3IKmdUVSPrK2Lw1sBWhyyhRZdF4u6SRDooPTykyu_VbLTGFgFFAiJtX2i0bc-Ayz8TFAVqiEr9c9s2LZEcTn8LBGP-ed7lUv5g5G860ESQV6m9OaIVcG5zuDC7BtwKR9OtRpl2t0kjLIDzcfRefTppem0W1qz4BmUldsqGB3OqwcVOX59KF5ClqSNzNhVSyKcXEFs_Rj-niTy1co6JlFvLVwoRhRKjwIr220DuayhSCIaAUNJi9hSk96zahqABgTjx8ggzCBiobUhQpmuEyxWdh0JVNUMvczhV-X8a6pzK4prCx2pMq8V5n8L1T4idRdsOrko6rWc_-b02TSUpoRV6E1CoplP3QiQJqcK1K5yz3v9OPIMFVnnL7bdtbdIwK6KYa-46bWpQHZ06MxGA75W3S002hH0jE2nZKQtNyXPjaaaYvehgFmTprk_Ez1VQfu4h-pY_2fzHJtoDoCB1Zu5UGwFmSBqYUsFVj3C149RGdd2cKd5K69DP1Km0BD59vqyWjVnLnrqI-txonX7P6pHVAR-tRx8z8AMPSNlSpUcPg3LJgxtKDVE-ta0RBdhZFKYRW-mSS19oyvmQOAG6SlhYJyatkfbghYLFLF8ICkgJACq4mzE1JNkcoZPqwHUXx5YyDctMCm6LreW8RmNqN9hPapVPvZRGnq5v_Mz1PWfR2yHSUpQu8T6qIpO6gafTsmbUKWqOfJdnb_VLfSUMJ2moAMpdQ7ehye-in5fC3Sj3eCTjdFeLwToL3ntp_04TDrXDgUmN1zuBKhjGF6Ctl4_x9Vb6mNTaBRWouuWdojmm1WQj-Yj2i-bjOz_wDGZ3M./download\n",
      "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.24.200\n",
      "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.24.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 190210 (186K) [application/octet-stream]\n",
      "Saving to: ‘./dict’\n",
      "\n",
      "./dict              100%[===================>] 185.75K   890KB/s    in 0.2s    \n",
      "\n",
      "2019-11-12 23:33:27 (890 KB/s) - ‘./dict’ saved [190210/190210]\n",
      "\n",
      "--2019-11-12 23:33:27--  https://nyu.box.com/shared/static/aqp0jyjaixjmukm5asasivq2bcfze075.jsonl\n",
      "Resolving nyu.box.com (nyu.box.com)... 107.152.27.197, 107.152.26.197\n",
      "Connecting to nyu.box.com (nyu.box.com)|107.152.27.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /public/static/aqp0jyjaixjmukm5asasivq2bcfze075.jsonl [following]\n",
      "--2019-11-12 23:33:27--  https://nyu.box.com/public/static/aqp0jyjaixjmukm5asasivq2bcfze075.jsonl\n",
      "Reusing existing connection to nyu.box.com:443.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://nyu.app.box.com/public/static/aqp0jyjaixjmukm5asasivq2bcfze075.jsonl [following]\n",
      "--2019-11-12 23:33:28--  https://nyu.app.box.com/public/static/aqp0jyjaixjmukm5asasivq2bcfze075.jsonl\n",
      "Resolving nyu.app.box.com (nyu.app.box.com)... 107.152.26.199, 107.152.27.199\n",
      "Connecting to nyu.app.box.com (nyu.app.box.com)|107.152.26.199|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://public.boxcloud.com/d/1/b1!LASqGKFi-2YrnYd1Mr83hPzXEio2zz4XSyl0GVWTSP_mG8JKDcwFTMuQR0uk2aXNvzQkCD49e6nQkd3L_umgRscfmrbHhfNUEWf081cnVyPoYqQFKdULRGoji2IkuhsjTpUPxlxGlTztQdWVTh6MEo3ZcJZU1hoLjuIzLELWITSd4oVfuVnn1_C-ilRMqtdtnw1dqrSJ9Bb1MzL-EhqUOM43OFGwYNLZwGEOL3Zx6XQy6RRyDoZdos6_UohYeSu8kLam2QJXgj4zQR-CCPI2s4guOEaTk5RT18y6tEwAzJ6e-_h2LIc9hyDu8iNLSDht_qQ-NCt1Ga7IlR9iVqFGQkRiYTIpw2HtROxDntSaTwasVCZiZzhgTnBoieZD-v_CPdP1ImFpFUx7Q_eDdd30gj1AqHU9ksDeT9u8cEF68495rJy85zEgAbdq152hAH6mauWM78jFGgMwHVTfhMjd4opHQk_gW8DXZcbguU6X8ArbhsQc1ZJkVRtuf7XIypskWp5ppYPCV5PooX5Qu6F4NLSLT5n0sh_-rKjgQDdo8KXJOjWhkwnAUwC8jhAJ-IUGyReW7GKnJe7xhSYx1Dv9LXM4HSf0FDMfytOz0HhaxYdGGKyCQOyQKUHbxIGILR8QvvmMvfDsGINymLt9ci2hjtZaM_OaTWsUS2Sqnge9PCrZpfeVrnBzHEm2Wx0TScYyvmSA-I9bkQmmEweog40D-1mMGu4mpMVTooxy4uoaJyT50ZnuuH58IPMc26a7DyREkokPrUdUuG91CRKIW9Koi2pJl2Qx9bQ7Ub8bPBW5lsPlr_f4CzlGUD_SxdjETdbGYv7q1flv_wkMJ08BEUb-SEkd5SD7z_Ei7mvYhmZPn9izz6okMxHxVs2N0PEh6Y6S9aBt4glLF2MqPghV-7bC4PCo7fAkL5U-yktHQwpa5tZ30K8HYAMBZSC7lZjsxqZQBxDo1X4tn3m30XGnYv9hb2mG8oESddm-QAtRGanxH21aeTWKPSDigU-M_hQf-qfc3JDtX-7GA3AGcYv28X3T3fTnc1dHQrZfXA906N5qbxN_lVnrhInPB0FS762uIdGHCi0mi-eGaemo3a1QhlrC6fas6MKe7R_7-lUbhVulhHmA03onv3ZjbWmYl-O1l_W8DvDATk8HP9Tyd3fxpkgwfUfCrqWHeYyWTm4X-GOI0JpBN_HHr7hOAaKw4ohbsxHUgveEfomqIrzzIq4DTR_pyxLoDwqfgAiVES783zSDFHN3zGFH3jftJqJM58V0Nob2oMR2xlbeOdnSNWF4crt5LxDNfZd9QYBToa1i4YziHq413wo18l6Fbbzpq2aZmnFBrquirzDj_Ehh6oMFFQMngNBIAnQux6PRw722QuXNCaLutZ1Vtcefg-AqyA../download [following]\n",
      "--2019-11-12 23:33:28--  https://public.boxcloud.com/d/1/b1!LASqGKFi-2YrnYd1Mr83hPzXEio2zz4XSyl0GVWTSP_mG8JKDcwFTMuQR0uk2aXNvzQkCD49e6nQkd3L_umgRscfmrbHhfNUEWf081cnVyPoYqQFKdULRGoji2IkuhsjTpUPxlxGlTztQdWVTh6MEo3ZcJZU1hoLjuIzLELWITSd4oVfuVnn1_C-ilRMqtdtnw1dqrSJ9Bb1MzL-EhqUOM43OFGwYNLZwGEOL3Zx6XQy6RRyDoZdos6_UohYeSu8kLam2QJXgj4zQR-CCPI2s4guOEaTk5RT18y6tEwAzJ6e-_h2LIc9hyDu8iNLSDht_qQ-NCt1Ga7IlR9iVqFGQkRiYTIpw2HtROxDntSaTwasVCZiZzhgTnBoieZD-v_CPdP1ImFpFUx7Q_eDdd30gj1AqHU9ksDeT9u8cEF68495rJy85zEgAbdq152hAH6mauWM78jFGgMwHVTfhMjd4opHQk_gW8DXZcbguU6X8ArbhsQc1ZJkVRtuf7XIypskWp5ppYPCV5PooX5Qu6F4NLSLT5n0sh_-rKjgQDdo8KXJOjWhkwnAUwC8jhAJ-IUGyReW7GKnJe7xhSYx1Dv9LXM4HSf0FDMfytOz0HhaxYdGGKyCQOyQKUHbxIGILR8QvvmMvfDsGINymLt9ci2hjtZaM_OaTWsUS2Sqnge9PCrZpfeVrnBzHEm2Wx0TScYyvmSA-I9bkQmmEweog40D-1mMGu4mpMVTooxy4uoaJyT50ZnuuH58IPMc26a7DyREkokPrUdUuG91CRKIW9Koi2pJl2Qx9bQ7Ub8bPBW5lsPlr_f4CzlGUD_SxdjETdbGYv7q1flv_wkMJ08BEUb-SEkd5SD7z_Ei7mvYhmZPn9izz6okMxHxVs2N0PEh6Y6S9aBt4glLF2MqPghV-7bC4PCo7fAkL5U-yktHQwpa5tZ30K8HYAMBZSC7lZjsxqZQBxDo1X4tn3m30XGnYv9hb2mG8oESddm-QAtRGanxH21aeTWKPSDigU-M_hQf-qfc3JDtX-7GA3AGcYv28X3T3fTnc1dHQrZfXA906N5qbxN_lVnrhInPB0FS762uIdGHCi0mi-eGaemo3a1QhlrC6fas6MKe7R_7-lUbhVulhHmA03onv3ZjbWmYl-O1l_W8DvDATk8HP9Tyd3fxpkgwfUfCrqWHeYyWTm4X-GOI0JpBN_HHr7hOAaKw4ohbsxHUgveEfomqIrzzIq4DTR_pyxLoDwqfgAiVES783zSDFHN3zGFH3jftJqJM58V0Nob2oMR2xlbeOdnSNWF4crt5LxDNfZd9QYBToa1i4YziHq413wo18l6Fbbzpq2aZmnFBrquirzDj_Ehh6oMFFQMngNBIAnQux6PRw722QuXNCaLutZ1Vtcefg-AqyA../download\n",
      "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.24.200\n",
      "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.24.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 93166014 (89M) [application/octet-stream]\n",
      "Saving to: ‘./train.jsonl’\n",
      "\n",
      "./train.jsonl       100%[===================>]  88.85M  27.8MB/s    in 3.5s    \n",
      "\n",
      "2019-11-12 23:33:32 (25.2 MB/s) - ‘./train.jsonl’ saved [93166014/93166014]\n",
      "\n",
      "--2019-11-12 23:33:33--  https://nyu.box.com/shared/static/eg4ivddtqib2hkf1k8rkxnmzmo0cq27p.jsonl\n",
      "Resolving nyu.box.com (nyu.box.com)... 107.152.27.197, 107.152.26.197\n",
      "Connecting to nyu.box.com (nyu.box.com)|107.152.27.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /public/static/eg4ivddtqib2hkf1k8rkxnmzmo0cq27p.jsonl [following]\n",
      "--2019-11-12 23:33:33--  https://nyu.box.com/public/static/eg4ivddtqib2hkf1k8rkxnmzmo0cq27p.jsonl\n",
      "Reusing existing connection to nyu.box.com:443.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://nyu.app.box.com/public/static/eg4ivddtqib2hkf1k8rkxnmzmo0cq27p.jsonl [following]\n",
      "--2019-11-12 23:33:33--  https://nyu.app.box.com/public/static/eg4ivddtqib2hkf1k8rkxnmzmo0cq27p.jsonl\n",
      "Resolving nyu.app.box.com (nyu.app.box.com)... 107.152.26.199, 107.152.27.199\n",
      "Connecting to nyu.app.box.com (nyu.app.box.com)|107.152.26.199|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://public.boxcloud.com/d/1/b1!GRzkLHTjmYXf683KiaYH7TfaCD0J6n0wv2jmMgrJI_wBayRS27b02qHJYczhJUahhYFaUc5kI5vvsC1S4JHVkafkRgyX2uNesInWz__aavHas9OmqwevOxUzfWM7EPPx4IQlvEfugtIYSpe1wDNaJp7TwbW_U4EWFvbLoGR7HH1Y4HZ_aaD0Qqjm3Sq7nehUqVilxnPGOlnPZV42xBIQvmD-AUOnWsf_qXE_dJ21t-Cd5Lcfdg5CEqjBFqXCsf_9rPmZSP26Zxrdn3MtgPwJFeFtAFfYmXblwAgLaP2EUEmWvGgHf6Fm5QxS7Ukva363PaJT6E8mR9F0Yt53ulOUpQjk347HLqLzS2jmGnPwaCTQ1b24zOTvQ3sxMOhnS3r6ovtB2QoiVigpNAAI_QPwgfXomM2RqblJTOvkLxcjBMhVNGBky-WpVOPWwQJ-Lt5TpncCrKBhvTQxcKrlgENwANVN3jC9e2k4ujTwx01NnHTZtmcT_IRZOFRtryRW8AaZKejnUIHPwdj4VARmJ5yjtfn4Rqk_IlQps3DJzs71E4qeqUvoQil0JUzLMeWsFUowpC0fnaMuVdoS7eobe6cLKLLopmcZQy3zaTE68kBejiQDYV15WhObPsocHj0Ok3dZruTL6Ok8ppseFPNY3oSlE6GGA8gLGCSz8-Qi0JM5pMkBx1c_l0FHYS5tsKPbcCh1AZe-BcqjNahCxCKA6Al-yb_OBHou6kK91NGSrGzqGwepXegw3U91ud3OQTVqdMhcwWqCdZTBQHhStQdUWx6udYaEsOa1Xi5tC_7lBJtc5ZvHWThu6KSpi_EqCiht6fhN6P1hgXJf6WsrWxjD52yic2sCfjc7soVOWWiBfZQSFiJ6FYLBejyeYPrWcToUx2hLMWcc6DUW0QhbFQGyvX1J002e0Ze-S4SANKOMcxlHAFh1t6bxg8ESgiYzRpRVhGmfxn3dkpxPFg-Bd2KRo2bnXpiWl2x0Ez9nkYWtWkeC0AZxq-kpi3pD74sgVn0ccGk6YunsBmWhEVOu3CnPaJnlLW99ffzWz1YCs32N55qQxeKtsbqnR5hg-_UcD4zSnnM1QH6oFSiWd_Cb7c1bnjQLza756_MSvIMBijjYIVaQHLBdjUhZxaEXw1sFMolF8HvGHxV9LwyMx3hu0__xGswQoqb-IrsS_8-B0pwjujmfGtQoPIGwkuZ-sl8AZxkLv9gVYflba01wU44zYqWFJlxMfTyCP-zw1btVuJ-B-Bg0iE3Ay8cQAdgU1WwyPfeuAdJV-EWmflvg365e8U982LeemQ1SR0SQrGy3t8Ubzw9o8dUvV3QubxPDHVcgUq7pX9Fl8GrN4182FIw_0rYLAQyc_MWb-7646YrndkCqIZ5y--YBRcPnpAuFveMofg../download [following]\n",
      "--2019-11-12 23:33:34--  https://public.boxcloud.com/d/1/b1!GRzkLHTjmYXf683KiaYH7TfaCD0J6n0wv2jmMgrJI_wBayRS27b02qHJYczhJUahhYFaUc5kI5vvsC1S4JHVkafkRgyX2uNesInWz__aavHas9OmqwevOxUzfWM7EPPx4IQlvEfugtIYSpe1wDNaJp7TwbW_U4EWFvbLoGR7HH1Y4HZ_aaD0Qqjm3Sq7nehUqVilxnPGOlnPZV42xBIQvmD-AUOnWsf_qXE_dJ21t-Cd5Lcfdg5CEqjBFqXCsf_9rPmZSP26Zxrdn3MtgPwJFeFtAFfYmXblwAgLaP2EUEmWvGgHf6Fm5QxS7Ukva363PaJT6E8mR9F0Yt53ulOUpQjk347HLqLzS2jmGnPwaCTQ1b24zOTvQ3sxMOhnS3r6ovtB2QoiVigpNAAI_QPwgfXomM2RqblJTOvkLxcjBMhVNGBky-WpVOPWwQJ-Lt5TpncCrKBhvTQxcKrlgENwANVN3jC9e2k4ujTwx01NnHTZtmcT_IRZOFRtryRW8AaZKejnUIHPwdj4VARmJ5yjtfn4Rqk_IlQps3DJzs71E4qeqUvoQil0JUzLMeWsFUowpC0fnaMuVdoS7eobe6cLKLLopmcZQy3zaTE68kBejiQDYV15WhObPsocHj0Ok3dZruTL6Ok8ppseFPNY3oSlE6GGA8gLGCSz8-Qi0JM5pMkBx1c_l0FHYS5tsKPbcCh1AZe-BcqjNahCxCKA6Al-yb_OBHou6kK91NGSrGzqGwepXegw3U91ud3OQTVqdMhcwWqCdZTBQHhStQdUWx6udYaEsOa1Xi5tC_7lBJtc5ZvHWThu6KSpi_EqCiht6fhN6P1hgXJf6WsrWxjD52yic2sCfjc7soVOWWiBfZQSFiJ6FYLBejyeYPrWcToUx2hLMWcc6DUW0QhbFQGyvX1J002e0Ze-S4SANKOMcxlHAFh1t6bxg8ESgiYzRpRVhGmfxn3dkpxPFg-Bd2KRo2bnXpiWl2x0Ez9nkYWtWkeC0AZxq-kpi3pD74sgVn0ccGk6YunsBmWhEVOu3CnPaJnlLW99ffzWz1YCs32N55qQxeKtsbqnR5hg-_UcD4zSnnM1QH6oFSiWd_Cb7c1bnjQLza756_MSvIMBijjYIVaQHLBdjUhZxaEXw1sFMolF8HvGHxV9LwyMx3hu0__xGswQoqb-IrsS_8-B0pwjujmfGtQoPIGwkuZ-sl8AZxkLv9gVYflba01wU44zYqWFJlxMfTyCP-zw1btVuJ-B-Bg0iE3Ay8cQAdgU1WwyPfeuAdJV-EWmflvg365e8U982LeemQ1SR0SQrGy3t8Ubzw9o8dUvV3QubxPDHVcgUq7pX9Fl8GrN4182FIw_0rYLAQyc_MWb-7646YrndkCqIZ5y--YBRcPnpAuFveMofg../download\n",
      "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.24.200\n",
      "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.24.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6044784 (5.8M) [application/octet-stream]\n",
      "Saving to: ‘./valid.jsonl’\n",
      "\n",
      "./valid.jsonl       100%[===================>]   5.76M  9.20MB/s    in 0.6s    \n",
      "\n",
      "2019-11-12 23:33:35 (9.20 MB/s) - ‘./valid.jsonl’ saved [6044784/6044784]\n",
      "\n",
      "--2019-11-12 23:33:36--  https://nyu.box.com/shared/static/24zsynuks8nzg7530tgakzh8o62id9xa.pt\n",
      "Resolving nyu.box.com (nyu.box.com)... 107.152.27.197, 107.152.26.197\n",
      "Connecting to nyu.box.com (nyu.box.com)|107.152.27.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /public/static/24zsynuks8nzg7530tgakzh8o62id9xa.pt [following]\n",
      "--2019-11-12 23:33:36--  https://nyu.box.com/public/static/24zsynuks8nzg7530tgakzh8o62id9xa.pt\n",
      "Reusing existing connection to nyu.box.com:443.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://nyu.app.box.com/public/static/24zsynuks8nzg7530tgakzh8o62id9xa.pt [following]\n",
      "--2019-11-12 23:33:36--  https://nyu.app.box.com/public/static/24zsynuks8nzg7530tgakzh8o62id9xa.pt\n",
      "Resolving nyu.app.box.com (nyu.app.box.com)... 107.152.26.199, 107.152.27.199\n",
      "Connecting to nyu.app.box.com (nyu.app.box.com)|107.152.26.199|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://public.boxcloud.com/d/1/b1!Vyi0YBIIZTEu7j7fsCGyUfX3yifLjvmJAiJYb20sNUBiBQaSRlqwKN1Kuf8MPJpyb35CicxFFMvYDMoi5USkuvdikCgQQjpuIKZH_ZhnrFcbDf85_ZQV1j0ORij8nWmoNFWMSgB_Q5j7eHXo3-irHvfD_S0kbL3gatQvITkB74uWmdy08kVbbtOAim5FNqomwvmWsonKyO-7krFFbXEZWMeVMV7S-b_Cead6UvTuOyaaaZlan3Tb7byRkmQNSZMYZDTere8FVUIk6mm89C1Kg44ffsq6mfnn6Z4fiaZjqu92JpA988_ED1PUcqZ0z5ZZAEHKJDMhHNnlo36MKt4h6pfV-21l_6tjn0exkM5O8zUcLMiwQEckzIWwQV7o7kByf6CmpgEYsO4Cpd_DR5uOeCt0qyqWfZXGfN3e8yHwwGPc7OVMYF8fwHwabgc5IZuirxxRN6PjX8c_dL0N4DmlENNsjLEIElXBBG85alhP-3deTBqFehtpQr3ilkwL2lFF6TKka5ONGwlKf_FCkS8d-dZ52iFjhh0WXlPphp0oO0aiQKZCY11vKVZ88FwTJtdPVGZn3IUGxMxn8g067Ir74sCgVNRZNggozDH_ezb3eQsZQHNZo5cAaxVg7NnCxtiCp1o0P7aKcAMjD5t_yG1svUcHxKCHC7H8TLSraeBz9Js52H046oBj59cTxg75kMyQu_3Ok8j5om4zZigZFZXP54s5xAeVUBfDEiQ2fJlMs9_go3EUOES6wZCW4vzj9DPFHTNXWNHS9-nlitK7umkYqXaSWG7gKBDEVLiU8sPPgFK6sGZkC9kgeCAcrOpSLJF4Ov08-pYo2I52wVnOCYQX6u_gZ-jTXO5lQZ56GLgKHVyVi0iVYNQH4xFDm-KPi0RWDw7tJJWCN3uSmXb3w2ibiXSGioFBXpZ4Y0zO-kIa3gveLgqtAQNbNvOi-LkBsO_i9xOObOz2OUTIJHJtbfaGSwse6KBY26qi0ve7pQh30DnHzUV6IVb50sDtCDa9-4ePtztLrHUC4Is3cpP_LvadeE0NW7UUnG1K8g1sSl6b0kTyJo_AVwdAq-o75D8vE74F_2MUBhZo3QYRGrUcFoGKtilcKbeZf4eUfGJvyr7zxFc4uCcmcbaZb4JB-B4jOxWZhzr0GMdXstFBPnfIkX7azud_mWmmOyO87Z-D1uLkTORZxCKL3z8GVmwlPd2oynH8idwEw0SirTPKqd1xPP5L7myxusPP6WTpPNcrsFjpbSioCptiYW3zpUgw7JfEmI_bOR0zjQ0xAxl3p9QW7kFa0hzU81B3XorZManQOSSdvPHj18Y_u2pr-j9kAG8HnRtGnxhQ00nrxsCf4iyUXVP0TVXxcNjXg7EOKflZrWYr3E1L7LRGdf2lUq_VvP_w1U0XS11druo./download [following]\n",
      "--2019-11-12 23:33:37--  https://public.boxcloud.com/d/1/b1!Vyi0YBIIZTEu7j7fsCGyUfX3yifLjvmJAiJYb20sNUBiBQaSRlqwKN1Kuf8MPJpyb35CicxFFMvYDMoi5USkuvdikCgQQjpuIKZH_ZhnrFcbDf85_ZQV1j0ORij8nWmoNFWMSgB_Q5j7eHXo3-irHvfD_S0kbL3gatQvITkB74uWmdy08kVbbtOAim5FNqomwvmWsonKyO-7krFFbXEZWMeVMV7S-b_Cead6UvTuOyaaaZlan3Tb7byRkmQNSZMYZDTere8FVUIk6mm89C1Kg44ffsq6mfnn6Z4fiaZjqu92JpA988_ED1PUcqZ0z5ZZAEHKJDMhHNnlo36MKt4h6pfV-21l_6tjn0exkM5O8zUcLMiwQEckzIWwQV7o7kByf6CmpgEYsO4Cpd_DR5uOeCt0qyqWfZXGfN3e8yHwwGPc7OVMYF8fwHwabgc5IZuirxxRN6PjX8c_dL0N4DmlENNsjLEIElXBBG85alhP-3deTBqFehtpQr3ilkwL2lFF6TKka5ONGwlKf_FCkS8d-dZ52iFjhh0WXlPphp0oO0aiQKZCY11vKVZ88FwTJtdPVGZn3IUGxMxn8g067Ir74sCgVNRZNggozDH_ezb3eQsZQHNZo5cAaxVg7NnCxtiCp1o0P7aKcAMjD5t_yG1svUcHxKCHC7H8TLSraeBz9Js52H046oBj59cTxg75kMyQu_3Ok8j5om4zZigZFZXP54s5xAeVUBfDEiQ2fJlMs9_go3EUOES6wZCW4vzj9DPFHTNXWNHS9-nlitK7umkYqXaSWG7gKBDEVLiU8sPPgFK6sGZkC9kgeCAcrOpSLJF4Ov08-pYo2I52wVnOCYQX6u_gZ-jTXO5lQZ56GLgKHVyVi0iVYNQH4xFDm-KPi0RWDw7tJJWCN3uSmXb3w2ibiXSGioFBXpZ4Y0zO-kIa3gveLgqtAQNbNvOi-LkBsO_i9xOObOz2OUTIJHJtbfaGSwse6KBY26qi0ve7pQh30DnHzUV6IVb50sDtCDa9-4ePtztLrHUC4Is3cpP_LvadeE0NW7UUnG1K8g1sSl6b0kTyJo_AVwdAq-o75D8vE74F_2MUBhZo3QYRGrUcFoGKtilcKbeZf4eUfGJvyr7zxFc4uCcmcbaZb4JB-B4jOxWZhzr0GMdXstFBPnfIkX7azud_mWmmOyO87Z-D1uLkTORZxCKL3z8GVmwlPd2oynH8idwEw0SirTPKqd1xPP5L7myxusPP6WTpPNcrsFjpbSioCptiYW3zpUgw7JfEmI_bOR0zjQ0xAxl3p9QW7kFa0hzU81B3XorZManQOSSdvPHj18Y_u2pr-j9kAG8HnRtGnxhQ00nrxsCf4iyUXVP0TVXxcNjXg7EOKflZrWYr3E1L7LRGdf2lUq_VvP_w1U0XS11druo./download\n",
      "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.24.200\n",
      "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.24.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 69267718 (66M) [application/octet-stream]\n",
      "Saving to: ‘./chat_model_best_22.pt’\n",
      "\n",
      "./chat_model_best_2 100%[===================>]  66.06M  18.8MB/s    in 3.9s    \n",
      "\n",
      "2019-11-12 23:33:41 (17.1 MB/s) - ‘./chat_model_best_22.pt’ saved [69267718/69267718]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131438/131438 [00:16<00:00, 8026.46it/s]\n",
      "100%|██████████| 7801/7801 [00:00<00:00, 8771.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading datasets and dictionary\n",
    "\n",
    "# downloading pretrained models and data\n",
    "\n",
    "### DOWNLOADING THE FILES\n",
    "import os\n",
    "\n",
    "### persona chat dataset\n",
    "if not os.path.exists('./dict'):\n",
    "    !wget \"https://nyu.box.com/shared/static/sj9f87tofpicll89xbc154pmbztu5q4h\" -O './dict'\n",
    "if not os.path.exists('./train.jsonl'):\n",
    "    !wget \"https://nyu.box.com/shared/static/aqp0jyjaixjmukm5asasivq2bcfze075.jsonl\" -O './train.jsonl'\n",
    "if not os.path.exists('./valid.jsonl'):\n",
    "    !wget \"https://nyu.box.com/shared/static/eg4ivddtqib2hkf1k8rkxnmzmo0cq27p.jsonl\" -O './valid.jsonl'\n",
    "\n",
    "if not os.path.exists('./chat_model_best_22.pt'):\n",
    "    !wget \"https://nyu.box.com/shared/static/24zsynuks8nzg7530tgakzh8o62id9xa.pt\" -O './chat_model_best_22.pt'\n",
    "\n",
    "chat_dict = ChatDictionary('./dict')\n",
    "train_dataset = ChatDataset('./train.jsonl', chat_dict)\n",
    "valid_dataset = ChatDataset('./valid.jsonl', chat_dict, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBMylZprbgo1"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, collate_fn=batchify, batch_size=256)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, collate_fn=batchify, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efLrBG9zdHW0"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"Encodes the input context.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, pad_idx=0, dropout=0, shared_lt=None):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        if shared_lt is None:\n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.embed_size, pad_idx)\n",
    "        else:\n",
    "            self.embedding = shared_lt\n",
    "            \n",
    "        self.gru = nn.GRU(\n",
    "            self.embed_size, self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, text_vec, text_lens, hidden=None, use_packed=True):\n",
    "        embedded = self.embedding(text_vec)\n",
    "        attention_mask = text_vec.ne(self.pad_idx) # ne function calculates not equal to element-wise\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "        if use_packed is True:\n",
    "            embedded = pack_padded_sequence(embedded, text_lens, batch_first=True)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        if use_packed is True:\n",
    "            output, output_lens = pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        return output, hidden, attention_mask\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"Generates a sequence of tokens in response to context.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout=0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size, 0)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            self.embed_size, self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0,\n",
    "        )\n",
    "        \n",
    "        self.attention = AttentionLayer(self.hidden_size, self.embed_size)\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        self.longest_label = 100\n",
    "\n",
    "    def forward(self, text_vec, decoder_hidden, encoder_states):\n",
    "        emb = self.embedding(text_vec)\n",
    "        emb = self.dropout(emb)\n",
    "        seqlen = text_vec.size(1)\n",
    "        encoder_output, encoder_hidden, attention_mask = encoder_states\n",
    "        \n",
    "        decoder_hidden = decoder_hidden\n",
    "        output = []\n",
    "        attn_w_log = []\n",
    "\n",
    "        for i in range(seqlen):\n",
    "            decoder_output, decoder_hidden = self.gru(emb[:,i,:].unsqueeze(1), decoder_hidden)\n",
    "            \n",
    "            # compute attention at each time step\n",
    "            decoder_output_attended, attn_weights = self.attention(decoder_output, decoder_hidden, encoder_output, attention_mask)\n",
    "            output.append(decoder_output_attended)\n",
    "            attn_w_log.append(attn_weights)\n",
    "            \n",
    "        output = torch.cat(output, dim=1).to(text_vec.device)\n",
    "        scores = self.out(output)\n",
    "        \n",
    "        return scores, decoder_hidden, attn_w_log\n",
    "    \n",
    "    def decode_forced(self, ys, encoder_states, xs_lens):\n",
    "        encoder_output, encoder_hidden, attention_mask = encoder_states\n",
    "        \n",
    "        batch_size = ys.size(0)\n",
    "        target_length = ys.size(1)\n",
    "        longest_label = max(target_length, self.longest_label)\n",
    "        \n",
    "        starts = torch.Tensor([1]).long().to(self.embedding.weight.device).expand(batch_size, 1).long()  # expand to batch size\n",
    "        \n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        y_in = ys.narrow(1, 0, ys.size(1) - 1)\n",
    "        decoder_input = torch.cat([starts, y_in], 1)\n",
    "        decoder_output, decoder_hidden, attn_w_log = self.forward(decoder_input, encoder_hidden, encoder_states)\n",
    "        _, preds = decoder_output.max(dim=2)\n",
    "        \n",
    "        return decoder_output, preds, attn_w_log\n",
    "    \n",
    "    \n",
    "class AttentionLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, embedding_size):\n",
    "        super().__init__()\n",
    "        input_dim = hidden_size\n",
    "\n",
    "        self.linear_out = nn.Linear(hidden_size+input_dim, input_dim, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, decoder_output, decoder_hidden, encoder_output, attention_mask):\n",
    "\n",
    "        batch_size, seq_length, hidden_size = encoder_output.size()\n",
    "\n",
    "        encoder_output_t = encoder_output.transpose(1,2)\n",
    "        \n",
    "        attention_scores = torch.bmm(decoder_output, encoder_output_t).squeeze(1)\n",
    "\n",
    "        attention_scores.masked_fill_((~attention_mask), -10e5)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "\n",
    "        mix = torch.bmm(attention_weights.unsqueeze(1), encoder_output)\n",
    "\n",
    "        combined = torch.cat((decoder_output.squeeze(1), mix.squeeze(1)), dim=1)\n",
    "\n",
    "        output = self.linear_out(combined).unsqueeze(1)\n",
    "        output = self.tanh(output)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "    \n",
    "class seq2seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic seq2seq model with attention mechanism.\n",
    "    \"\"\"\n",
    "    def __init__(self, opts):\n",
    "\n",
    "        super().__init__()\n",
    "        self.opts = opts\n",
    "        \n",
    "        self.decoder = DecoderRNN(\n",
    "                                    vocab_size=self.opts['vocab_size'],\n",
    "                                    embed_size=self.opts['embedding_size'],\n",
    "                                    hidden_size=self.opts['hidden_size'],\n",
    "                                    num_layers=self.opts['num_layers_dec'],\n",
    "                                    dropout=self.opts['dropout'],\n",
    "                                )\n",
    "        \n",
    "        self.encoder = EncoderRNN(\n",
    "                                    vocab_size=self.opts['vocab_size'],\n",
    "                                    embed_size=self.opts['embedding_size'],\n",
    "                                    hidden_size=self.opts['hidden_size'],\n",
    "                                    num_layers=self.opts['num_layers_enc'],\n",
    "                                    dropout=self.opts['dropout'],\n",
    "                                    shared_lt=self.decoder.embedding\n",
    "        )\n",
    "        \n",
    "    def train(self):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        \n",
    "    def eval(self):\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-gh2sDSbkYD"
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "\n",
    "load_pretrained = True\n",
    "    \n",
    "if load_pretrained is True:\n",
    "    if current_device == 'cuda':\n",
    "        model_pt = torch.load('./chat_model_best_22.pt')\n",
    "    else:\n",
    "        model_pt = torch.load('./chat_model_best_22.pt', map_location=torch.device('cpu'))\n",
    "    opts = model_pt['opts']\n",
    "    \n",
    "    model = seq2seq(opts)\n",
    "    model.load_state_dict(model_pt['state_dict'])\n",
    "    model.to(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJwxLf6lfeTg"
   },
   "outputs": [],
   "source": [
    "# implement nucleus sampling here.\n",
    "# you must cite any code you use from other sources!\n",
    "import numpy as np\n",
    "\n",
    "def nucleus_sampling(model, batch, batch_size, prob_thre):\n",
    "    \"\"\"\n",
    "    batch: the input batch which we want to sample the output on\n",
    "    batch_size: the relative batch size\n",
    "    prob_thre: the probability threshold to choose top p next token\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        text_vecs = batch['text_vecs'].to(current_device)\n",
    "        encoded = model.encoder(text_vecs, batch['text_lens'], use_packed=batch['use_packed'])\n",
    "        encoder_output, encoder_hidden, attention_mask = encoded\n",
    "\n",
    "        # First define __start__ as the starting point of our sampling\n",
    "        starts = torch.Tensor([1]).long().to(model.decoder.embedding.weight.device).expand(batch_size, 1).long()  # expand to batch size\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Start sampling\n",
    "        samp = [starts]\n",
    "        probs_selecting = []\n",
    "\n",
    "        # We want to stop when every sequence has 2 as their ends (2 == __end__)\n",
    "        finish_mask = torch.Tensor([0]*batch_size).byte().to(model.decoder.embedding.weight.device)\n",
    "        current_sequences = starts\n",
    "        _attn_w_log = []\n",
    "\n",
    "        def find_indices(sorted_prob, prob_thre): \n",
    "            # Given a sorted probs, return the number of probs and sum of probs that could add up to >= threshold     \n",
    "            sum_now = 0\n",
    "            count = 0\n",
    "            while sum_now < prob_thre:\n",
    "                sum_now += sorted_prob[count].item()\n",
    "                count += 1\n",
    "            return count, sum_now\n",
    "\n",
    "        for time_step in range(1000):\n",
    "            decoder_output, decoder_hidden, attn_w_log = model.decoder(current_sequences, decoder_hidden, encoded)\n",
    "            all_probs = torch.softmax(decoder_output, dim=-1)\n",
    "            new_samp_all = []\n",
    "            new_prob_list = []\n",
    "            for i in range(batch_size):\n",
    "                single_next = all_probs[i, :, :].squeeze()\n",
    "                _probs, _indices = torch.sort(single_next, descending=True)\n",
    "                count, sum_p = find_indices(_probs, prob_thre)\n",
    "                new_probs = _probs[:count] / sum_p\n",
    "                _indices = _indices[:count]\n",
    "                # Now sample an index from the new conditional distribution\n",
    "                new_pred = _indices[torch.multinomial(new_probs, 1)].view(-1, 1).long()\n",
    "                prob_for_this_token = _probs[new_pred.item()].view(-1, 1)\n",
    "                #new_pred = torch.Tensor([np.random.choice(_indices, p = _probs)]).view(-1, 1).long()\n",
    "                new_samp_all.append(new_pred)\n",
    "                new_prob_list.append(prob_for_this_token)\n",
    "\n",
    "            _samp = torch.cat(new_samp_all, dim=1).to(model.decoder.embedding.weight.device)\n",
    "            prob_batch = torch.cat(new_prob_list, dim=1).to(model.decoder.embedding.weight.device)\n",
    "            samp.append(_samp)\n",
    "            probs_selecting.append(prob_batch)\n",
    "            _attn_w_log.append(attn_w_log)\n",
    "\n",
    "            finish_mask += (_samp == 2).byte().view(-1)\n",
    "            \n",
    "            if not (torch.any(~finish_mask.bool())): # ~ is invert\n",
    "                break\n",
    "            \n",
    "            current_sequences = _samp\n",
    "        \n",
    "        samp = torch.cat(samp, dim=-1)\n",
    "        probs_selecting = torch.cat(probs_selecting, dim=-1)\n",
    "            \n",
    "    return samp, probs_selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1573601935583,
     "user": {
      "displayName": "Xiao Li",
      "photoUrl": "",
      "userId": "17628369663427228897"
     },
     "user_tz": 300
    },
    "id": "SpkzyUlbxn-Q",
    "outputId": "1d415474-acc2-453b-b3fe-8d309f8a7260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__start__ i am from california , where are you from ? __end__\n",
      "-7.423248277044979\n"
     ]
    }
   ],
   "source": [
    "# A test run\n",
    "inputs = RETOK.findall(\"your persona: i live in texas.\\n hello , where are you ? ?\")\n",
    "\n",
    "test_batch = {\n",
    "    'text_vecs': torch.tensor([chat_dict.t2v(inputs)], dtype=torch.long, device=model.decoder.embedding.weight.device),\n",
    "    'text_lens': torch.tensor([len(inputs)], dtype=torch.long),\n",
    "    'use_packed': True,\n",
    "}\n",
    "\n",
    "sample, probs = nucleus_sampling(model, test_batch, 1, 0.1)#.tolist()\n",
    "print(chat_dict.v2t(*sample.tolist()))\n",
    "print(np.average(np.log(probs.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N03fFFhOfeTi"
   },
   "source": [
    "## You present here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36564,
     "status": "ok",
     "timestamp": 1573591755797,
     "user": {
      "displayName": "Xiao Li",
      "photoUrl": "",
      "userId": "17628369663427228897"
     },
     "user_tz": 300
    },
    "id": "athOySwpfeTj",
    "outputId": "2ad872b4-2018-4ad2-a024-a6945599763e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input is: your persona : i read twenty books a year . \n",
      " your persona : i ' m a stunt double as my second job . \n",
      " your persona : i only eat __unk__ . \n",
      " your persona : i was raised in a single parent household . \n",
      " hello what are doing today ?\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Section 2.1\n",
    "# Q2 and Q3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "number_decodings = 100\n",
    "prob_thre_list = [0.1, 0.5, 0.9]\n",
    "# Selecting a single input from the validation set\n",
    "index = 0\n",
    "valid_input = valid_dataset[index][0]\n",
    "print(f\"Our input is: {chat_dict.v2t(valid_input.tolist())}\")\n",
    "test_input = {\n",
    "    'text_vecs': valid_input.view(1, -1).to(model.decoder.embedding.weight.device),\n",
    "    'text_lens': torch.tensor([len(valid_input)], dtype=torch.long),\n",
    "    'use_packed': True,\n",
    "}\n",
    "\n",
    "# Compute the average log-probability of generated sequences for each value of prob_thre\n",
    "# Also store the samples\n",
    "log_p_dict = {}\n",
    "all_samples = {}\n",
    "for thre in prob_thre_list:\n",
    "    log_p_dict[thre] = []\n",
    "    all_samples[thre] = []\n",
    "    for i in range(number_decodings):\n",
    "        sample, probs = nucleus_sampling(model, test_input, 1, thre)\n",
    "        # Store the sample\n",
    "        all_samples[thre].append(*sample.tolist())\n",
    "        # Compute log_p and add them up\n",
    "        log_p_total = torch.mean(torch.log(probs))\n",
    "        log_p_dict[thre].append(log_p_total)\n",
    "\n",
    "avg_log_p = [np.mean(log_p_dict[i]) for i in log_p_dict]\n",
    "plt.plot(prob_thre_list, avg_log_p)\n",
    "plt.title(\"Average Log Probability vs. Probability threshold\")\n",
    "plt.xticks([0.1, 0.5, 0.9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1573591840279,
     "user": {
      "displayName": "Xiao Li",
      "photoUrl": "",
      "userId": "17628369663427228897"
     },
     "user_tz": 300
    },
    "id": "U8W1aCZHfeTl",
    "outputId": "86bb9e72-b411-4537-df5e-8d9d621a20e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAL9f9r9aI5Cfj14AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q3's plot\n",
    "unique_token_count = []\n",
    "for thre in all_samples:\n",
    "    all_tokens = []\n",
    "    [all_tokens.extend(l) for l in all_samples[thre]]\n",
    "    unique_token_count.append(len(set(all_tokens)))\n",
    "\n",
    "# Plot\n",
    "plt.plot(prob_thre_list, unique_token_count)\n",
    "plt.title(\"Unique tokens count for different prob. threshold\")\n",
    "plt.xticks([0.1, 0.5, 0.9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iu4RgTJbfeTn"
   },
   "source": [
    "## 2.2 N-Gram blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grYLFlVUfeTo",
    "outputId": "d3feb183-83f8-433e-9692-61a36fe448b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# implement n-gram blocking\n",
    "# carefully read instructions in pdf\n",
    "\n",
    "# we give you some small hint code here which can be helpful\n",
    "\n",
    "l = [1,2,3,4,5,6,4,5,6]\n",
    "\n",
    "history = tuple(l[-2:])\n",
    "\n",
    "print(history)\n",
    "\n",
    "banned = []\n",
    "\n",
    "for ngram in zip(*[l[i:] for i in range(3)]):\n",
    "    if ngram[:-1] == history:\n",
    "        banned.append(ngram[-1])\n",
    "        \n",
    "print(banned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LojppHLhfeTr"
   },
   "source": [
    "## You present here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNG0agwffeTr"
   },
   "outputs": [],
   "source": [
    "# check pdf to see what you expected to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-FKFRKyfeTt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezklc-zwfeTv"
   },
   "source": [
    "# Part 3 Interactive chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8t1J0lkfeTy"
   },
   "outputs": [],
   "source": [
    "# implement logic for interactive chat here\n",
    "# the easiest is to just use python input functionality\n",
    "\n",
    "def transfer(input):\n",
    "    # Transfer an input to a tensor\n",
    "    _inp_tokened = RETOK.findall(input)\n",
    "    _inp_tokened_id = chat_dict.t2v(_inp_tokened)\n",
    "    tensor_input = torch.tensor(_inp_tokened_id, dtype=torch.long)\n",
    "    return tensor_input\n",
    "\n",
    "def make_it_batch(model, input_tensor):\n",
    "    # Make a input tensor a batch\n",
    "    device_now = model.decoder.embedding.weight.device\n",
    "    return {\n",
    "        'text_vecs': input_tensor.view(1, -1).to(device_now),\n",
    "        'text_lens': torch.tensor([len(input_tensor)], dtype=torch.long),\n",
    "        'use_packed': True}\n",
    "\n",
    "def logging(chat_history):\n",
    "    print(\"\\n\")\n",
    "    print(\"Here's the full dialog history\")\n",
    "    print(chat_dict.v2t(chat_history.tolist()))\n",
    "    return None\n",
    "\n",
    "# Now we start to implement chat function\n",
    "def chat(model, chat_history, start = True):\n",
    "    new_input = input(\"What do you want to say next\\n\")\n",
    "    if new_input == \"\": # If the user don't want to continue the chat\n",
    "        logging(chat_history)\n",
    "        return None\n",
    "    else:\n",
    "        if start:\n",
    "            chat_history = transfer(chat_history)\n",
    "        new_line_id = torch.tensor(chat_dict.t2v([\"\\n\"]), dtype=torch.long)\n",
    "        # Add user's input to chat history\n",
    "        # TODO\n",
    "        chat_history = torch.cat([chat_history, new_line_id, transfer(new_input)])\n",
    "        # Now do the sampling\n",
    "        input_for_samp = make_it_batch(model, chat_history)\n",
    "        output, probs = nucleus_sampling(model, input_for_samp, 1, 0.5)\n",
    "        output = output.squeeze()[1:-1]\n",
    "        print(f\"The model says: {chat_dict.v2t(output.tolist())} \\n\")\n",
    "        new_chat = torch.cat([chat_history, new_line_id, output])\n",
    "        return chat(model, new_chat, start = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rK0ryIsXfeT0"
   },
   "source": [
    "## You present here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 111113,
     "status": "ok",
     "timestamp": 1573602192619,
     "user": {
      "displayName": "Xiao Li",
      "photoUrl": "",
      "userId": "17628369663427228897"
     },
     "user_tz": 300
    },
    "id": "MFSRxmAXamsQ",
    "outputId": "21c1e134-db8d-4302-d9a4-f21971973e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to say next\n",
      "hi, where do you live?\n",
      "The model says: i live in the mountains so i ' m a country trainer \n",
      "\n",
      "What do you want to say next\n",
      "do you like climb mountains?\n",
      "The model says: i do not . i am not sure about them \n",
      "\n",
      "What do you want to say next\n",
      "where are you from?\n",
      "The model says: i am from new york city \n",
      "\n",
      "What do you want to say next\n",
      "how many children do you have?\n",
      "The model says: i have three kids , and you ? \n",
      "\n",
      "What do you want to say next\n",
      "I do not have any kids. do you like school?\n",
      "The model says: i do . what do you do for a living ? \n",
      "\n",
      "What do you want to say next\n",
      "i drive cars. do you like cars?\n",
      "The model says: i do . i ' m a huge fan of guns \n",
      "\n",
      "What do you want to say next\n",
      "\n",
      "\n",
      "\n",
      "Here's the full dialog history\n",
      "your persona : i love disneyland and mickey mouse . \n",
      " your persona : i love to spend time with my family . \n",
      " your persona : i ' m a baby delivery nurse . \n",
      " your persona : i walk three miles every day . \n",
      " \n",
      " hi , where do you live ? \n",
      " i live in the mountains so i ' m a country trainer \n",
      " do you like climb mountains ? \n",
      " i do not . i am not sure about them \n",
      " where are you from ? \n",
      " i am from new york city \n",
      " how many children do you have ? \n",
      " i have three kids , and you ? \n",
      " __unk__ do not have any kids . do you like school ? \n",
      " i do . what do you do for a living ? \n",
      " i drive cars . do you like cars ? \n",
      " i do . i ' m a huge fan of guns\n"
     ]
    }
   ],
   "source": [
    "# Dialogue sample\n",
    "# First pick a persona\n",
    "index = 20\n",
    "sample = valid_dataset[index][0]\n",
    "persona_list = chat_dict.v2t(sample.tolist()).split(\"\\n\")\n",
    "persona = \"\"\n",
    "for item in persona_list:\n",
    "    if \"your persona\" in item:\n",
    "        persona += item\n",
    "        persona += \"\\n\"\n",
    "\n",
    "# If we want to self input persona, uncooment next line        \n",
    "# persona = \"your persona: i am from china.\\nyour persona: i currently live in jersey.\\nyour persona: i come from a small town.\\nyour persona: my favorite drink is coke.\\nyour persona: i am very bad at homework.\"\n",
    "chat(model, persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89981,
     "status": "ok",
     "timestamp": 1573602325233,
     "user": {
      "displayName": "Xiao Li",
      "photoUrl": "",
      "userId": "17628369663427228897"
     },
     "user_tz": 300
    },
    "id": "lkwXHUVJfeT3",
    "outputId": "8be969f8-c750-455b-df18-d761659430a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your persona : i have two dogs . \n",
      " your persona : i like to work on vintage cars . \n",
      " your persona : my favorite music is country . \n",
      " your persona : i own two vintage mustangs . \n",
      "\n",
      "What do you want to say next\n",
      "how are you?\n",
      "The model says: i am good . just got back from my shift at a beach . \n",
      "\n",
      "What do you want to say next\n",
      "do you have any dogs?\n",
      "The model says: no , i am a dog person . \n",
      "\n",
      "What do you want to say next\n",
      "how many dogs do you have?\n",
      "The model says: i have a husky . we have a couple dogs . \n",
      "\n",
      "What do you want to say next\n",
      "do you like music?\n",
      "The model says: i like all music . i love to listen to rock music . \n",
      "\n",
      "What do you want to say next\n",
      "do you drive cars?\n",
      "The model says: i do . i have been everywhere . \n",
      "\n",
      "What do you want to say next\n",
      "do you have any vintage car?\n",
      "The model says: i have a job at a small town . \n",
      "\n",
      "What do you want to say next\n",
      "\n",
      "\n",
      "\n",
      "Here's the full dialog history\n",
      "your persona : i have two dogs . \n",
      " your persona : i like to work on vintage cars . \n",
      " your persona : my favorite music is country . \n",
      " your persona : i own two vintage mustangs . \n",
      " \n",
      " how are you ? \n",
      " i am good . just got back from my shift at a beach . \n",
      " do you have any dogs ? \n",
      " no , i am a dog person . \n",
      " how many dogs do you have ? \n",
      " i have a husky . we have a couple dogs . \n",
      " do you like music ? \n",
      " i like all music . i love to listen to rock music . \n",
      " do you drive cars ? \n",
      " i do . i have been everywhere . \n",
      " do you have any vintage car ? \n",
      " i have a job at a small town .\n"
     ]
    }
   ],
   "source": [
    "# Dialogue sample\n",
    "index = 12\n",
    "sample = valid_dataset[index][0]\n",
    "persona_list = chat_dict.v2t(sample.tolist()).split(\"\\n\")\n",
    "persona = \"\"\n",
    "for item in persona_list:\n",
    "    if \"your persona\" in item:\n",
    "        persona += item\n",
    "        persona += \"\\n\"\n",
    "print(persona)\n",
    "\n",
    "chat(model, persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89774,
     "status": "ok",
     "timestamp": 1573602433548,
     "user": {
      "displayName": "Xiao Li",
      "photoUrl": "",
      "userId": "17628369663427228897"
     },
     "user_tz": 300
    },
    "id": "-yrTqhAqAHqf",
    "outputId": "fc193c48-c497-44fa-94e9-88c5489de3f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your persona : i ' m a little girl . \n",
      " your persona : i ' ve superpowers . \n",
      " your persona : i like to make time stop . \n",
      " your persona : i live in the cloud . \n",
      "\n",
      "What do you want to say next\n",
      "how are you?\n",
      "The model says: i am doing good , thanks . how are you ? \n",
      "\n",
      "What do you want to say next\n",
      "i am ok. where do you live?\n",
      "The model says: i live in the suburbs . i love to surf . \n",
      "\n",
      "What do you want to say next\n",
      "are you boy or girl?\n",
      "The model says: i ' m not sure what that ' s . \n",
      "\n",
      "What do you want to say next\n",
      "do you like superpowers?\n",
      "The model says: yes , i ' ve not . i ' m very shy . \n",
      "\n",
      "What do you want to say next\n",
      "so you are a shy girl.\n",
      "The model says: yes , i am in high school . \n",
      "\n",
      "What do you want to say next\n",
      "do you have any hobby?\n",
      "The model says: no , i don ' t . i like to hike . \n",
      "\n",
      "What do you want to say next\n",
      "\n",
      "\n",
      "\n",
      "Here's the full dialog history\n",
      "your persona : i ' m a little girl . \n",
      " your persona : i ' ve superpowers . \n",
      " your persona : i like to make time stop . \n",
      " your persona : i live in the cloud . \n",
      " \n",
      " how are you ? \n",
      " i am doing good , thanks . how are you ? \n",
      " i am ok . where do you live ? \n",
      " i live in the suburbs . i love to surf . \n",
      " are you boy or girl ? \n",
      " i ' m not sure what that ' s . \n",
      " do you like superpowers ? \n",
      " yes , i ' ve not . i ' m very shy . \n",
      " so you are a shy girl . \n",
      " yes , i am in high school . \n",
      " do you have any hobby ? \n",
      " no , i don ' t . i like to hike .\n"
     ]
    }
   ],
   "source": [
    "# Dialogue sample\n",
    "index = 35\n",
    "sample = valid_dataset[index][0]\n",
    "persona_list = chat_dict.v2t(sample.tolist()).split(\"\\n\")\n",
    "persona = \"\"\n",
    "for item in persona_list:\n",
    "    if \"your persona\" in item:\n",
    "        persona += item\n",
    "        persona += \"\\n\"\n",
    "print(persona)\n",
    "\n",
    "chat(model, persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQfIzySYAjrh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
